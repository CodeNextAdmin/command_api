[
 {
   "command": "utmpdump",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# utmpdump\n\n> Dump and load btmp, utmp and wtmp accounting files.\n\n- Dump the `/var/log/wtmp` file to the standard output as plain text:\n\n`utmpdump {{/var/log/wtmp}}`\n\n- Load a previously dumped file into `/var/log/wtmp`:\n\n`utmpdump -r {{dumpfile}} > {{/var/log/wtmp}}`\n"
 },
 {
   "command": "cpufreq-info",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# cpufreq-info\n\n> A tool to show CPU frequency information.\n\n- Show CPU frequency information for all CPUs:\n\n`cpufreq-info`\n\n- Show CPU frequency information for the specified CPU:\n\n`cpufreq-info -c {{cpu_number}}`\n\n- Show the allowed minimum and maximum CPU frequency:\n\n`cpufreq-info -l`\n\n- Show the current minimum and maximum CPU frequency and policy in table format:\n\n`cpufreq-info -o`\n\n- Show available CPU frequency policies:\n\n`cpufreq-info -g`\n\n- Show current CPU work frequency in a human-readable format, according to the cpufreq kernel module:\n\n`cpufreq-info -f -m`\n\n- Show current CPU work frequency in a human-readable format, by reading it from hardware (only available to root):\n\n`sudo cpufreq-info -w -m`\n"
 },
 {
   "command": "pihole",
   "doc_url": "https://pi-hole.net",
   "doc_text": "\n\n\n\n\nPi-hole – A black hole for Internet advertisements\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\nSkip to content\n\n\n\n \n\nGitHub\n\nCore\nWeb\nFTL\nAPI\nDocker\n\n\nCommunity\n\nLog in with Discourse\nMy Account\nDiscourse\nReddit\nTwitter\n\n\nAbout\n\nDocumentation\nContact\nPrivacy\nTrademark Rules And Brand Guidelines\nDeveloping Apps For Pi-hole\n\n\nBlog\nDonate\n \n\n\n\n\n\n\n\n\nPi-hole® Network-wide Ad BlockingA black hole for Internet advertisementsInstallBecome A PatronDonate \n\n\n\n\n\n\n\n\n\n\n\n1. Install a supported operating system\nYou can run Pi-hole in a container, or deploy it directly to a supported operating system via our automated installer.\nDocker install\n\nSupported operating systems\n\n\n\n\n\n\n\n\n\n2. Install Pi-hole\nOur intelligent, automated installer asks you a few questions and then sets everything up for you.  Once complete, move onto step 3.\n Install Pi-hole \n\n\n\n\n\n\n\n\n\n3. Use Pi-hole as your DNS server\nConfigure your router’s DHCP options to force clients to use Pi-hole as their DNS server, or manually configure each device​ to use the Pi-hole as their DNS server.\nUse Pi-hole as your DNS server\n\n\n\n\n\n\n\n\n\n4. Block ads everywhere, even on the go\nBy pairing your Pi-hole with a VPN, you can have ad blocking on your cellular devices, helping with limited bandwidth data plans.\nPi-hole + VPN\n\n\n\n\n\n\n\n\n\n\nNetwork-wide protection\nInstead of browser plugins or other software on each computer, install Pi-hole in one place and your entire network is protected.\n\n\n\nBlock in-app advertisements\nNetwork-level blocking allows you to block ads in non-traditional places such as mobile apps and smart TVs, regardless of hardware or OS.\n\n\n\nImprove network performance\nSince advertisements are blocked before they are downloaded, network performance is improved and will feel faster.\n\n\n\nMonitor statistics\nOur Web interface offers control of your Pi-hole and a central place to view statistics.  We also include an API for extending these stats.\n\n\n\n\n\n\n\n\nPi-hole is free, but powered by your donations.\n\nDonate\n\n\n\n\n\n\n\nWeb Interface\nIn addition to blocking advertisements, Pi-hole has an informative Web interface that shows stats on all the domains being queried on your network.\n\n\n\n\n\n\n\n\n\nBuilt-in DHCP Server\nPi-hole works fine with an existing DHCP server, but you can use Pi-hole’s to keep your network management in one place.\n\n\n\n\n\n\n\n\n\nManage White And Black Lists\nFine tune your experience by blacklisting or whitlisting domains.  Extend this capability with powerful regex statements.\n\n\n\n\n\n\n\n\n\nQuery Log\nSee all the domains being queried on your network, where they originated, and more.\n\n\n\n\n\n\n\n\n\nLong Term Statistics\nQueries are stored in a database and can be queried at any time.  Learn about what’s happening on your network over time.\n\n\n\n\n\n\n\n\n\nAudit Log\nKeep track of the most queried domains and add them to a white or blacklist from a central page.\n\n\n\n\n\n\n\n\n\nPrivacy Modes\nChoose from four different privacy modes that works for your environment.\n\n\n\n\n\n\n\n\n\nOther Settings\nControl and configure other settings from the Web interface.\n\n\n\n\n\n\n\n\nOur Team\nThe Pi-hole developers are spread across the globe and work on the project in their spare time.  We are a 100% remote team.\n\n\n\n\nDan Schaper\nCo-founder\n\n\n\n\nAdam Warner\nDeveloper\n\n\n\n\nMark Drobnak\nDeveloper\n\n\n\n\nDr. Dominic\nDeveloper\n\n\n\n\nAdam Hill\nDocker Maintainer\n\n\n\n\nBlayne Campbell\nDeveloper\n\n\n\n\n\n\n\n\n\nPatrons Get Special Perks And Early Information\nMonthly patrons get access to special perks such as Pi-hole inspired art and special metal coins.  We also share information with patrons before the general public.\nBecome a patron\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubscribe to Blog via Email\n\nEnter your email address to subscribe to this blog and receive notifications of new posts by email.\n \n\n\t\t\t\t\t\tJoin 3,469 other subscribers\t\t\t\t\t\t\n\n\n\n\t\t\t\t\t\t\tEmail Address                        \n\n\n\n\n\n\n\n\n\t                        Subscribe                        \n\n\n\n\n\nFollow Us on Social Media\n\n\n\n\n \n\n\n\n\n\n                ©  2020 Pi-hole.               \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n",
   "man_entry": "",
   "tldr_summary": "# pihole\n\n> Terminal interface for the Pi-Hole ad-blocking DNS server.\n> More information: <https://pi-hole.net>.\n\n- Check the Pi-hole daemon's status:\n\n`pihole status`\n\n- Monitor detailed system status:\n\n`pihole chronometer`\n\n- Start or stop the daemon:\n\n`pihole {{enable|disable}}`\n\n- Restart the daemon (not the server itself):\n\n`pihole restartdns`\n\n- Whitelist or blacklist a domain:\n\n`pihole {{whitelist|blacklist}} {{example.com}}`\n\n- Search the lists for a domain:\n\n`pihole query {{example.com}}`\n"
 },
 {
   "command": "journalctl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# journalctl\n\n> Query the systemd journal.\n\n- Show all messages from this boot:\n\n`journalctl -b`\n\n- Show all messages from last boot:\n\n`journalctl -b -1`\n\n- Follow new messages (like `tail -f` for traditional syslog):\n\n`journalctl -f`\n\n- Show all messages by a specific unit:\n\n`journalctl -u {{unit}}`\n\n- Filter messages within a time range (either timestamp or placeholders like \"yesterday\"):\n\n`journalctl --since {{now|today|yesterday|tomorrow}} --until {{YYYY-MM-DD HH:MM:SS}}`\n\n- Show all messages by a specific process:\n\n`journalctl _PID={{pid}}`\n\n- Show all messages by a specific executable:\n\n`journalctl {{path/to/executable}}`\n"
 },
 {
   "command": "reboot",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nREBOOT(8)\t\t  BSD System Manager's Manual\t\t     REBOOT(8)\n\nNAME\n     halt, reboot -- stopping and restarting the system\n\nSYNOPSIS\n     halt [-lnqu]\n     reboot [-lnq]\n\nDESCRIPTION\n     The halt and reboot utilities flush the file system cache to disk, send\n     all running processes a SIGTERM (and subsequently a SIGKILL) and, respec-\n     tively, halt or restart the system.  The action is logged, including\n     entering a shutdown record into the wtmp(5) file.\n\n     When the system is halted with the halt command, the system is powered\n     off.\n\n     The options are as follows:\n\n     -l      The halt or reboot is not recorded in the system log.  This\n\t     option is intended for applications such as shutdown(8), that\n\t     call reboot or halt and log this themselves.\n\n     -n      The file system cache is not flushed.  This option should proba-\n\t     bly not be used.\n\n     -q      The system is halted or restarted quickly and ungracefully, and\n\t     only the flushing of the file system cache is performed (if the\n\t     -n option is not specified).  This option should probably not be\n\t     used.\n\n     -u      The system is halted up until the point of removing system power,\n\t     but waits before removing power for 5 minutes so that an external\n\t     UPS (uninterruptible power supply) can forcibly remove power.\n\t     This simulates a dirty shutdown to permit a later automatic power\n\t     on. OS X uses this mode automatically with supported UPSs in\n\t     emergency shutdowns.\n\n     Normally, the shutdown(8) utility is used when the system needs to be\n     halted or restarted, giving users advance warning of their impending doom\n     and cleanly terminating specific programs.\n\nSIGTERM TO SIGKILL INTERVAL\n     The SIGKILL will follow the SIGTERM by an intentionally indeterminate\n     period of time.  Programs are expected to take only enough time to flush\n     all dirty data and exit.  Developers are encouraged to file a bug with\n     the OS vendor, should they encounter an issue with this functionality.\n\nSEE ALSO\n     wtmp(5), shutdown(8), sync(8)\n\nHISTORY\n     A reboot utility appeared in Version 6 AT&T UNIX.\n\nBSD\t\t\t\t June 9, 1993\t\t\t\t   BSD\n",
   "tldr_summary": "# reboot\n\n> Reboot the system.\n\n- Reboot immediately:\n\n`reboot`\n\n- Reboot immediately without gracefully shutting down:\n\n`reboot -f`\n"
 },
 {
   "command": "systemctl",
   "doc_url": "https://www.freedesktop.org/software/systemd/man/systemctl.html",
   "doc_text": "systemctlIndex Â·\n  Directives systemd 246Namesystemctl â Control the systemd system and service managerSynopsissystemctl  [OPTIONS...]  COMMAND  [UNIT...]DescriptionÂ¶systemctl may be used to introspect and\n    control the state of the \"systemd\" system and\n    service manager. Please refer to\n    systemd(1)\n    for an introduction into the basic concepts and functionality this\n    tool manages.CommandsÂ¶The following commands are understood:Unit CommandsÂ¶list-units [PATTERNâ¦]Â¶List units that systemd currently has in memory. This includes units that are\n            either referenced directly or through a dependency, units that are pinned by applications programmatically,\n            or units that were active in the past and have failed. By default only units which are active, have pending\n            jobs, or have failed are shown; this can be changed with option --all. If one or more\n            PATTERNs are specified, only units matching one of them are shown. The units\n            that are shown are additionally filtered by --type= and --state= if those\n            options are specified.Produces output similar to\n              UNIT                         LOAD   ACTIVE SUB     DESCRIPTION\n  sys-module-fuse.device       loaded active plugged /sys/module/fuse\n  -.mount                      loaded active mounted Root Mount\n  boot-efi.mount               loaded active mounted /boot/efi\n  systemd-journald.service     loaded active running Journal Service\n  systemd-logind.service       loaded active running Login Service\nâ user@1000.service            loaded failed failed  User Manager for UID 1000\n  â¦\n  systemd-tmpfiles-clean.timer loaded active waiting Daily Cleanup of Temporary Directories\n\nLOAD   = Reflects whether the unit definition was properly loaded.\nACTIVE = The high-level unit activation state, i.e. generalization of SUB.\nSUB    = The low-level unit activation state, values depend on unit type.\n\n123 loaded units listed. Pass --all to see loaded but inactive units, too.\nTo show all installed unit files use 'systemctl list-unit-files'.\n            \n            The header and the last unit of a given type are underlined if the\n            terminal supports that. A colored dot is shown next to services which\n            were masked, not found, or otherwise failed.The LOAD column shows the load state, one of loaded,\n            not-found, bad-setting, error,\n            masked. The ACTIVE columns shows the general unit state, one of\n            active, reloading, inactive,\n            failed, activating, deactivating. The SUB\n            column shows the unit-type-specific detailed state of the unit, possible values vary by unit type. The list\n            of possible LOAD, ACTIVE, and SUB states is not constant and new systemd releases may both add and remove\n            values. systemctl --state=help command maybe be used to display the\n            current set of possible values.This is the default command.list-sockets [PATTERNâ¦]Â¶List socket units currently in memory, ordered by listening address.  If one or more\n            PATTERNs are specified, only socket units matching one of them are\n            shown. Produces output similar to\n            \nLISTEN           UNIT                        ACTIVATES\n/dev/initctl     systemd-initctl.socket      systemd-initctl.service\nâ¦\n[::]:22          sshd.socket                 sshd.service\nkobject-uevent 1 systemd-udevd-kernel.socket systemd-udevd.service\n\n5 sockets listed.\n            Note: because the addresses might contains spaces, this output\n            is not suitable for programmatic consumption.\n            Also see --show-types, --all, and --state=.list-timers [PATTERNâ¦]Â¶List timer units currently in memory, ordered by the time they elapse next. If one or more\n            PATTERNs are specified, only units matching one of them are shown.\n            Produces output similar to\n            \nNEXT                         LEFT          LAST                         PASSED     UNIT                         ACTIVATES\nn/a                          n/a           Thu 2017-02-23 13:40:29 EST  3 days ago ureadahead-stop.timer        ureadahead-stop.service\nSun 2017-02-26 18:55:42 EST  1min 14s left Thu 2017-02-23 13:54:44 EST  3 days ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.service\nSun 2017-02-26 20:37:16 EST  1h 42min left Sun 2017-02-26 11:56:36 EST  6h ago     apt-daily.timer              apt-daily.service\nSun 2017-02-26 20:57:49 EST  2h 3min left  Sun 2017-02-26 11:56:36 EST  6h ago     snapd.refresh.timer          snapd.refresh.service\n            \nNEXT shows the next time the timer will run.LEFT shows how long till the next time the timer runs.LAST shows the last time the timer ran.PASSED shows how long has passed since the timer last ran.UNIT shows the name of the timerACTIVATES shows the name the service the timer activates when it runs.Also see --all and --state=.start PATTERNâ¦Â¶Start (activate) one or more units specified on the command line.Note that unit glob patterns expand to names of units currently in memory. Units which are\n            not active and are not in a failed state usually are not in memory, and will not be matched by\n            any pattern. In addition, in case of instantiated units, systemd is often unaware of the instance\n            name until the instance has been started. Therefore, using glob patterns with\n            start has limited usefulness. Also, secondary alias names of units are not\n            considered.Option --all may be used to also operate on inactive units which are\n            referenced by other loaded units. Note that this is not the same as operating on \"all\" possible\n            units, because as the previous paragraph describes, such a list is ill-defined. Nevertheless,\n            systemctl start --all GLOB may be useful if all the\n            units that should match the pattern are pulled in by some target which is known to be loaded.\n            stop PATTERNâ¦Â¶Stop (deactivate) one or more units specified on the command line.This command will fail if the unit does not exist or if stopping of the unit is prohibited (see\n            RefuseManualStop= in\n            systemd.unit(5)).\n            It will not fail if any of the commands configured to stop the unit\n            (ExecStop=, etc.) fail, because the manager will still forcibly terminate the\n            unit.reload PATTERNâ¦Â¶Asks all units listed on the command line to reload\n            their configuration. Note that this will reload the\n            service-specific configuration, not the unit configuration\n            file of systemd. If you want systemd to reload the\n            configuration file of a unit, use the\n            daemon-reload command. In other words:\n            for the example case of Apache, this will reload Apache's\n            httpd.conf in the web server, not the\n            apache.service systemd unit\n            file.This command should not be confused with the\n            daemon-reload command.restart PATTERNâ¦Â¶Stop and then start one or more units specified on the command line. If the units are not running\n            yet, they will be started.Note that restarting a unit with this command does not necessarily flush out all of the unit's\n            resources before it is started again. For example, the per-service file descriptor storage facility (see\n            FileDescriptorStoreMax= in\n            systemd.service(5)) will\n            remain intact as long as the unit has a job pending, and is only cleared when the unit is fully stopped and\n            no jobs are pending anymore. If it is intended that the file descriptor store is flushed out, too, during a\n            restart operation an explicit systemctl stop command followed by systemctl\n            start should be issued.try-restart PATTERNâ¦Â¶Stop and then start one or more units specified on the\n            command line if the units are running. This does nothing\n            if units are not running.reload-or-restart PATTERNâ¦Â¶Reload one or more units if they support it. If not, stop and then start them instead. If the units\n            are not running yet, they will be started.try-reload-or-restart PATTERNâ¦Â¶Reload one or more units if they support it. If not, stop and then start them instead. This does\n            nothing if the units are not running.isolate UNITÂ¶Start the unit specified on the command line and its dependencies\n            and stop all others, unless they have\n            IgnoreOnIsolate=yes (see\n            systemd.unit(5)).\n            If a unit name with no extension is given, an extension of\n            \".target\" will be assumed.This command is dangerous, since it will immediately stop processes that are not enabled in\n            the new target, possibly including the graphical environment or terminal you are currently using.\n            Note that this is allowed only on units where\n            AllowIsolate= is enabled. See\n            systemd.unit(5)\n            for details.kill PATTERNâ¦Â¶Send a signal to one or more processes of the\n            unit. Use --kill-who= to select which\n            process to kill. Use --signal= to select\n            the signal to send.clean PATTERNâ¦Â¶Remove the configuration, state, cache, logs or runtime data of the specified units. Use\n            --what= to select which kind of resource to remove. For service units this may\n            be used to remove the directories configured with ConfigurationDirectory=,\n            StateDirectory=, CacheDirectory=,\n            LogsDirectory= and RuntimeDirectory=, see\n            systemd.exec(5)\n            for details. For timer units this may be used to clear out the persistent timestamp data if\n            Persistent= is used and --what=state is selected, see\n            systemd.timer(5). This\n            command only applies to units that use either of these settings. If --what= is\n            not specified, both the cache and runtime data are removed (as these two types of data are\n            generally redundant and reproducible on the next invocation of the unit).freeze PATTERNâ¦Â¶Freeze one or more units specified on the\n            command line using cgroup freezerFreezing the unit will cause all processes contained within the cgroup corresponding to the unit\n            to be suspended. Being suspended means that unit's processes won't be scheduled to run on CPU until thawed.\n            Note that this command is supported only on systems that use unified cgroup hierarchy. Unit is automatically\n            thawed just before we execute a job against the unit, e.g. before the unit is stopped.thaw PATTERNâ¦Â¶Thaw (unfreeze) one or more units specified on the\n            command line.This is the inverse operation to the freeze command and resumes the execution of\n            processes in the unit's cgroup.is-active PATTERNâ¦Â¶Check whether any of the specified units are active\n            (i.e. running). Returns an exit code\n            0 if at least one is active, or\n            non-zero otherwise. Unless --quiet is\n            specified, this will also print the current unit state to\n            standard output.is-failed PATTERNâ¦Â¶Check whether any of the specified units are in a\n            \"failed\" state. Returns an exit code\n            0 if at least one has failed,\n            non-zero otherwise. Unless --quiet is\n            specified, this will also print the current unit state to\n            standard output.status [PATTERNâ¦|PIDâ¦]]Â¶Show terse runtime status information about one or\n            more units, followed by most recent log data from the\n            journal. If no units are specified, show system status. If\n            combined with --all, also show the status of\n            all units (subject to limitations specified with\n            -t). If a PID is passed, show information\n            about the unit the process belongs to.This function is intended to generate human-readable\n            output. If you are looking for computer-parsable output,\n            use show instead. By default, this\n            function only shows 10 lines of output and ellipsizes\n            lines to fit in the terminal window. This can be changed\n            with --lines and --full,\n            see above. In addition, journalctl\n            --unit=NAME or\n            journalctl\n            --user-unit=NAME use\n            a similar filter for messages and might be more\n            convenient.\n            systemd implicitly loads units as necessary, so just running the status will\n            attempt to load a file. The command is thus not useful for determining if something was already loaded or\n            not.  The units may possibly also be quickly unloaded after the operation is completed if there's no reason\n            to keep it in memory thereafter.\n            ExampleÂ 1.Â Example output from systemctl status $ systemctl status bluetooth\nâ bluetooth.service - Bluetooth service\n   Loaded: loaded (/usr/lib/systemd/system/bluetooth.service; enabled; vendor preset: enabled)\n   Active: active (running) since Wed 2017-01-04 13:54:04 EST; 1 weeks 0 days ago\n     Docs: man:bluetoothd(8)\n Main PID: 930 (bluetoothd)\n   Status: \"Running\"\n    Tasks: 1\n   Memory: 648.0K\n      CPU: 435ms\n   CGroup: /system.slice/bluetooth.service\n           ââ930 /usr/lib/bluetooth/bluetoothd\n\nJan 12 10:46:45 example.com bluetoothd[8900]: Not enough free handles to register service\nJan 12 10:46:45 example.com bluetoothd[8900]: Current Time Service could not be registered\nJan 12 10:46:45 example.com bluetoothd[8900]: gatt-time-server: Input/output error (5)\nThe dot (\"â\") uses color on supported terminals to summarize the unit state at a glance. White\n            indicates an \"inactive\" or \"deactivating\" state. Red indicates a\n            \"failed\" or \"error\" state and green indicates an\n            \"active\", \"reloading\" or \"activating\" state.\n            The \"Loaded:\" line in the output will show \"loaded\" if the unit has been loaded into\n            memory. Other possible values for \"Loaded:\" include: \"error\" if there was a problem\n            loading it, \"not-found\" if no unit file was found for this unit,\n            \"bad-setting\" if an essential unit file setting could not be parsed and\n            \"masked\" if the unit file has been masked. Along with showing the path to the unit file,\n            this line will also show the enablement state.  Enabled commands start at boot.  See the full table of\n            possible enablement states â including the definition of \"masked\" â in the documentation\n            for the is-enabled command.\n            The \"Active:\" line shows active state.  The value is usually \"active\" or\n            \"inactive\". Active could mean started, bound, plugged in, etc depending on the unit type.\n            The unit could also be in process of changing states, reporting a state of \"activating\" or\n            \"deactivating\". A special \"failed\" state is entered when the service\n            failed in some way, such as a crash, exiting with an error code or timing out. If the failed state is\n            entered the cause will be logged for later reference.show [PATTERNâ¦|JOBâ¦]Â¶Show properties of one or more units, jobs, or the manager itself. If no argument is specified,\n            properties of the manager will be shown. If a unit name is specified, properties of the unit are shown, and\n            if a job ID is specified, properties of the job are shown. By default, empty properties are suppressed. Use\n            --all to show those too. To select specific properties to show, use\n            --property=. This command is intended to be used whenever computer-parsable output is\n            required. Use status if you are looking for formatted human-readable output.Many properties shown by systemctl show map directly to configuration settings of\n            the system and service manager and its unit files. Note that the properties shown by the command are\n            generally more low-level, normalized versions of the original configuration settings and expose runtime\n            state in addition to configuration. For example, properties shown for service units include the service's\n            current main process identifier as \"MainPID\" (which is runtime state), and time settings\n            are always exposed as properties ending in the \"â¦USec\" suffix even if a matching\n            configuration options end in \"â¦Sec\", because microseconds is the normalized time unit used\n            by the system and service manager.cat PATTERNâ¦Â¶Show backing files of one or more units. Prints the\n            \"fragment\" and \"drop-ins\" (source files) of units. Each\n            file is preceded by a comment which includes the file\n            name. Note that this shows the contents of the backing files\n            on disk, which may not match the system manager's\n            understanding of these units if any unit files were\n            updated on disk and the daemon-reload\n            command wasn't issued since.set-property UNIT PROPERTY=VALUEâ¦Â¶Set the specified unit properties at runtime where\n            this is supported. This allows changing configuration\n            parameter properties such as resource control settings at\n            runtime. Not all properties may be changed at runtime, but\n            many resource control settings (primarily those in\n            systemd.resource-control(5))\n            may. The changes are applied immediately, and stored on disk\n            for future boots, unless --runtime is\n            passed, in which case the settings only apply until the\n            next reboot. The syntax of the property assignment follows\n            closely the syntax of assignments in unit files.Example: systemctl set-property foobar.service CPUWeight=200If the specified unit appears to be inactive, the\n            changes will be only stored on disk as described\n            previously hence they will be effective when the unit will\n            be started.Note that this command allows changing multiple properties at the same time, which is\n            preferable over setting them individually.Example: systemctl set-property foobar.service CPUWeight=200 MemoryMax=2G IPAccounting=yesLike with unit file configuration settings, assigning an empty setting usually resets a\n            property to its defaults.Example: systemctl set-property avahi-daemon.service IPAddressDeny=help PATTERNâ¦|PIDâ¦Â¶Show manual pages for one or more units, if\n            available. If a PID is given, the manual pages for the unit\n            the process belongs to are shown.reset-failed [PATTERNâ¦]Â¶Reset the \"failed\" state of the specified units, or if no unit name is passed, reset\n            the state of all units. When a unit fails in some way (i.e. process exiting with non-zero error code,\n            terminating abnormally or timing out), it will automatically enter the \"failed\" state and\n            its exit code and status is recorded for introspection by the administrator until the service is\n            stopped/re-started or reset with this command.In addition to resetting the \"failed\" state of a unit it also resets various other\n            per-unit properties: the start rate limit counter of all unit types is reset to zero, as is the restart\n            counter of service units. Thus, if a unit's start limit (as configured with\n            StartLimitIntervalSec=/StartLimitBurst=) is hit and the unit refuses\n            to be started again, use this command to make it startable again.\nlist-dependencies\n            [UNIT...]\n          Â¶Shows units required and wanted by the specified\n            units. This recursively lists units following the\n            Requires=,\n            Requisite=,\n            ConsistsOf=,\n            Wants=, BindsTo=\n            dependencies. If no units are specified,\n            default.target is implied.By default, only target units are recursively\n            expanded. When --all is passed, all other\n            units are recursively expanded as well.Options --reverse,\n            --after, --before\n            may be used to change what types of dependencies\n            are shown.Note that this command only lists units currently loaded into memory by the service manager. In\n            particular, this command is not suitable to get a comprehensive list at all reverse dependencies on a\n            specific unit, as it won't list the dependencies declared by units currently not loaded.Unit File CommandsÂ¶list-unit-files [PATTERNâ¦]Â¶List unit files installed on the system, in combination with their enablement state (as reported by\n            is-enabled). If one or more PATTERNs are specified, only unit\n            files whose name matches one of them are shown (patterns matching unit file system paths are not\n            supported).enable UNITâ¦, enable PATHâ¦Â¶Enable one or more units or unit instances. This will create a set of symlinks, as encoded in the\n            [Install] sections of the indicated unit files. After the symlinks have been created,\n            the system manager configuration is reloaded (in a way equivalent to daemon-reload), in\n            order to ensure the changes are taken into account immediately. Note that this does\n            not have the effect of also starting any of the units being enabled. If this is\n            desired, combine this command with the --now switch, or invoke start\n            with appropriate arguments later. Note that in case of unit instance enablement (i.e. enablement of units of\n            the form foo@bar.service), symlinks named the same as instances are created in the\n            unit configuration directory, however they point to the single template unit file they are instantiated\n            from.This command expects either valid unit names (in which case various unit file directories are\n            automatically searched for unit files with appropriate names), or absolute paths to unit files (in which\n            case these files are read directly). If a specified unit file is located outside of the usual unit file\n            directories, an additional symlink is created, linking it into the unit configuration path, thus ensuring\n            it is found when requested by commands such as start. The file system where the linked\n            unit files are located must be accessible when systemd is started (e.g. anything underneath\n            /home or /var is not allowed, unless those directories are\n            located on the root file system).This command will print the file system operations executed. This output may be suppressed by passing\n            --quiet.\n            Note that this operation creates only the symlinks suggested in the [Install]\n            section of the unit files. While this command is the recommended way to manipulate the unit configuration\n            directory, the administrator is free to make additional changes manually by placing or removing symlinks\n            below this directory. This is particularly useful to create configurations that deviate from the suggested\n            default installation. In this case, the administrator must make sure to invoke\n            daemon-reload manually as necessary, in order to ensure the changes are taken into\n            account.\n            Enabling units should not be confused with starting (activating) units, as done by the\n            start command. Enabling and starting units is orthogonal: units may be enabled without\n            being started and started without being enabled. Enabling simply hooks the unit into various suggested\n            places (for example, so that the unit is automatically started on boot or when a particular kind of\n            hardware is plugged in). Starting actually spawns the daemon process (in case of service units), or binds\n            the socket (in case of socket units), and so on.Depending on whether --system, --user, --runtime,\n            or --global is specified, this enables the unit for the system, for the calling user only,\n            for only this boot of the system, or for all future logins of all users.  Note that in the last case, no\n            systemd daemon configuration is reloaded.Using enable on masked units is not supported and results in an error.disable UNITâ¦Â¶Disables one or more units. This removes all symlinks to the unit files backing the specified units\n            from the unit configuration directory, and hence undoes any changes made by enable or\n            link. Note that this removes all symlinks to matching unit files,\n            including manually created symlinks, and not just those actually created by enable or\n            link. Note that while disable undoes the effect of\n            enable, the two commands are otherwise not symmetric, as disable may\n            remove more symlinks than a prior enable invocation of the same unit created.This command expects valid unit names only, it does not accept paths to unit files.In addition to the units specified as arguments, all units are disabled that are listed in the\n            Also= setting contained in the [Install] section of any of the unit\n            files being operated on.This command implicitly reloads the system manager configuration after completing the operation. Note\n            that this command does not implicitly stop the units that are being disabled. If this is desired, either\n            combine this command with the --now switch, or invoke the stop command\n            with appropriate arguments later.This command will print information about the file system operations (symlink removals)\n            executed. This output may be suppressed by passing --quiet.\n            This command honors --system, --user, --runtime\n            and --global in a similar way as enable.reenable UNITâ¦Â¶Reenable one or more units, as specified on the command line. This is a combination of\n            disable and enable and is useful to reset the symlinks a unit file is\n            enabled with to the defaults configured in its [Install] section. This command expects\n            a unit name only, it does not accept paths to unit files.preset UNITâ¦Â¶Reset the enable/disable status one or more unit files, as specified on\n            the command line, to the defaults configured in the preset policy files. This\n            has the same effect as disable or\n            enable, depending how the unit is listed in the preset\n            files.Use --preset-mode= to control whether units shall be\n            enabled and disabled, or only enabled, or only disabled.If the unit carries no install information, it will be silently ignored\n            by this command. UNIT must be the real unit name,\n            any alias names are ignored silently.For more information on the preset policy format, see\n            systemd.preset(5).\n            For more information on the concept of presets, please consult the\n            Preset\n            document.preset-allÂ¶Resets all installed unit files to the defaults\n            configured in the preset policy file (see above).Use --preset-mode= to control\n            whether units shall be enabled and disabled, or only\n            enabled, or only disabled.is-enabled UNITâ¦Â¶Checks whether any of the specified unit files are\n            enabled (as with enable). Returns an\n            exit code of 0 if at least one is enabled, non-zero\n            otherwise. Prints the current enable status (see table).\n            To suppress this output, use --quiet.\n            To show installation targets, use --full.\n            TableÂ 1.Â \n                is-enabled output\n              NameDescriptionExit Code\"enabled\"Enabled via .wants/, .requires/ or Alias= symlinks (permanently in /etc/systemd/system/, or transiently in /run/systemd/system/).0\"enabled-runtime\"\"linked\"Made available through one or more symlinks to the unit file (permanently in /etc/systemd/system/ or transiently in /run/systemd/system/), even though the unit file might reside outside of the unit file search path.> 0\"linked-runtime\"\"alias\"The name is an alias (symlink to another unit file).0\"masked\"Completely disabled, so that any start operation on it fails (permanently in /etc/systemd/system/ or transiently in /run/systemd/systemd/).> 0\"masked-runtime\"\"static\"The unit file is not enabled, and has no provisions for enabling in the [Install] unit file section.0\"indirect\"The unit file itself is not enabled, but it has a non-empty Also= setting in the [Install] unit file section, listing other unit files that might be enabled, or it has an alias under a different name through a symlink that is not specified in Also=. For template unit files, an instance different than the one specified in DefaultInstance= is enabled.0\"disabled\"The unit file is not enabled, but contains an [Install] section with installation instructions.> 0\"generated\"The unit file was generated dynamically via a generator tool. See systemd.generator(7). Generated unit files may not be enabled, they are enabled implicitly by their generator.0\"transient\"The unit file has been created dynamically with the runtime API. Transient units may not be enabled.0\"bad\"The unit file is invalid or another error occurred. Note that is-enabled will not actually return this state, but print an error message instead. However the unit file listing printed by list-unit-files might show it.> 0mask UNITâ¦Â¶Mask one or more units, as specified on the command line. This will link these unit files to\n            /dev/null, making it impossible to start them. This is a stronger version of\n            disable, since it prohibits all kinds of activation of the unit, including enablement\n            and manual activation. Use this option with care. This honors the --runtime option to only\n            mask temporarily until the next reboot of the system. The --now option may be used to\n            ensure that the units are also stopped. This command expects valid unit names only, it does not accept unit\n            file paths.unmask UNITâ¦Â¶Unmask one or more unit files, as specified on the command line. This will undo the effect of\n            mask. This command expects valid unit names only, it does not accept unit file\n            paths.link PATHâ¦Â¶Link a unit file that is not in the unit file search paths into the unit file search path. This\n            command expects an absolute path to a unit file. The effect of this may be undone with\n            disable. The effect of this command is that a unit file is made available for commands\n            such as start, even though it is not installed directly in the unit search path. The\n            file system where the linked unit files are located must be accessible when systemd is started\n            (e.g. anything underneath /home or /var is not allowed, unless\n            those directories are located on the root file system).revert UNITâ¦Â¶Revert one or more unit files to their vendor versions. This command removes drop-in configuration\n            files that modify the specified units, as well as any user-configured unit file that overrides a matching\n            vendor supplied unit file. Specifically, for a unit \"foo.service\" the matching directories\n            \"foo.service.d/\" with all their contained files are removed, both below the persistent and\n            runtime configuration directories (i.e. below /etc/systemd/system and\n            /run/systemd/system); if the unit file has a vendor-supplied version (i.e. a unit file\n            located below /usr) any matching persistent or runtime unit file that overrides it is\n            removed, too. Note that if a unit file has no vendor-supplied version (i.e. is only defined below\n            /etc/systemd/system or /run/systemd/system, but not in a unit\n            file stored below /usr), then it is not removed. Also, if a unit is masked, it is\n            unmasked.Effectively, this command may be used to undo all changes made with systemctl\n            edit, systemctl set-property and systemctl mask and puts\n            the original unit file with its settings back in effect.add-wants TARGET\nUNITâ¦, add-requires TARGET\nUNITâ¦Â¶Adds \"Wants=\" or \"Requires=\"\n            dependencies, respectively, to the specified\n            TARGET for one or more units. This command honors --system,\n            --user, --runtime and\n            --global in a way similar to\n            enable.edit UNITâ¦Â¶Edit a drop-in snippet or a whole replacement file if\n            --full is specified, to extend or override the\n            specified unit.Depending on whether --system (the default),\n            --user, or --global is specified,\n            this command creates a drop-in file for each unit either for the system,\n            for the calling user, or for all futures logins of all users. Then,\n            the editor (see the \"Environment\" section below) is invoked on\n            temporary files which will be written to the real location if the\n            editor exits successfully.If --full is specified, this will copy the\n            original units instead of creating drop-in files.If --force is specified and any units do\n            not already exist, new unit files will be opened for editing.If --runtime is specified, the changes will\n            be made temporarily in /run and they will be\n            lost on the next reboot.If the temporary file is empty upon exit, the modification of\n            the related unit is canceled.After the units have been edited, systemd configuration is\n            reloaded (in a way that is equivalent to daemon-reload).\n            Note that this command cannot be used to remotely edit units\n            and that you cannot temporarily edit units which are in\n            /etc, since they take precedence over\n            /run.get-defaultÂ¶Return the default target to boot into. This returns\n            the target unit name default.target\n            is aliased (symlinked) to.set-default TARGETÂ¶Set the default target to boot into. This sets\n            (symlinks) the default.target alias\n            to the given target unit.Machine CommandsÂ¶list-machines [PATTERNâ¦]Â¶List the host and all running local containers with\n            their state. If one or more\n            PATTERNs are specified, only\n            containers matching one of them are shown.\n            Job CommandsÂ¶list-jobs [PATTERNâ¦]Â¶List jobs that are in progress. If one or more\n            PATTERNs are specified, only\n            jobs for units matching one of them are shown.When combined with --after or --before the list is augmented with\n            information on which other job each job is waiting for, and which other jobs are waiting for it, see\n            above.cancel JOBâ¦Â¶Cancel one or more jobs specified on the command line\n            by their numeric job IDs. If no job ID is specified, cancel\n            all pending jobs.Environment CommandsÂ¶show-environmentÂ¶Dump the systemd manager environment block. This is the environment\n            block that is passed to all processes the manager spawns. The environment\n            block will be dumped in straight-forward form suitable for sourcing into\n            most shells. If no special characters or whitespace is present in the variable\n            values, no escaping is performed, and the assignments have the form\n            \"VARIABLE=value\". If whitespace or characters which have\n            special meaning to the shell are present, dollar-single-quote escaping is\n            used, and assignments have the form \"VARIABLE=$'value'\".\n            This syntax is known to be supported by\n            bash(1),\n            zsh(1),\n            ksh(1),\n            and\n            busybox(1)'s\n            ash(1),\n            but not\n            dash(1)\n            or\n            fish(1).\n            set-environment VARIABLE=VALUEâ¦Â¶Set one or more systemd manager environment variables,\n            as specified on the command line.unset-environment VARIABLEâ¦Â¶Unset one or more systemd manager environment\n            variables. If only a variable name is specified, it will be\n            removed regardless of its value. If a variable and a value\n            are specified, the variable is only removed if it has the\n            specified value.\nimport-environment\n            [VARIABLEâ¦]\n          Â¶Import all, one or more environment variables set on\n            the client into the systemd manager environment block. If\n            no arguments are passed, the entire environment block is\n            imported. Otherwise, a list of one or more environment\n            variable names should be passed, whose client-side values\n            are then imported into the manager's environment\n            block.Manager State CommandsÂ¶daemon-reloadÂ¶Reload the systemd manager configuration. This will\n            rerun all generators (see\n            systemd.generator(7)),\n            reload all unit files, and recreate the entire dependency\n            tree. While the daemon is being reloaded, all sockets\n            systemd listens on behalf of user configuration will stay\n            accessible.This command should not be confused with the\n            reload command.daemon-reexecÂ¶Reexecute the systemd manager. This will serialize the\n            manager state, reexecute the process and deserialize the\n            state again. This command is of little use except for\n            debugging and package upgrades. Sometimes, it might be\n            helpful as a heavy-weight daemon-reload.\n            While the daemon is being reexecuted, all sockets systemd listening\n            on behalf of user configuration will stay accessible.\n            log-level [LEVEL]Â¶If no argument is given, print the current log level of the manager. If an\n          optional argument LEVEL is provided, then the command changes the\n          current log level of the manager to LEVEL (accepts the same values as\n          --log-level= described in\n          systemd(1)).\n          log-target [TARGET]Â¶If no argument is given, print the current log target of the manager. If an\n          optional argument TARGET is provided, then the command changes the\n          current log target of the manager to TARGET (accepts the same values as\n          --log-target=, described in\n          systemd(1)).\n          service-watchdogs [yes|no]Â¶If no argument is given, print the current state of service runtime watchdogs of\n          the manager. If an optional boolean argument is provided, then globally enables or disables the\n          service runtime watchdogs (WatchdogSec=) and emergency actions (e.g.\n          OnFailure= or StartLimitAction=); see\n          systemd.service(5).\n          The hardware watchdog is not affected by this setting.System CommandsÂ¶is-system-runningÂ¶Checks whether the system is operational. This\n            returns success (exit code 0) when the system is fully up\n            and running, specifically not in startup, shutdown or\n            maintenance mode, and with no failed services. Failure is\n            returned otherwise (exit code non-zero). In addition, the\n            current state is printed in a short string to standard\n            output, see the table below. Use --quiet to\n            suppress this output.Use --wait to wait until the boot\n            process is completed before printing the current state and\n            returning the appropriate error status. If --wait\n            is in use, states initializing or\n            starting will not be reported, instead\n            the command will block until a later state (such as\n            running or degraded)\n            is reached.TableÂ 2.Â is-system-running outputNameDescriptionExit CodeinitializingEarly bootup, before\n                    basic.target is reached\n                    or the maintenance state entered.\n                    > 0startingLate bootup, before the job queue\n                    becomes idle for the first time, or one of the\n                    rescue targets are reached.> 0runningThe system is fully\n                    operational.0degradedThe system is operational but one or more\n                    units failed.> 0maintenanceThe rescue or emergency target is\n                    active.> 0stoppingThe manager is shutting\n                    down.> 0offlineThe manager is not\n                    running. Specifically, this is the operational\n                    state if an incompatible program is running as\n                    system manager (PID 1).> 0unknownThe operational state could not be\n                    determined, due to lack of resources or another\n                    error cause.> 0defaultÂ¶Enter default mode. This is equivalent to systemctl isolate default.target. This\n            operation is blocking by default, use --no-block to request asynchronous behavior.rescueÂ¶Enter rescue mode. This is equivalent to systemctl isolate rescue.target. This\n            operation is blocking by default, use --no-block to request asynchronous behavior.emergencyÂ¶Enter emergency mode. This is equivalent to systemctl isolate\n            emergency.target. This operation is blocking by default, use --no-block to\n            request asynchronous behavior.haltÂ¶Shut down and halt the system. This is mostly equivalent to systemctl start halt.target\n            --job-mode=replace-irreversibly --no-block, but also prints a wall message to all users. This command is\n            asynchronous; it will return after the halt operation is enqueued, without waiting for it to complete. Note\n            that this operation will simply halt the OS kernel after shutting down, leaving the hardware powered\n            on. Use systemctl poweroff for powering off the system (see below).If combined with --force, shutdown of all running services is skipped, however all\n            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the\n            system halt.  If --force is specified twice, the operation is immediately executed without\n            terminating any processes or unmounting any file systems. This may result in data loss. Note that when\n            --force is specified twice the halt operation is executed by systemctl\n            itself, and the system manager is not contacted. This means the command should succeed even when the system\n            manager has crashed.poweroffÂ¶Shut down and power-off the system. This is mostly equivalent to systemctl start\n            poweroff.target --job-mode=replace-irreversibly --no-block, but also prints a wall message to all\n            users. This command is asynchronous; it will return after the power-off operation is enqueued, without\n            waiting for it to complete.If combined with --force, shutdown of all running services is skipped, however all\n            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the\n            powering off. If --force is specified twice, the operation is immediately executed without\n            terminating any processes or unmounting any file systems. This may result in data loss. Note that when\n            --force is specified twice the power-off operation is executed by\n            systemctl itself, and the system manager is not contacted. This means the command should\n            succeed even when the system manager has crashed.rebootÂ¶Shut down and reboot the system. This is mostly equivalent to systemctl start reboot.target\n            --job-mode=replace-irreversibly --no-block, but also prints a wall message to all users. This\n            command is asynchronous; it will return after the reboot operation is enqueued, without waiting for it to\n            complete.If combined with --force, shutdown of all running services is skipped, however all\n            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the\n            reboot. If --force is specified twice, the operation is immediately executed without\n            terminating any processes or unmounting any file systems. This may result in data loss. Note that when\n            --force is specified twice the reboot operation is executed by\n            systemctl itself, and the system manager is not contacted. This means the command should\n            succeed even when the system manager has crashed.If the switch --reboot-argument= is given, it will be passed as the optional\n            argument to the reboot(2)\n            system call.kexecÂ¶Shut down and reboot the system via kexec. This is equivalent to\n            systemctl start kexec.target --job-mode=replace-irreversibly --no-block. This command is\n            asynchronous; it will return after the reboot operation is enqueued, without waiting for it to\n            complete.If combined with --force, shutdown of all running services is skipped, however all\n            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the\n            reboot.exit [EXIT_CODE]Â¶Ask the service manager to quit. This is only supported for user service managers (i.e. in\n            conjunction with the --user option) or in containers and is equivalent to\n            poweroff otherwise. This command is asynchronous; it will return after the exit\n            operation is enqueued, without waiting for it to complete.The service manager will exit with the specified exit code, if\n            EXIT_CODE is passed.switch-root ROOT [INIT]Â¶Switches to a different root directory and executes a new system manager process below it. This is\n            intended for usage in initial RAM disks (\"initrd\"), and will transition from the initrd's system manager\n            process (a.k.a. \"init\" process) to the main system manager process which is loaded from the actual host\n            volume. This call takes two arguments: the directory that is to become the new root directory, and the path\n            to the new system manager binary below it to execute as PID 1. If the latter is omitted or the empty\n            string, a systemd binary will automatically be searched for and used as init. If the system manager path is\n            omitted, equal to the empty string or identical to the path to the systemd binary, the state of the\n            initrd's system manager process is passed to the main system manager, which allows later introspection of\n            the state of the services involved in the initrd boot phase.suspendÂ¶Suspend the system. This will trigger activation of the special target unit\n            suspend.target. This command is asynchronous, and will return after the suspend\n            operation is successfully enqueued. It will not wait for the suspend/resume cycle to complete.hibernateÂ¶Hibernate the system. This will trigger activation of the special target unit\n            hibernate.target. This command is asynchronous, and will return after the hibernation\n            operation is successfully enqueued. It will not wait for the hibernate/thaw cycle to complete.hybrid-sleepÂ¶Hibernate and suspend the system. This will trigger activation of the special target unit\n            hybrid-sleep.target. This command is asynchronous, and will return after the hybrid\n            sleep operation is successfully enqueued. It will not wait for the sleep/wake-up cycle to complete.suspend-then-hibernateÂ¶Suspend the system and hibernate it after the delay specified in systemd-sleep.conf.\n            This will trigger activation of the special target unit suspend-then-hibernate.target.\n            This command is asynchronous, and will return after the hybrid sleep operation is successfully enqueued.\n            It will not wait for the sleep/wake-up or hibernate/thaw cycle to complete.Parameter SyntaxÂ¶Unit commands listed above take either a single unit name (designated as UNIT),\n      or multiple unit specifications (designated as PATTERNâ¦). In the first case, the\n      unit name with or without a suffix must be given. If the suffix is not specified (unit name is \"abbreviated\"),\n      systemctl will append a suitable suffix, \".service\" by default, and a type-specific suffix in\n      case of commands which operate only on specific unit types. For example,\n      # systemctl start sshd and\n      # systemctl start sshd.service\n      are equivalent, as are\n      # systemctl isolate default\n      and\n      # systemctl isolate default.target\n      Note that (absolute) paths to device nodes are automatically converted to device unit names, and other (absolute)\n      paths to mount unit names.\n      # systemctl status /dev/sda\n# systemctl status /home\n      are equivalent to:\n      # systemctl status dev-sda.device\n# systemctl status home.mount\n      In the second case, shell-style globs will be matched against the primary names of all units currently in memory;\n      literal unit names, with or without a suffix, will be treated as in the first case. This means that literal unit\n      names always refer to exactly one unit, but globs may match zero units and this is not considered an\n      error.Glob patterns use\n      fnmatch(3),\n      so normal shell-style globbing rules are used, and\n      \"*\", \"?\",\n      \"[]\" may be used. See\n      glob(7)\n      for more details. The patterns are matched against the primary names of\n      units currently in memory, and patterns which do not match anything\n      are silently skipped. For example:\n      # systemctl stop sshd@*.service\n      will stop all sshd@.service instances. Note that alias names of units, and units that aren't\n      in memory are not considered for glob expansion.\n      For unit file commands, the specified UNIT should be the name of the unit file\n      (possibly abbreviated, see above), or the absolute path to the unit file:\n      # systemctl enable foo.service\n      or\n      # systemctl link /path/to/foo.service\nOptionsÂ¶The following options are understood:-t, --type=Â¶The argument should be a comma-separated list of unit\n          types such as service and\n          socket.\n          If one of the arguments is a unit type, when listing\n          units, limit display to certain unit types. Otherwise, units\n          of all types will be shown.As a special case, if one of the arguments is\n          help, a list of allowed values will be\n          printed and the program will exit.--state=Â¶The argument should be a comma-separated list of unit\n          LOAD, SUB, or ACTIVE states. When listing units, show only\n          those in the specified states. Use --state=failed\n          to show only failed units.As a special case, if one of the arguments is\n          help, a list of allowed values will be\n          printed and the program will exit.-p, --property=Â¶When showing unit/job/manager properties with the\n          show command, limit display to properties\n          specified in the argument. The argument should be a\n          comma-separated list of property names, such as\n          \"MainPID\". Unless specified, all known\n          properties are shown. If specified more than once, all\n          properties with the specified names are shown. Shell\n          completion is implemented for property names.For the manager itself,\n          systemctlÂ show will show all available\n          properties. Those properties are documented in\n          systemd-system.conf(5).\n          Properties for units vary by unit type, so showing any\n          unit (even a non-existent one) is a way to list properties\n          pertaining to this type. Similarly, showing any job will list\n          properties pertaining to all jobs. Properties for units are\n          documented in\n          systemd.unit(5),\n          and the pages for individual unit types\n          systemd.service(5),\n          systemd.socket(5),\n          etc.-PÂ¶Equivalent to --value --property=, i.e. shows the\n          value of the property without the property name or \"=\". Note that using\n          -P once will also affect all properties listed with\n          -p/--property=.-a, --allÂ¶When listing units with list-units, also show inactive units and\n          units which are following other units. When showing unit/job/manager properties, show all\n          properties regardless whether they are set or not.To list all units installed in the file system, use the\n          list-unit-files command instead.When listing units with list-dependencies, recursively show\n          dependencies of all dependent units (by default only dependencies of target units are\n          shown).When used with status, show journal messages in full, even if they include\n          unprintable characters or are very long. By default, fields with unprintable characters are\n          abbreviated as \"blob data\". (Note that the pager may escape unprintable characters again.)-r, --recursiveÂ¶When listing units, also show units of local\n          containers. Units of local containers will be prefixed with\n          the container name, separated by a single colon character\n          (\":\").--reverseÂ¶Show reverse dependencies between units with\n          list-dependencies, i.e. follow\n          dependencies of type WantedBy=,\n          RequiredBy=,\n          PartOf=, BoundBy=,\n          instead of Wants= and similar.\n          --afterÂ¶With list-dependencies, show the\n          units that are ordered before the specified unit. In other\n          words, recursively list units following the\n          After= dependency.Note that any After= dependency is\n          automatically mirrored to create a\n          Before= dependency. Temporal dependencies\n          may be specified explicitly, but are also created implicitly\n          for units which are WantedBy= targets\n          (see\n          systemd.target(5)),\n          and as a result of other directives (for example\n          RequiresMountsFor=). Both explicitly\n          and implicitly introduced dependencies are shown with\n          list-dependencies.When passed to the list-jobs command, for each printed job show which other jobs are\n          waiting for it. May be combined with --before to show both the jobs waiting for each job as\n          well as all jobs each job is waiting for.--beforeÂ¶With list-dependencies, show the\n          units that are ordered after the specified unit. In other\n          words, recursively list units following the\n          Before= dependency.When passed to the list-jobs command, for each printed job show which other jobs it\n          is waiting for. May be combined with --after to show both the jobs waiting for each job as\n          well as all jobs each job is waiting for.--with-dependenciesÂ¶When used with status,\n          cat, list-units, and\n          list-unit-files, those commands print all\n          specified units and the dependencies of those units.Options --reverse,\n          --after, --before\n          may be used to change what types of dependencies\n          are shown.-l, --fullÂ¶Do not ellipsize unit names, process tree entries,\n          journal output, or truncate unit descriptions in the output\n          of status, list-units,\n          list-jobs, and\n          list-timers.Also, show installation targets in the output of\n          is-enabled.--valueÂ¶When printing properties with show, only print the value, and skip the\n          property name and \"=\". Also see option -P above.--show-typesÂ¶When showing sockets, show the type of the socket.--job-mode=Â¶When queuing a new job, this option controls how to deal with\n        already queued jobs. It takes one of \"fail\",\n        \"replace\",\n        \"replace-irreversibly\",\n        \"isolate\",\n        \"ignore-dependencies\",\n        \"ignore-requirements\",\n        \"flush\", or\n        \"triggering\". Defaults to\n        \"replace\", except when the\n        isolate command is used which implies the\n        \"isolate\" job mode.If \"fail\" is specified and a requested\n        operation conflicts with a pending job (more specifically:\n        causes an already pending start job to be reversed into a stop\n        job or vice versa), cause the operation to fail.If \"replace\" (the default) is\n        specified, any conflicting pending job will be replaced, as\n        necessary.If \"replace-irreversibly\" is specified,\n        operate like \"replace\", but also mark the new\n        jobs as irreversible. This prevents future conflicting\n        transactions from replacing these jobs (or even being enqueued\n        while the irreversible jobs are still pending). Irreversible\n        jobs can still be cancelled using the cancel\n        command. This job mode should be used on any transaction which\n        pulls in shutdown.target.\"isolate\" is only valid for start\n        operations and causes all other units to be stopped when the\n        specified unit is started. This mode is always used when the\n        isolate command is used.\"flush\" will cause all queued jobs to\n        be canceled when the new job is enqueued.If \"ignore-dependencies\" is specified,\n        then all unit dependencies are ignored for this new job and\n        the operation is executed immediately. If passed, no required\n        units of the unit passed will be pulled in, and no ordering\n        dependencies will be honored. This is mostly a debugging and\n        rescue tool for the administrator and should not be used by\n        applications.\"ignore-requirements\" is similar to\n        \"ignore-dependencies\", but only causes the\n        requirement dependencies to be ignored, the ordering\n        dependencies will still be honored.-T, --show-transactionÂ¶When enqueuing a unit job (for example as effect of a systemctl start\n          invocation or similar), show brief information about all jobs enqueued, covering both the requested\n          job and any added because of unit dependencies. Note that the output will only include jobs\n          immediately part of the transaction requested. It is possible that service start-up program code\n          run as effect of the enqueued jobs might request further jobs to be pulled in. This means that\n          completion of the listed jobs might ultimately entail more jobs than the listed ones.--failÂ¶Shorthand for --job-mode=fail.When used with the kill command,\n          if no units were killed, the operation results in an error.\n          -i, --ignore-inhibitorsÂ¶When system shutdown or a sleep state is requested, ignore inhibitor locks. Applications can establish\n          inhibitor locks to avoid that certain important operations (such as CD burning or suchlike) are interrupted\n          by system shutdown or a sleep state. Any user may take these locks and privileged users may override these\n          locks. If any locks are taken, shutdown and sleep state requests will normally fail (unless privileged) and a\n          list of active locks is printed. However, if --ignore-inhibitors is specified, the\n          established locks are ignored and not shown, and the operation attempted anyway, possibly requiring\n          additional privileges.--dry-runÂ¶Just print what would be done. Currently supported by verbs\n          halt, poweroff, reboot,\n          kexec, suspend, hibernate,\n          hybrid-sleep, suspend-then-hibernate,\n          default, rescue,\n          emergency, and exit.-q, --quietÂ¶Suppress printing of the results of various commands\n          and also the hints about truncated log lines. This does not\n          suppress output of commands for which the printed output is\n          the only result (like show). Errors are\n          always printed.--no-blockÂ¶Do not synchronously wait for the requested operation\n          to finish. If this is not specified, the job will be\n          verified, enqueued and systemctl will\n          wait until the unit's start-up is completed. By passing this\n          argument, it is only verified and enqueued. This option may not be\n          combined with --wait.--waitÂ¶Synchronously wait for started units to terminate again.\n          This option may not be combined with --no-block.\n          Note that this will wait forever if any given unit never terminates\n          (by itself or by getting stopped explicitly); particularly services\n          which use \"RemainAfterExit=yes\".When used with is-system-running, wait\n          until the boot process is completed before returning.--userÂ¶Talk to the service manager of the calling user,\n      rather than the service manager of the system.--systemÂ¶Talk to the service manager of the system. This is the\n      implied default.--failedÂ¶List units in failed state. This is equivalent to\n          --state=failed.--no-wallÂ¶Do not send wall message before halt, power-off and reboot.--globalÂ¶When used with enable and\n          disable, operate on the global user\n          configuration directory, thus enabling or disabling a unit\n          file globally for all future logins of all users.--no-reloadÂ¶When used with enable and\n          disable, do not implicitly reload daemon\n          configuration after executing the changes.--no-ask-passwordÂ¶When used with start and related\n          commands, disables asking for passwords. Background services\n          may require input of a password or passphrase string, for\n          example to unlock system hard disks or cryptographic\n          certificates. Unless this option is specified and the\n          command is invoked from a terminal,\n          systemctl will query the user on the\n          terminal for the necessary secrets. Use this option to\n          switch this behavior off. In this case, the password must be\n          supplied by some other means (for example graphical password\n          agents) or the service might fail. This also disables\n          querying the user for authentication for privileged\n          operations.--kill-who=Â¶When used with kill, choose which\n          processes to send a signal to. Must be one of\n          main, control or\n          all to select whether to kill only the main\n          process, the control process or all processes of the\n          unit. The main process of the unit is the one that defines\n          the life-time of it. A control process of a unit is one that\n          is invoked by the manager to induce state changes of it. For\n          example, all processes started due to the\n          ExecStartPre=,\n          ExecStop= or\n          ExecReload= settings of service units are\n          control processes. Note that there is only one control\n          process per unit at a time, as only one state change is\n          executed at a time. For services of type\n          Type=forking, the initial process started\n          by the manager for ExecStart= is a\n          control process, while the process ultimately forked off by\n          that one is then considered the main process of the unit (if\n          it can be determined). This is different for service units\n          of other types, where the process forked off by the manager\n          for ExecStart= is always the main process\n          itself. A service unit consists of zero or one main process,\n          zero or one control process plus any number of additional\n          processes. Not all unit types manage processes of these\n          types however. For example, for mount units, control processes\n          are defined (which are the invocations of\n          /usr/bin/mount and\n          /usr/bin/umount), but no main process\n          is defined. If omitted, defaults to\n          all.-s, --signal=Â¶When used with kill, choose which\n          signal to send to selected processes. Must be one of the\n          well-known signal specifiers such as SIGTERM, SIGINT or\n          SIGSTOP. If omitted, defaults to\n          SIGTERM.--what=Â¶Select what type of per-unit resources to remove when the clean command is\n          invoked, see below. Takes one of configuration, state,\n          cache, logs, runtime to select the\n          type of resource. This option may be specified more than once, in which case all specified resource\n          types are removed. Also accepts the special value all as a shortcut for\n          specifying all five resource types. If this option is not specified defaults to the combination of\n          cache and runtime, i.e. the two kinds of resources that\n          are generally considered to be redundant and can be reconstructed on next invocation.-f, --forceÂ¶When used with enable, overwrite\n          any existing conflicting symlinks.When used with edit, create all of the\n          specified units which do not already exist.When used with halt, poweroff, reboot or\n          kexec, execute the selected operation without shutting down all units. However, all\n          processes will be killed forcibly and all file systems are unmounted or remounted read-only. This is hence a\n          drastic but relatively safe option to request an immediate reboot. If --force is specified\n          twice for these operations (with the exception of kexec), they will be executed\n          immediately, without terminating any processes or unmounting any file systems. Warning: specifying\n          --force twice with any of these operations might result in data loss. Note that when\n          --force is specified twice the selected operation is executed by\n          systemctl itself, and the system manager is not contacted. This means the command should\n          succeed even when the system manager has crashed.--message=Â¶When used with halt, poweroff or reboot, set a\n          short message explaining the reason for the operation. The message will be logged together with the default\n          shutdown message.--nowÂ¶When used with enable, the units\n          will also be started. When used with disable or\n          mask, the units will also be stopped. The start\n          or stop operation is only carried out when the respective enable or\n          disable operation has been successful.--root=Â¶When used with\n          enable/disable/is-enabled\n          (and related commands), use the specified root path when looking for unit\n          files. If this option is present, systemctl will operate on\n          the file system directly, instead of communicating with the systemd\n          daemon to carry out changes.--runtimeÂ¶When used with enable,\n          disable, edit,\n          (and related commands), make changes only temporarily, so\n          that they are lost on the next reboot. This will have the\n          effect that changes are not made in subdirectories of\n          /etc but in /run,\n          with identical immediate effects, however, since the latter\n          is lost on reboot, the changes are lost too.Similarly, when used with\n          set-property, make changes only\n          temporarily, so that they are lost on the next\n          reboot.--preset-mode=Â¶Takes one of \"full\" (the default),\n          \"enable-only\",\n          \"disable-only\". When used with the\n          preset or preset-all\n          commands, controls whether units shall be disabled and\n          enabled according to the preset rules, or only enabled, or\n          only disabled.-n, --lines=Â¶When used with status, controls the number of journal lines to show, counting from\n          the most recent ones. Takes a positive integer argument, or 0 to disable journal output. Defaults to\n          10.-o, --output=Â¶When used with status, controls the\n          formatting of the journal entries that are shown. For the\n          available choices, see\n          journalctl(1).\n          Defaults to \"short\".--firmware-setupÂ¶When used with the reboot command, indicate to the system's firmware to reboot into\n          the firmware setup interface. Note that this functionality is not available on all systems.--boot-loader-menu=Â¶When used with the reboot command, indicate to the system's boot loader to show the\n          boot loader menu on the following boot. Takes a time value as parameter â indicating the menu timeout. Pass\n          zero in order to disable the menu timeout. Note that not all boot loaders support this\n          functionality.--boot-loader-entry=Â¶When used with the reboot command, indicate to the system's boot loader to boot into\n          a specific boot loader entry on the following boot. Takes a boot loader entry identifier as argument, or\n          \"help\" in order to list available entries. Note that not all boot loaders support this\n          functionality.--reboot-argument=Â¶This switch is used with reboot. The value is architecture and firmware specific. As an example, \"recovery\"\n            might be used to trigger system recovery, and \"fota\" might be used to trigger a\n            âfirmware over the airâ update.--plainÂ¶When used with list-dependencies,\n          list-units or list-machines,\n          the output is printed as a list instead of a tree, and the bullet\n          circles are omitted.-H, --host=Â¶Execute the operation remotely. Specify a hostname, or a\n      username and hostname separated by \"@\", to\n      connect to. The hostname may optionally be suffixed by a\n      port ssh is listening on, separated by \":\", and then a\n      container name, separated by \"/\", which\n      connects directly to a specific container on the specified\n      host. This will use SSH to talk to the remote machine manager\n      instance. Container names may be enumerated with\n      machinectl -H\n      HOST. Put IPv6 addresses in brackets.-M, --machine=Â¶Execute operation on a local container. Specify a\n      container name to connect to.--no-pagerÂ¶Do not pipe output into a pager.--no-legendÂ¶Do not print the legend, i.e. column headers and the\n      footer with hints.-h, --helpÂ¶Print a short help text and exit.\n    --versionÂ¶Print a short version string and exit.Exit statusÂ¶On success, 0 is returned, a non-zero failure code otherwise.systemctl uses the return codes defined by LSB, as defined in\n    LSB 3.0.0.\n    TableÂ 3.Â LSB return codesValueDescription in LSBUse in systemd0\"program is running or service is OK\"unit is active1\"program is dead and /var/run pid file exists\"unit not failed (used by is-failed)2\"program is dead and /var/lock lock file exists\"unused3\"program is not running\"unit is not active4\"program or service status is unknown\"no such unitThe mapping of LSB service states to systemd unit states is imperfect, so it is better to\n    not rely on those return values but to look for specific unit states and substates instead.\n    EnvironmentÂ¶$SYSTEMD_EDITORÂ¶Editor to use when editing units; overrides\n        $EDITOR and $VISUAL. If neither\n        $SYSTEMD_EDITOR nor $EDITOR nor\n        $VISUAL are present or if it is set to an empty\n        string or if their execution failed, systemctl will try to execute well\n        known editors in this order:\n        editor(1),\n        nano(1),\n        vim(1),\n        vi(1).\n        $SYSTEMD_PAGERÂ¶Pager to use when --no-pager is not given; overrides\n      $PAGER. If neither $SYSTEMD_PAGER nor $PAGER are set, a\n      set of well-known pager implementations are tried in turn, including\n      less(1) and\n      more(1), until one is found. If\n      no pager implementation is discovered no pager is invoked. Setting this environment variable to an empty string\n      or the value \"cat\" is equivalent to passing --no-pager.$SYSTEMD_LESSÂ¶Override the options passed to less (by default\n      \"FRSXMK\").Users might want to change two options in particular:KÂ¶XÂ¶See\n      less(1)\n      for more discussion.$SYSTEMD_LESSCHARSETÂ¶Override the charset passed to less (by default \"utf-8\", if\n      the invoking terminal is determined to be UTF-8 compatible).$SYSTEMD_COLORSÂ¶The value must be a boolean. Controls whether colorized output should be\n      generated. This can be specified to override the decision that systemd makes based\n      on $TERM and what the console is connected to.$SYSTEMD_URLIFYÂ¶The value must be a boolean. Controls whether clickable links should be generated in\n      the output for terminal emulators supporting this. This can be specified to override the decision that\n      systemd makes based on $TERM and other conditions.See AlsoÂ¶\nsystemd(1),\n      journalctl(1),\n      loginctl(1),\n      machinectl(1),\n      systemd.unit(5),\n      systemd.resource-control(5),\n      systemd.special(7),\n      wall(1),\n      systemd.preset(5),\n      systemd.generator(7),\n      glob(7)\n",
   "man_entry": "",
   "tldr_summary": "# systemctl\n\n> Control the systemd system and service manager.\n> More information: <https://www.freedesktop.org/software/systemd/man/systemctl.html>.\n\n- List failed units:\n\n`systemctl --failed`\n\n- Start/Stop/Restart/Reload a service:\n\n`systemctl start/stop/restart/reload {{unit}}`\n\n- Show the status of a unit:\n\n`systemctl status {{unit}}`\n\n- Enable/Disable a unit to be started on bootup:\n\n`systemctl enable/disable {{unit}}`\n\n- Mask/Unmask a unit, prevent it to be started on bootup:\n\n`systemctl mask/unmask {{unit}}`\n\n- Reload systemd, scanning for new or changed units:\n\n`systemctl daemon-reload`\n\n- Check if a unit is active:\n\n`systemctl is-active {{unit}}`\n\n- Check if a unit is enabled:\n\n`systemctl is-enabled {{unit}}`\n"
 },
 {
   "command": "tomb",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# tomb\n\n> Manage encrypted storage directories that can be safely transported and hidden in a filesystem.\n\n- Create a new tomb with an initial size of 100MB:\n\n`tomb dig -s {{100}} {{encrypted_directory.tomb}}`\n\n- Create a new key file that can be used to lock a tomb; user will be prompted for a password for the key:\n\n`tomb forge {{encrypted_directory.tomb.key}}`\n\n- Initialize and lock an empty tomb using a key made with `forge`:\n\n`tomb lock {{encrypted_directory.tomb}} -k {{encrypted_directory.tomb.key}}`\n\n- Mount a tomb (by default in /media) using its key, making it usable as a regular filesystem directory:\n\n`tomb open {{encrypted_directory.tomb}} -k {{encrypted_directory.tomb.key}}`\n\n- Close a tomb (fails if the tomb is being used by a process):\n\n`tomb close {{encrypted_directory.tomb}}`\n\n- Forcefully close all open tombs, killing any applications using them:\n\n`tomb slam all`\n\n- List all open tombs:\n\n`tomb list`\n"
 },
 {
   "command": "nmon",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# nmon\n\n> A system administrator, tuner, and benchmark tool.\n\n- Start nmon:\n\n`nmon`\n\n- Save records to file (\"-s 300 -c 288\" by default):\n\n`nmon -f`\n\n- Save records to file with a total of 240 measurements, by taking 30 seconds between each measurement:\n\n`nmon -f -s {{30}} -c {{240}}`\n"
 },
 {
   "command": "rspamc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rspamc\n\n> Command line client for rspamd servers.\n\n- Train the bayesian filter to recognise an email as spam:\n\n`rspamc learn_spam {{path/to/email_file}}`\n\n- Train the bayesian filter to recognise an email as ham:\n\n`rspamc learn_ham {{path/to/email_file}}`\n\n- Generate a manual report on an email:\n\n`rspamc symbols {{path/to/email_file}}`\n\n- Show server statistics:\n\n`rspamc stat`\n"
 },
 {
   "command": "gs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# gs\n\n> GhostScript is a PDF and PostScript interpreter.\n\n- To view a file:\n\n`gs -dQUIET -dBATCH {{file.pdf}}`\n\n- Reduce PDF file size to 150 dpi images for reading on a ebook device:\n\n`gs -dNOPAUSE -dQUIET -dBATCH -sDEVICE=pdfwrite -dPDFSETTINGS=/ebook -sOutputFile={{output.pdf}} {{input.pdf}}`\n\n- Convert PDF file (pages 1 through 3) to an image with 150 dpi resolution:\n\n`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=jpeg -r150 -dFirstPage={{1}} -dLastPage={{3}} -sOutputFile={{output_%d.jpg}} {{input.pdf}}`\n\n- Extract pages from a PDF file:\n\n`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input.pdf}}`\n\n- Merge PDF files:\n\n`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input1.pdf}} {{input2.pdf}}`\n\n- Convert from PostScript file to PDF file:\n\n`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input.ps}}`\n"
 },
 {
   "command": "pwdx",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pwdx\n\n> Print working directory of a process.\n\n- Print current working directory of a process:\n\n`pwdx {{process_id}}`\n"
 },
 {
   "command": "flatpak",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# flatpak\n\n> Build, install and run flatpak applications and runtimes.\n\n- Run an installed application:\n\n`flatpak run {{name}}`\n\n- Install an application from a remote source:\n\n`flatpak install {{remote}} {{name}}`\n\n- List all installed applications and runtimes:\n\n`flatpak list`\n\n- Update all installed applications and runtimes:\n\n`flatpak update`\n\n- Add a remote source:\n\n`flatpak remote-add --if-not-exists {{remote_name}} {{remote_url}}`\n\n- List all configured remote sources:\n\n`flatpak remote-list`\n"
 },
 {
   "command": "inotify-wait",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# inotifywait\n\n> Waits for changes to one or more files.\n\n- Run a command when a file changes:\n\n`while inotifywait {{path/to/file}}; do {{command}}; done`\n\n- Be quiet about watching for changes:\n\n`while inotifywait --quiet {{path/to/file}}; do {{command}}; done`\n\n- Watch a directory recursively for changes:\n\n`while inotifywait --recursive {{path/to/directory}}; do {{command}}; done`\n\n- Exclude files matching a regular expression:\n\n`while inotifywait --recursive {{path/to/directory}} --exlude '{{regex}}'; do {{command}}; done`\n\n- Wait at most 30 seconds:\n\n`while inotifywait --timeout {{30}} {{path/to/file}}; do {{command}}; done`\n\n- Only watch for file modification events:\n\n`while inotifywait --event {{modify}} {{path/to/file}}; do {{command}}; done`\n"
 },
 {
   "command": "tcptraceroute",
   "doc_url": "https://github.com/mct/tcptraceroute",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - mct/tcptraceroute: A traceroute implementation using TCP packets\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmct\n\n/\n\ntcptraceroute\n\n\n\n\n\n\n\n    Watch\n \n      11\n    \n\n\n\n\n      Star\n\n\n      78\n    \n\n\n\n\n          Fork\n\n\n        17\n      \n\n\n\n\n\n        A traceroute implementation using TCP packets\n      \n\n\n\nmichael.toren.net/code/tcptraceroute/\n\n\n\n\n\n            GPL-2.0 License\n        \n\n\n\n\n78\n        stars\n \n\n17\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n3\n \n\n\n\nPull requests\n3\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n19\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nmct\n\nCall `pcap_lib_version()` rather than access `pcap_version` directly\n\n\n\n…\n\n\n\n3772409\n\nMay 5, 2017\n\n\n\n\n\nCall `pcap_lib_version()` rather than access `pcap_version` directly\n\nCloses #5\n\nThanks!\n\n3772409\n\n\n\nGit stats\n\n\n\n\n\n29\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\nAUTHORS\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING\n\n\n \n\n\n \n\n\n\n\n\n\n\nChangeLog\n\n\n \n\n\n \n\n\n\n\n\n\n\nINSTALL\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile.am\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nNEWS\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME\n\n\n \n\n\n \n\n\n\n\n\n\n\nVERSION\n\n\n \n\n\n \n\n\n\n\n\n\n\naclocal.m4\n\n\n \n\n\n \n\n\n\n\n\n\n\ncapture.c\n\n\n \n\n\n \n\n\n\n\n\n\n\ncapture.h\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.guess\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.h.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.sub\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfigure\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfigure.ac\n\n\n \n\n\n \n\n\n\n\n\n\n\ndatalink.c\n\n\n \n\n\n \n\n\n\n\n\n\n\ndatalink.h\n\n\n \n\n\n \n\n\n\n\n\n\n\nexamples.txt\n\n\n \n\n\n \n\n\n\n\n\n\n\ninstall-sh\n\n\n \n\n\n \n\n\n\n\n\n\n\nmain.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nmissing\n\n\n \n\n\n \n\n\n\n\n\n\n\nmkinstalldirs\n\n\n \n\n\n \n\n\n\n\n\n\n\nprobe.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nprobe.h\n\n\n \n\n\n \n\n\n\n\n\n\n\nstamp-h.in\n\n\n \n\n\n \n\n\n\n\n\n\n\ntcptraceroute.1\n\n\n \n\n\n \n\n\n\n\n\n\n\ntcptraceroute.1.html\n\n\n \n\n\n \n\n\n\n\n\n\n\ntcptraceroute.h\n\n\n \n\n\n \n\n\n\n\n\n\n\ntcptraceroute.lsm\n\n\n \n\n\n \n\n\n\n\n\n\n\ntestsuite.pl\n\n\n \n\n\n \n\n\n\n\n\n\n\ntraceroute.cgi\n\n\n \n\n\n \n\n\n\n\n\n\n\nutil.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nutil.h\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README\n      \n\n\ntcptraceroute -- A traceroute implementation using TCP packets\nCopyright (c) 2001-2015  Michael C. Toren <mct@toren.net>\n\nUpdates are available from <http://michael.toren.net/code/tcptraceroute/>\n\nRequires libnet <http://www.packetfactory.net/libnet> and libpcap\n<http://www.tcpdump.org/>.  For compilation instructions, see the\nINSTALL file.\n\nThis program is free software; you can redistribute it and/or modify it\nunder the terms of the GNU General Public License, version 2, as published\nby the Free Software Foundation.\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\nor FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\nfor more details.\n\nA copy of the GNU GPL is available as /usr/doc/copyright/GPL on Debian\nsystems, or on the World Wide Web at http://www.gnu.org/copyleft/gpl.html\nYou can also obtain it by writing to the Free Software Foundation, Inc.,\n59 Temple Place - Suite 330, Boston, MA 02111-1307, USA\n\n\n\n\n\n\n\n\nAbout\n\n      A traceroute implementation using TCP packets\n    \n\n\n\nmichael.toren.net/code/tcptraceroute/\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-2.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\n\n\n19\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 2\n\n\n\n\n\n \n\nmct\nMichael Toren\n \n\n\n\n\n \n\njbackman\nJustin Backman\n \n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC\n52.5%\n\n\n\n\n\nMakefile\n12.4%\n\n\n\n\n\nShell\n11.2%\n\n\n\n\n\nM4\n7.3%\n\n\n\n\n\nHTML\n6.5%\n\n\n\n\n\nRoff\n5.3%\n\n\n\n\n\nPerl\n4.8%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# tcptraceroute\n\n> A traceroute implementation using TCP packets.\n> More information: <https://github.com/mct/tcptraceroute>.\n\n- Trace the route to a host:\n\n`tcptraceroute {{host}}`\n\n- Specify the destination port and packet length in bytes:\n\n`tcptraceroute {{host}} {{destination_port}} {{packet_length}}`\n\n- Specify the local source port and source address:\n\n`tcptraceroute {{host}} -p {{source_port}} -s {{source_address}}`\n\n- Set the first and maximum TTL:\n\n`tcptraceroute {{host}} -f {{first_ttl} -m {{max_ttl}}`\n\n- Specify the wait time and number of queries per hop:\n\n`tcptraceroute {{host}} -w {{wait_time}} -q {{number_of_queries}}`\n\n- Specify the interface:\n\n`tcptraceroute {{host}} -i {{interface}}`\n"
 },
 {
   "command": "fc-match",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "FC-MATCH(1)\t\t\t\t\t\t\t   FC-MATCH(1)\n\n\n\nNAME\n       fc-match - match available fonts\n\nSYNOPSIS\n       fc-match [ -asvVh ]  [ --all ]  [ --sort ]  [ --verbose ]  [  [ -f for-\n       mat ]  [ --format format ]  ]  [ --version ]  [ --help ]\n\n\t[ pattern  [ element... ]   ]\n\nDESCRIPTION\n       fc-match matches pattern (empty pattern by default)  using  the\tnormal\n       fontconfig matching rules to find the best font available. If --sort is\n       given, the sorted list of best matching fonts is displayed.  The  --all\n       option  works like --sort except that no pruning is done on the list of\n       fonts.\n\n       If any elements are specified, only those are printed.  Otherwise short\n       file  name,  family,  and  style  are printed, unless verbose output is\n       requested.\n\nOPTIONS\n       This program follows the usual  GNU  command  line  syntax,  with  long\n       options\tstarting  with\ttwo  dashes  (`-').  A\tsummary  of options is\n       included below.\n\n       -a     Displays sorted list of best matching fonts, but do not  do  any\n\t      pruning on the list.\n\n       -s     Displays sorted list of best matching fonts.\n\n       -v     Print  verbose  output of the whole font pattern for each match,\n\t      or elements if any is provided.\n\n       -f     Format output according to the format specifier format.\n\n       -V     Show version of the program and exit.\n\n       -h     Show summary of options.\n\n       pattern\n\t      Displays fonts matching pattern (uses empty pattern by default).\n\n       element\n\t      If set, the element property is displayed for matching fonts.\n\nSEE ALSO\n       fc-list(1)  FcFontMatch(3)  FcFontSort(3)  FcPatternFormat(3) fc-cat(1)\n       fc-cache(1) fc-pattern(1) fc-query(1) fc-scan(1)\n\n       The fontconfig user's guide, in\tHTML  format:  /usr/share/doc/fontcon-\n       fig/fontconfig-user.html.\n\nAUTHOR\n       This manual page was updated by Patrick Lam <plam@csail.mit.edu>.\n\n\n\n\t\t\t\t Aug 13, 2008\t\t\t   FC-MATCH(1)\n",
   "tldr_summary": "# fc-match\n\n> Match available fonts.\n\n- Return a sorted list of best matching fonts:\n\n`fc-match -s '{{DejaVu Serif}}'`\n"
 },
 {
   "command": "conky",
   "doc_url": "https://github.com/brndnmtthws/conky",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - brndnmtthws/conky: Light-weight system monitor for X.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbrndnmtthws\n\n/\n\nconky\n\n\n\n\n\n\n\n\n          Sponsor\n        \n\n\n\n\n\n\n              Sponsor brndnmtthws/conky\n            \n\n\n\n\n\n\n\n\n\n\n\n\n    Watch\n \n      177\n    \n\n\n\n\n      Star\n\n\n      4.2k\n    \n\n\n\n\n          Fork\n\n\n        471\n      \n\n\n\n\n\n        Light-weight system monitor for X.\n      \n\n\n\ngithub.com/brndnmtthws/conky/wiki\n\n\n\n\n\n            View license\n        \n\n\n\n\n4.2k\n        stars\n \n\n471\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n180\n \n\n\n\nPull requests\n2\n \n\n\n\nActions\n\n \n\n\n\nProjects\n2\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nbranches\n\n\n\n43\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n \n\n\n\n\nBojanoN\n\n\n   and   brndnmtthws\n\nfixed nil value call error while converting old sytax config\n\n\n\n…\n\n\n\n1abae95\n\nAug 31, 2020\n\n\n\n\n\nfixed nil value call error while converting old sytax config\n\n\n1abae95\n\n\n\nGit stats\n\n\n\n\n\n3,522\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github\n\n\n\nCreate FUNDING.yml\n\n\n\nJul 27, 2020\n\n\n\n\n\n\n\n3rdparty/toluapp\n\n\n\nDrop luajit support (Lua 5.1 API).\n\n\n\nDec 24, 2018\n\n\n\n\n\n\n\nappimage\n\n\n\nTest `make install` target, and release build.\n\n\n\nMar 9, 2019\n\n\n\n\n\n\n\nbin\n\n\n\nFix python command for clang checks (2 -> 3).\n\n\n\nJan 8, 2020\n\n\n\n\n\n\n\ncmake\n\n\n\nBump version for next release.\n\n\n\nJul 27, 2020\n\n\n\n\n\n\n\ndata\n\n\n\nfix alignment in default conf\n\n\n\nOct 19, 2019\n\n\n\n\n\n\n\ndoc\n\n\n\nAdd missing mpd_comment variable.\n\n\n\nJul 27, 2020\n\n\n\n\n\n\n\nextras\n\n\n\nfixed nil value call error while converting old sytax config\n\n\n\nAug 31, 2020\n\n\n\n\n\n\n\nlogo\n\n\n\nAdd AppImage integration.\n\n\n\nJan 9, 2019\n\n\n\n\n\n\n\nlua\n\n\n\nAdd clang 8 to builds.\n\n\n\nApr 14, 2019\n\n\n\n\n\n\n\nsrc\n\n\n\nAdd missing mpd_comment variable.\n\n\n\nJul 27, 2020\n\n\n\n\n\n\n\ntests\n\n\n\nAdd Tests in new Test files (#852)\n\n\n\nJun 20, 2019\n\n\n\n\n\n\n\n.clang-format\n\n\n\nMake GitLab build work with clang checks.\n\n\n\nFeb 23, 2019\n\n\n\n\n\n\n\n.clang-tidy\n\n\n\nMake GitLab build work with clang checks.\n\n\n\nFeb 23, 2019\n\n\n\n\n\n\n\n.dockerignore\n\n\n\nRefactor Dockerfile.\n\n\n\nFeb 21, 2019\n\n\n\n\n\n\n\n.editorconfig\n\n\n\nApply a bunch of code fixes from sonarcloud. (#492)\n\n\n\nMay 13, 2018\n\n\n\n\n\n\n\n.gitignore\n\n\n\nAdd AppImage integration.\n\n\n\nJan 9, 2019\n\n\n\n\n\n\n\n.gitlab-ci.yml\n\n\n\nFix image push commands in gitlab build.\n\n\n\nApr 14, 2019\n\n\n\n\n\n\n\n.travis.yml\n\n\n\nFix for appimage build.\n\n\n\nJun 23, 2019\n\n\n\n\n\n\n\nAUTHORS\n\n\n\nAdd Google LLC to AUTHORS\n\n\n\nMar 3, 2019\n\n\n\n\n\n\n\nCMakeLists.txt\n\n\n\nAdd a separate option for building html documentation.\n\n\n\nMar 27, 2019\n\n\n\n\n\n\n\nCONTRIBUTING.md\n\n\n\nReorganize, adjust wording.\n\n\n\nMar 4, 2019\n\n\n\n\n\n\n\nCOPYING\n\n\n\nupdate copyright year to 2019\n\n\n\nJan 5, 2019\n\n\n\n\n\n\n\nDockerfile\n\n\n\nRefactor Dockerfile.\n\n\n\nFeb 21, 2019\n\n\n\n\n\n\n\nLICENSE\n\n\n\nGPLv3 is the default license.\n\n\n\nJan 25, 2018\n\n\n\n\n\n\n\nLICENSE.BSD\n\n\n\nAdd note on GPL licensing.\n\n\n\nMar 3, 2019\n\n\n\n\n\n\n\nREADME.cmake\n\n\n\nDeprecate autotools, update docs to reflect cmake build system.\n\n\n\nJan 1, 2010\n\n\n\n\n\n\n\nREADME.docker\n\n\n\nUsing X11 conky in a container\n\n\n\nFeb 18, 2018\n\n\n\n\n\n\n\nREADME.md\n\n\n\nUpdate README.md\n\n\n\nNov 1, 2019\n\n\n\n\n\n\n\nconky.desktop\n\n\n\nAdd AppImage integration.\n\n\n\nJan 9, 2019\n\n\n\n\n\n\n\nsonar-project.properties\n\n\n\nAdd some basic unit tests.\n\n\n\nDec 24, 2018\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\n  \n\nConky is a free, light-weight system monitor for X, that displays\nany kind of information on your desktop.\n👉 Grab the latest release from GitHub.\n📹 An introduction to Conky (YouTube).\nFeatures\nConky can display more than 300 built-in objects, including support for:\n\nA plethora of OS stats (uname, uptime, CPU usage, mem\nusage, disk usage, \"top\" like process stats, and network\nmonitoring, just to name a few).\nBuilt-in IMAP and POP3 support.\nBuilt-in support for many popular music players (MPD,\nXMMS2, Audacious).\nCan be extended using built-in Lua support, or any of your\nown scripts and programs (more).\nBuilt-in Imlib2 and Cairo bindings for arbitrary drawing\nwith Lua (more).\nRuns on Linux, FreeBSD, OpenBSD, DragonFlyBSD, NetBSD, Solaris, Haiku OS, and macOS!\n\n... and much much more.\nConky can display information either as text, or using simple progress\nbars and graph widgets, with different fonts and colours.\nScreenshots\n\n\n\nSee the User Configs below for more screenshots and associated config files.\nQuickstart\nConky comes bundled with many package managers. However, if you'd like to try the latest release of Conky, you can try the AppImage build. If you have jq and curl installed, run the following command to fetch the latest AppImage:\n$ curl -sL -o conky-x86_64.AppImage \\\n    $(curl -sL https://api.github.com/repos/brndnmtthws/conky/releases/latest | \\\n    jq --raw-output '.assets[0] | .browser_download_url')\n$ ls\nconky-x86_64.AppImage\nIf you don't have jq and curl installed, go to\nhttps://github.com/brndnmtthws/conky/releases/latest and fetch the latest\nAppImage. Then:\n$ chmod +x ./conky-x86_64.AppImage\n$ ./conky-x86_64.AppImage -C > ~/.conkyrc\n$ ./conky-x86_64.AppImage\nAnd that's it! Check out the Wiki for more details on configuring Conky.\nNote: To use the AppImage, you may need to install additional runtime libraries.\nDocumentation\nThe GitHub Wiki serves as a central hub for all of\nConky's documentation.\n\nInstallation\nConfiguration Settings\nUser Configs\nFrequently Asked Questions\n\nLicense\nConky is licensed under the terms of the GPLv3 license.\nContributing\nContributions are welcome from anyone.\nPlease read CONTRIBUTING.md for guidelines on contributing to Conky.\n\n\n\n\n\n\n\n\nAbout\n\n      Light-weight system monitor for X.\n    \n\n\n\ngithub.com/brndnmtthws/conky/wiki\n\n\nTopics\n\n\n\n  conky\n\n\n  imlib2\n\n\n  cairo\n\n\n  lua\n\n\n  c-plus-plus\n\n\n  system-monitoring\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n      43\n\n\n\n\n\nConky v1.11.6\n\n          Latest\n \nJul 27, 2020\n\n \n\n        + 42 releases\n\n\n\n\n\nSponsor this project\n\n\n\n \n\n\n Sponsor\n        \n\n  Learn more about GitHub Sponsors\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 123\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 112 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++\n84.0%\n\n\n\n\n\nC\n6.4%\n\n\n\n\n\nCMake\n4.8%\n\n\n\n\n\nObjective-C++\n2.3%\n\n\n\n\n\nPython\n1.5%\n\n\n\n\n\nVim script\n0.4%\n\n\n\n\n\nOther\n0.6%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# conky\n\n> Light-weight system monitor for X.\n> More information: <https://github.com/brndnmtthws/conky>.\n\n- Launch with default, built-in config:\n\n`conky`\n\n- Create a new default config:\n\n`conky -C > ~/.conkyrc`\n\n- Launch conky with a given config file:\n\n`conky -c {{path/to/config}}`\n\n- Start in the background (daemonize):\n\n`conky -d`\n\n- Align conky on the desktop:\n\n`conky -a {{{top,bottom,middle}_{left,right,middle}}}`\n\n- Pause for 5 seconds at startup before launching:\n\n`conky -p {{5}}`\n"
 },
 {
   "command": "wpa_cli",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# wpa_cli\n\n> Add and configure wlan interfaces.\n\n- Scan for available networks:\n\n`wpa_cli scan`\n\n- Show scan results:\n\n`wpa_cli scan_results`\n\n- Add a network:\n\n`wpa_cli add_network {{number}}`\n\n- Set a network's SSID:\n\n`wpa_cli set_network {{number}} ssid \"{{SSID}}\"`\n\n- Enable network:\n\n`wpa_cli enable_network {{number}}`\n\n- Save config:\n\n`wpa_cli save_config`\n"
 },
 {
   "command": "mycli",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mycli\n\n> A CLI for MySQL, MariaDB, and Percona with auto-completion and syntax highlighting.\n\n- Connect to a database with the currently logged in user:\n\n`mycli {{database_name}}`\n\n- Connect to a database with the specified user:\n\n`mycli -u {{user}} {{database_name}}`\n\n- Connect to a database on the specified host with the specified user:\n\n`mycli -u {{user}} -h {{host}} {{database_name}}`\n"
 },
 {
   "command": "apt",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "apt(1)\t\t\t\t\t\t\t\t\tapt(1)\n\n\n\nNAME\n       apt - annotation processing tool\n\nSYNOPSIS\n       apt  [ -classpath classpath ] [ -sourcepath sourcepath ] [ -d directory\n       ] [ -s directory ] [ -factorypath path ] [ -factory class ] [ -print  ]\n       [  -nocompile  ] [ -A [ key [ =val ] ] ] [ javac option ] sourcefiles [\n       @files ]\n\nDESCRIPTION\n       The tool apt, annotation processing tool, includes a set of new reflec-\n       tive APIs and supporting infrastructure to process program annotations.\n       The apt reflective APIs provide a build-time,  source-based,  read-only\n       view  of  program  structure.  These  reflective  APIs  are designed to\n       cleanly model the JavaTM programming language's type system  after  the\n       addition  of  generics.\tFirst, apt runs annotation processors that can\n       produce new source code and other files. Next, apt can  cause  compila-\n       tion  of  both original and generated source files, easing development.\n       The reflective APIs and other APIs used to interact with the  tool  are\n       subpackages of com.sun.mirror.\n\n       A  fuller  discussion  of how the tool operates as well as instructions\n       for  developing\twith  apt  are\tin  Getting  Started   with   apt   at\n       http://java.sun.com/j2se/1.5.0/docs/guide/apt/GettingStarted.html.\n\nPARAMETERS\n       Options may be in any order. For a discussion of parameters which apply\n       to a specific option, see OPTIONS below.\n\n       sourcefiles    Zero or more source files to be processed.\n\n       @files\t      One or more  files  that\tlist  source  files  or  other\n\t\t      options.\n\nOPTIONS\n   apt specific options\n       -s dir\t      Specify  the directory root under which processor-gener-\n\t\t      ated source files will be placed; files  are  placed  in\n\t\t      subdirectories based on package namespace.\n\n       -nocompile     Do not compile sources files to class files.\n\n       -print\t      Print  out  textual  representation  of specified types;\n\t\t      perform no annotation processing or compilation.\n\n       -A[key[=val]]  Options to pass to annotation processors\t--  these  are\n\t\t      not  interpreted by apt directly, but are made available\n\t\t      for use by individual processors\n\n       -factorypath path\n\t\t      Specify where to find annotation processor factories; if\n\t\t      this  option  is used, the classpath is not searched for\n\t\t      factories.\n\n       -factory classname\n\t\t      Name of annotation processor factory  to\tuse;  bypasses\n\t\t      default discovery process\n\n   Options shared with javac\n       -d dir\t      Specify  where  to  place  processor and javac generated\n\t\t      class files\n\n       -cp path       or\n       -classpath path\n\t\t      Specify where to find user class\tfiles  and  annotation\n\t\t      processor  factories.  If  -factorypath  is  given,  the\n\t\t      classpath is not searched for factories.\n\n       Consult the javac(1) man page for information on javac options.\n\nNOTES\n       The apt tool and its associated APIs may be changed  or\tsuperseded  in\n       future j2se releases.\n\nSEE ALSO\n       javac(1) java(1)\n\n\n\n\t\t\t\t 13 June 2004\t\t\t\tapt(1)\n",
   "tldr_summary": "# apt\n\n> Package management utility for Debian based distributions.\n> Recommended replacement for apt-get when used interactively in Ubuntu versions 16.04 and later.\n\n- Update the list of available packages and versions (it's recommended to run this before other `apt` commands):\n\n`sudo apt update`\n\n- Search for a given package:\n\n`apt search {{package}}`\n\n- Show information for a package:\n\n`apt show {{package}}`\n\n- Install a package, or update it to the latest available version:\n\n`sudo apt install {{package}}`\n\n- Remove a package (using `purge` instead also removes its configuration files):\n\n`sudo apt remove {{package}}`\n\n- Upgrade all installed packages to their newest available versions:\n\n`sudo apt upgrade`\n\n- List all packages:\n\n`apt list`\n\n- List installed packages:\n\n`apt list --installed`\n"
 },
 {
   "command": "runit",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# runit\n\n> 3-stage init system.\n\n- Start runit's 3-stage init scheme:\n\n`runit`\n\n- Shut down runit:\n\n`kill --CONT {{runit_pid}}`\n"
 },
 {
   "command": "http_load",
   "doc_url": "http://www.acme.com/software/http_load/",
   "doc_text": "\n\n\n\n\nhttp_load\n\n\n\nhttp_load - multiprocessing http test client\nFetch the software.\n\n\n\n      http_load runs multiple http fetches in parallel, to test the throughput\n      of a web server.\n      However unlike most such test clients, it runs in a single process,\n      so it doesn't bog down the client machine.\n      It can be configured to do https fetches as well.\n    \n\n      You give it a file containing a list of URLs that may be fetched,\n      a flag specifying how to start connections (either by rate or\n      by number of simulated users), and a flag specifying when to quit\n      (either after a given number of fetches or a given elapsed time).\n      There are also optional flags for checksums, throttling, random jitter,\n      and progress reports.\n    \n\n      Sample run:\n    \n\n% ./http_load -rate 5 -seconds 10 urls\n49 fetches, 2 max parallel, 289884 bytes, in 10.0148 seconds\n5916 mean bytes/connection\n4.89274 fetches/sec, 28945.5 bytes/sec\nmsecs/connect: 28.8932 mean, 44.243 max, 24.488 min\nmsecs/first-response: 63.5362 mean, 81.624 max, 57.803 min\nHTTP response codes:\n  code 200 -- 49\n    \n\n      See the manual entry for more details.\n    \n\n\n\n      See also:\n      http_ping,\n      http_get,\n      thttpd.\nA page of other http load-test tools.\nACME Labs / Software / http_load\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# http_load\n\n> A HTTP benchmarking tool.\n> Runs multiple HTTP fetches in parallel to test the throughput of a web server.\n> More information: <http://www.acme.com/software/http_load/>.\n\n- Emulate 20 requests based on a given URL list file per second for 60 seconds:\n\n`http_load -rate {{20}} -seconds {{60}} {{path/to/urls.txt}}`\n\n- Emulate 5 concurrent requests based on a given URL list file for 60 seconds:\n\n`http_load -parallel {{5}} -seconds {{60}} {{path/to/urls.txt}}`\n\n- Emulate 1000 requests at 20 requests per second, based on a given URL list file:\n\n`http_load -rate {{20}} -fetches {{1000}} {{path/to/urls.txt}}`\n\n- Emulate 1000 requests at 5 concurrent requests at a time, based on a given URL list file:\n\n`http_load -parallel {{5}} -fetches {{1000}} {{path/to/urls.txt}}`\n"
 },
 {
   "command": "pstree",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pstree\n\n> A convenient tool to show running processes as a tree.\n\n- Display a tree of processes:\n\n`pstree`\n\n- Display a tree of processes with PIDs:\n\n`pstree -p`\n\n- Display all process trees rooted at processes owned by specified user:\n\n`pstree {{user}}`\n"
 },
 {
   "command": "nm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "NM(1)\t\t\t\t\t\t\t\t\t NM(1)\n\n\n\nNAME\n       nm - display name list (symbol table)\n\nSYNOPSIS\n       llvm-nm [ -agnoprumxjlPA ] [ - ] [ -t format ] [[ -arch arch_flag ]...]\n       [ file ... ] [ -s segname sectname ]\n\n       nm-classic [ -agnoprumxjlfPA [ s segname sectname ]] [ - ] [ -t\tformat\n       ] [[ -arch arch_flag ]...] [ file ... ]\n\nDESCRIPTION\n       As  of  Xcode  8.0  the default nm(1) tool is llvm-nm(1).  They for the\n       most part have the same options except for -f and -s which the  differ-\n       ences are noted below.  More help on options for llvm-nm(1) is provided\n       when running it with the --help option.\n\n       Nm displays the name list (symbol table of nlist  structures)  of  each\n       object  file  in  the  argument list.  In some cases, as with an object\n       that has had strip(1) with its -T option used on the object,  that  can\n       be different than the dyld information.\tFor that information use dyld-\n       info(1).\n\n       If an argument is an archive, a listing for each object file in the ar-\n       chive  will be produced.  File can be of the form libx.a(x.o), in which\n       case only symbols from that member of the object file are listed.  (The\n       parentheses  have  to  be  quoted  to get by the shell.)  If no file is\n       given, the symbols in a.out are listed.\n\n       Each symbol name is  preceded  by  its  value  (blanks  if  undefined).\n       Unless the -m option is specified, this value is followed by one of the\n       following characters, representing the symbol type:  U  (undefined),  A\n       (absolute),  T  (text  section symbol), D (data section symbol), B (bss\n       section symbol), C  (common  symbol),  -  (for  debugger  symbol  table\n       entries; see -a below), S (symbol in a section other than those above),\n       or I (indirect symbol).\tIf the symbol  is  local  (non-external),  the\n       symbol's  type  is  instead  represented by the corresponding lowercase\n       letter.\tA lower case u in a dynamic shared library indicates  a  unde-\n       fined  reference  to  a\tprivate external in another module in the same\n       library.\n\n       If  the\tsymbol\tis  a  Objective  C  method,  the   symbol   name   is\n       +-[Class_name(category_name)  method:name:],  where  `+'  is  for class\n       methods, `-' is for instance methods, and  (category_name)  is  present\n       only when the method is in a category.\n\n       The output is sorted alphabetically by default.\n\n       Options are:\n\n       -a     Display  all  symbol table entries, including those inserted for\n\t      use by debuggers.\n\n       -g     Display only global (external) symbols.\n\n       -n     Sort numerically rather than alphabetically.\n\n       -o     Prepend file or archive element name to each output line, rather\n\t      than only once.\n\n       -p     Don't sort; display in symbol-table order.\n\n       -r     Sort in reverse order.\n\n       -u     Display only undefined symbols.\n\n       -U     Don't display undefined symbols.\n\n       -m     Display  the  N_SECT  type  symbols  (Mach-O  symbols)  as (seg-\n\t      ment_name, section_name) followed by  either  external  or  non-\n\t      external\tand then the symbol name.  Undefined, common, absolute\n\t      and indirect symbols get\tdisplayed  as  (undefined),  (common),\n\t      (absolute), and (indirect), respectively.\n\n       -x     Display  the  symbol  table entry's fields in hexadecimal, along\n\t      with the name as a string.\n\n       -j     Just display the symbol names (no value or type).\n\n       -s segname sectname\n\t      List only those symbols in the section (segname,sectname).   For\n\t      llvm-nm(1)  this\toption\tmust  be last on the command line, and\n\t      after the files.\n\n       -l     List a pseudo symbol .section_start if  no  symbol  has  as  its\n\t      value  the  starting address of the section.  (This is used with\n\t      the -s option above.)\n\n       -arch arch_type\n\t      Specifies the architecture, arch_type, of the file for nm(1)  to\n\t      operate  on  when  the file is a universal file (see arch(3) for\n\t      the currently known arch_types).\tThe arch_type can be \"all\"  to\n\t      operate  on  all\tarchitectures  in the file.  The default is to\n\t      display the symbols from only the host architecture, if the file\n\t      contains\tit;  otherwise,  symbols  for all architectures in the\n\t      file are displayed.\n\n       -f  format\n\t      For llvm-nm(1) this specifies the output format.\t Where\tformat\n\t      can be bsd, sysv, posix or darwin.\n\n       -f     For  nm-classic(1)  this\tdisplays the symbol table of a dynamic\n\t      library flat (as one file not separate modules).\tThis is  obso-\n\t      lete and not supported with llvm-nm(1).\n\n       -A     Write the pathname or library name of an object on each line.\n\n       -P     Write information in a portable output format.\n\n       -t format\n\t      For the -P output, write the numeric value in the specified for-\n\t      mat. The format shall be dependent on the single character  used\n\t      as the format option-argument:\n\n       d      The value shall be written in decimal (default).\n\n       o      The value shall be written in octal.\n\n       x      The value shall be written in hexadecimal.\n\n       -L     Display  the  symbols in the bitcode files in the (__LLVM,__bun-\n\t      dle) section if present instead of the  object's\tsymbol\ttable.\n\t      This  is the default if the object has no symbol table and there\n\t      is an (__LLVM,__bundle) section.\n\nSEE ALSO\n       ar(1), ar(5), Mach-O(5), stab(5), nlist(3), dyldinfo(1)\n\nBUGS\n       Displaying Mach-O symbols with -m is too verbose.  Without the -m, sym-\n       bols in the Objective C sections get displayed as an `s'.\n\n\n\nApple, Inc.\t\t\t May 23, 2017\t\t\t\t NM(1)\n",
   "tldr_summary": "# nm\n\n> List symbol names in object files.\n\n- List global (extern) functions in a file (prefixed with T):\n\n`nm -g {{file.o}}`\n\n- List only undefined symbols in a file:\n\n`nm -u {{file.o}}`\n\n- List all symbols, even debugging symbols:\n\n`nm -a {{file.o}}`\n\n- Demangle C++ symbols (make them readable):\n\n`nm --demangle {{file.o}}`\n"
 },
 {
   "command": "xinput",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xinput\n\n> List available input devices, query information about a device and change input device settings.\n\n- List all input devices:\n\n`xinput list`\n\n- Disable an input:\n\n`xinput disable {{id}}`\n\n- Enable an input:\n\n`xinput enable {{id}}`\n\n- Disconnect an input from its master:\n\n`xinput float {{id}}`\n\n- Reattach an input as slave to a master:\n\n`xinput reattach {{id}} {{master_id}}`\n"
 },
 {
   "command": "viewnior",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# viewnior\n\n> Simple and elegant image viewer.\n\n- View an image:\n\n`viewnior {{path/to/image.ext}}`\n\n- View in fullscreen mode:\n\n`viewnior --fullscreen {{path/to/image.ext}}`\n\n- View fullscreen in slideshow mode:\n\n`viewnior --slideshow {{path/to/image.ext}}`\n"
 },
 {
   "command": "cpulimit",
   "doc_url": "http://cpulimit.sourceforge.net/",
   "doc_text": "\n\nCPU limit\n\n\n\n\n\n\n\n\n\n\nCPU Usage Limiter for Linux\n\n\n\n\n\nWhat is it?\ncpulimit is a simple program which attempts to limit the cpu usage of a process\n(expressed in percentage, not in cpu time).\nThis is useful to control batch jobs, when you don't want them to eat too much cpu.\nIt does not act on the nice value or other scheduling priority stuff, but on the real cpu usage.\nAlso, it is able to adapt itself to the overall system load, dynamically and quickly.\n\n\nNews\n23 May 2012\nCPUlimit has moved to github. Follow me and stay tuned.\n\n\n23 May 2012\nNerd enough? Check out my new blog :)\n\n\n29 November 2010\nAre you a Londoner? If so, why don't you check out my new project ?\n\n\n26 August 2010\nThis is just to say I love open source. I really do. I'm receiving everyday new patches, suggestions, ports, feature requests (and even compliments).\nThis is the strength of open source, it grows thanks to the community.\n\nKeep going!\n\n25 July 2010\nAre you a mathematician, physicist, scientist, or just a curious person? Check out my new project thomthom\n\n14 May 2009\nDo you like cpulimit?\nNominate it as the best tool for sysadmins!\n\n26 November 2008\nAbcuser has written a great HOWTO for Ubuntu users. Check it out here!\n\n10 September 2008\nA team of researchers is successfully using cpulimit on Mare Nostrum, one of the most powerful computers in Europe. And I'm not kidding :)\n\n7 September 2008\nSpecial thanks to Wyatt for the donation and for providing me a Mac OS X shell.\n\n30 August 2008\nI've received a lot of requests for porting cpulimit to Mac OS X. So I've decided to do it, maybe there will be also a GUI. Stay tuned!\n\n10 August 2008\nBig thanks to Alexander, who made a huge donation to cpulimit.\n\n16 February 2008\nAs promised, the subprocesses control implementation is at last in cpulimit svn. Check it out!\n\n10 February 2008\nA subversion repository is available thanks to sourceforge.\nYou can get latest source code (still unstable!) running the command:\nsvn checkout https://cpulimit.svn.sourceforge.net/svnroot/cpulimit/trunk cpulimit\nOr you can browse the code from the web interface.\n\n8 February 2008\nStarted subprocesses control implementation, since a lot of people are asking about this feature.\nSo stay tuned for a new version.\n\n18 January 2007\nNow the project is listed on the FSF/UNESCO Free Software Directory. Very glad for that!\n\n26 December 2006\n\nNew homepage at http://cpulimit.sourceforge.net\n\n23 December 2006\nSource uploaded to sourceforge.\n\n9 August 2006\nStarted a new project at sourceforge. You can see it here.\n\nHow it works\n\nNote that you don't need to read this paragraph in order to use cpulimit, you can safely skip it if you are not interested in tweaking cpulimit.\nSo, you are curious to know the secrets of cpulimit :) Of course there is no secret if you are a C developer, but I will try to explain to everyone.\nThe work of cpulimit is done all in userspace, so it doesn't interfere with the Linux scheduler.\nBasically, the target process, which you can specify by pid, name, or command line, is continuosly paused and resumed by sending it SIGSTOP and SIGCONT signals. Signals are sent by cpulimit in appropriate moments, based on the limit specified by user and the process statistics read from /proc.\n[To be continued...]\n\nSystem Requirements\ncpulimit should run on every Linux 2.2 or greater.\nIt has been reported by several users that cpulimit works fine even on SMP hardware, but consider that if you have more than one cpu there is\na little difference in the meaning of cpu usage (see below).\nIf you can modify the source code of cpulimit to make it run in another OS, please notify me, so I can publish your code.\nI think that the only non-portable code is to iterate through the process list and get process statistics.\n\nInstructions\nDownload last stable version from here or get the latest source code from Subversion repository with this command:\nsvn checkout https://cpulimit.svn.sourceforge.net/svnroot/cpulimit/trunk cpulimit\nThen extract the source and compile with make:\n\ntar zxf cpulimit-xxx.tar.gz\ncd cpulimit-xxx\nmake\n\n\nExecutable file name is cpulimit. You may want to copy it in /usr/bin.\n\nExamples of use\n\nLimit the process 'bigloop' by executable name to 40% CPU:\n\ncpulimit --exe bigloop --limit 40\ncpulimit --exe /usr/local/bin/bigloop --limit 40\n\nLimit a process by PID to 55% CPU:\n\ncpulimit --pid 2960 --limit 55\n\nLaunch a process by command line and limit it to 40% (in development version only!):\n\ncpulimit --limit 40 /etc/rc.d/rc.boinc start\n\nNotes\n\nIf your machine has one processor you can limit the percentage from 0% to 100%, which means that if you set for example 50%, your process cannot use more than 500 ms of cpu time for each second.\nBut if your machine has four processors, percentage may vary from 0% to 400%, so setting the limit to 200% means to use no more than half of the available power. In any case, the percentage is the same of what you see when you run top.\n\n\ncpulimit should run at least with the same user running the controlled process.\nBut it is much better if you run cpulimit as root, in order to have a higher priority and a more precise control.\nNow cpulimit does limit also the children of the specified process. The code is still experimental, so let me know how it is.\n\n\ncpulimit is written just for fun by Angelo Marletta.\nPlease send your feedback, bug reports, feature requests or just thanks:) to marlonx80 at hotmail dot com\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# cpulimit\n\n> A tool to throttle the CPU usage of other processes.\n> More information: <http://cpulimit.sourceforge.net/>.\n\n- Limit an existing process with PID 1234 to only use 25% of the CPU:\n\n`cpulimit --pid {{1234}} --limit {{25%}}`\n\n- Limit an existing program by its executable name:\n\n`cpulimit --exe {{program}} --limit {{25}}`\n\n- Launch a given program and limit it to only use 50% of the CPU:\n\n`cpulimit --limit {{50}} -- {{program arg1 arg2 ...}}`\n\n- Launch a program, limit its CPU usage to 50% and run cpulimit in the background:\n\n`cpulimit --limit {{50}} --background -- {{program}}`\n\n- Kill its process if the program's CPU usage goes over 50%:\n\n`cpulimit --limit 50 --kill -- {{program}}`\n\n- Throttle both it and its child processes so that none go about 25% CPU:\n\n`cpulimit --limit {{25}} --monitor-forks -- {{program}}`\n"
 },
 {
   "command": "ip",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nIP(4)\t\t\t BSD Kernel Interfaces Manual\t\t\t IP(4)\n\nNAME\n     ip -- Internet Protocol\n\nSYNOPSIS\n     #include <sys/socket.h>\n     #include <netinet/in.h>\n\n     int\n     socket(AF_INET, SOCK_RAW, proto);\n\nDESCRIPTION\n     IP is the transport layer protocol used by the Internet protocol family.\n     Options may be set at the IP level when using higher-level protocols that\n     are based on IP (such as TCP and UDP).  It may also be accessed through a\n     ``raw socket'' when developing new protocols, or special-purpose applica-\n     tions.\n\n     There are several IP-level setsockopt(2) /getsockopt(2) options.\n     IP_OPTIONS may be used to provide IP options to be transmitted in the IP\n     header of each outgoing packet or to examine the header options on incom-\n     ing packets.  IP options may be used with any socket type in the Internet\n     family.  The format of IP options to be sent is that specified by the IP\n     protocol specification (RFC-791), with one exception: the list of\n     addresses for Source Route options must include the first-hop gateway at\n     the beginning of the list of gateways.  The first-hop gateway address\n     will be extracted from the option list and the size adjusted accordingly\n     before use.  To disable previously specified options, use a zero-length\n     buffer:\n\n     setsockopt(s, IPPROTO_IP, IP_OPTIONS, NULL, 0);\n\n     IP_TOS and IP_TTL may be used to set the type-of-service and time-to-live\n     fields in the IP header for SOCK_STREAM and SOCK_DGRAM sockets. For exam-\n     ple,\n\n     int tos = IPTOS_LOWDELAY;\t     /* see <netinet/in.h> */\n     setsockopt(s, IPPROTO_IP, IP_TOS, &tos, sizeof(tos));\n\n     int ttl = 60;\t\t     /* max = 255 */\n     setsockopt(s, IPPROTO_IP, IP_TTL, &ttl, sizeof(ttl));\n\n     If the IP_RECVDSTADDR option is enabled on a SOCK_DGRAM socket, the\n     recvmsg call will return the destination IP address for a UDP datagram.\n     The msg_control field in the msghdr structure points to a buffer that\n     contains a cmsghdr structure followed by the IP address.  The cmsghdr\n     fields have the following values:\n\n     cmsg_len = CMSG_LEN(sizeof(struct in_addr))\n     cmsg_level = IPPROTO_IP\n     cmsg_type = IP_RECVDSTADDR\n\n     If the IP_RECVTOS option is enabled on a SOCK_DGRAM or SOCK_RAW socket,\n     the recvmsg call will return the TOS (type of service) field of the IP\n     header.  The msg_control field in the msghdr structure points to a buffer\n     that contains a cmsghdr structure followed by the TOS.  The cmsghdr\n     fields have the following values:\n\n     cmsg_len = CMSG_LEN(sizeof(u_char))\n     cmsg_level = IPPROTO_IP\n     cmsg_type = IP_RECVTOS\n\n   Multicast Options\n     IP multicasting is supported only on AF_INET sockets of type SOCK_DGRAM\n     and SOCK_RAW, and only on networks where the interface driver supports\n     multicasting.\n\n     The IP_MULTICAST_TTL option changes the time-to-live (TTL) for outgoing\n     multicast datagrams in order to control the scope of the multicasts:\n\n     u_char ttl;     /* range: 0 to 255, default = 1 */\n     setsockopt(s, IPPROTO_IP, IP_MULTICAST_TTL, &ttl, sizeof(ttl));\n\n     Datagrams with a TTL of 1 are not forwarded beyond the local network.\n     Multicast datagrams with a TTL of 0 will not be transmitted on any net-\n     work, but may be delivered locally if the sending host belongs to the\n     destination group and if multicast loopback has not been disabled on the\n     sending socket (see below).  Multicast datagrams with TTL greater than 1\n     may be forwarded to other networks if a multicast router is attached to\n     the local network.\n\n     For hosts with multiple interfaces, each multicast transmission is sent\n     from the primary network interface.  The IP_MULTICAST_IF option overrides\n     the default for subsequent transmissions from a given socket:\n\n     struct in_addr addr;\n     setsockopt(s, IPPROTO_IP, IP_MULTICAST_IF, &addr, sizeof(addr));\n\n     where \"addr\" is the local IP address of the desired interface or\n     INADDR_ANY to specify the default interface.  An interface's local IP\n     address and multicast capability can be obtained via the SIOCGIFCONF and\n     SIOCGIFFLAGS ioctls.  Normal applications should not need to use this\n     option.\n\n     If a multicast datagram is sent to a group to which the sending host\n     itself belongs (on the outgoing interface), a copy of the datagram is, by\n     default, looped back by the IP layer for local delivery.  The\n     IP_MULTICAST_LOOP option gives the sender explicit control over whether\n     or not subsequent datagrams are looped back:\n\n     u_char loop;    /* 0 = disable, 1 = enable (default) */\n     setsockopt(s, IPPROTO_IP, IP_MULTICAST_LOOP, &loop, sizeof(loop));\n\n     This option improves performance for applications that may have no more\n     than one instance on a single host (such as a router demon), by eliminat-\n     ing the overhead of receiving their own transmissions.  It should gener-\n     ally not be used by applications for which there may be more than one\n     instance on a single host (such as a conferencing program) or for which\n     the sender does not belong to the destination group (such as a time\n     querying program).\n\n     A multicast datagram sent with an initial TTL greater than 1 may be\n     delivered to the sending host on a different interface from that on which\n     it was sent, if the host belongs to the destination group on that other\n     interface.  The loopback control option has no effect on such delivery.\n\n     A host must become a member of a multicast group before it can receive\n     datagrams sent to the group.  To join a multicast group, use the\n     IP_ADD_MEMBERSHIP option:\n\n     struct ip_mreq mreq;\n     setsockopt(s, IPPROTO_IP, IP_ADD_MEMBERSHIP, &mreq, sizeof(mreq));\n\n     where mreq is the following structure:\n\n     struct ip_mreq {\n\t struct in_addr imr_multiaddr; /* multicast group to join */\n\t struct in_addr imr_interface; /* interface to join on */\n     }\n\n     imr_interface should be INADDR_ANY to choose the default multicast inter-\n     face, or the IP address of a particular multicast-capable interface if\n     the host is multihomed.  Membership is associated with a single inter-\n     face; programs running on multihomed hosts may need to join the same\n     group on more than one interface.\tUp to IP_MAX_MEMBERSHIPS (currently\n     20) memberships may be added on a single socket.\n\n     To drop a membership, use:\n\n     struct ip_mreq mreq;\n     setsockopt(s, IPPROTO_IP, IP_DROP_MEMBERSHIP, &mreq, sizeof(mreq));\n\n     where mreq contains the same values as used to add the membership.  Mem-\n     berships are dropped when the socket is closed or the process exits.\n\n   Raw IP Sockets\n     Raw IP sockets are connectionless, and are normally used with the sendto\n     and recvfrom calls, though the connect(2) call may also be used to fix\n     the destination for future packets (in which case the read(2) or recv(2)\n     and write(2) or send(2) system calls may be used).\n\n     If proto is 0, the default protocol IPPROTO_RAW is used for outgoing\n     packets, and only incoming packets destined for that protocol are\n     received.\tIf proto is non-zero, that protocol number will be used on\n     outgoing packets and to filter incoming packets.\n\n     Outgoing packets automatically have an IP header prepended to them (based\n     on the destination address and the protocol number the socket is created\n     with), unless the IP_HDRINCL option has been set.\tIncoming packets are\n     received with IP header and options intact.\n\n     IP_HDRINCL indicates the complete IP header is included with the data and\n     may be used only with the SOCK_RAW type.\n\n     #include <netinet/ip.h>\n\n     int hincl = 1;\t\t     /* 1 = on, 0 = off */\n     setsockopt(s, IPPROTO_IP, IP_HDRINCL, &hincl, sizeof(hincl));\n\n     Unlike previous BSD releases, the program must set all the fields of the\n     IP header, including the following:\n\n     ip->ip_v = IPVERSION;\n     ip->ip_hl = hlen >> 2;\n     ip->ip_id = 0;  /* 0 means kernel set appropriate value */\n     ip->ip_off = offset;\n     ip->ip_len = len;\n\n     Note that the ip_off and ip_len fields are in host byte order.\n\n     If the header source address is set to INADDR_ANY, the kernel will choose\n     an appropriate address.\n\nDIAGNOSTICS\n     A socket operation may fail with one of the following errors returned:\n\n     [EISCONN]\t      when trying to establish a connection on a socket which\n\t\t      already has one, or when trying to send a datagram with\n\t\t      the destination address specified and the socket is\n\t\t      already connected;\n\n     [ENOTCONN]       when trying to send a datagram, but no destination\n\t\t      address is specified, and the socket hasn't been con-\n\t\t      nected;\n\n     [ENOBUFS]\t      when the system runs out of memory for an internal data\n\t\t      structure;\n\n     [EADDRNOTAVAIL]  when an attempt is made to create a socket with a net-\n\t\t      work address for which no network interface exists.\n\n     [EACESS]\t      when an attempt is made to create a raw IP socket by a\n\t\t      non-privileged process.\n\n     The following errors specific to IP may occur when setting or getting IP\n     options:\n\n     [EINVAL]\t      An unknown socket option name was given.\n\n     [EINVAL]\t      The IP option field was improperly formed; an option\n\t\t      field was shorter than the minimum value or longer than\n\t\t      the option buffer provided.\n\nSEE ALSO\n     getsockopt(2), recv(2), send(2), icmp(4), inet(4), intro(4)\n\nHISTORY\n     The ip protocol appeared in 4.2BSD.\n\n4.2 Berkeley Distribution      November 30, 1993     4.2 Berkeley Distribution\n",
   "tldr_summary": "# ip\n\n> Show / manipulate routing, devices, policy routing and tunnels.\n\n- List interfaces with detailed info:\n\n`ip a`\n\n- Display the routing table:\n\n`ip r`\n\n- Show neighbors (ARP table):\n\n`ip n`\n\n- Make an interface up/down:\n\n`ip link set {{interface}} up/down`\n\n- Add/Delete an ip address to an interface:\n\n`ip addr add/del {{ip}}/{{mask}} dev {{interface}}`\n\n- Add a default route:\n\n`ip route add default via {{ip}} dev {{interface}}`\n"
 },
 {
   "command": "vncserver",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# vncserver\n\n> Launches a VNC (Virtual Network Computing) desktop.\n\n- Launch a VNC Server on next available display:\n\n`vncserver`\n\n- Launch a VNC Server with specific screen geometry:\n\n`vncserver --geometry {{width}}x{{height}}`\n\n- Kill an instance of VNC Server running on a specific display:\n\n`vncserver --kill :{{display_number}}`\n"
 },
 {
   "command": "lrzip",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lrzip\n\n> A large file compression program.\n> See also `lrunzip`, `lrztar`, `lrzuntar`.\n\n- Compress a file with LZMA - slow compression, fast decompression:\n\n`lrzip {{filename}}`\n\n- Compress a file with BZIP2 - good middle ground for compression/speed:\n\n`lrzip -b {{filename}}`\n\n- Compress with ZPAQ - extreme compression, but very slow:\n\n`lrzip -z {{filename}}`\n\n- Compress with LZO - light compression, extremely fast decompression:\n\n`lrzip -l {{filename}}`\n\n- Compress a file and password protect/encrypt it:\n\n`lrzip -e {{filename}}`\n\n- Override the number of processor threads to use:\n\n`lrzip -p {{8}} {{filename}}`\n"
 },
 {
   "command": "print",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# print\n\n> An alias to a `run-mailcap`'s action print.\n> Originally `run-mailcap` is used to process mime-type/file.\n\n- Print action can be used to print any file on default run-mailcap tool:\n\n`print {{filename}}`\n\n- With `run-mailcap`:\n\n`run-mailcap --action=print {{filename}}`\n"
 },
 {
   "command": "vgcreate",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# vgcreate\n\n> Create volume groups combining multiple mass-storage devices.\n\n- Create a new volume group called vg1 using the `/dev/sda1` device:\n\n`vgcreate {{vg1}} {{/dev/sda1}}`\n\n- Create a new volume group called vg1 using multiple devices:\n\n`vgcreate {{vg1}} {{/dev/sda1}} {{/dev/sdb1}} {{/dev/sdc1}}`\n"
 },
 {
   "command": "lsusb",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lsusb\n\n> Display information about USB buses and devices connected to them.\n\n- List all the USB devices available:\n\n`lsusb`\n\n- List the USB hierarchy as a tree:\n\n`lsusb -t`\n\n- List verbose information about USB devices:\n\n`lsusb --verbose`\n\n- List detailed information about a USB device:\n\n`lsusb -D {{device}}`\n\n- List devices with a specified vendor and product id only:\n\n`lsusb -d {{vendor}}:{{product}}`\n"
 },
 {
   "command": "authconfig",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# authconfig\n\n> A CLI interface for configuring system authentication resources.\n\n- Display the current configuration (or dry run):\n\n`authconfig --test`\n\n- Configure the server to use a different password hashing algorithm:\n\n`authconfig --update --passalgo={{algorithm}}`\n\n- Enable LDAP authentication:\n\n`authconfig --update --enableldapauth`\n\n- Disable LDAP authentication:\n\n`authconfig --update --disableldapauth`\n\n- Enable Network Information Service (NIS):\n\n`authconfig --update --enablenis`\n\n- Enable Kerberos:\n\n`authconfig --update --enablekrb5`\n\n- Enable Winbind (Active Directory) authentication:\n\n`authconfig --update --enablewinbindauth`\n\n- Enable local authorization:\n\n`authconfig --update --enablelocauthorize`\n"
 },
 {
   "command": "mkfs.ntfs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs.ntfs\n\n> Creates a NTFS filesystem inside a partition.\n\n- Create a NTFS filesystem inside partition 1 on device b (`sdb1`):\n\n`mkfs.ntfs {{/dev/sdb1}}`\n\n- Create filesystem with a volume-label:\n\n`mkfs.ntfs -L {{volume_label}} {{/dev/sdb1}}`\n\n- Create filesystem with specific UUID:\n\n`mkfs.ntfs -U {{UUID}} {{/dev/sdb1}}`\n"
 },
 {
   "command": "nmcli",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# nmcli\n\n> A command line tool for controlling NetworkManager.\n\n- Check the nmcli version:\n\n`nmcli --version`\n\n- Call general help:\n\n`nmcli --help`\n\n- Call help on a command:\n\n`nmcli {{command}} --help`\n\n- Execute an `nmcli` command:\n\n`nmcli {{command}}`\n"
 },
 {
   "command": "adduser",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# adduser\n\n> User addition utility.\n\n- Create a new user with a default home directory and prompt the user to set a password:\n\n`adduser {{username}}`\n\n- Create a new user without a home directory:\n\n`adduser --no-create-home {{username}}`\n\n- Create a new user with a home directory at the specified path:\n\n`adduser --home {{path/to/home}} {{username}}`\n\n- Create a new user with the specified shell set as the login shell:\n\n`adduser --shell {{path/to/shell}} {{username}}`\n\n- Create a new user belonging to the specified group:\n\n`adduser --ingroup {{group}} {{username}}`\n\n- Add an existing user to the specified group:\n\n`adduser {{username}} {{group}}`\n"
 },
 {
   "command": "wpa_passphrase",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# wpa_passphrase\n\n> Generate a WPA-PSK key from an ASCII passphrase for a given SSID.\n\n- Compute and display the WPA-PSK key for a given SSID reading the passphrase from stdin:\n\n`wpa_passphrase {{SSID}}`\n\n- Compute and display WPA-PSK key for a given SSID specifying the passphrase as an argument:\n\n`wpa_passphrase {{SSID}} {{passphrase}}`\n"
 },
 {
   "command": "mknod",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nMKNOD(8)\t\t  BSD System Manager's Manual\t\t      MKNOD(8)\n\nNAME\n     mknod -- make device special file\n\nSYNOPSIS\n     mknod [-F format] name [c | b] major minor\n     mknod [-F format] name [c | b] major unit subunit\n     mknod name [c | b] number\n     mknod name w\n\nDESCRIPTION\n     The mknod command creates device special files.\n\n     To make nodes manually, the required arguments are:\n\n     name    Device name, for example ``sd'' for a SCSI disk on an HP300 or a\n\t     ``pty'' for pseudo-devices.\n\n     b | c | w\n\t     Type of device. If the device is a block type device such as a\n\t     tape or disk drive which needs both cooked and raw special files,\n\t     the type is b.  Whiteout nodes are type w.  All other devices are\n\t     character type devices, such as terminal and pseudo devices, and\n\t     are type c.\n\n     major   The major device number is an integer number which tells the ker-\n\t     nel which device driver entry point to use.\n\n     minor   The minor device number tells the kernel which one of several\n\t     similar devices the node corresponds to; for example, it may be a\n\t     specific serial port or pty.\n\n     unit and subunit\n\t     The unit and subunit numbers select a subset of a device; for\n\t     example, the unit may specify a particular SCSI disk, and the\n\t     subunit a partition on that disk.\t(Currently this form of speci-\n\t     fication is only supported by the bsdos format, for compatibility\n\t     with the BSD/OS mknod(8).)\n\n     Device numbers for different operating systems may be packed in a differ-\n     ent format.  To create device nodes that may be used by such an operating\n     system (e.g. in an exported file system used for netbooting), the -F\n     option is used.  The following formats are recognized: native, 386bsd,\n     4bsd, bsdos, freebsd, hpux, isc, linux, netbsd, osf1, sco, solaris,\n     sunos, svr3, svr4 and ultrix.\n\n     Alternatively, a single opaque device number may be specified.\n\nSEE ALSO\n     mkfifo(1), mkfifo(2), mknod(2)\n\nHISTORY\n     A mknod command appeared in Version 6 AT&T UNIX.  The -F option appeared\n     in NetBSD 1.4.\n\nNetBSD 1.4\t\t      September 11, 1998\t\t    NetBSD 1.4\n",
   "tldr_summary": "# mknod\n\n> Create block or character device special files.\n\n- Create a block device:\n\n`sudo mknod {{path/to/device_file}} b {{major_device_number}} {{minor_device_number}}`\n\n- Create a character device:\n\n`sudo mknod {{path/to/device_file}} c {{major_device_number}} {{minor_device_number}}`\n\n- Create a FIFO (queue) device:\n\n`sudo mknod {{path/to/device_file}} p`\n\n- Create a device file with default SELinux security context:\n\n`sudo mknod -Z {{path/to/device_file}} {{type}} {{major_device_number}} {{minor_device_number}}`\n"
 },
 {
   "command": "runsvchdir",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# runsvchdir\n\n> Change the directory `runsvdir` uses by default.\n\n- Switch `runsvdir` directories:\n\n`sudo runsvchdir {{/path/to/directory}}`\n"
 },
 {
   "command": "gnome-terminal",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# gnome-terminal\n\n> The GNOME Terminal emulator.\n\n- Open a new GNOME terminal window:\n\n`gnome-terminal`\n\n- Run a specific command in a new terminal window:\n\n`gnome-terminal -- {{command}}`\n\n- Open a new tab in the last opened window instead:\n\n`gnome-terminal --tab`\n\n- Set the title of the new tab:\n\n`gnome-terminal --tab --title \"{{title}}\"`\n"
 },
 {
   "command": "i3lock",
   "doc_url": "https://i3wm.org/i3lock",
   "doc_text": "\n\n\ni3 - improved tiling wm\n\n\n\n\n\n\n\n\n\ni3 - improved tiling WM\n\nDocs\nScreens\nFAQ\nContact\nBugs\n\n\n\ni3lock\n\n  i3lock is a simple screen locker like slock. After starting it, you will see\n  a white screen (you can configure the color/an image). You can return to your\n  screen by entering your password.\n\nImprovements\n\n\n    i3lock forks, so you can combine it with an alias to suspend to RAM (run\n    \"i3lock && echo mem > /sys/power/state\" to get a locked screen\n    after waking up your computer from suspend to RAM)\n  \n\n    You can specify either a background color or a PNG image which will be\n    displayed while your screen is locked.\n  \n\n    You can specify whether i3lock should bell upon a wrong password.\n  \n\n    i3lock uses PAM and therefore is compatible with LDAP etc.\n  \n\nInstall\n\n  Many distributions include i3lock as a (potentially optional) dependency\n  of the i3 package (see Downloads). You can also\n  look for the specific package in your distribution, e.g. on Debian and\n  Debian-based distributions:\n\n\nsudo apt-get install i3lock\n\nReleases\n\n\ni3lock-2.12.tar.bz2 (2019-07-21,\n    GPG signature)\n  \n\ni3lock-2.11.1.tar.bz2 (2018-10-18,\n    GPG signature)\n  \n\ni3lock-2.11.tar.bz2 (2018-10-10,\n    GPG signature)\n  \n\ni3lock-2.10.tar.bz2 (2017-11-25,\n    GPG signature)\n  \n\ni3lock-2.9.1.tar.bz2 (2017-06-21,\n    GPG signature)\n  \n\ni3lock-2.9.tar.bz2 (2017-05-26,\n    GPG signature)\n  \n\ni3lock-2.8.tar.bz2 (2016-06-04,\n    GPG signature)\n  \n\ni3lock-2.7.tar.bz2 (2015-05-20,\n    GPG signature)\n  \n\ni3lock-2.6.tar.bz2 (2014-07-18,\n    GPG signature)\n  \n\ni3lock-2.5.tar.bz2 (2013-06-09,\n    GPG signature)\n  \n\ni3lock-2.4.1.tar.bz2 (2012-06-02,\n    GPG signature)\n  \n\ni3lock-2.4.tar.bz2 (2012-04-01,\n    GPG signature)\n  \n\ni3lock-2.3.1.tar.bz2 (2012-03-15,\n    GPG signature)\n  \n\ni3lock-2.3.tar.bz2 (2012-03-15,\n    GPG signature)\n  \n\ni3lock-2.2.tar.bz2 (2011-11-06,\n    GPG signature)\n  \n\ni3lock-2.1.tar.gz (2011-03-13,\n    GPG signature)\n  \n\ni3lock-2.0.tar.gz (2010-09-05,\n    GPG signature)\n  \ni3lock-1.0.tar.gz (2009-05-10,\n  GPG signature)\ni3lock-0.9.tar.gz\n\nDevelopment\n\n  i3lock is currently developed at \n  https://github.com/i3/i3lock. Checkouts of the master branch are intended to\n  be stable and working all the time. Integration of new features happens in a separate branch.\n\n\n\n\n        © 2009-present Michael Stapelberg,\n        Impressum,\n        Source\n\n\n",
   "man_entry": "",
   "tldr_summary": "# i3lock\n\n> Simple screen locker built for the i3 window manager.\n> More information: <https://i3wm.org/i3lock>.\n\n- Lock screen with a simple color background (rrggbb format):\n\n`i3lock -c {{0000ff}}`\n\n- Lock screen to a PNG background:\n\n`i3lock -i {{path/to/picture.png}}`\n\n- Disable the unlock indicator (removes feedback on keypress):\n\n`i3lock -u`\n\n- Display mouse pointer instead of hiding it ('default' for default pointer, 'win' for a MS Windows pointer):\n\n`i3lock -p {{default|win}}`\n\n- Lock screen to a PNG background displayed in multiple monitors, with enabled mouse pointer:\n\n`i3lock -i {{path/to/picture.png}} -p {{default|win}} -t`\n"
 },
 {
   "command": "ss",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ss\n\n> Utility to investigate sockets.\n\n- Show all TCP/UDP/RAW/UNIX sockets:\n\n`ss -a {{-t|-u|-w|-x}}`\n\n- Filter TCP sockets by states, only/exclude:\n\n`ss {{state/exclude}} {{bucket/big/connected/synchronized/...}}`\n\n- Show all TCP sockets connected to the local HTTPS port (443):\n\n`ss -t src :{{443}}`\n\n- Show all TCP sockets listening on the local 8080 port:\n\n`ss -lt src :{{8080}}`\n\n- Show all TCP sockets along with processes connected to a remote ssh port:\n\n`ss -pt dst :{{ssh}}`\n\n- Show all UDP sockets connected on specific source and destination ports:\n\n`ss -u 'sport == :{{source_port}} and dport == :{{destination_port}}'`\n\n- Show all TCP IPv4 sockets locally connected on the subnet 192.168.0.0/16:\n\n`ss -4t src {{192.168/16}}`\n"
 },
 {
   "command": "aptitude",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# aptitude\n\n> Debian and Ubuntu package management utility.\n\n- Synchronize list of packages and versions available. This should be run first, before running subsequent aptitude commands:\n\n`aptitude update`\n\n- Install a new package and its dependencies:\n\n`aptitude install {{package}}`\n\n- Search for a package:\n\n`aptitude search {{package}}`\n\n- Search for an installed package (`?installed` is an aptitude search term):\n\n`aptitude search '?installed({{package}})'`\n\n- Remove a package and all packages depending on it:\n\n`aptitude remove {{package}}`\n\n- Upgrade installed packages to newest available versions:\n\n`aptitude upgrade`\n\n- Upgrade installed packages (like `aptitude upgrade`) including removing obsolete packages and installing additional packages to meet new package dependencies:\n\n`aptitude full-upgrade`\n\n- Put an installed package on hold to prevent it from being automatically upgraded:\n\n`aptitude hold '?installed({{package}})'`\n"
 },
 {
   "command": "cewl",
   "doc_url": "https://digi.ninja/projects/cewl.php",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCeWL - Custom Wordlist Generator - DigiNinja\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomeHire meLabsBlogProjectsContact\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCeWL - Custom Word List generator \nHomeProjectsGeneralCeWL - Custom Word List\n\n\n\t\t\tBased on a discussion on PaulDotCom episode 129 about creating custom word lists by spidering a targets website and collecting unique words I decided to write CeWL, the Custom Word List generator. CeWL is a ruby app which spiders a given url to a specified depth, optionally following external links, and returns a list of words which can then be used for password crackers such as John the Ripper.\n\t\t\n\n\t\t\tCeWL also has an associated command line app, FAB (Files Already Bagged) which uses the same meta data extraction techniques to create author/creator lists from already downloaded.\n\t\t\nChange Log\nVersion 5.2\n\n\t\t\tLoads of changes including:\n\t\t\n\nCode refactoring by @g0tmi1k\nInternationalisation - should now handle non-ASCII sites much better\nFound more ways to pull words out of JavaScript content and other areas that aren't normal HTML\nLots of little bug fixes\n\nVersion 5.1\n\n\t\t\tAdded the GPL-3+ licence to allow inclusion in Debian.\n\t\t\n\n\t\t\tAdded a Gemfile to make installing gems easier.\n\t\t\nVersion 5.0\n\nAdds proxy support from the command line and the ability to pass in\ncredentials for both basic and digest authentication. Usage is simple, check\nthe help (--help) for full information.\n\n\nA few other smaller bug fixes as well.\n\nVersion 4.3\n\n\t\t\tCeWL now sorts the words found by count and optionally (new --count argument) includes the word count in the output. I've left the words in the case they are in the pages so \"Product\" is different to \"product\" I figure that if it is being used for password generation then the case may be significant so let the user strip it if they want to. There are also more improvments to the stability of the spider in this release.\n\t\t\n\n\t\t\tBy default, CeWL sticks to just the site you have specified and will go to a depth of 2 links, this behaviour can be changed by passing arguments. Be careful if setting a large depth and allowing it to go offsite, you could end up drifting on to a lot of other domains. All words of three characters and over are output to stdout. This length can be increased and the words can be written to a file rather than screen so the app can be automated.\n\t\t\nVersion 4.2\n\n\t\t\tVersion 4.2 fixes a pretty major bug that I found while fixing a smaller bug for @yorikv. The bug was related to a hack I had to put in place because of a problem I was having with the spider, while I was looking in to it I spotted this line which is the one that the spider uses to find new links in downloaded pages:\n\t\t\nweb_page.scan(/href=\"(.*?)\"/i).flatten.map do |link|\n\n\t\t\tThis is fine if all the links look like this:\n\t\t\n<a href=\"test.php\">link</a>\n\n\t\t\tBut if the link looks like either of these:\n\t\t\n<a href='test.php'>link</a>\n<a href=test.php>link</a>\n\n\t\t\tthe regex will fail so the links will be ignored.\n\t\t\n\n\t\t\tTo fix this up I've had to override the function that parses the page to find all the links, rather than use a regex I've changed it to use Nokogiri which is designed to parse a page looking for links rather than just running through it with a custom regex. This brings in a new dependency but I think it is worth it for the fix to the functionality. I also found another bug where a link like this:\n\t\t\n<a href='#name'>local</a>\n\n\t\t\twhich should be ignored as it just links to an internal name was actually being translated to '/#name' which may unintentionally mean referencing the index page. I've fixed this one as well after a lot of debugging to find how best to do it.\n\t\t\n\n\t\t\tA final addition is to allow a user to specify a depth of 0 which allows CeWL to spider a single page.\n\t\t\n\n\t\t\tI'm only putting this out as a point release as I'd like to rewrite the spidering to use a better spider, that will come out as the next major release.\n\t\t\nVersion 4.1\n\n\t\t\tVersion 4.1 is mainly bug fixes but one important feature change is the addition of two new parameters, meta_file and email_file. Previously you specified the filename for email and metadata output as optional fields to the email and meta parameters but I found that if you used the parameters in a specific order you could end up with this:\n\t\t\n./cewl.rb --email http://www.digininja.org\n\n\t\t\tThis would take the URL as the output filename for the email parameter which isn't what is meant, hence removing the optional filename from the email parameter and adding the email_file parameter instead.\n\t\t\n\n\t\t\tThe main change in version 4 is the upgrade to run with Ruby 1.9.x, this has been tested on various machines and on BT5 as that is a popular platform for running it and it appears to run fine. Another minor change is that Up to version 4 all HTML tags were stripped out before the page was parsed for words, this meant that text in alt and title tags were missed. I now grab the text from those tags before stripping the HTML to give those extra few works.\n\t\t\nVersion 3.0\n\n\t\t\tVersion 3 of CeWL addresses a problem spotted by Josh Wright. The Spider gem doesn't handle JavaScript redirection URLs, for exmaple an index page containing just the following:\n\t\t\n<script language=\"JavaScript\">\nself.location.href =\n'http://www.FOO.com/FOO/connect/FOONet/Top+Navigator/Home';\n</script>\n\n\n\t\t\twasn't spidered because the redirect wasn't picked up. I now scan through a page looking for any lines containing \"location.href=\" and then add the given URL to the list of pages to spider.\n\t\t\nVersion 2.0\n\n\t\t\tVersion 2 of CeWL can also create two new lists, a list of email addresses found in mailto links and a list of author/creator names collected from meta data found in documents on the site. It can currently process documents in Office pre 2007, Office 2007 and PDF formats. This user data can then be used to create the list of usernames to be used in association with the password list.\n\t\t\nPronunciation\n\n\t\t\tSeeing as I was asked, CeWL is pronounced \"cool\".\n\t\t\nDownload\n\n\t\t\tThe latest version is now available on GitHub. Tagged releases are also available in various distros, including Kali.\n\t\t\n\ndownload cewl version 5.2\ndownload cewl version 5.1\ndownload cewl version 5.0\ndownload cewl version 4.3\ndownload cewl version 4.2\ndownload cewl version 4.1\ndownload cewl version 3.0\n\nInstallation\n\n\t\t\tCeWL needs the rubygems package to be installed along with the following gems:\n\t\t\n\nnokogiri\nmime-types\nmini_exiftool\nrubyzip\nspider\n\n\n\t\t\tThese can be installed by running\n\t\t\nbundle install\n\n\t\tfrom the cewl directory. The mini_exiftool gem also requires the exiftool application to be installed.\n\t\t\n\n\t\t\tOn BT5 there is a problem with the version of Ruby installed by default. To get around this I've found the following works well on a brand new BT5 install:\n\t\t\ngem source -c\ngem install --user-install spider http_configuration mini_exiftool zip mime-types\n\n\t\t\tTo use the gems you may also need to set the following environment variable:\n\t\t\nRUBYOPT=\"rubygems\"\n\n\t\t\tThen just save CeWL to a directory and make it executable.\n\t\t\nUsage\n\n\t\t\tcewl [OPTION] ... URL\n\t\t\n\n--help, -hShow help\n--depth x, -d xThe depth to spider to, default 2\n--min_word_length, -mThe minimum word length, this strips out all words under the specified length, default 3\n--offsite, -oBy default, the spider will only visit the site specified. With this option it will also visit external sites\n--write, -w fileWrite the ouput to the file rather than to stdout\n--ua, -u user-agentChange the user agent\n-vVerbose, show debug and extra output\n--no-words, -nDon't output the wordlist\n--meta, -a fileInclude meta data, optional output file\n--email, -e fileInclude email addresses, optional output file\n--meta_file fileFilename for metadata output\n--email_file fileFilename for email output\n--meta-temp-dir directoryThe directory used used by exiftool when parsing files, the default is /tmp\n--count, -c:Show the count for each of the words found\n--auth_typeDigest or basic\n--auth_userAuthentication username\n--auth_passAuthentication password\n--proxy_hostProxy host\n--proxy_portProxy port, default 8080\n--proxy_usernameUsername for proxy, if required\n--proxy_passwordPassword for proxy, if required\n--verbose, -vVerbose\nURLThe site to spider.\n\nCommon Problems\n\n\t\t\tHere are a couple of the common problems people have seen while trying to use CeWL and FAB.\n\t\t\nMissing exiftool\n\n\t\tIf you see this error while trying to run either CeWL or FAB\n\t\t\n\n/usr/lib/ruby/gems/1.8/gems/mini_exiftool-1.0.1/lib/mini_exiftool.rb:246:in `exiftool_version': Command 'exiftool' not found (MiniExiftool::Error)\nfrom /usr/lib/ruby/gems/1.8/gems/mini_exiftool-1.0.1/lib/mini_exiftool.rb:265\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `gem_original_require'\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `require'\nfrom ./cewl_lib.rb:1\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require'\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'\nfrom ./cewl.rb:58\n\n\t\t\tthen the application can't access exiftool. Either install it or make sure it is in your path.\n\t\t\nHTTPS Problem\n\n\t\t\tIt has been reported that if you see this problem\n\t\t\n/usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require': no such file to load -- net/https (LoadError)\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'\nfrom /usr/lib/ruby/gems/1.8/gems/spider-0.4.4/lib/spider/spider_instance.rb:30\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require'\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'\nfrom /usr/lib/ruby/gems/1.8/gems/spider-0.4.4/lib/spider.rb:26\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `gem_original_require'\nfrom /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `require'\nfrom ./cewl.rb:56\n\n\t\t\tThen you need the Ruby libopenssl package. In Debian the package is called libopenssl-ruby.\n\t\t\nSpider Missing Pages\n\n\t\t\tSomeone has reported that the spider misses some pages which are have querystrings on them. I haven't been able to reproduce this in my tests. If anyone has this problem and can reproduce it please let me know and I'll investigate it further.\n\t\t\n\n\nTable of Contents\n\nPronunciation\nDownload\nInstallation\nUsage\nCommon Problems\n\nCategories\n\nWifi\nNetworking\nMetasploit\nGeneral\n\n\nSupport The Site\n\n\t\tI don't get paid for any of the projects on this site so if you'd like to support my work you can do so by using the affiliate links below where I either get account credits or cash back. Usually only pennies, but they all add up.\n\t\n\n\nBuy me a smoothie\n\n\n\n\n\n\n\n\n\n\n\n\tAll content created by Robin Wood unless otherwise stated\n\t\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# cewl\n\n> URL spidering tool for making a cracking wordlist from web content.\n> More information: <https://digi.ninja/projects/cewl.php>.\n\n- Create a wordlist file from the given URL up to 2 links depth:\n\n`cewl --depth {{2}} --write {{path/to/wordlist.txt}} {{url}}`\n\n- Output an alpha-numeric wordlist from the given URL with words of minimum 5 characters:\n\n`cewl --with-numbers --min_word_length {{5}} {{url}}`\n\n- Output a wordlist from the given URL in debug mode including email addresses:\n\n`cewl --debug --email {{url}}`\n\n- Output a wordlist from the given URL using HTTP Basic or Digest authentication:\n\n`cewl --auth_type {{basic|digest}} --auth_user {{username}} --auth_pass {{password}} {{url}}`\n\n- Output a wordlist from the given URL through a proxy:\n\n`cewl --proxy_host {{host}} --proxy_port {{port}} {{url}}`\n"
 },
 {
   "command": "mullvad",
   "doc_url": "https://mullvad.net/",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMullvad VPN - Privacy is a universal right\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMullvad VPN\n\n\n\n\n\n\n\n\nHelp\nServers\nBlog\nPolicies\nAbout\n\n\n\nLog in\n\n\nMy account\n\n\n\n\n\n\nDownload\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou have a right to privacy\nIn a society increasingly determined to erode that right, a fast, trustworthy and easy-to-use VPN is a good first step toward reclaiming it.\n\n\nGenerate account\nWhat is a VPN?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nCompy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvade hackers and trackers\nWhen you connect to the internet with Mullvad, we ensure that the traffic to and from your computer is encrypted to the highest standards even if you are using a public WiFi network at a cafe or hotel.\n\n\n\n\nKeep your privacy\nWe keep no activity logs, do not ask for personal information, and even encourage anonymous payments via cash or one of the cryptocurrencies we accept.  Your IP address is replaced by one of ours, ensuring that your device's activity and location are not linked to you.\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEasy to use\nUsing Mullvad is straightforward and simple – just download and install the app. You won't need to waste time with setup configurations or a multi-step registration process. We built Mullvad with ease of use in mind.\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy is a universal right\nPrivacy is fundamental to a well-functioning society because it allows norms, ethics, and laws to be safely discussed and challenged. Without privacy, a free and open society can neither flourish nor exist.\n\nThat is why we provide a VPN service that helps keep your online activity, identity, and location private for only €5/month.\n\n\nGenerate account\nWhat is a VPN?\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started with Mullvad\n\n\n\n\n\n\n\n1. Generate an account number\nThe account number is the only thing you need to connect to Mullvad VPN. We ask for no email, no phone number, no personal information whatsoever.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n651805498695\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n651805498695\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Pay only €5/month (≈$5.50)\nJust one flat rate of €5 per month for peace-of-mind privacy. If you’re not satisfied, we offer a 30-day money back guarantee.\n\n\n\n\n3. Download Mullvad and you're set\nDownload the Mullvad VPN app, enter your account number, and you're ready to roll. Use your account on up to 5 devices.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n651805498695\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Become a privacy ninja\nWhen protecting your online privacy, no single-step solution exists. Instead, it is about changing your habits and using certain tools. Read our guide.\n\n\n\n\n\n\n\nGet started now\nGenerate account\n\n\n\n\n\n\n\n\n\nMullvad\n\nHelp\nServers\nBlog\nWhat is a VPN?\nWhat is privacy?\nDownload\nPress\nJobs\n\n\n\nPolicies\n\nOpen source\nPrivacy policy\nCookies\nTerms of service\nPartnerships and resellers\nReviews, ads and affiliates\nReporting a bug or vulnerability\n\n\n\nAddress\n\nMullvad VPN AB\nBox 53049\n400 14 Gothenburg\nSweden\n\n\n\nFollow us\n\n\n\n\nMullvadNet\n\n\n\n\n\n@mullvadnet\n\n\n\n\n\nmullvad\n\n\n\n\n\nsupport@mullvad.net\n\n\n\nGPG key\n\n\n\n\nOnion service: xcln5hkbriyklr6n.onion\nLanguage\n\n\n\n\n\nEnglish\n\n\n\n\n\n\n\n\nالعربيّة\nDansk\nDeutsch\nEnglish\nEspañol\nفارسی\nSuomi\nFrançais\nItaliano\n日本語\n한국어\nNederlands\nNorsk\nPolski\nPortuguês\nРусский\nSvenska\nภาษาไทย\nTürkçe\n繁體中文\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# mullvad\n\n> CLI client for Mullvad VPN.\n> More information: <https://mullvad.net/>.\n\n- Link your mullvad account with the specified account number:\n\n`mullvad account set {{account_number}}`\n\n- Enable LAN access while VPN is on:\n\n`mullvad lan set allow`\n\n- Establish the VPN tunnel:\n\n`mullvad connect`\n\n- Check status of VPN tunnel:\n\n`mullvad status`\n"
 },
 {
   "command": "konsole",
   "doc_url": "https://konsole.kde.org",
   "doc_text": "\n\n\n\n\nKonsole\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Konsole\n          \n\n\nChangelog\n\n\nDownload\n\n\nGet Involved\n\n\nUser support\n\n\nDonation\n\n\n\n\n      Made by KDE\n    \n\n\n\n\n\n\n\nKonsole\nA powerful and customizable terminal emulator.\n\n\n\n\n\nKonsole - KDE's Terminal Emulator\n\n[konqi@kde ~]$ cd $HOME\n[konqi@kde ~]$ echo \"Welcome home\"\nWelcome home\n[konqi@kde ~]$ echo \"Konsole is KDE's Terminal Emulator\"\nKonsole is KDE's Terminal Emulator\n[konqi@kde ~]$ cat konsole_features.txt\n* Multiple tabs support\n* Multiple profiles support\n* Silence and Activity monitoring\n* Bookmark support\n* Searching\n* Saving output\n* Multiple splits in any tab\n    \nScreenshots\n\n\n\nSome of Konsole's new features in 20.08 release.\n\n\nKonsole is also integrated into multiple other KDE Applications making it easier to reach and more convenient. For example, KDevelop, Kate and Dolphin all use Konsole as an integrated terminal emulator.\n\n\n\nDolphin using the integrate Konsole widget.\n\n\n\n\n\n\n\n\n                        Donate to KDE\n                        Why Donate?\n\n\n\n\n\n\n\n\n\n\n\n €\n                        Donate via PayPal\n\nOther ways to donate\n\n\n\n\n\n\nCommunity\nForums\n\n\nNews & Press\nAnnouncements\nKDE.news\nPlanet KDE\n\n\n\n\nPost on Facebook\nShare on Twitter\nShare on Diaspora\nShare on Mastodon\nShare on LinkedIn\nShare on Reddit\nShare on YouTube\nShare on PeerTube\nShare on VK\nShare on Instagram\n\n\n\n\n                Maintained by \n                    KDE www\n\n\n                KDE® and the K Desktop Environment® logo are registered trademarks of KDE e.V. |\n                Legal\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# konsole\n\n> Konsole: The KDE terminal emulator.\n> More information: <https://konsole.kde.org>.\n\n- Open a new Konsole in a specific directory:\n\n`konsole --workdir {{path/to/directory}}`\n\n- Run a specific command and do not close the window after it exits:\n\n`konsole --noclose -e {{command}}`\n\n- Open a new tab:\n\n`konsole --new-tab`\n\n- Open a Konsole in the background and bring to the front when Ctrl+Shift+F12 (by default) is pressed:\n\n`konsole --background-mode`\n\n- Open a Konsole with the emergency FALLBACK profile:\n\n`konsole --fallback-profile`\n"
 },
 {
   "command": "lvextend",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lvextend\n\n> Increase the size of a logical volume.\n\n- Increase a volume's size to 120GB:\n\n`lvextend --size {{120G}} {{logical_volume}}`\n\n- Increase a volume's size by 40GB as well as the underlying filesystem:\n\n`lvextend --size +{{40G}} -r {{logical_volume}}`\n\n- Increase a volume's size to 100% of the free phyiscal volume space:\n\n`lvextend --size {{100}}%FREE {{logical_volume}}`\n"
 },
 {
   "command": "dunstify",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dunstify\n\n> A notification tool that is an extension of notify-send, but has more features based around dunst.\n> Works with all options that work for notify-send.\n\n- Show a notification with a given title and message:\n\n`dunstify {{\"Title\"}} {{\"Message\"}}`\n\n- Show a notification with specified urgency:\n\n`dunstify {{\"Title\"}} {{\"Message}}\" -u {{low|normal|critical}}`\n\n- Specify a message ID (overwrites any previous messages with the same ID):\n\n`dunstify {{\"Title\"}} {{\"Message\"}} -r {{123}}`\n\n- To see other possible options:\n\n`notify-send --help`\n"
 },
 {
   "command": "xeyes",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xeyes\n\n> Display eyes on the screen that follow the mouse cursor.\n\n- Launch xeyes on the local machine's default display:\n\n`xeyes`\n\n- Launch xeyes on a remote machine's display 0, screen 0:\n\n`xeyes -display {{remote_host}}:{{0}}.{{0}}`\n"
 },
 {
   "command": "dmenu",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dmenu\n\n> Dynamic menu.\n> Creates a menu from a text input with each item on a new line.\n\n- Display a menu of the output of the `ls` command:\n\n`{{ls}} | dmenu`\n\n- Display a menu with custom items separated by a new line (`\\n`):\n\n`echo -e \"{{red}}\\n{{green}}\\n{{blue}}\" | dmenu`\n\n- Let the user choose between multiple items and save the selected one to a file:\n\n`echo -e \"{{red}}\\n{{green}}\\n{{blue}}\" | dmenu > {{color.txt}}`\n\n- Launch dmenu on a specific monitor:\n\n`ls | dmenu -m {{1}}`\n\n- Display dmenu at the bottom of the screen:\n\n`ls | dmenu -b`\n"
 },
 {
   "command": "wipefs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# wipefs\n\n> Wipe filesystem, raid, or partition-table signatures from a device.\n\n- Display signatures for specified device:\n\n`sudo wipefs {{/dev/sda}}`\n\n- Wipe all available signatures for specified device:\n\n`sudo wipefs --all {{/dev/sda}}`\n\n- Perform dry run:\n\n`sudo wipefs --all --no-act {{/dev/sda}}`\n\n- Force wipe, even if the filesystem is mounted:\n\n`sudo wipefs --all --force {{/dev/sda}}`\n"
 },
 {
   "command": "efibootbgr",
   "doc_url": "https://linux.die.net/man/8/efibootmgr",
   "doc_text": "\n\nefibootmgr(8): change EFI Boot Manager - Linux man page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nefibootmgr(8) - Linux man page\nName\nefibootmgr - manipulate the EFI Boot Manager\nSynopsis\n\n\n\n\n\nefibootmgr [ -a ] [ -A ] [ -b XXXX ] [ -B XXXX ] [ -c ] [ -d DISK ] [ -e\n1|3|-1 ] [ -E NUM ] [ -g ] [ -H XXXX ] [ -i NAME ] [ -l NAME ] [ -L\nLABEL ] [ -n XXXX ] [ -N ] [ -o XXXX,YYYY,ZZZZ ... ] [ -O ] [ -p\nPART ] [ -q ] [ -t seconds ] [ -T ] [ -u ] [ -U XXXX ] [ -v ] [ -V ] [ -w ] [\n-@ file ]\nDescription\nefibootmgr is a userspace application used to modify the Intel Extensible Firmware Interface (EFI) Boot Manager. This application can create and\ndestroy boot entries, change the boot order, change the next running boot option, and more.\nDetails on the EFI Boot Manager are available from the EFI Specification, v1.02 or later, available from: <URL:http://developer.intel.com>\nNote: efibootmgr requires that the kernel support access to EFI non-volatile variables (through /proc/efi/vars on 2.4 kernels,\n/sys/firmware/efi/vars on 2.6 kernels). modprobe efivars should do the trick.\nOptions\nThe following is a list of options accepted by efibootmgr:\n\n-a | --active\nSets bootnum active\n-A | --inactive\nSets bootnum inactive\n-b | --bootnum XXXX\nModify BootXXXX (hex)\n-B | --delete-bootnum\nDelete bootnum (hex)\n-c | --create\nCreate new variable bootnum and add to bootorder\n-d | --disk DISK\nThe disk containing the loader (defaults to /dev/sda)\n-e | --edd 1|3|-1\nForce EDD 1.0 or 3.0 creation variables, or guess.\n-E | --device NUM\nEDD 1.0 device number (defaults to 0x80)\n-g | --gpt\nForce disk with invalid PMBR to be treated as GPT\n-H | --acpi_hid XXXX\nset the ACPI HID (used with -i)\n-i | --iface NAME\ncreate a netboot entry for the named interface\n-l | --loader NAME\nSpecify a loader (defaults to \\\\elilo.efi)\n-L | --label LABEL\nBoot manager display label (defaults to \"Linux\")\n-n | --bootnext XXXX\nSet BootNext to XXXX (hex)\n-N | --delete-bootnext\nDelete BootNext\n-o | --bootorder XXXX,YYYY,ZZZZ\nExplicitly set BootOrder (hex)\n-O | --delete-bootorder\nDelete BootOrder\n-p | --part PART\nPartition number containing the bootloader (defaults to 1)\n-q | --quiet\nQuiet mode - supresses output.\n--test filename\nDon't write to NVRAM, write to filename.\n-t | --timeout seconds\nBoot Manager timeout, in seconds.\n-T | --delete-timeout\nDelete Timeout variable.\n-u | --unicode | --UCS-2\npass extra command line arguments as UCS-2 (default is ASCII)\n-U | --acpi_uid XXXX\nset the ACPI UID (used with -i)\n-v | --verbose\nVerbose mode - prints additional information\n-V | --version\nJust print version string and exit.\n-w | --write-signature\nwrite unique signature to the MBR if needed\n-@ | --append-binary-args\nappend extra variable args from file (use - to read from stdin). Data in file is appended as command line arguments to the boot loader command, with no\nmodification to the data, so you can pass any binary or text data necessary.\nExamples\n.\nDisplaying the Current Settings (must Be Root).\n[root@localhost ~]# efibootmgr BootCurrent: 0004 BootNext: 0003 BootOrder: 0004,0000,0001,0002,0003 Timeout: 30 seconds Boot0000* Diskette Drive(device:0)\nBoot0001* CD-ROM Drive(device:FF) Boot0002* Hard Drive(Device:80)/HD(Part1,Sig00112233) Boot0003* PXE Boot: MAC(00D0B7C15D91) Boot0004* Linux\nThis shows:\n\n\nBootCurrent - the boot entry used to start the currently running system\nBootOrder - the boot order as would appear in the boot manager. The boot manager tries to boot the first active entry in this list. If unsuccessful, it\ntries the next entry, and so on.\nBootNext - the boot entry which is scheduled to be run on next boot. This supercedes BootOrder for one boot only, and is deleted by the boot manager after\nfirst use. This allows you to change the next boot behavior without changing BootOrder.\nTimeout - the time in seconds between when the boot manager appears on the screen until when it automatically chooses the startup value from BootNext or\nBootOrder.\nFive boot entries (0000 - 0004), along with the active/inactive flag (* means active) and the name displayed on the screen.\n.\nCreating a New Boot Option\nAn OS installer would call efibootmgr -c. This assumes that /boot/efi is your EFI System Partition, and is mounted at /dev/sda1. This\ncreates a new boot option, called \"Linux\", and puts it at the top of the boot order list. Options may be passed to modify the default behavior. The default OS\nLoader is elilo.efi.\n.\nChanging the Boot Order\nAssuming the configuration in Example #1, efibootmgr -o 3,4 could be called to specify PXE boot first, then Linux boot.\n.\nChanging the Boot Order for the Next Boot Only\nAssuming the configuration in Example #1, efibootmgr -n 4 could be called to specify that the Linux entry be taken on next boot.\n.\nDeleting a Boot Option\nAssuming the configuration in Example #1, efibootmgr -b 4 -B could be called to delete entry 4 and remove it from the BootOrder.\n.\nCreating Network Boot Entries\nA system administrator wants to create a boot option to network boot (PXE). Unfortunately, this requires knowing a little more information about your system\nthan can be easily found by efibootmgr, so you've got to pass additional information - the ACPI HID and UID values. These can generally be found by using the\nEFI Boot Manager (in the EFI environment) to create a network boot entry, then using efibootmgr to print it verbosely. Here's one example: Boot003*\nAcpi(PNP0A03,0)/PCI(5|0)/Mac(00D0B7F9F510) \\ ACPI(a0341d0,0)PCI(0,5)MAC(00d0b7f9f510,0) In this case, the ACPI HID is \"0A0341d0\" and the UID is \"0\". For the\nzx2000 gigE, the HID is \"222F\" and the UID is \"500\". For the rx2000 gigE, the HID is \"0002\" and the UID is \"100\". You create the boot entry with: efibootmgr\n-c -i eth0 -H 222F -U 500 -L netboot\nBugs\nPlease direct any bugs, features, patches, etc. to Matt Domsch <Matt_Domsch@dell.com>.\nAuthor\nThis man page was generated by dann frazier <dannf@debian.org> for the Debian GNU/Linux operating system, but may be used by others.\nSee Also\nelilo(1)\n\n\n\n\n\n\n\n\n\nSite Search\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nlinux docs\nlinux man pages\npage load time\n\n\nToys\nworld sunlight\nmoon phase\ntrace explorer\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# efibootmgr\n\n> Manipulate the UEFI Boot Manager (the Bootoptions).\n> More information: https://linux.die.net/man/8/efibootmgr.\n\n- List the current settings / bootnums:\n\n`efibootmgr`\n\n- List the filepaths:\n\n`efibootmgr -v`\n\n- Add UEFI Shell v2 as a boot option:\n\n`sudo efibootmgr -c -d {{/dev/sda1}} -l {{\\EFI\\tools\\Shell.efi}} -L \"{{UEFI Shell}}\"`\n\n- Change the current boot order:\n\n`sudo efibootmgr -o {{0002,0008,0001,0005}}`\n\n- Delete a boot option:\n\n`sudo efibootmgr -b {{0008}} --delete-bootnum`\n"
 },
 {
   "command": "makepkg",
   "doc_url": "https://wiki.archlinux.org/index.php/Makepkg",
   "doc_text": "\n\n\nmakepkg - ArchWiki\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome Packages Forums Wiki Bugs Security AUR Download \n\n\n\n\n\n\n\n\nmakepkg\n\nFrom ArchWiki\n\n\nJump to navigation\nJump to search\n\n\nRelated articles\nCreating packages\nPKGBUILD\n.SRCINFO\nArch User Repository\npacman\nOfficial repositories\nArch Build System\n\nmakepkg is a script to automate the building of packages. The requirements for using the script are a build-capable Unix platform and a PKGBUILD.\nmakepkg is provided by the pacman package.\n\nContents\n\n1 Configuration\n\n1.1 Packager information\n1.2 Package output\n1.3 Signature checking\n\n\n2 Usage\n3 Tips and tricks\n\n3.1 Reduce source download and extraction times\n3.2 Building optimized binaries\n3.3 Improving compile times\n\n3.3.1 Parallel compilation\n3.3.2 Building from files in memory\n3.3.3 Using a compilation cache\n\n\n3.4 Generate new checksums\n3.5 Use other compression algorithms\n3.6 Utilizing multiple cores on compression\n3.7 Show packages with specific packager\n3.8 Build 32-bit packages on a 64-bit system\n\n\n4 Troubleshooting\n\n4.1 Specifying install directory for QMAKE based packages\n4.2 WARNING: Package contains reference to $srcdir\n4.3 Makepkg fails to download dependencies when behind proxy\n\n4.3.1 Enable proxy by setting its URL in XferCommand\n4.3.2 Enable proxy via sudoer's env_keep\n\n\n4.4 Makepkg fails, but make succeeds\n\n\n5 See also\n\n\nConfiguration\nSee makepkg.conf(5) for details on configuration options for makepkg.\nThe system configuration is available in /etc/makepkg.conf, but user-specific changes can be made in $XDG_CONFIG_HOME/pacman/makepkg.conf or ~/.makepkg.conf. It is recommended to review the configuration prior to building packages.\n\nPackager information\nEach package is tagged with metadata identifying amongst others also the packager. By default, user-compiled packages are marked with Unknown Packager. If multiple users will be compiling packages on a system, or you are otherwise distributing your packages to other users, it is convenient to provide real contact. This can be done by setting the PACKAGER variable in makepkg.conf.\nTo check this on an installed package:\n\n$ pacman -Qi package\n...\nPackager       : John Doe <john@doe.com>\n...\n\nTo automatically produce signed packages, also set the GPGKEY variable in makepkg.conf.\n\nPackage output\nBy default, makepkg creates the package tarballs in the working directory and downloads source data directly to the src/ directory. Custom paths can be configured, for example to keep all built packages in ~/build/packages/ and all sources in ~/build/sources/.\nConfigure the following makepkg.conf variables if needed:\n\nPKGDEST — directory for storing resulting packages\nSRCDEST — directory for storing source data (symbolic links will be placed to src/ if it points elsewhere)\nSRCPKGDEST — directory for storing resulting source packages (built with makepkg -S)\nTip: The PKGDEST directory can be cleaned up with e.g. paccache -c ~/build/packages/ as described in pacman#Cleaning the package cache.\nSignature checking\nNote: The signature checking implemented in makepkg does not use pacman's keyring, instead relying on the user's keyring.[1]\nIf a signature file in the form of .sig or .asc is part of the PKGBUILD source array, makepkg automatically attempts to verify it. In case the user's keyring does not contain the needed public key for signature verification, makepkg will abort the installation with a message that the PGP key could not be verified. \nIf a needed public key for a package is missing, the PKGBUILD will most likely contain a validpgpkeys entry with the required key IDs. You can import it manually, or you can find it on a keyserver and import it from there.\n\nUsage\nBefore continuing, install the base-devel group. Packages belonging to this group are not required to be listed as build-time dependencies (makedepends) in PKGBUILD files.\n\nNote:\nMake sure sudo is configured properly for commands passed to pacman.\nRunning makepkg itself as root is disallowed.[2] Besides how a PKGBUILD may contain arbitrary commands, building as root is generally considered unsafe.[3] Users who have no access to a regular user account should run makepkg as the nobody user.\nTo build a package, one must first create a PKGBUILD, or build script, as described in Creating packages. Existing scripts are available from the Arch Build System (ABS) tree or the AUR. Once in possession of a PKGBUILD, change to the directory where it is saved and run the following command to build the package:\n\n$ makepkg\n\nIf required dependencies are missing, makepkg will issue a warning before failing. To build the package and install needed dependencies, add the flag -s/--syncdeps:\n\n$ makepkg --syncdeps\n\nAdding the -r/--rmdeps flag causes makepkg to remove the make dependencies later, which are no longer needed. If constantly building packages, consider using Pacman/Tips and tricks#Removing unused packages (orphans) once in a while instead.\n\nNote:\nThese dependencies must be available in the configured repositories; see pacman#Repositories and mirrors for details. Alternatively, one can manually install dependencies prior to building (pacman -S --asdeps dep1 dep2).\nOnly global values are used when installing dependencies, i.e any override done in a split package's packaging function will not be used.\n\nOnce all dependencies are satisfied and the package builds successfully, a package file (pkgname-pkgver.pkg.tar.zst) will be created in the working directory. To install, use -i/--install (same as pacman -U pkgname-pkgver.pkg.tar.zst):\n\n$ makepkg --install\n\nTo clean up leftover files and folders, such as files extracted to the $srcdir, add the option -c/--clean. This is useful for multiple builds of the same package or updating the package version, while using the same build folder. It prevents obsolete and remnant files from carrying over to the new builds:\n\n$ makepkg --clean\n\nFor more, see makepkg(8).\n\nTips and tricks\nReduce source download and extraction times\nMake use of SRCDEST, especially when building VCS packages, to save time acquiring and unpacking sources in subsequent rebuilds.\n\nBuilding optimized binaries\nA performance improvement of the packaged software can be achieved by enabling compiler optimizations for the host machine. The downside is that binaries compiled for a specific processor architecture will not run correctly on other machines. On x86_64 machines, there are rarely significant enough real world performance gains that would warrant investing the time to rebuild official packages.\nHowever, it is very easy to reduce performance by using \"nonstandard\" compiler flags. Many compiler optimizations are only useful in certain situations and should not be indiscriminately applied to every package. Unless you can verify/benchmark that something is faster, there is a very good chance it is not! The Gentoo GCC optimization and Safe CFLAGS wiki articles provide more in-depth information about compiler optimization.\nThe options passed to a C/C++ compiler (e.g. gcc or clang) are controlled by the CFLAGS, CXXFLAGS, and CPPFLAGS environment variables. For use in the Arch build system, makepkg exposes these environment variables as configuration options in makepkg.conf. The default values are configured to produce generic binaries that can be installed on a wide range of machines.\n\nNote:\nKeep in mind that not all build systems use the variables configured in makepkg.conf. For example, cmake disregards the preprocessor options environment variable, CPPFLAGS. Consequently, many PKGBUILDs contain workarounds with options specific to the build system used by the packaged software.\nThe configuration provided with the source code in the Makefile or a specific argument in the compilation command line takes precedence and can potentially override the one in makepkg.conf.\n\nGCC can automatically detect and enable safe architecture-specific optimizations. To use this feature, first remove any -march and -mtune flags, then add -march=native. For example:\n\n/etc/makepkg.conf\nCFLAGS=\"-march=native -O2 -pipe -fstack-protector-strong -fno-plt\"\nCXXFLAGS=\"${CFLAGS}\"\nTo see what flags this enables on your machine, run:\n\n$ gcc -march=native -v -Q --help=target\n\nNote: If you specify different value than -march=native, then -Q --help=target will not work as expected.[4] You need to go through a compilation phase to find out which options are really enabled. See Gentoo:Safe CFLAGS#Manual for instructions.\nStarting in pacman version 5.2.2, makepkg.conf also includes overrides for the RUSTFLAGS environment variable, for flags given to the Rust compiler. The Rust compiler can also detect and enable architecture-specific optimizations for your CPU, by adding -C target-cpu=native to the given RUSTFLAGS value:\n\n/etc/makepkg.conf\nRUSTFLAGS=\"-C opt-level=2 -C target-cpu=native\"\nTo see which CPU features this will enable, run:\n\n$ rustc -C target-cpu=native --print cfg\n\nRunning --print cfg without -C target-cpu=native will print the default configuration. The opt-level parameter can be changed to 3, s, or z as desired. See The Rust compiler's documentation for details.\n\nImproving compile times\nParallel compilation\nThe make build system uses the MAKEFLAGS environment variable to specify additional options for make. The variable can also be set in the makepkg.conf file.\nUsers with multi-core/multi-processor systems can specify the number of jobs to run simultaneously. This can be accomplished with the use of nproc to determine the number of available processors, e.g. MAKEFLAGS=\"-j$(nproc)\". Some PKGBUILDs specifically override this with -j1, because of race conditions in certain versions or simply because it is not supported in the first place. Packages that fail to build because of this should be reported on the bug tracker (or in the case of AUR packages, to the package maintainer) after making sure that the error is indeed being caused by your MAKEFLAGS.\nSee make(1) for a complete list of available options.\n\nBuilding from files in memory\nAs compiling requires many I/O operations and handling of small files, moving the working directory to a tmpfs may bring improvements in build times. \nThe BUILDDIR variable can be temporarily exported to makepkg to set the build directory to an existing tmpfs. For example:\n\n$ BUILDDIR=/tmp/makepkg makepkg\n\nPersistent configuration can be done in makepkg.conf by uncommenting the BUILDDIR option, which is found at the end of the BUILD ENVIRONMENT section in the default /etc/makepkg.conf file. Setting its value to e.g. BUILDDIR=/tmp/makepkg will make use of the Arch's default /tmp temporary file system.\n\nNote:\nAvoid compiling larger packages in tmpfs to prevent running out of memory.\nThe tmpfs folder must be mounted without the noexec option, otherwise it will prevent built binaries from being executed.\nKeep in mind that packages compiled in tmpfs will not persist across reboot. Consider setting the PKGDEST option appropriately to move the built package automatically to a persistent directory.\n\nUsing a compilation cache\nThe use of ccache can improve build times by caching the results of compilations for successive use.\n\nGenerate new checksums\nInstall pacman-contrib and run the following command in the same directory as the PKGBUILD file to generate new checksums:\n\n$ updpkgsums\n\nThe checksums can also be obtained with e.g sha256sum and added to the sha256sums array by hand.\n\nUse other compression algorithms\nTo speed up both packaging and installation, with the tradeoff of having larger package archives, you can change PKGEXT.\nFor example, the following skips compression of the package file, which will in turn have no need to be decompressed on install:\n\n$ PKGEXT='.pkg.tar' makepkg\n\nAs another example, the following uses the lzop algorithm, with the lzop package required:\n\n$ PKGEXT='.pkg.tar.lzo' makepkg\n\nTo make one of these settings permanent, set PKGEXT in /etc/makepkg.conf.\n\nUtilizing multiple cores on compression\nxz supports symmetric multiprocessing (SMP) via the --threads flag to speed up compression. For example, to let makepkg use as many CPU cores as possible to compress packages, edit COMPRESSXZ array in /etc/makepkg.conf:\n\nCOMPRESSXZ=(xz -c -z - --threads=0)\n\npigz is a drop-in, parallel implementation for gzip which by default uses all available CPU cores (the -p/--processes flag can be used to employ less cores):\n\nCOMPRESSGZ=(pigz -c -f -n)\n\npbzip2 is a drop-in, parallel implementation for bzip2 which also uses all available CPU cores by default. The -p# flag can be used to employ less cores (note: no space between the -p and number of cores).\n\nCOMPRESSBZ2=(pbzip2 -c -f)\n\nzstd supports symmetric multiprocessing (SMP) via the --threads flag to speed up compression. For example, to let makepkg use as many CPU cores as possible to compress packages, edit COMPRESSZST array in /etc/makepkg.conf:\n\nCOMPRESSZST=(zstd -c -z -q - --threads=0)\n\nShow packages with specific packager\nexpac is a pacman database extraction utility. This command shows all packages installed on the system with the packager named packagername:\n\n$ expac \"%n %p\" | grep \"packagername\" | column -t\n\nThis shows all packages installed on the system with the packager set in the /etc/makepkg variable PACKAGER. This shows only packages that are in a repository defined in /etc/pacman.conf.\n\n$ . /etc/makepkg.conf; grep -xvFf <(pacman -Qqm) <(expac \"%n\\t%p\" | grep \"$PACKAGER$\" | cut -f1)\n\nBuild 32-bit packages on a 64-bit system\nWarning: Errors have been reported when using this method to build the linux package.\nFirst, enable the multilib repository and install multilib-devel.\nThen create a 32-bit configuration file\n\n~/.makepkg.i686.conf\nCARCH=\"i686\"\nCHOST=\"i686-unknown-linux-gnu\"\nCFLAGS=\"-m32 -march=i686 -mtune=generic -O2 -pipe -fstack-protector-strong\"\nCXXFLAGS=\"${CFLAGS}\"\nLDFLAGS=\"-m32 -Wl,-O1,--sort-common,--as-needed,-z,relro\"\nand invoke makepkg as such\n\n$ linux32 makepkg --config ~/.makepkg.i686.conf\n\nTroubleshooting\nSpecifying install directory for QMAKE based packages\nThe makefile generated by qmake uses the environment variable INSTALL_ROOT to specify where the program should be installed. Thus this package function should work:\n\nPKGBUILD\n...\npackage() {\n\tcd \"$srcdir/${pkgname%-git}\"\n\tmake INSTALL_ROOT=\"$pkgdir\" install\n}\n...\nNote, that qmake also has to be configured appropriately. For example put this in your .pro file:\n\nYourProject.pro\n...\ntarget.path = /usr/local/bin\nINSTALLS += target\n...\nWARNING: Package contains reference to $srcdir\nSomehow, the literal strings contained in the variables $srcdir or $pkgdir ended up in one of the installed files in your package.\nTo identify which files, run the following from the makepkg build directory:\n\n$ grep -R \"$PWD/src\" pkg/\n\nOne possible cause would be from the usage of __FILE__ macro in C/C++ code with full path passed to compiler.\n\nMakepkg fails to download dependencies when behind proxy\nWhen makepkg calls dependencies, it calls pacman to install the packages, which requires administrative privileges via sudo. However, sudo does not pass any environment variables to the privileged environment, and includes the proxy-related variables ftp_proxy, http_proxy, https_proxy, and no_proxy.\nIn order to have makepkg working behind a proxy you have to do one of the following methods.\n\nEnable proxy by setting its URL in XferCommand\nThe XferCommand can be set to use the desired proxy URL in /etc/pacman.conf.  Add or uncomment the following line in your pacman.conf[5]:\n\n/etc/pacman.conf\n...\nXferCommand = /usr/bin/curl -x http://username:password@proxy.proxyhost.com:80 -L -C - -f -o %o %u\n...\n\nEnable proxy via sudoer's env_keep\nAlternatively, one may want to use sudoer's env_keep option, which enables preserving given variables the privileged environment. See Sudo#Environment variables for more information.\n\nMakepkg fails, but make succeeds\nIf something manually compiles using make, but fails through makepkg, it is almost certainly because /etc/makepkg.conf sets a compilation variable to something reasonable that usually works, but that what you are compiling is incompatible with.  Try adding these flags to the PKGBUILD options array:\n!buildflags, to prevent its default CPPFLAGS, CFLAGS, CXXFLAGS, and LDFLAGS.\n!makeflags, to prevent its default MAKEFLAGS, in case you have edited /etc/makepkg.conf to enable parallel builds.\n!debug, to prevent its default DEBUG_CFLAGS, and DEBUG_CXXFLAGS, in case your package is a debug build.\nIf any of these fix the problem, this could indicate you can report a bug upstream, if you isolate exactly which flag is causing the problem.\n\nSee also\nmakepkg(8)\nmakepkg.conf(5)\nA Brief Tour of the Makepkg Process\nmakepkg source code\n\n\n\n\nRetrieved from \"https://wiki.archlinux.org/index.php?title=Makepkg&oldid=635338\"\nCategories: Package developmentAbout ArchCommands\n\n\n\n\nNavigation menu\n\n\nPersonal tools\n\nCreate accountLog in \n\n\n\nNamespaces\n\nPageDiscussion \n\n\n\n\nVariants\n\n\n\n\n\n\n\nViews\n\nReadView sourceView history \n\n\n\nMore\n\n\n\n\n\nSearch\n\n\n\n \n\n\n\n\n\n\n\nNavigation\n\n\nMain pageTable of contentsGetting involvedWiki newsRandom page \n\n\n\nInteraction\n\n\nHelpContributingRecent changesRecent talksNew pagesStatisticsRequests \n\n\n\nTools\n\n\nWhat links hereRelated changesSpecial pagesPrintable versionPermanent linkPage information \n\n\n\nIn other languages\n\n\nالعربيةΕλληνικάEspañolفارسیFrançaisItaliano日本語NederlandsPortuguêsРусскийСрпски / srpski中文（简体）‎ \n\n\n\n\n\n\n This page was last edited on 14 September 2020, at 09:39.\nContent is available under GNU Free Documentation License 1.3 or later unless otherwise noted.\n\n\nPrivacy policy\nAbout ArchWiki\nDisclaimers\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# makepkg\n\n> Creates a package installable with the `pacman` package manager.\n> Runs the commands from a PKGBUILD file to build the package.\n> More information: <https://wiki.archlinux.org/index.php/Makepkg>.\n\n- Make a package (run in the same directory as a PKGBUILD):\n\n`makepkg`\n\n- Make a package and install its dependencies:\n\n`makepkg --syncdeps`\n\n- Same as above, but install the package with `pacman` when done:\n\n`makepkg --syncdeps --install`\n\n- Make a package, but skip source checksums:\n\n`makepkg --skipchecksums`\n"
 },
 {
   "command": "calc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# calc\n\n> An interactive arbitrary-precision calculator on the terminal.\n\n- Start calc in interactive mode:\n\n`calc`\n\n- Perform a calculation in non-interactive mode:\n\n`calc -p '{{85 * (36 / 4)}}'`\n"
 },
 {
   "command": "chcpu",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# chcpu\n\n> Enable/disable a system's CPUs.\n\n- Disable CPUs via a list of CPU ID numbers:\n\n`chcpu -d {{1,3}}`\n\n- Enable a set of CPUs via a range of CPU ID numbers:\n\n`chcpu -e {{1-10}}`\n"
 },
 {
   "command": "xclip",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xclip\n\n> X11 clipboard manipulation tool, similar to `xsel`.\n> Handles the X primary and secondary selections, plus the system clipboard (`Ctrl + C`/`Ctrl + V`).\n\n- Copy the output from a command to the X11 primary selection area (clipboard):\n\n`echo 123 | xclip`\n\n- Copy the output from a command to a given X11 selection area:\n\n`echo 123 | xclip -selection {{primary|secondary|clipboard}}`\n\n- Copy the contents of a file to the system clipboard, using short notation:\n\n`echo 123 | xclip -sel clip`\n\n- Copy the contents of a file into the system clipboard:\n\n`xclip -sel clip {{input_file.txt}}`\n\n- Copy the contents of a PNG image into the system clipboard (can be pasted in other programs correctly):\n\n`xclip -sel clip -t image/png {{input_file.png}}`\n\n- Paste the contents of the X11 primary selection area to the console:\n\n`xclip -o`\n\n- Paste the contents of the system clipboard to the console:\n\n`xclip -o -sel clip`\n\n- Paste the contents of the system clipboard into a file:\n\n`xclip -o -sel clip > {{output_file.txt}}`\n"
 },
 {
   "command": "update-alternatives",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# update-alternatives\n\n> A convenient tool for maintaining symbolic links to determine default commands.\n\n- Add a symbolic link:\n\n`sudo update-alternatives --install {{path/to/symlink}} {{command_name}} {{path/to/command_binary}} {{priority}}`\n\n- Configure a symbolic link for \"java\":\n\n`sudo update-alternatives --config {{java}}`\n\n- Remove a symbolic link:\n\n`sudo update-alternatives --remove {{java}} {{/opt/java/jdk1.8.0_102/bin/java}}`\n\n- Display information about a specified command:\n\n`update-alternatives --display {{java}}`\n\n- Display all commands and their current selection:\n\n`update-alternatives --get-selections`\n"
 },
 {
   "command": "pkgmk",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pkgmk\n\n> Make a binary package for use with pkgadd on CRUX.\n\n- Make and download a package:\n\n`pkgmk -d`\n\n- Install the package after making it:\n\n`pkgmk -d -i`\n\n- Upgrade the package after making it:\n\n`pkgmk -d -u`\n\n- Ignore the footprint when making a package:\n\n`pkgmk -d -if`\n\n- Ignore the MD5 sum when making a package:\n\n`pkgmk -d -im`\n\n- Update the package's footprint:\n\n`pkgmk -uf`\n"
 },
 {
   "command": "dnf",
   "doc_url": "https://dnf.readthedocs.io/",
   "doc_text": " \n\n\n\nDNF, the next-generation replacement for YUM — dnf latest documentation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n dnf\n          \n\n          \n          \n\n                latest\n              \n\n\n\n\n\n\n\n\n\n\nDNF Use Cases\nDNF Command Reference\nDNF Configuration Reference\nDNF Automatic\nDNF API Reference\nDNF Userâs FAQ\nModularity\nStored Transaction JSON Format\nDNF Release Notes\nChanges in DNF CLI compared to YUM\nChanges in DNF plugins compared to YUM plugins\nChanges in DNF plugins compared to YUM utilities\nChanges in the DNF hook API compared to YUM\nChanges in DNF-2 compared to DNF-1\n\n\n\n\n\n\n\ndnf\n\n\n\n\n\nDocs »\nDNF, the next-generation replacement for YUM\n\n Edit on GitHub\n\n\n\n\n\n\n\nDNF, the next-generation replacement for YUMÂ¶\nContents:\n\n\nDNF Use Cases\nDNF Command Reference\nDNF Configuration Reference\nDNF Automatic\nDNF API Reference\nDNF Userâs FAQ\nModularity\nStored Transaction JSON Format\nDNF Release Notes\nChanges in DNF CLI compared to YUM\nChanges in DNF plugins compared to YUM plugins\nChanges in DNF plugins compared to YUM utilities\nChanges in the DNF hook API compared to YUM\nChanges in DNF-2 compared to DNF-1\n\n\nDNF Plugins and components\n\nDNF Plugins Core\nDNF Plugins Extras\n`Hawkey`_\n\nIndices and tables\n\nIndex\nModule Index\nSearch Page\n\n\n\n\n\n\nNext \n\n\n\n\n        © Copyright 2020\n      \n        \n          Revision 5d2be3b0.\n        \n\n\n  Built with Sphinx using a theme provided by Read the Docs. \n\n\n\n\n\n\n\n\n Read the Docs\n      v: latest\n      \n\n\n\nVersions\nlatest\nstable\n\n\nDownloads\npdf\nhtml\nepub\n\n\nOn Read the Docs\n\nProject Home\n\n\nBuilds\n\n\n\n      Free document hosting provided by Read the Docs.\n\n    \n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# dnf\n\n> Package management utility for RHEL, Fedora, and CentOS (replaces yum).\n> More information: <https://dnf.readthedocs.io/>.\n\n- Upgrade installed packages to the newest available versions:\n\n`sudo dnf upgrade`\n\n- Search packages via keywords:\n\n`dnf search {{keywords}}`\n\n- Display details about a package:\n\n`dnf info {{package}}`\n\n- Install a new package:\n\n`sudo dnf install {{package}}`\n\n- Install a new package and assume yes to all questions:\n\n`sudo dnf -y install {{package}}`\n\n- Remove a package:\n\n`sudo dnf remove {{package}}`\n\n- List installed packages:\n\n`dnf list --installed`\n\n- Find which packages provide a given file:\n\n`dnf provides {{file}}`\n"
 },
 {
   "command": "http-prompt",
   "doc_url": "http://example.com",
   "doc_text": "\n\nExample Domain\n\n\n\n\n\n\n\nExample Domain\nThis domain is for use in illustrative examples in documents. You may use this\n    domain in literature without prior coordination or asking for permission.\nMore information...\n\n\n",
   "man_entry": "",
   "tldr_summary": "# http-prompt\n\n> An interactive command-line HTTP client featuring autocomplete and syntax highlighting.\n\n- Launch a session targeting the default url of http://localhost:8000 or the previous session:\n\n`http-prompt`\n\n- Launch a session with a given url:\n\n`http-prompt {{http://example.com}}`\n\n- Launch a session with some initial options:\n\n`http-prompt {{localhost:8000/api}} --auth {{username:password}}`\n"
 },
 {
   "command": "trash",
   "doc_url": "https://github.com/andreafrancia/trash-cli",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - andreafrancia/trash-cli: Command line interface to the freedesktop.org trashcan.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nandreafrancia\n\n/\n\ntrash-cli\n\n\n\n\n\n\n\n    Watch\n \n      39\n    \n\n\n\n\n      Star\n\n\n      1.6k\n    \n\n\n\n\n          Fork\n\n\n        106\n      \n\n\n\n\n\n        Command line interface to the freedesktop.org trashcan.\n      \n\n\n\n            GPL-2.0 License\n        \n\n\n\n\n1.6k\n        stars\n \n\n106\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n73\n \n\n\n\nPull requests\n10\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n17\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nandreafrancia\n\nRefactor: moved CleanableTrashcan to empty.py\n\n\n\n…\n\n\n\n130e812\n\nAug 20, 2019\n\n\n\n\n\nRefactor: moved CleanableTrashcan to empty.py\n\n\n130e812\n\n\n\nGit stats\n\n\n\n\n\n797\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\ndocs\n\n\n\nUpdate upstream URL for safe-rm\n\n\n\nJan 1, 2014\n\n\n\n\n\n\n\nintegration_tests\n\n\n\nRefactor: removed module cmds.py\n\n\n\nAug 20, 2019\n\n\n\n\n\n\n\nman/man1\n\n\n\nAdd a reference to trash-rm(1) to all man pges\n\n\n\nDec 31, 2016\n\n\n\n\n\n\n\ntasks\n\n\n\nFix mkdir option in tasks/make-disk.osx\n\n\n\nJan 4, 2017\n\n\n\n\n\n\n\ntrashcli\n\n\n\nRefactor: moved CleanableTrashcan to empty.py\n\n\n\nAug 20, 2019\n\n\n\n\n\n\n\nunit_tests\n\n\n\nRefactor: now also 'now' is injected\n\n\n\nJan 25, 2017\n\n\n\n\n\n\n\n.ackrc\n\n\n\nAdd configuration for ack\n\n\n\nDec 25, 2016\n\n\n\n\n\n\n\n.ctags\n\n\n\nTweak ctags\n\n\n\nDec 31, 2016\n\n\n\n\n\n\n\n.gitignore\n\n\n\nAdd integration test for the whole trash-put script\n\n\n\nJan 24, 2017\n\n\n\n\n\n\n\nCOPYING\n\n\n\nFirst import.\n\n\n\nJul 24, 2007\n\n\n\n\n\n\n\nCREDITS.txt\n\n\n\nAdd credit for Lee Yeoh\n\n\n\nJan 19, 2017\n\n\n\n\n\n\n\nDONE.txt\n\n\n\nWrite-up history for next release 0.12.4\n\n\n\nApr 12, 2012\n\n\n\n\n\n\n\nHISTORY.txt\n\n\n\nUpdate HISTORY.txt\n\n\n\nJan 22, 2017\n\n\n\n\n\n\n\nMANIFEST.in\n\n\n\nfixed inclusion of README.rst when creating distribution package\n\n\n\nJun 21, 2012\n\n\n\n\n\n\n\nREADME.rst\n\n\n\nUpdate README.rst\n\n\n\nAug 15, 2017\n\n\n\n\n\n\n\nTODO.txt\n\n\n\nClean TODO.txt\n\n\n\nDec 31, 2016\n\n\n\n\n\n\n\nVagrantfile\n\n\n\nSwitch to ubuntu/yakkety64 that is supposed to present bug #52 (crash…\n\n\n\nDec 26, 2016\n\n\n\n\n\n\n\nbugs.txt\n\n\n\nSome refactors\n\n\n\nAug 12, 2012\n\n\n\n\n\n\n\ncheck_release_installation.py\n\n\n\nAdd check for easy_install3 installation\n\n\n\nJan 13, 2017\n\n\n\n\n\n\n\ninstall-rpm.sh\n\n\n\nMade\n\n\n\nDec 23, 2008\n\n\n\n\n\n\n\nrequirements-dev.txt\n\n\n\nRemove dependency from dingus and fudge.\n\n\n\nApr 12, 2012\n\n\n\n\n\n\n\nsetup.cfg\n\n\n\nNow trash-list checks for sticky bit and symlinks.\n\n\n\nApr 11, 2012\n\n\n\n\n\n\n\nsetup.py\n\n\n\nRefactor: removed module cmds.py\n\n\n\nAug 20, 2019\n\n\n\n\n\n\n\ntrash-put\n\n\n\nAdd integration test for the whole trash-put script\n\n\n\nJan 24, 2017\n\n\n\n\n\n\n\ntrash-rm\n\n\n\nNow the integration test use the generated trash-rm script, and the g…\n\n\n\nJan 24, 2017\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.rst\n      \n\n\ntrash-cli - Command Line Interface to FreeDesktop.org Trash.\n\ntrash-cli trashes files recording the original path, deletion date, and\npermissions. It uses the same trashcan used by KDE, GNOME, and XFCE, but you\ncan invoke it from the command line (and scripts).\nIt provides these commands:\ntrash-put           trash files and directories.\ntrash-empty         empty the trashcan(s).\ntrash-list          list trashed files.\ntrash-restore       restore a trashed file.\ntrash-rm            remove individual files from the trashcan.\n\n\nUsage\nTrash a file:\n$ trash-put foo\n\nList trashed files:\n$ trash-list\n2008-06-01 10:30:48 /home/andrea/bar\n2008-06-02 21:50:41 /home/andrea/bar\n2008-06-23 21:50:49 /home/andrea/foo\n\nSearch for a file in the trashcan:\n$ trash-list | grep foo\n2007-08-30 12:36:00 /home/andrea/foo\n2007-08-30 12:39:41 /home/andrea/foo\n\nRestore a trashed file:\n$ trash-restore\n0 2007-08-30 12:36:00 /home/andrea/foo\n1 2007-08-30 12:39:41 /home/andrea/bar\n2 2007-08-30 12:39:41 /home/andrea/bar2\n3 2007-08-30 12:39:41 /home/andrea/foo2\n4 2007-08-30 12:39:41 /home/andrea/foo\nWhat file to restore [0..4]: 4\n$ ls foo\nfoo\n\nRemove all files from the trashcan:\n$ trash-empty\n\nRemove only the files that have been deleted more than <days> ago:\n$ trash-empty <days>\n\nExample:\n$ date\nTue Feb 19 20:26:52 CET 2008\n$ trash-list\n2008-02-19 20:11:34 /home/einar/today\n2008-02-18 20:11:34 /home/einar/yesterday\n2008-02-10 20:11:34 /home/einar/last_week\n$ trash-empty 7\n$ trash-list\n2008-02-19 20:11:34 /home/einar/today\n2008-02-18 20:11:34 /home/einar/yesterday\n$ trash-empty 1\n$ trash-list\n2008-02-19 20:11:34 /home/einar/today\n\nRemove only files matching a pattern:\n$ trash-rm \\*.o\n\nNote: you need to use quotes in order to protect the pattern from shell expansion.\n\nFAQ\n\nHow to create a top level .Trash dir?\nSteps\nsudo mkdir --parent /.Trash\nsudo chmod a+rw /.Trash\nsudo chmod +t /.Trash\n\n\nCan I alias rm to trash-put?\nYou can but you shouldn't. In the early days I thought it was a good idea to do\nthat but now I changed my mind.\nAlthough the interface of trash-put seems to be compatible with rm, it has\ndifferent semantics which will cause you problems. For example, while rm\nrequires -R for deleting directories trash-put does not.\n\nBut sometimes I forget to use trash-put, really can't I?\nYou could alias rm to something that will remind you to not use it:\nalias rm='echo \"This is not the command you are looking for.\"; false'\n\nThen, if you really want to use rm, simply prepend a slash to bypass the alias:\n\\rm file-without-hope\n\nNote that Bash aliases are used only in interactive shells, so using\nthis alias should not interfere with scripts that expect to use rm.\n\nInstallation\n\nThe easy way\nRequirements:\n\n\nPython 2.7 or Python 3\nsetuptools (use apt-get install python-setuptools on Debian)\n\n\nInstallation command:\neasy_install trash-cli\n\n\nFrom sources\nSystem-wide installation:\ngit clone https://github.com/andreafrancia/trash-cli.git\ncd trash-cli\nsudo python setup.py install\n\nUser-only installation:\ngit clone https://github.com/andreafrancia/trash-cli.git\ncd trash-cli\npython setup.py install --user\n\n\nBugs and feedback\nIf you discover a bug please report it here:\n\nhttps://github.com/andreafrancia/trash-cli/issues\nYou can also email me to andrea@andreafrancia.it. On Twitter I'm @andreafrancia.\n\nDevelopment\nEnvironment setup:\nvirtualenv env --no-site-packages\nsource env/bin/activate\npip install -r requirements-dev.txt\n\nRunning tests:\nnosetests unit_tests           # run only unit tests\nnosetests integration_tests    # run all integration tests\nnosetests -A 'not stress_test' # run all tests but stress tests\nnosetests                      # run all tests\n\nCheck the installation process before release:\npython check_release_installation.py\n\nProfiling unit tests:\npip install gprof2dot\nnosetests --with-profile --profile-stats-file stats.pf --profile-restrict=unit_tests unit_tests\ngprof2dot -w  -f pstats stats.pf | dot -Tsvg >| stats.svg\nopen stats.svg\n\n\n\n\n\n\n\n\n\nAbout\n\n      Command line interface to the freedesktop.org trashcan.\n    \nTopics\n\n\n\n  python\n\n\n  linux\n\n\n  trashcan\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-2.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\n\n\n17\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n        Used by 71\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            + 63\n          \n\n\n\n\n\n\n\n    Contributors 13\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 2 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\nPython\n99.5%\n\n\n\n\n\nShell\n0.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# trash\n\n> A CLI for managing your trashcan / recycling bin.\n> More information: <https://github.com/andreafrancia/trash-cli>.\n\n- Delete a file (send to trash):\n\n`trash {{path/to/file}}`\n\n- List files in trash:\n\n`trash-list`\n\n- Restore file from trash:\n\n`trash-restore`\n\n- Empty trash:\n\n`trash-empty`\n\n- Empty trash, keeping files trashed less than {{10}} days ago:\n\n`trash-empty {{10}}`\n\n- Remove all files named 'foo' from the trash:\n\n`trash-rm foo`\n\n- Remove all files with a given original location:\n\n`trash-rm {{/absolute/path/to/file_or_directory}}`\n"
 },
 {
   "command": "ptx",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ptx\n\n> Generate a permuted index of words from one or more text files.\n\n- Generate a permuted index where the first field of each line is an index reference:\n\n`ptx --references {{path/to/file}}`\n\n- Generate a permuted index with automatically generated index references:\n\n`ptx --auto-reference {{path/to/file}}`\n\n- Generate a permuted index with a fixed width:\n\n`ptx --width={{width_in_columns}} {{path/to/file}}`\n\n- Generate a permuted index with a list of filtered words:\n\n`ptx --only-file={{path/to/filter}} {{path/to/file}}`\n\n- Generate a permuted index with SYSV-style behaviors:\n\n`ptx --traditional {{path/to/file}}`\n"
 },
 {
   "command": "pkg-config",
   "doc_url": "https://www.freedesktop.org/wiki/Software/pkg-config/",
   "doc_text": "\n\n\npkg-config\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwww/ \n\nSoftware/ \n\n\n\npkg-config\n\n\n\n\n\n\nEdit\nPage History\nRepo Info\n\n\n\n\n\npkg-config\npkg-config is a helper tool used when compiling applications and\nlibraries. It helps you insert the correct compiler options on the\ncommand line so an application can use gcc -o test test.c `pkg-config\n--libs --cflags glib-2.0` for instance, rather than hard-coding values\non where to find glib (or other libraries). It is language-agnostic, so\nit can be used for defining the location of documentation tools, for\ninstance.\nThe program is free software and licensed under the\nGPL version 2 or any later\nversion (at your option).\npkg-config works on multiple platforms: Linux and other UNIX-like\noperating systems, Mac OS X and Windows. It does not require anything\nbut a reasonably well working C compiler and a C library, but can use an\ninstalled glib if that is present. (A copy of recent glib2 is shipped\ntogether with pkg-config versions since 0.27, and this is sufficient for\npkg-config to compile and work properly.)\nThe first implementation was written in shell, by James Henstridge.\nLater, it was rewritten in C by Havoc Pennington. It also grew an\nautoconf macro written by Tim Janik, later rewritten by Scott James\nRemnant. The current maintainers are\nTollef Fog Heen tfheen@err.no and\nDan Nicholson dbn.lists@gmail.com.\nThe current release of pkg-config is version\n0.29.2\nand can be found in\n/releases.\npkg-config is available from the git repository\nat git://anongit.freedesktop.org/pkg-config (browse)\nBugs can be filed in the\nFreedesktop.org bug tracker\nThere is a mailing list for development and user questions at\npkg-config@lists.freedesktop.org\n(Archives)\n(Subscribe)\nNew and veteran users alike may find\nDan Nicholsonâs Guide to pkg-config\ninformative, particularly\nthe FAQ section\nwhich provides examples of where the Requires.private field is\nappropriate.\n\n\n\n\n\nLinks:\n\nSoftware\n\n\nLast edited Mon May  7 16:24:22 2018\n\n\n\n\n\n\n\n",
   "man_entry": "pkg-config(1)\t\t\t\t\t\t\t pkg-config(1)\n\n\n\nNAME\n       pkg-config - Return metainformation about installed libraries\n\nSYNOPSIS\n       pkg-config  [--modversion]  [--version]\t[--help] [--atleast-pkgconfig-\n       version=VERSION] [--print-errors]  [--short-errors]  [--silence-errors]\n       [--errors-to-stdout]   [--debug]  [--cflags]  [--libs]  [--libs-only-L]\n       [--libs-only-l] [--cflags-only-I]  [--libs-only-other]  [--cflags-only-\n       other]  [--variable=VARIABLENAME] [--define-variable=VARIABLENAME=VARI-\n       ABLEVALUE] [--print-variables] [--uninstalled]  [--exists]  [--atleast-\n       version=VERSION]    [--exact-version=VERSION]   [--max-version=VERSION]\n       [--validate]   [--list-all]    [--print-provides]    [--print-requires]\n       [--print-requires-private] [LIBRARIES...]\n\nDESCRIPTION\n       The  pkg-config program is used to retrieve information about installed\n       libraries in the system.  It is typically  used\tto  compile  and  link\n       against\tone  or more libraries.  Here is a typical usage scenario in a\n       Makefile:\n\n       program: program.c\n\t    cc program.c `pkg-config --cflags --libs gnomeui`\n\n       pkg-config retrieves information about packages from  special  metadata\n       files.  These  files  are named after the package, and has a .pc exten-\n       sion.   On  most  systems,  pkg-config  looks  in   /usr/lib/pkgconfig,\n       /usr/share/pkgconfig,\t\t/usr/local/lib/pkgconfig\t   and\n       /usr/local/share/pkgconfig for these files.  It will additionally  look\n       in the colon-separated (on Windows, semicolon-separated) list of direc-\n       tories specified by the PKG_CONFIG_PATH environment variable.\n\n       The package name specified on the pkg-config command line is defined to\n       be the name of the metadata file, minus the .pc extension. If a library\n       can install multiple versions simultaneously, it must give each version\n       its  own  name (for example, GTK 1.2 might have the package name \"gtk+\"\n       while GTK 2.0 has \"gtk+-2.0\").\n\n       In addition to specifying a package name on the command line, the  full\n       path  to  a  given .pc file may be given instead. This allows a user to\n       directly query a particular .pc file.\n\nOPTIONS\n       The following options are supported:\n\n       --modversion\n\t      Requests that the version information of the libraries specified\n\t      on  the  command\tline be displayed.  If pkg-config can find all\n\t      the libraries on the command line, each library's version string\n\t      is  printed  to  stdout, one version per line. In this case pkg-\n\t      config exits successfully. If one or more libraries is  unknown,\n\t      pkg-config exits with a nonzero code, and the contents of stdout\n\t      are undefined.\n\n       --version\n\t      Displays the version of pkg-config and terminates.\n\n       --atleast-pkgconfig-version=VERSION\n\t      Requires at least the given version of pkg-config.\n\n       --help Displays a help message and terminates.\n\n       --print-errors\n\t      If one or more of the modules on\tthe  command  line,  or  their\n\t      dependencies,  are not found, or if an error occurs in parsing a\n\t      .pc file, then this option  will\tcause  errors  explaining  the\n\t      problem\tto  be\tprinted.  With\t\"predicate\"  options  such  as\n\t      \"--exists\" pkg-config runs silently  by  default,  because  it's\n\t      usually used in scripts that want to control what's output. This\n\t      option can be used  alone  (to  just  print  errors  encountered\n\t      locating modules on the command line) or with other options. The\n\t      PKG_CONFIG_DEBUG_SPEW  environment   variable   overrides   this\n\t      option.\n\n       --short-errors\n\t      Print short error messages.\n\n       --silence-errors\n\t      If  one  or  more  of  the modules on the command line, or their\n\t      dependencies, are not found, or if an error occurs in parsing  a\n\t      a  .pc  file,  then  this option will keep errors explaining the\n\t      problem from being printed. With\t\"predicate\"  options  such  as\n\t      \"--exists\"  pkg-config  runs  silently  by default, because it's\n\t      usually used in scripts that want to control what's  output.  So\n\t      this  option  is\tonly useful with options such as \"--cflags\" or\n\t      \"--modversion\"  that  print  errors  by  default.  The  PKG_CON-\n\t      FIG_DEBUG_SPEW environment variable overrides this option.\n\n       --errors-to-stdout\n\t      If printing errors, print them to stdout rather than the default\n\t      stderr\n\n       --debug\n\t      Print debugging information. This is slightly different than the\n\t      PKG_CONFIG_DEBUG_SPEW  environment  variable,  which also enable\n\t      \"--print-errors\".\n\n\n       The following options are used to compile and link programs:\n\n       --cflags\n\t      This prints pre-processor and compile flags required to  compile\n\t      the  packages on the command line, including flags for all their\n\t      dependencies. Flags are \"compressed\" so that each identical flag\n\t      appears  only  once.  pkg-config exits with a nonzero code if it\n\t      can't find metadata for one or more of the packages on the  com-\n\t      mand line.\n\n       --cflags-only-I\n\t      This  prints  the -I part of \"--cflags\". That is, it defines the\n\t      header search path but doesn't specify anything else.\n\n       --cflags-only-other\n\t      This prints parts of \"--cflags\" not covered  by  \"--cflags-only-\n\t      I\".\n\n       --libs This  option is identical to \"--cflags\", only it prints the link\n\t      flags. As with \"--cflags\", duplicate flags are merged (maintain-\n\t      ing proper ordering), and flags for dependencies are included in\n\t      the output.\n\n       --libs-only-L\n\t      This prints the -L/-R part of \"--libs\". That is, it defines  the\n\t      library  search path but doesn't specify which libraries to link\n\t      with.\n\n       --libs-only-l\n\t      This prints the -l part of \"--libs\" for the libraries  specified\n\t      on  the command line. Note that the union of \"--libs-only-l\" and\n\t      \"--libs-only-L\" may be smaller than \"--libs\", due to flags  such\n\t      as -rdynamic.\n\n       --libs-only-other\n\t      This prints the parts of \"--libs\" not covered by \"--libs-only-L\"\n\t      and \"--libs-only-l\", such as \"--pthread\".\n\n       --variable=VARIABLENAME\n\t      This returns the value of a variable defined in a package's  .pc\n\t      file.  Most  packages define the variable \"prefix\", for example,\n\t      so you can say:\n\t\t$ pkg-config --variable=prefix glib-2.0\n\t\t/usr/\n\n       --define-variable=VARIABLENAME=VARIABLEVALUE\n\t      This sets a global value for a variable, overriding the value in\n\t      any  .pc\tfiles. Most packages define the variable \"prefix\", for\n\t      example, so you can say:\n\t\t$ pkg-config --print-errors --define-variable=prefix=/foo \\\n\t\t\t     --variable=prefix glib-2.0\n\t\t/foo\n\n       --print-variables\n\t      Returns a list of all variables defined in the package.\n\n\n       --uninstalled\n\t      Normally if you request the package \"foo\" and the package  \"foo-\n\t      uninstalled\"  exists,  pkg-config will prefer the \"-uninstalled\"\n\t      variant. This  allows  compilation/linking  against  uninstalled\n\t      packages.  If you specify the \"--uninstalled\" option, pkg-config\n\t      will return successfully\tif  any  \"-uninstalled\"  packages  are\n\t      being used, and return failure (false) otherwise.  (The PKG_CON-\n\t      FIG_DISABLE_UNINSTALLED environment  variable  keeps  pkg-config\n\t      from  implicitly\tchoosing  \"-uninstalled\"  packages, so if that\n\t      variable is set, they will only have been used  if  you  pass  a\n\t      name like \"foo-uninstalled\" on the command line explicitly.)\n\n       --exists\n\n       --atleast-version=VERSION\n\n       --exact-version=VERSION\n\n       --max-version=VERSION\n\t      These  options  test  whether the package or list of packages on\n\t      the command line are known to pkg-config, and optionally whether\n\t      the  version  number of a package meets certain constraints.  If\n\t      all packages exist and meet the specified  version  constraints,\n\t      pkg-config  exits  successfully.\tOtherwise  it exits unsuccess-\n\t      fully. Only the first VERSION comparing option will be  honored.\n\t      Subsequent options of this type will be ignored.\n\n\t      Rather  than using the version-test options, you can simply give\n\t      a version constraint after each package name, for example:\n\t\t$ pkg-config --exists 'glib-2.0 >= 1.3.4 libxml = 1.8.3'\n\t      Remember to use --print-errors if you want error messages.  When\n\t      no  output  options  are\tsupplied  to  pkg-config,  --exists is\n\t      implied.\n\n       --validate\n\t      Checks the syntax of a package's .pc file for validity. This  is\n\t      the  same as --exists except that dependencies are not verified.\n\t      This can be useful for package developers to test their .pc file\n\t      prior to release:\n\t\t$ pkg-config --validate ./my-package.pc\n\n       --msvc-syntax\n\t      This  option  is available only on Windows. It causes pkg-config\n\t      to output -l  and  -L  flags  in\tthe  form  recognized  by  the\n\t      Microsoft  Visual  C++  command-line compiler, cl. Specifically,\n\t      instead of -Lx:/some/path it  prints  /libpath:x/some/path,  and\n\t      instead  of -lfoo it prints foo.lib. Note that the --libs output\n\t      consists of flags for the linker, and should be placed on the cl\n\t      command line after a /link switch.\n\n       --define-prefix\n\t      --dont-define-prefix  These  options  control whether pkg-config\n\t      overrides the value of the variable prefix  in  each  .pc  file.\n\t      With  --define-prefix, pkg-config uses the installed location of\n\t      the .pc file to determine the prefix. --dont-define-prefix  pre-\n\t      vents this behavior. The default is usually --define-prefix.\n\n\t      When this feature is enabled and a .pc file is found in a direc-\n\t      tory named pkgconfig, the prefix for that package is assumed  to\n\t      be  the  grandparent  of the directory where the file was found,\n\t      and the prefix variable is overridden for that file accordingly.\n\n\t      If  the value of a variable in a .pc file begins with the origi-\n\t      nal, non-overridden, value of  the  prefix  variable,  then  the\n\t      overridden value of prefix is used instead. This allows the fea-\n\t      ture to work even when the variables have been expanded  in  the\n\t      .pc file.\n\n       --prefix-variable=PREFIX\n\t      Set  the\tname of the variable that pkg-config overrides instead\n\t      of prefix when using the --define-prefix feature.\n\n       --static\n\t      Output  libraries  suitable  for\tstatic\tlinking.   That  means\n\t      including  any  private libraries in the output.\tThis relies on\n\t      proper tagging in the .pc files, else  a\ttoo  large  number  of\n\t      libraries will ordinarily be output.\n\n       --list-all\n\t      List all modules found in the pkg-config path.\n\n       --print-provides\n\t      List all modules the given packages provides.\n\n       --print-requires\n\t      List all modules the given packages requires.\n\n       --print-requires-private\n\t      List  all modules the given packages requires for static linking\n\t      (see --static).\n\nENVIRONMENT VARIABLES\n       PKG_CONFIG_PATH\n\t      A colon-separated  (on  Windows,\tsemicolon-separated)  list  of\n\t      directories to search for .pc files.  The default directory will\n\t      always be searched after searching  the  path;  the  default  is\n\t      libdir/pkgconfig:datadir/pkgconfig  where  libdir  is the libdir\n\t      for pkg-config and datadir is the datadir for pkg-config when it\n\t      was installed.\n\n       PKG_CONFIG_DEBUG_SPEW\n\t      If set, causes pkg-config to print all kinds of debugging infor-\n\t      mation and report all errors.\n\n       PKG_CONFIG_TOP_BUILD_DIR\n\t      A value to set for the magic variable pc_top_builddir which  may\n\t      appear in .pc files. If the environment variable is not set, the\n\t      default value '$(top_builddir)'  will  be  used.\tThis  variable\n\t      should  refer to the top builddir of the Makefile where the com-\n\t      pile/link flags reported by pkg-config will be used.  This  only\n\t      matters when compiling/linking against a package that hasn't yet\n\t      been installed.\n\n       PKG_CONFIG_DISABLE_UNINSTALLED\n\t      Normally if you request the package \"foo\" and the package  \"foo-\n\t      uninstalled\"  exists,  pkg-config will prefer the \"-uninstalled\"\n\t      variant. This  allows  compilation/linking  against  uninstalled\n\t      packages.  If this environment variable is set, it disables said\n\t      behavior.\n\n       PKG_CONFIG_SYSTEM_INCLUDE_PATH\n\t      A path variable containing system directories  searched  by  the\n\t      compiler.  This is normally /usr/include.\n\n       CPATH  C_INCLUDE_PATH  CPLUS_INCLUDE_PATH Additional paths to append to\n\t      PKG_CONFIG_SYSTEM_INCLUDE_PATH.  These correspond to environment\n\t      variables  used  by  many  compilers to affect the header search\n\t      path. These are ignored on Windows builds when --msvc-syntax  is\n\t      in use.\n\n       INCLUDE\n\t      Additional  paths to append to PKG_CONFIG_SYSTEM_INCLUDE_PATH on\n\t      Windows builds when --msvc-syntax is in use. This corresponds to\n\t      the  environment variable used by MSVC to add directories to the\n\t      include file search path.\n\n       PKG_CONFIG_ALLOW_SYSTEM_CFLAGS\n\t      Don't strip system paths\tout  of  Cflags.  See  PKG_CONFIG_SYS-\n\t      TEM_INCLUDE_PATH for the definition of system paths.\n\n       PKG_CONFIG_SYSTEM_LIBRARY_PATH\n\t      A  path  variable  containing system directories searched by the\n\t      linker.  This is normally /usr/lib:/lib but is dependent on  the\n\t      pkg-config  build  and  can  contain  other  directories such as\n\t      /usr/lib64.\n\n       PKG_CONFIG_ALLOW_SYSTEM_LIBS\n\t      Don't strip  system  paths  out  of  Libs.  See  PKG_CONFIG_SYS-\n\t      TEM_LIBRARY_PATH for the definition of system paths.\n\n       PKG_CONFIG_SYSROOT_DIR\n\t      Modify  -I  and -L to use the directories located in target sys-\n\t      root.  this option is useful when cross-compiling packages  that\n\t      use  pkg-config  to  determine CFLAGS and LDFLAGS. -I and -L are\n\t      modified to point to the new system  root.  this\tmeans  that  a\n\t      -I/usr/include/libfoo will become -I/var/target/usr/include/lib-\n\t      foo with a PKG_CONFIG_SYSROOT_DIR  equal\tto  /var/target  (same\n\t      rule apply to -L)\n\n       PKG_CONFIG_LIBDIR\n\t      Replaces\t the  default  pkg-config  search  directory,  usually\n\t      /usr/lib/pkgconfig:/usr/share/pkgconfig.\n\n       PKG_CONFIG_$PACKAGE_$VARIABLE\n\t      Overrides the variable VARIABLE  in  the\tpackage  PACKAGE.  The\n\t      environment  variable  should  have the package name and package\n\t      variable upper cased with non-alphanumeric characters  converted\n\t      to underscores. For example, setting PKG_CONFIG_GLADEUI_2_0_CAT-\n\t      ALOGDIR  will  override  the  variable   \"catalogdir\"   in   the\n\t      \"gladeui-2.0\" package.\n\nPKG-CONFIG DERIVED VARIABLES\n       pkg-config  sets a few metadata variables that can be used in .pc files\n       or queried at runtime.\n\n       pc_path\n\t      The default search path used by pkg-config  when\tsearching  for\n\t      .pc files. This can be used in a query for the pkg-config module\n\t      itself itself:\n\t\t$ pkg-config --variable pc_path pkg-config\n\n       pcfiledir\n\t      The installed location of the .pc file.  This  can  be  used  to\n\t      query  the location of the .pc file for a particular module, but\n\t      it can also be used to make .pc files relocatable. For instance:\n\t      prefix=${pcfiledir}/../..\n\t      exec_prefix=${prefix}\n\t      libdir=${exec_prefix}/lib\n\t      includedir=${prefix}/include\n\n       pc_sysrootdir\n\t      The  sysroot  directory set by the user. When the sysroot direc-\n\t      tory has not been set, this value is /.  See the PKG_CONFIG_SYS-\n\t      ROOT_DIR environment variable for more details.\n\n       pc_top_builddir\n\t      Location of the user's top build directory when calling pkg-con-\n\t      fig.  This is useful to dynamically set paths in uninstalled .pc\n\t      files. See the PKG_CONFIG_TOP_BUILD_DIR environment variable for\n\t      more details.\n\nWINDOWS SPECIALITIES\n       The pkg-config default search path is ignored on Windows. Instead,  the\n       search path is constructed by using the installed directory of pkg-con-\n       fig and then appending lib\\pkgconfig and share\\pkgconfig.  This can  be\n       augmented   or\treplaced  using  the  standard\tenvironment  variables\n       described above.\n\nAUTOCONF MACROS\n       PKG_CHECK_MODULES(VARIABLE-PREFIX, MODULES [,ACTION-IF-FOUND  [,ACTION-\n       IF-NOT-FOUND]])\n\n\t      The macro PKG_CHECK_MODULES can be used in configure.ac to check\n\t      whether modules exist. A typical usage would be:\n\t       PKG_CHECK_MODULES([MYSTUFF], [gtk+-2.0 >= 1.3.5 libxml = 1.8.4])\n\n\t      This  would  result in MYSTUFF_LIBS and MYSTUFF_CFLAGS substitu-\n\t      tion variables, set to the libs and cflags for the given\tmodule\n\t      list.   If  a  module  is  missing  or has the wrong version, by\n\t      default configure will abort with  a  message.  To  replace  the\n\t      default\t   action,     specify\t   an\t  ACTION-IF-NOT-FOUND.\n\t      PKG_CHECK_MODULES will not print any error messages if you spec-\n\t      ify  your  own  ACTION-IF-NOT-FOUND.   However,  it will set the\n\t      variable MYSTUFF_PKG_ERRORS, which you can use to  display  what\n\t      went wrong.\n\n\t      Note   that  if  there  is  a  possibility  the  first  call  to\n\t      PKG_CHECK_MODULES might  not  happen,  you  should  be  sure  to\n\t      include  an explicit call to PKG_PROG_PKG_CONFIG in your config-\n\t      ure.ac.\n\n\t      Also note that repeated usage of VARIABLE-PREFIX is  not\trecom-\n\t      mended.  After the first successful usage, subsequent calls with\n\t      the same VARIABLE-PREFIX will simply use the _LIBS  and  _CFLAGS\n\t      variables set from the previous usage without calling pkg-config\n\t      again.\n\n       PKG_PREREQ(MIN-VERSION)\n\t      Checks that the version of the pkg-config autoconf macros in use\n\t      is at least MIN-VERSION. This can be used to ensure a particular\n\t      pkg-config macro will be available.\n\n       PKG_PROG_PKG_CONFIG([MIN-VERSION])\n\n\t      Defines the PKG_CONFIG variable to the  best  pkg-config\tavail-\n\t      able,  useful  if  you  need  pkg-config\tbut  don't want to use\n\t      PKG_CHECK_MODULES.\n\n\t      If the first call to PKG_PROG_PKG_CONFIG is conditional, then it\n\t      will  not  work  correctly in all cases. Since many of the other\n\t      macros such as PKG_CHECK_MODULES require PKG_PROG_PKG_CONFIG  to\n\t      know which pkg-config program to run, PKG_PROG_PKG_CONFIG may be\n\t      run for the first time from a  conditional  from\tone  of  these\n\t      macros.  Therefore, if any of the pkg-config macros will be used\n\t      under a conditional, it's best to run PKG_PROG_PKG_CONFIG before\n\t      any of the other macros are used.\n\n\n       PKG_CHECK_MODULES_STATIC(VARIABLE-PREFIX,   MODULES   [,ACTION-IF-FOUND\n       [,ACTION-IF-NOT-FOUND]])\n\t      Enables\tstatic\tlinking  through  --static  prior  to  calling\n\t      PKG_CHECK_MODULES.\n\n       PKG_CHECK_EXISTS(MODULES, [ACTION-IF-FOUND], [ACTION-IF-NOT-FOUND])\n\n\t      Check to see whether a particular set of modules exists.\t Simi-\n\t      lar  to PKG_CHECK_MODULES(), but does not set variables or print\n\t      errors.\n\n\t      Similar to PKG_CHECK_MODULES, make sure that the first  instance\n\t      of  this\tor  PKG_CHECK_MODULES  is called, or make sure to call\n\t      PKG_PROG_PKGCONFIG manually.\n\n\n       PKG_INSTALLDIR(DIRECTORY)\n\n\t      Substitutes the variable pkgconfigdir as the  location  where  a\n\t      module  should  install  pkg-config  .pc\tfiles.\tBy default the\n\t      directory is $libdir/pkgconfig, but the default can  be  changed\n\t      by passing DIRECTORY.  The user can override through the --with-\n\t      pkgconfigdir parameter.\n\n       PKG_NOARCH_INSTALLDIR(DIRECTORY)\n\n\t      Substitutes the variable\tnoarch_pkgconfigdir  as  the  location\n\t      where  a\tmodule\tshould install arch-independent pkg-config .pc\n\t      files. By default the directory is $datadir/pkgconfig,  but  the\n\t      default  can be changed by passing DIRECTORY. The user can over-\n\t      ride through the --with-noarch-pkgconfigdir parameter.\n\n       PKG_CHECK_VAR(VARIABLE,\tMODULE,  CONFIG-VARIABLE,   [ACTION-IF-FOUND],\n       [ACTION-IF-NOT-FOUND])\n\n\t      Retrieves the value of the pkg-config  variable  CONFIG-VARIABLE\n\t      from  MODULE and stores it in VARIABLE. Note that repeated usage\n\t      of VARIABLE is not recommended as the check will be  skipped  if\n\t      the variable is already set.\n\n\nMETADATA FILE SYNTAX\n       To  add a library to the set of packages pkg-config knows about, simply\n       install a .pc file. You should install this file to libdir/pkgconfig.\n\n       Here is an example file:\n       # This is a comment\n       prefix=/home/hp/unst   # this defines a variable\n       exec_prefix=${prefix}  # defining another variable in terms of the first\n       libdir=${exec_prefix}/lib\n       includedir=${prefix}/include\n\n       Name: GObject\t\t\t\t# human-readable name\n       Description: Object/type system for GLib # human-readable description\n       Version: 1.3.1\n       URL: http://www.gtk.org\n       Requires: glib-2.0 = 1.3.1\n       Conflicts: foobar <= 4.5\n       Libs: -L${libdir} -lgobject-1.3\n       Libs.private: -lm\n       Cflags: -I${includedir}/glib-2.0 -I${libdir}/glib/include\n\n       You would normally generate the file using configure, so that the  pre-\n       fix, etc. are set to the proper values.\tThe GNU Autoconf manual recom-\n       mends generating files like .pc files at build time rather than config-\n       ure time, so when you build the .pc file is a matter of taste and pref-\n       erence.\n\n       Files have two kinds of line: keyword lines start with a keyword plus a\n       colon,  and variable definitions start with an alphanumeric string plus\n       an equals sign. Keywords are defined in advance and have special  mean-\n       ing  to\tpkg-config;  variables do not, you can have any variables that\n       you wish (however, users may expect to  retrieve  the  usual  directory\n       name variables).\n\n       Note that variable references are written \"${foo}\"; you can escape lit-\n       eral \"${\" as \"$${\".\n\n       Name:  This field should be a human-readable name for the package. Note\n\t      that it is not the name passed as an argument to pkg-config.\n\n       Description:\n\t      This should be a brief description of the package\n\n       URL:   An  URL where people can get more information about and download\n\t      the package\n\n       Version:\n\t      This  should  be\tthe  most-specific-possible  package   version\n\t      string.\n\n       Requires:\n\t      This  is a comma-separated list of packages that are required by\n\t      your package. Flags from dependent packages will be merged in to\n\t      the flags reported for your package. Optionally, you can specify\n\t      the version of the required package (using the operators\t=,  <,\n\t      >,  >=,  <=);  specifying a version allows pkg-config to perform\n\t      extra sanity checks. You may only mention the same  package  one\n\t      time  on\tthe  Requires:\tline.  If  the version of a package is\n\t      unspecified, any version will be used with no checking.\n\n       Requires.private:\n\t      A list of packages required by this package. The difference from\n\t      Requires\tis that the packages listed under Requires.private are\n\t      not taken into account when a flag list is computed for  dynami-\n\t      cally linked executable (i.e., when --static was not specified).\n\t      In the situation where each .pc file corresponds to  a  library,\n\t      Requires.private shall be used exclusively to specify the depen-\n\t      dencies between the libraries.\n\n       Conflicts:\n\t      This optional line allows pkg-config to perform additional  san-\n\t      ity  checks, primarily to detect broken user installations.  The\n\t      syntax is the same as Requires: except that  you\tcan  list  the\n\t      same  package  more than once here, for example \"foobar = 1.2.3,\n\t      foobar = 1.2.5, foobar >= 1.3\", if you have reason to do so.  If\n\t      a  version isn't specified, then your package conflicts with all\n\t      versions of the mentioned package.  If a user tries to use  your\n\t      package  and  a  conflicting package at the same time, then pkg-\n\t      config will complain.\n\n       Libs:  This line should give the link flags specific to\tyour  package.\n\t      Don't  add  any flags for required packages; pkg-config will add\n\t      those automatically.\n\n       Libs.private:\n\t      This line should list any private  libraries  in\tuse.   Private\n\t      libraries  are  libraries  which\tare  not  exposed through your\n\t      library, but are needed in the case of static linking. This dif-\n\t      fers  from Requires.private in that it references libraries that\n\t      do not have package files installed.\n\n       Cflags:\n\t      This line should list the compile flags specific to  your  pack-\n\t      age.  Don't add any flags for required packages; pkg-config will\n\t      add those automatically.\n\nAUTHOR\n       pkg-config was written by James Henstridge, rewritten  by  Martijn  van\n       Beers, and rewritten again by Havoc Pennington. Tim Janik, Owen Taylor,\n       and Raja Harinath submitted suggestions and  some  code.   gnome-config\n       was  written  by  Miguel de Icaza, Raja Harinath and various hackers in\n       the GNOME team.\tIt was inspired by Owen Taylor's gtk-config program.\n\nBUGS\n       pkg-config does not handle mixing of  parameters  with  and  without  =\n       well.  Stick with one.\n\n       Bugs can be reported at http://bugs.freedesktop.org/ under the pkg-con-\n       fig component.\n\n\n\n\t\t\t\t\t\t\t\t pkg-config(1)\n",
   "tldr_summary": "# pkg-config\n\n> Provide the details of installed libraries for compiling applications.\n> More information: <https://www.freedesktop.org/wiki/Software/pkg-config/>.\n\n- Get the list of libraries and their dependencies:\n\n`pkg-config --libs {{library1 library2 ...}}`\n\n- Get the list of libraries, their dependencies, and proper cflags for gcc:\n\n`pkg-config --cflags --libs {{library1 library2 ...}}`\n\n- Compile your code with libgtk-3, libwebkit2gtk-4.0 and all their dependencies:\n\n`c++ example.cpp $(pkg-config --cflags --libs gtk+-3.0 webkit2gtk-4.0) -o example`\n"
 },
 {
   "command": "as",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "AS(1)\t\t\t\t\t\t\t\t\t AS(1)\n\n\n\nNAME\n       as - Mac OS X Mach-O GNU-based assemblers\n\nSYNOPSIS\n       as [ option ...\t] [ file ...  ]\n\nDESCRIPTION\n       The  as\tcommand  translates assembly code in the named files to object\n       code.  If no files are specified, as reads from stdin.\tAll  undefined\n       symbols\tin  the  assembly  are\ttreated  as global.  The output of the\n       assembly is left in the file a.out by default.\n\n       The program /usr/bin/as is actually a driver that  executes  assemblers\n       for specific target architectures.  If no target architecture is speci-\n       fied, it defaults to the architecture of the host it is running on.\n\nOPTIONS\n       -o name\n\t      Name the output file name instead of a.out.\n\n       -arch arch_type\n\t      Specifies the target architecture, arch_type, of\tthe  assembler\n\t      to be executed.  The target assemblers for each architecture are\n\t      in\t    /usr/libexec/gcc/darwin/arch_type/as\t    or\n\t      /usr/local/libexec/gcc/darwin/arch_type/as.   There  is only one\n\t      assembler for an architecture family.  If the  specified\ttarget\n\t      architecture is a machine-specific implementation, the assembler\n\t      for   that    architecture    family    is    executed\t(e.g.,\n\t      /usr/libexec/gcc/darwin/ppc/as  for -arch ppc604e).  See arch(3)\n\t      for the currently known arch_types.\n\n       -arch_multiple\n\t      Precede any displayed messages with a line stating  the  program\n\t      name  (as) and the architecture (from the -arch arch_type flag),\n\t      to distinguish which architecture the error messages  refer  to.\n\t      When  the cc(1) driver program is run with multiple -arch flags,\n\t      it invokes as with the -arch_multiple option.\n\n       -force_cpusubtype_ALL\n\t      By default, the assembler will produce the CPU subtype  ALL  for\n\t      the  object file it is assembling if it finds no implementation-\n\t      specific instructions.  Also  by\tdefault,  the  assembler  will\n\t      allow  implementation-specific instructions and will combine the\n\t      CPU subtype for those specific implementations.\tThe  combining\n\t      of  specific  implementations is architecture-dependent; if some\n\t      combination of instructions is not allowed, an error  is\tgener-\n\t      ated.    With   the  optional  -force_cpusubtype_ALL  flag,  all\n\t      instructions are allowed and the object file's CPU subtype  will\n\t      be  the  ALL subtype.  If the target architecture specified is a\n\t      machine-specific\timplementation\t(e.g.,\t-arch  ppc603,\t -arch\n\t      i486),  the  assembler will flag as errors instructions that are\n\t      not supported on that  architecture,  and  it  will  produce  an\n\t      object  file  with the CPU subtype for that specific implementa-\n\t      tion (even if no implementation-specific instructions are used).\n\t      The  -force_cpusubtype_ALL  flag\tis the default for all x86 and\n\t      x86_64 architectures.\n\n       -dynamic\n\t      Enables dynamic linking features.  This is the default.\n\n       -static\n\t      Causes the assembler to treat  as  an  error  any  features  for\n\t      dynamic linking.\tAlso causes the .text directive to not include\n\t      the pure_instructions section attribute.\n\n       --     Use stdin for the assembly source input.\n\n       -n     Instructs the assembler not to assume  that  the\tassembly  file\n\t      starts  with  a .text directive.\tUse this option when an output\n\t      file is not to contain a (__TEXT,__text) section or this section\n\t      is not to be first one in the output file.\n\n       -f     Fast;  no  need  for  the assembler preprocessor (``app'').  The\n\t      assembler preprocessor can also be turned off  by  starting  the\n\t      assembly\tfile  with  \"#NO_APP\\n\".   This is intended for use by\n\t      compilers which produce assembly code in a strict \"clean\" format\n\t      that  specifies  exactly where whitespace can go.  The assembler\n\t      preprocessor needs to be\trun  on  hand-written  assembly  files\n\t      and/or  files  that have been preprocessed by the C preprocessor\n\t      cpp.  This is typically needed when assembler files  are\tassem-\n\t      bled  through  the use of the cc(1) command, which automatically\n\t      runs the C preprocessor on assembly source files.  The assembler\n\t      preprocessor strips out excess spaces, turns single-quoted char-\n\t      acters into a decimal constants, and turns # <number> <filename>\n\t      <level>  into  .line <number>;.file <filename>  pairs.  When the\n\t      assembler preprocessor has been turned off by a  \"#NO_APP\\n\"  at\n\t      the start of a file, it can be turned back on and off again with\n\t      pairs of \"#APP\\n\" and \"#NO_APP\\n\" at the\tbeginnings  of\tlines.\n\t      This  is\tused  by the compiler to wrap assembly statements pro-\n\t      duced from asm() statements.\n\n       -g     Produce debugging information for the symbolic  debugger\tgdb(1)\n\t      so  that\tthe assembly source can be debugged symbolically.  The\n\t      debugger depends on correct use of the C preprocessor's #include\n\t      directive  or  the  assembler's .include directive:  Any include\n\t      file that produces instructions in the  (__TEXT,__text)  section\n\t      must be included while a .text directive is in effect.  In other\n\t      words, there must be a .text directive before the  include,  and\n\t      the  .text  directive  must still be in effect at the end of the\n\t      include file.  Otherwise, the debugger will get confused when in\n\t      that assembly file.\n\n       -v     Display  the version of the assembler (both the Mac OS X version\n\t      and the GNU version it is based on).\n\n       -V     Print the path and the command line of the assembler the\tassem-\n\t      bler driver is using.\n\n       -Idir  Add  the\tdirectory dir to the list of directories to search for\n\t      files included with the .include directive.  The\tdefault  place\n\t      to search is the current directory.\n\n       -W     Suppress warnings.\n\n       -L     Save  non-global\tdefined  labels  beginning  with an 'L'; these\n\t      labels are normally discarded to save  space  in\tthe  resultant\n\t      symbol table.  The compiler generates such temporary labels.\n\n       -q     Use  the\tclang(1) integrated assembler instead of the GNU based\n\t      system assembler.  This is the  default  for  the  x86  and  arm\n\t      architectures.\n\n       -Q     Use the GNU based system assembler.\n\nAssembler options for the PowerPC processors\n       -static_branch_prediction_Y_bit\n\t      Treat  a\tsingle trailing '+' or '-' after a conditional PowerPC\n\t      branch instruction as a static branch prediction that  sets  the\n\t      Y-bit  in the opcode.  Pairs of trailing \"++\" or \"--\" always set\n\t      the AT-bits. This is the default for Mac OS X.\n\n       -static_branch_prediction_AT_bits\n\t      Treat a single trailing '+' or '-' after a  conditional  PowerPC\n\t      branch  instruction  as a static branch prediction that sets the\n\t      AT-bits in the opcode. Pairs of trailing \"++\" or \"--\" always set\n\t      the  AT-bits  but  with  this option a warning is issued if this\n\t      syntax is used.  With this flag the assembler behaves  like  the\n\t      IBM tools.\n\n       -no_ppc601\n\t      Treat any PowerPC 601 instructions as an error.\n\nFILES\n       a.out\t output file\n\nSEE ALSO\n       The  Mac  OS  X\tAssembler Reference in the Xcode documentation viewer:\n       Perform a title search for \"assembler\" in Apple > Developer Tools  Ref-\n       erence Library.\n       The assembler source in the cctools module of the Darwin sources.\n       cc(1), ld(1), nm(1), otool(1), arch(3), Mach-O(5)\n\n\n\nApple Inc.\t\t       February 12, 2015\t\t\t AS(1)\n",
   "tldr_summary": "# as\n\n> Portable GNU assembler.\n> Primarily intended to assemble output from `gcc` to be used by `ld`.\n\n- Assemble a file, writing the output to a.out:\n\n`as {{file.s}}`\n\n- Assemble the output to a given file:\n\n`as {{file.s}} -o {{out.o}}`\n\n- Generate output faster by skipping whitespace and comment preprocessing. (Should only be used for trusted compilers):\n\n`as -f {{file.s}}`\n\n- Include a given path to the list of directories to search for files specified in .include directives:\n\n`as -I {{path/to/directory}} {{file.s}}`\n"
 },
 {
   "command": "genkernel",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# genkernel\n\n> Gentoo Linux utility to compile and install kernels.\n\n- Automatically compile and install a generic kernel:\n\n`sudo genkernel all`\n\n- Build and install the bzImage|initramfs|kernel|ramdisk only:\n\n`sudo genkernel {{bzImage|initramfs|kernel|ramdisk}}`\n\n- Apply changes to the kernel configuration before compiling and installing:\n\n`sudo genkernel --menuconfig all`\n\n- Generate a kernel with a custom name:\n\n`sudo genkernel --kernname={{custom_name}} all`\n\n- Use a kernel source outside of the default directory /usr/src/linux:\n\n`sudo genkernel --kerneldir={{path/to/directory}} all`\n"
 },
 {
   "command": "ipcrm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nipcrm(1)\t\t  BSD General Commands Manual\t\t      ipcrm(1)\n\nNAME\n     ipcrm -- remove the specified message queues, semaphore sets, and shared\n     memory segments\n\nSYNOPSIS\n     ipcrm [-M shmkey] [-m shmid] [-Q msgkey] [-q msqid] [-S semkey]\n\t   [-s semid] ...\n\nDESCRIPTION\n     Ipcrm removes the specified message queues, semaphores and shared memory\n     segments.\tThese System V IPC objects can be specified by their creation\n     id or any associated key.\n\n     The following options are used to specify which IPC objects will be\n     removed.  Any number and combination of these options can be used:\n\n     -M shmkey\n\t     Mark the shared memory segment associated with key shmkey for\n\t     removal.  This marked segment will be destroyed after the last\n\t     detach.\n\n     -m shmid\n\t     Mark the shared memory segment associated with id shmid for\n\t     removal.  This marked segment will be destroyed after the last\n\t     detach.\n\n     -Q msgkey\n\t     Remove the message queue associated with key msgkey from the sys-\n\t     tem.\n\n     -q msqid\n\t     Remove the message queue associated with the id msqid from the\n\t     system.\n\n     -S semkey\n\t     Remove the semaphore set associated with key semkey from the sys-\n\t     tem.\n\n     -s semid\n\t     Removes the semaphore set associated with id semid from the sys-\n\t     tem.\n\n     The identifiers and keys associated with these System V IPC objects can\n     be determined by using ipcs(1)\n\nSEE ALSO\n     ipcs(1)\n\nBSD\t\t\t\tAugust 8, 1994\t\t\t\t   BSD\n",
   "tldr_summary": "# ipcrm\n\n> Delete IPC (Inter-process Communication) resources.\n\n- Delete a shared memory segment by ID:\n\n`ipcrm --shmem-id {{shmem_id}}`\n\n- Delete a shared memory segment by key:\n\n`ipcrm --shmem-key {{shmem_key}}`\n\n- Delete an IPC queue by ID:\n\n`ipcrm --queue-id {{ipc_queue_id}}`\n\n- Delete an IPC queue by key:\n\n`ipcrm --queue-key {{ipc_queue_key}}`\n\n- Delete a semaphore by ID:\n\n`ipcrm --semaphore-id {{semaphore_id}}`\n\n- Delete a semaphore by key:\n\n`ipcrm --semaphore-key {{semaphore_key}}`\n\n- Delete all IPC resources:\n\n`ipcrm --all`\n"
 },
 {
   "command": "larasail",
   "doc_url": "https://github.com/thedevdojo/larasail",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - thedevdojo/larasail: LaraSail - Set Sail with your Laravel app on DigitalOcean\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthedevdojo\n\n/\n\nlarasail\n\n\n\n\n\n\n\n    Watch\n \n      15\n    \n\n\n\n\n      Star\n\n\n      291\n    \n\n\n\n\n          Fork\n\n\n        54\n      \n\n\n\n\n\n        LaraSail - Set Sail with your Laravel app on DigitalOcean\n      \n\n\n\ndevdojo.com/blog/chitchat/larasail-laravel-on-digital-ocean\n\n\n\n\n\n291\n        stars\n \n\n54\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n6\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n1\ntag\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nbobbyiliev\n\nAdded CONTRIBUTING.md file (#36)\n\n\n\n…\n\n\n\nc72b25c\n\nSep 22, 2020\n\n\n\n\n\nAdded CONTRIBUTING.md file (#36)\n\n\nc72b25c\n\n\n\nGit stats\n\n\n\n\n\n74\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.larasail\n\n\n\nCertbot install fix for Ubuntu 20.04 (#34)\n\n\n\nAug 19, 2020\n\n\n\n\n\n\n\nCONTRIBUTING.md\n\n\n\nAdded CONTRIBUTING.md file (#36)\n\n\n\nSep 22, 2020\n\n\n\n\n\n\n\nREADME.md\n\n\n\nAdded CONTRIBUTING.md file (#36)\n\n\n\nSep 22, 2020\n\n\n\n\n\n\n\ninstall\n\n\n\n#8 - Let's Encrypt integration (#17)\n\n\n\nJun 17, 2020\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\n\nLaraSail\nLaraSail is a CLI tool for Laravel to help you Sail the Servers of the DigitalOcean\n\n\nYou'll need a DigitalOcean Account before getting started (Signup here), then you'll need to create a New Droplet. Make sure to select Ubuntu Server:\n\nInstallation\nSSH into your server and run the following command:\ncurl -sL https://github.com/thedevdojo/larasail/archive/master.tar.gz | tar xz && source larasail-master/install\n\nYou can make sure it's installed by running\nlarasail -h\n\nSetup Your Laravel Server\nlarasail setup\n\nThe default configuration will install Nginx, PHP 7.4, and MySQL 5.7. If you wish to use PHP 7.1, PHP 7.2, or PHP 7.3, you can include the argument php71/php72/php73 like so:\nlarasail setup php71 # Install with PHP 7.1\nlarasail setup php72 # Install with PHP 7.2\nlarasail setup php73 # Install with PHP 7.3\n\nCreating a New Site\nYou can now Clone a Repo or Create a New Laravel app within the /var/www folder:\ncd /var/www && laravel new mywebsite\n\nThen, you'll need to setup a new Nginx Host by running:\nlarasail host mywebsite.com /var/www/mywebsite\n\nlarasail host accepts 2 parameters:\n\nYour website domain (website.com)\nThe location of the files for your site (/var/www/website/public)\n\nFinally, point your Domain to the IP address of your new server... And Wallah, you're ready to rock 🤘 with your new Laravel website.\nPasswords\nWhen installing and setting up Larasail there are 2 passwords that are randomly generated.\n\nThe password for the new larasail user created on the server.\nThe default MySQL password\n\nTo get the larasail user password you can type in the following command:\nlarasail pass\n\nAnd the password for the larasail user will be displayed. Next, to get the default MySQL root password you can type the following command:\nlarasail mysqlpass\n\nAnd the MySQL root password will be displayed.\nSwitching to Larasail user\nWhen you SSH into your server you may want to Switch Users back to the larasail user, You can do so with the following command:\nsu - larasail\n\nMake sure to star this repo and watch this repo for future updates. Thanks for checking out Larasail ⛵\nContributing\nIf you are contributing, please read the contributing file before submitting your pull requests.\n\n\n\n\n\n\n\n\nAbout\n\n      LaraSail - Set Sail with your Laravel app on DigitalOcean\n    \n\n\n\ndevdojo.com/blog/chitchat/larasail-laravel-on-digital-ocean\n\n\nResources\n\n\n\n      Readme\n \n\n\n\n\n\n\n    Releases\n\n\n\n1\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 3\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\nShell\n100.0%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# larasail\n\n> A CLI tool for managing Laravel on Digital Ocean servers.\n> More information: <https://github.com/thedevdojo/larasail>.\n\n- Set up the server with Laravel dependencies using the default PHP version:\n\n`larasail setup`\n\n- Set up the server with Laravel dependencies using a specific PHP version:\n\n`larasail setup {{php71}}`\n\n- Add a new Laravel site:\n\n`larasail host {{domain}} {{path/to/site_directory}}`\n\n- Retrieve the Larasail user password:\n\n`larasail pass`\n\n- Retrieve the Larasail MySQL password:\n\n`larasail mysqlpass`\n"
 },
 {
   "command": "yum",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# yum\n\n> Package management utility for RHEL, Fedora, and CentOS (for older versions).\n\n- Synchronize list of packages and versions available. This should be run first, before running subsequent yum commands:\n\n`yum update`\n\n- Install a new package:\n\n`yum install {{package}}`\n\n- Install a new package and assume yes to all questions (also works with update, great for automated updates):\n\n`yum -y install {{package}}`\n\n- Find the package that provides a particular command:\n\n`yum provides {{command}}`\n\n- Remove a package:\n\n`yum remove {{package}}`\n\n- Upgrade installed packages to newest available versions:\n\n`yum upgrade`\n"
 },
 {
   "command": "tcpkill",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# tcpkill\n\n> Kills specified in-progress TCP connections.\n\n- Kill in-progress connections at a specified interface, host and port:\n\n`tcpkill -i {{eth1}} host {{192.95.4.27}} and port {{2266}}`\n"
 },
 {
   "command": "jobs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# jobs\n\n> BASH builtin for viewing information about processes spawned by the current shell.\n\n- View jobs spawned by the current shell:\n\n`jobs`\n\n- List jobs and their process ids:\n\n`jobs -l`\n\n- Display information about jobs with changed status:\n\n`jobs -n`\n\n- Display process id of process group leader:\n\n`jobs -p`\n\n- Display running processes:\n\n`jobs -r`\n\n- Display stopped processes:\n\n`jobs -s`\n"
 },
 {
   "command": "mssh",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mssh\n\n> GTK+ based SSH client for interacting with multiple SSH servers at once.\n\n- Open a new window and connect to multiple SSH servers:\n\n`mssh {{user@host1}} {{user@host2}} {{...}}`\n\n- Open a new window and connect to a group of servers predefined in `~/.mssh_clusters`:\n\n`mssh --alias {{alias_name}}`\n"
 },
 {
   "command": "runsv",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# runsv\n\n> Start and manage a runit service.\n\n- Start a runit service as the current user:\n\n`runsv {{path/to/service}}`\n\n- Start a runit service as root:\n\n`sudo runsv {{path/to/service}}`\n"
 },
 {
   "command": "popd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# popd\n\n> Remove a directory placed on the directory stack by the `pushd` command.\n\n- Remove the top directory from the stack and cd to it:\n\n`popd`\n\n- Remove the Nth directory (starting from zero to the left from the list printed with `dirs`):\n\n`popd +N`\n\n- Remove the Nth directory (starting from zero to the right from the list printed with `dirs`):\n\n`popd -N`\n"
 },
 {
   "command": "ipcmk",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ipcmk\n\n> Create IPC (Inter-process Communication) resources.\n\n- Create a shared memory segment:\n\n`ipcmk --shmem {{segment_size_in_bytes}}`\n\n- Create a semaphore:\n\n`ipcmk --semaphore {{element_size}}`\n\n- Create a message queue:\n\n`ipcmk --queue`\n\n- Create a shared memory segment with specific permissions (default is 0644):\n\n`ipcmk --shmem {{segment_size_in_bytes}} {{octal_permissons}}`\n"
 },
 {
   "command": "pushd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# pushd\n\n> Place a directory on a stack so it can be accessed later.\n> See also `popd` to switch back to original directory.\n\n- Switch to directory and push it on the stack:\n\n`pushd < {{directory}}`\n\n- Switch first and second directories on the stack:\n\n`pushd`\n\n- Rotate stack by making the 5th element the top of the stack:\n\n`pushd +4`\n"
 },
 {
   "command": "ceph",
   "doc_url": "https://ceph.io",
   "doc_text": "\n\n\nCeph Homepage - Ceph\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMenu\n\n\n\n\n\nDocumentation\nBlog\nWiki\nIRC / Lists\nThe Ceph Foundation\nDownload\n \n\n\n\nSearch\n\n \n\n\n\n\n\n\n\n\nSearch\n\n Discover\n\nIntroduction to Ceph\nBlog\nVideos\nResources\n\n\nUse\n\nGet Ceph\nInstall Ceph\nUse cases\nUsers\n\n\nCode\n\nGithub\nIssue tracking\nBuild status\n\n\nGet Involved\n\nFoundation\nCommunity\n\nCeph Community Meetings\n\n\nContribute\nTeam\nUser Survey\nEvents\n\n\n Documentation\nBlog\nWiki\nIRC / Lists\nThe Ceph Foundation\nDownload\n \n\n\n\n\n\n\n\nDiscover\n\nIntroduction to Ceph\nBlog\nVideos\nResources\n\n\nUse\n\nGet Ceph\nInstall Ceph\nUse cases\nUsers\n\n\nCode\n\nGithub\nIssue tracking\nBuild status\n\n\nGet Involved\n\nFoundation\nCommunity\n\nCeph Community Meetings\n\n\nContribute\nTeam\nUser Survey\nEvents\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWALKTHROUGH KRBD I/O FLOW\nA live code walkthrough with Q/A.\n\nJoin us Live!\n\n\n\n\n\n\n\n\nSTS Tech Talk\nPritha Srivastava on August 27th at 17:00 UTC will be sharing about the Secure Token Service (STS) in the Rados Gateway.\n\nJoin us Live!\n\n\n\n\n\n\n\n\nEDGE APPLICATIONS\nHear from Red Hat summer interns on their latest project with Ceph.\n\nWatch now!\n\n\n\n\n\n\n\n\nTHE FUTURE OF STORAGE™\nCeph is a unified, distributed storage system designed for excellent performance, reliability and scalability.\n\n\n\n\n\n\n\n\n\nGET INVOLVED\nAnyone can contribute to Ceph, and not just by writing lines of code!\n\nRead more\n\n\n\n\n\n\n\n\nFACE-TO-FACE\nThere are tons of places to come talk to us face-to-face. Come join us for Ceph Days, Conferences, Cephalocon, or others!\n\nRead more\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\t\t\t\tObject storage\t\t\t\t\t\t\t\t\n\nCeph provides seamless access to objects using native language bindings or radosgw (RGW), a REST interface that’s compatible with applications written for S3 and Swift.\n\n\n\t\t\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\t\t\t\tBlock storage\t\t\t\t\t\t\t\t\n\nCeph’s RADOS Block Device (RBD) provides access to block device images that are striped and replicated across the entire storage cluster.\n\n\n\t\t\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\t\t\t\tFile system\t\t\t\t\t\t\t\t\n\nCeph provides a POSIX-compliant network file system (CephFS) that aims for high performance, large data storage, and maximum compatibility with legacy applications.\n\n\n\t\t\t\t\t\t\t\t\tRead more\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\nLatest Tweets \nCeph Science Working Group 2020-09-23 recording is now available https://t.co/NLGfObtn9k https://t.co/fdCGiiXemG@Ceph9 hours agoRT @Cypress_XT: ✅ Upgraded to #Ceph Octopus\n🆗 Autoscale in progress...\n✅ Convert cluster from ceph-deploy to #cephadm\n\nMind blowed once aga…@Ceph10 hours agoRT @Cypress_XT: ✅ Upgraded to #Ceph Octopus\n🆗 Autoscale in progress...\n⬛️ Convert cluster from ceph-deploy to cephadm https://t.co/P5l4TOam…@Ceph10 hours ago\n\n\n\n\n\tPrivacy & Cookies: This site uses cookies. By continuing to use this website, you agree to their use. \nTo find out more, including how to control cookies, see here:\n\t\n\t\tCookie Policy\t\n\n \n\n\n\n\n\n\n\nPLANET\n\nView all\t\t\t\t\t\t\t\n\n\n\n\n\n\nSeptember 17, 2020\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tThe [InfoSec] Stack\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\nSeptember 16, 2020\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSUSE publishes first steps towards Windows clients\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\nJuly 24, 2020\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSUSE Enterprise Storage delivers best CephFS benchmark on Ar...\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\nBLOG\n\nView all\t\t\t\t\t\t\t\n\n\n\n\n\n\nSeptember 2020, 16\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tv15.2.5 Octopus released\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\nThis is the fifth release of the Ceph Octopus stable release series. This release brings a range of fixes across all components. We recommend that all Octopus users upgrade to this release. Notable Changes¶ CephFS: Automatic static subtree partitioning policies may now be configured using the new distributed and random... \n\n\n\n\n \n\n\t\t\t\t\t\t\t\t\t\t\t\tabhishekl\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\nSeptember 2020, 15\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tDecember 2020 Outreachy: Ceph &...\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\n \n\n\t\t\t\t\t\t\t\t\t\t\t\tMike Perez\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\nSeptember 2020, 01\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCeph Community Newsletter, August 2...\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\n \n\n\t\t\t\t\t\t\t\t\t\t\t\tMike Perez\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntop\n\n\n\n\n\n\n\n\nCeph Storage\n\nObject Storage\nBlock Storage\nFile System\nGetting Started\nUse Cases\n\n\n\nCommunity\n\nBlog\nFeatured Developers\nEvents\nContribute\nCareers\n\n\n\nResources\n\nGetting help\nMailing Lists & IRC\nPublications\nLogos\nCeph Tech Talks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2019 All rights reserved.\n\n\nCode of Conduct\nTerms Of Service\nPrivacy Statement\nTrademarks\nSecurity\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# ceph\n\n> A unified storage system.\n> More information: <https://ceph.io>.\n\n- Check cluster health status:\n\n`ceph status`\n\n- Check cluster usage stats:\n\n`ceph df`\n\n- Get the statistics for the placement groups in a cluster:\n\n`ceph pg dump --format {{plain}}`\n\n- Create a storage pool:\n\n`ceph osd pool create {{pool_name}} {{page_number}}`\n\n- Delete a storage pool:\n\n`ceph osd pool delete {{pool_name}}`\n\n- Rename a storage pool:\n\n`ceph osd pool rename {{current_name}} {{new_name}}`\n\n- Self-repair pool storage:\n\n`ceph pg repair {{pool_name}}`\n"
 },
 {
   "command": "pkgrm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pkgrm\n\n> Remove a package from a CRUX system.\n\n- Remove an installed package:\n\n`pkgrm {{package_name}}`\n"
 },
 {
   "command": "stress",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# stress\n\n> A tool to stress test CPU, memory, and IO on a Linux system.\n\n- Spawn 4 workers to stress test CPU:\n\n`stress -c {{4}}`\n\n- Spawn 2 workers to stress test IO and timeout after 5 seconds:\n\n`stress -i {{2}} -t {{5}}`\n\n- Spawn 2 workers to stress test memory (each worker allocates 256M bytes):\n\n`stress -m {{2}} --vm-bytes {{256M}}`\n\n- Spawn 2 workers spinning on write()/unlink() (each worker writes 1G bytes):\n\n`stress -d {{2}} --hdd-bytes {{1GB}}`\n"
 },
 {
   "command": "mkfs.ext4",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs.ext4\n\n> Creates an ext4 filesystem inside a partition.\n\n- Create an ext4 filesystem inside partition 1 on device b (`sdb1`):\n\n`sudo mkfs.ext4 {{/dev/sdb1}}`\n\n- Create an ext4 filesystem with a volume-label:\n\n`sudo mkfs.ext4 -L {{volume_label}} {{/dev/sdb1}}`\n"
 },
 {
   "command": "free",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nMALLOC(3)\t\t BSD Library Functions Manual\t\t     MALLOC(3)\n\nNAME\n     calloc, free, malloc, realloc, reallocf, valloc -- memory allocation\n\nSYNOPSIS\n     #include <stdlib.h>\n\n     void *\n     calloc(size_t count, size_t size);\n\n     void\n     free(void *ptr);\n\n     void *\n     malloc(size_t size);\n\n     void *\n     realloc(void *ptr, size_t size);\n\n     void *\n     reallocf(void *ptr, size_t size);\n\n     void *\n     valloc(size_t size);\n\nDESCRIPTION\n     The malloc(), calloc(), valloc(), realloc(), and reallocf() functions\n     allocate memory.  The allocated memory is aligned such that it can be\n     used for any data type, including AltiVec- and SSE-related types.\tThe\n     free() function frees allocations that were created via the preceding\n     allocation functions.\n\n     The malloc() function allocates size bytes of memory and returns a\n     pointer to the allocated memory.\n\n     The calloc() function contiguously allocates enough space for count\n     objects that are size bytes of memory each and returns a pointer to the\n     allocated memory.\tThe allocated memory is filled with bytes of value\n     zero.\n\n     The valloc() function allocates size bytes of memory and returns a\n     pointer to the allocated memory.  The allocated memory is aligned on a\n     page boundary.\n\n     The realloc() function tries to change the size of the allocation pointed\n     to by ptr to size, and returns ptr.  If there is not enough room to\n     enlarge the memory allocation pointed to by ptr, realloc() creates a new\n     allocation, copies as much of the old data pointed to by ptr as will fit\n     to the new allocation, frees the old allocation, and returns a pointer to\n     the allocated memory.  If ptr is NULL, realloc() is identical to a call\n     to malloc() for size bytes.  If size is zero and ptr is not NULL, a new,\n     minimum sized object is allocated and the original object is freed.  When\n     extending a region allocated with calloc(3), realloc(3) does not guaran-\n     tee that the additional memory is also zero-filled.\n\n     The reallocf() function is identical to the realloc() function, except\n     that it will free the passed pointer when the requested memory cannot be\n     allocated.  This is a FreeBSD specific API designed to ease the problems\n     with traditional coding styles for realloc causing memory leaks in\n     libraries.\n\n     The free() function deallocates the memory allocation pointed to by ptr.\n     If ptr is a NULL pointer, no operation is performed.\n\nRETURN VALUES\n     If successful, calloc(), malloc(), realloc(), reallocf(), and valloc()\n     functions return a pointer to allocated memory.  If there is an error,\n     they return a NULL pointer and set errno to ENOMEM.\n\n     For realloc(), the input pointer is still valid if reallocation failed.\n     For reallocf(), the input pointer will have been freed if reallocation\n     failed.\n\n     The free() function does not return a value.\n\nDEBUGGING ALLOCATION ERRORS\n     A number of facilities are provided to aid in debugging allocation errors\n     in applications.  These facilities are primarily controlled via environ-\n     ment variables.  The recognized environment variables and their meanings\n     are documented below.\n\nENVIRONMENT\n     The following environment variables change the behavior of the alloca-\n     tion-related functions.\n\n     MallocDebugReport\t\t  If set, specifies where messages are writ-\n\t\t\t\t  ten. Set to \"stderr\" to write messages to\n\t\t\t\t  the standard error stream, \"none\" to discard\n\t\t\t\t  all messages and \"crash\" to write messages\n\t\t\t\t  to standard error only for a condition that\n\t\t\t\t  is about to cause a crash. When not set,\n\t\t\t\t  message are written to the standard error\n\t\t\t\t  stream if it appears to be a terminal (that\n\t\t\t\t  is, if isatty(STDERR_FILENO) returns a non-\n\t\t\t\t  zero value) and are otherwise discarded.\n\n     MallocGuardEdges\t\t  If set, add a guard page before and after\n\t\t\t\t  each large block.\n\n     MallocDoNotProtectPrelude\t  If set, do not add a guard page before large\n\t\t\t\t  blocks, even if the MallocGuardEdges envi-\n\t\t\t\t  ronment variable is set.\n\n     MallocDoNotProtectPostlude   If set, do not add a guard page after large\n\t\t\t\t  blocks, even if the MallocGuardEdges envi-\n\t\t\t\t  ronment variable is set.\n\n     MallocStackLogging \t  The default behavior if this is set is to\n\t\t\t\t  record all allocation and deallocation\n\t\t\t\t  events to an on-disk log, along with stacks,\n\t\t\t\t  so that tools like leaks(1) and\n\t\t\t\t  malloc_history(1) can be used.\n\n\t\t\t\t  Set to \"vm\" to record only allocation of\n\t\t\t\t  virtual memory regions allocated by system\n\t\t\t\t  calls and mach traps, such as by mmap(1)\n\n\t\t\t\t  Set to \"malloc\" to record only allocations\n\t\t\t\t  via malloc(3) and related interfaces, not\n\t\t\t\t  virtual memory regions.\n\n\t\t\t\t  Set to \"lite\" to record current allocations\n\t\t\t\t  only, not history.   These are recorded by\n\t\t\t\t  in-memory data structures, instead of an on-\n\t\t\t\t  disk log.\n\n     MallocStackLoggingNoCompact  If set, record all stacks in a manner that\n\t\t\t\t  is compatible with the malloc_history pro-\n\t\t\t\t  gram.\n\n     MallocStackLoggingDirectory  If set, records stack logs to the directory\n\t\t\t\t  specified instead of saving them to the\n\t\t\t\t  default location (/tmp).\n\n     MallocScribble\t\t  If set, fill memory that has been allocated\n\t\t\t\t  with 0xaa bytes.  This increases the likeli-\n\t\t\t\t  hood that a program making assumptions about\n\t\t\t\t  the contents of freshly allocated memory\n\t\t\t\t  will fail.  Also if set, fill memory that\n\t\t\t\t  has been deallocated with 0x55 bytes.  This\n\t\t\t\t  increases the likelihood that a program will\n\t\t\t\t  fail due to accessing memory that is no\n\t\t\t\t  longer allocated. Note that due to the way\n\t\t\t\t  in which freed memory is managed internally,\n\t\t\t\t  the 0x55 pattern may not appear in some\n\t\t\t\t  parts of a deallocated memory block.\n\n     MallocCheckHeapStart <s>\t  If set, specifies the number of allocations\n\t\t\t\t  <s> to wait before begining periodic heap\n\t\t\t\t  checks every <n> as specified by\n\t\t\t\t  MallocCheckHeapEach.\tIf\n\t\t\t\t  MallocCheckHeapStart is set but\n\t\t\t\t  MallocCheckHeapEach is not specified, the\n\t\t\t\t  default check repetition is 1000.\n\n     MallocCheckHeapEach <n>\t  If set, run a consistency check on the heap\n\t\t\t\t  every <n> operations.  MallocCheckHeapEach\n\t\t\t\t  is only meaningful if MallocCheckHeapStart\n\t\t\t\t  is also set.\n\n     MallocCheckHeapSleep <t>\t  Sets the number of seconds to sleep (waiting\n\t\t\t\t  for a debugger to attach) when\n\t\t\t\t  MallocCheckHeapStart is set and a heap cor-\n\t\t\t\t  ruption is detected.\tThe default is 100\n\t\t\t\t  seconds.  Setting this to zero means not to\n\t\t\t\t  sleep at all.  Setting this to a negative\n\t\t\t\t  number means to sleep (for the positive num-\n\t\t\t\t  ber of seconds) only the very first time a\n\t\t\t\t  heap corruption is detected.\n\n     MallocCheckHeapAbort <b>\t  When MallocCheckHeapStart is set and this is\n\t\t\t\t  set to a non-zero value, causes abort(3) to\n\t\t\t\t  be called if a heap corruption is detected,\n\t\t\t\t  instead of any sleeping.\n\n     MallocErrorAbort\t\t  If set, causes abort(3) to be called if an\n\t\t\t\t  error was encountered in malloc(3) or\n\t\t\t\t  free(3) , such as a calling free(3) on a\n\t\t\t\t  pointer previously freed.\n\n     MallocCorruptionAbort\t  Similar to MallocErrorAbort but will not\n\t\t\t\t  abort in out of memory conditions, making it\n\t\t\t\t  more useful to catch only those errors which\n\t\t\t\t  will cause memory corruption.  MallocCorrup-\n\t\t\t\t  tionAbort is always set on 64-bit processes.\n\n     MallocHelp \t\t  If set, print a list of environment vari-\n\t\t\t\t  ables that are paid heed to by the alloca-\n\t\t\t\t  tion-related functions, along with short\n\t\t\t\t  descriptions.  The list should correspond to\n\t\t\t\t  this documentation.\n\nDIAGNOSTIC MESSAGES\nSEE ALSO\n     leaks(1), malloc_history(1), abort(3), malloc_size(3),\n     malloc_zone_malloc(3), posix_memalign(3), libgmalloc(3)\n\nBSD\t\t\t\t Aug 13, 2008\t\t\t\t   BSD\n",
   "tldr_summary": "# free\n\n> Display amount of free and used memory in the system.\n\n- Display system memory:\n\n`free`\n\n- Display memory in Bytes/KB/MB/GB:\n\n`free -{{b|k|m|g}}`\n\n- Display memory in human readable units:\n\n`free -h`\n\n- Refresh the output every 2 seconds:\n\n`free -s {{2}}`\n"
 },
 {
   "command": "httpie",
   "doc_url": "https://example.com",
   "doc_text": "\n\nExample Domain\n\n\n\n\n\n\n\nExample Domain\nThis domain is for use in illustrative examples in documents. You may use this\n    domain in literature without prior coordination or asking for permission.\nMore information...\n\n\n",
   "man_entry": "",
   "tldr_summary": "# httpie\n\n> A user friendly command line HTTP tool.\n\n- Send a GET request (default method with no request data):\n\n`http {{https://example.com}}`\n\n- Send a POST request (default method with request data):\n\n`http {{https://example.com}} {{hello=World}}`\n\n- Send a POST request with redirected input:\n\n`http {{https://example.com}} < {{file.json}}`\n\n- Send a PUT request with a given json body:\n\n`http PUT {{https://example.com/todos/7}} {{hello=world}}`\n\n- Send a DELETE request with a given request header:\n\n`http DELETE {{https://example.com/todos/7}} {{API-Key:foo}}`\n\n- Show the whole HTTP exchange (both request and response):\n\n`http -v {{https://example.com}}`\n\n- Download a file:\n\n`http --download {{https://example.com}}`\n"
 },
 {
   "command": "whatis",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "whatis(1)\t\t\t\t\t\t\t     whatis(1)\n\n\n\nNAME\n       whatis - search the whatis database for complete words.\n\nSYNOPSIS\n       whatis keyword ...\n\nDESCRIPTION\n       whatis  searches  a set of database files containing short descriptions\n       of system commands for keywords and displays the result on the standard\n       output.\tOnly complete word matches are displayed.\n\n       The  whatis  database  is  created using the command /usr/libexec/make-\n       whatis.\n\nAUTHOR\n       John W. Eaton was the  original\tauthor\tof  man.   Zeyd  M.  Ben-Halim\n       released  man  1.2,  and  Andries Brouwer followed up with versions 1.3\n       thru 1.5p.  Federico  Lucifredi\t<flucifredi@acm.org>  is  the  current\n       maintainer.\n\nSEE ALSO\n       apropos(1), man(1).\n\n\n\n\t\t\t      September 19, 2005\t\t     whatis(1)\n",
   "tldr_summary": "# whatis\n\n> Display one-line descriptions from manual pages.\n\n- Display a description from a man page:\n\n`whatis {{command}}`\n\n- Don't cut the description off at the end of the line:\n\n`whatis --long {{command}}`\n\n- Display descriptions for all commands matching a glob:\n\n`whatis --wildcard {{net*}}`\n\n- Search man page descriptions with a regular expression:\n\n`whatis --regex '{{wish[0-9]\\.[0-9]}}'`\n"
 },
 {
   "command": "dstat",
   "doc_url": "http://dag.wieers.com/home-made/dstat",
   "doc_text": "\n\nDAG: Dstat: Versatile resource statistics tool\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog\nAbout me\nBookmarks\nCurriculum vitae\nEvents\nHome-made\n\n · Apt/Yum RPM repository\n · Cars\n · DAR\n · Dconf\n · Distcc compilers\n · Dstat\n\n ·  · Features\n ·  · Screenshot\n ·  · Download\n ·  · Mailinglist\n ·  · Sourcecode\n ·  · Documentation\n\n · Dwall\n · Dweb\n · Dwscan\n · mrepo\n · PyTone plugins\n · QLogic Autoconf\n · Sarah\n · Soapbox\n · Squidguard\n · unoconv\n · wascii\n · wiipresent\nHowtos\nPhoto archive\nRPM packages\nWebsites\nTODO\n\n\n\n\n\n\nShortcuts:\nDconf ·\n\t\t\tDstat ·\n\t\t\tDwall ·\n\t\t\tDweb ·\n\t\t\tDwscan ·\n\t\t\tLyrics ·\n\t\t\tmrepo ·\n\t\t\tPixies.. ·\n\t\t\tRPMs ·\n\t\t\tunoconv ·\n\t\t\twascii ·\n\t\t\twiipresent ·\n\t\t\tYam ·\n\t\t\n\n\nGoogle Site Search:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n» Dag Wieers » Home-made » Dstat: Versatile resource statistics tool \nDstat: Versatile resource statistics tool\n\n\n\nDstat is a versatile replacement for vmstat, iostat, netstat and ifstat.\nDstat overcomes some of their limitations and adds some extra features,\nmore counters and flexibility. Dstat is handy for monitoring systems\nduring performance tuning tests, benchmarks or troubleshooting.\n\n\nDstat allows you to view all of your system resources in real-time, you\ncan eg. compare disk utilization in combination with interrupts from your\nIDE controller, or compare the network bandwidth numbers directly\nwith the disk throughput (in the same interval).\n\n\nDstat gives you detailed selective information in columns and clearly\nindicates in what magnitude and unit the output is displayed. Less\nconfusion, less mistakes. And most importantly, it makes it very easy\nto write plugins to collect your own counters and extend in ways you\nnever expected.\n\n\nDstat's output by default is designed for being interpreted by\nhumans in real-time, however you can export details to CSV output\nto a file to be imported later into Gnumeric or Excel to generate\ngraphs.\n\nFeatures\n\n Combines vmstat, iostat, ifstat, netstat information and more\n\t Shows stats in exactly the same timeframe\n\t Enable/order counters as they make most sense during analysis/troubleshooting\n\t Modular design\n\t Written in python so easily extendable for the task at hand\n\t Easy to extend, add your own counters (please contribute those)\n\t Includes many external plugins to show how easy it is to add counters\n\t Can summarize grouped block/network devices and give total numbers\n\t Can show interrupts per device\n\t Very accurate timeframes, no timeshifts when system is stressed\n\t Shows exact units and limits conversion mistakes\n\t Indicate different units with different colors\n\t Show intermediate results when delay > 1\n\t Allows to export CSV output, which can be imported in Gnumeric and Excel to make graphs\n\nExternal plugins\nHere are the existing plugins, send me your own plugins.\n\n[dag@moria ~]# dstat --list\ninternal:\n        aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock, \n        mem, net, page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix, \n        vm\n/usr/share/dstat:\n        battery, battery-remain, cpufreq, dbus, disk-recsize, disk-tps, disk-util, dstat, \n        dstat-cpu, dstat-ctxt, dstat-mem, fan, freespace, gpfs, gpfs-ops, helloworld, \n        innodb-buffer, innodb-io, innodb-ops, lustre, mem-adv, memcache-hits, mysql-io, \n        mysql-keys, mysql5-cmds, mysql5-conn, mysql5-io, mysql5-keys, net-packets, nfs3, \n        nfs3-ops, nfsd3, nfsd3-ops, ntp, pcap-ssh, postfix, power, proc-count, proc-count2, \n        proc-count3, qmail, rpc, rpcd, sendmail, snooze, squid, test, thermal, top-bio, \n        top-bio-adv, top-childwait, top-cpu, top-cpu-adv, top-cpu2, top-cpu3, top-cputime, \n        top-cputime-avg, top-int, top-io, top-io-adv, top-latency, top-latency-avg, top-mem, \n        top-oom, top-tcp-ports, utmp, vm-memctl, vmk-hba, vmk-int, vmk-nic, vz-cpu, vz-io, \n        vz-ubc, wifi\n\n\nSee the Manual for options and a summary of each external plugin.\n\nFuture\n\n Add /etc/dstat.conf configuration file to customize\n\t Create a complete counter/object model structure\n\t Interface directly with rrdtool for real-time graphing\n\t Create client-server application model for remote graphing\n\t See Github for more details\n\nScreenshot 1\n[dag@moria ~]$ dstat --help\nUsage: dstat [-afv] [options..] [delay [count]]\nVersatile tool for generating system resource statistics\n\nDstat options:\n  -c, --cpu              enable cpu stats\n     -C 0,3,total           include cpu0, cpu3 and total\n  -d, --disk             enable disk stats\n     -D total,hda           include hda and total\n  -g, --page             enable page stats\n  -i, --int              enable interrupt stats\n     -I 5,eth2              include int5 and interrupt used by eth2\n  -l, --load             enable load stats\n  -m, --mem              enable memory stats\n  -n, --net              enable network stats\n     -N eth1,total          include eth1 and total\n  -p, --proc             enable process stats\n  -r, --io               enable io stats (I/O requests completed)\n  -s, --swap             enable swap stats\n     -S swap1,total         include swap1 and total\n  -t, --time             enable time/date output\n  -T, --epoch            enable time counter (seconds since epoch)\n  -y, --sys              enable system stats\n\n  --aio                  enable aio stats\n  --fs, --filesystem     enable fs stats\n  --ipc                  enable ipc stats\n  --lock                 enable lock stats\n  --raw                  enable raw stats\n  --socket               enable socket stats\n  --tcp                  enable tcp stats\n  --udp                  enable udp stats\n  --unix                 enable unix stats\n  --vm                   enable vm stats\n\n  --plugin-name          enable plugins by plugin name (see manual)\n  --list                 list all available plugins\n\n  -a, --all              equals -cdngy (default)\n  -f, --full             automatically expand -C, -D, -I, -N and -S lists\n  -v, --vmstat           equals -pmgdsc -D total\n\n  --float                force float values on screen\n  --integer              force integer values on screen\n\n  --bw, --blackonwhite   change colors for white background terminal\n  --nocolor              disable colors (implies --noupdate)\n  --noheaders            disable repetitive headers\n  --noupdate             disable intermediate updates\n  --output file          write CSV output to file\n\ndelay is the delay in seconds between each update (default: 1)\ncount is the number of updates to display before exiting (default: unlimited)\n\nScreenshot 2\nOnly in black and white :)\n[dag@moria ~]# dstat\n----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--\nusr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw \n  5   0  93   0   0   0| 154k   84k|   0     0 |   0     0 |1081  1116 \n 13   0  87   0   0   0|   0     0 |   0     0 |   0     0 |1036   696 \n  8   0  92   0   1   0|   0  8192B|   0     0 |   0     0 |1073   936 \n  0   0  99   0   0   1|   0     0 |   0     0 |   0     0 |1072   940 \n  1   1  97   0   2   0|   0     0 |   0     0 |   0     0 |1252  1727 \n  1   1  98   0   1   0|   0     0 |   0     0 |   0     0 |1126  1191 \n  1   0  99   0   0   0|   0     0 |   0     0 |   0     0 |1045   908 \n  0   0  99   0   0   0|   0    44k|   0     0 |   0     0 |1051   904 \n  1   1  99   0   0   0|   0     0 |   0     0 |   0     0 |1036   850 \n  1   0 100   0   0   0|   0     0 |   0     0 |   0     0 |1029   757 \n\nScreenshot 3\n[dag@moria ~]$ dstat -c --top-cpu -d --top-bio --top-latency\n----total-cpu-usage---- -most-expensive- -dsk/total- ----most-expensive---- --highest-total--\nusr sys idl wai hiq siq|  cpu process   | read  writ|  block i/o process   | latency process \n  5   0  94   0   0   0|firefox      3.6| 148k   81k|init [5]     98k   50B|pdflush        21\n  2   1  98   0   0   0|wnck-applet  0.5|   0     0 |                      |at-spi-regist   5\n  2   1  98   0   0   0|firefox      0.5|   0     0 |                      |Xorg            1\n  1   2  97   0   0   1|                |   0     0 |                      |Xorg            1\n  1   1  98   0   0   0|                |   0     0 |                      |ksoftirqd/1    10\n  1   1  97   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/0     5\n  2   1  97   0   0   0|firefox      0.5|   0     0 |firefox       0    28k|ksoftirqd/0     5\n  2   1  97   0   0   0|firefox      0.5|   0     0 |                      |Xorg            1\n  1   1  97   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/0     6\n  2   1  98   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/0     6\n  1   2  98   0   0   0|                |   0     0 |                      |ksoftirqd/1     8\n  2   1  98   0   0   0|iwlagn       0.5|   0    72k|kjournald     0    32k|ksoftirqd/1    12\n  1   1  97   0   0   0|                |   0     0 |                      |iwlagn/0        1\n  1   1  98   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/1     8\n\nReal screenshot\nHere are 2 screenshots of older dstat versions in action.\n\nDstat 0.4 on a Power5 system that is being stress tested.\n\n\nDstat 0.3 (first release) on 5 RHEL3 nodes in a cluster from a Windows terminal.\n\nBug reports\nIf you've found a bug, please check the\nGithub issue-tracker \nfor known problems and send me updates if you have more information to\nprovide.\n\nPlease also copy&paste the output of the problem, with a description,\nthe version of the kernel and if appropriate the involved /proc entries.\n\nDstat has a --debug option to profile plugins and show what plugins and\n/proc entries are affected. Dstat also shows some more information with\nthe --version option that might be useful.\n\n\nDownload\nThe following packages (in order of appearance) are available.\n\n\n Red Hat Enterprise Linux / CentOS  Fedora  Gentoo  OpenSUSE  Debian  Mandriva  Alt Linux  cAos  Ubuntu Breezy  Linspire  Sourcemage  rPath  PLD Linux  Slackware  Tiny Core Linux\n\nor grab the latest 0.7.3 tarball at:\n\n\thttps://github.com/dagwieers/dstat/archive/0.7.3.tar.gz\nMailinglist\nThere's a mailinglist about dstat and some other related tools at:\nhttp://lists.repoforge.org/mailman/listinfo/tools\nSourcecode\nYou can have access to the latest changes via subversion from:\n\n\n https://github.com/dagwieers/dstat\nDocumentation\nThe current asciidoc manual page is found here:\n\n https://github.com/dagwieers/dstat/blob/master/docs/dstat.1.adoc\n\nSubversion also holds the current documentation and example config-files,\nso please look there for more information. If you have improvements, found\na bug or have a great idea, please mail me so we can look at how to integrate\nit.\n\n\n ChangeLog  COPYING  README  TODO  WISHLIST  /docs/\nWhat users have to say\nI found some comments about dstat on blogs, here's what they say:\n\n\n http://www.michael-prokop.at/blog/?p=298  http://tadek.pietraszek.org/blog/2005/09/14/monitoring-resource-usage-in-linux/  http://patrick.wagstrom.net/weblog/linux/dstat-for-fun-and-profit.xml  http://www.linuxjournal.com/article/9003\n\n\n\n\n\nAnything to add/change to this page? Send me your thoughts!Copyright © 1995-2009 Dag Wieërs. All rights reserved.Last modified on: Mon 28 March 2016 \n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# dstat\n\n> Versatile tool for generating system resource statistics.\n> More information: <http://dag.wieers.com/home-made/dstat>.\n\n- Display CPU, disk, net, paging and system statistics:\n\n`dstat`\n\n- Display statistics every 5 seconds and 4 updates only:\n\n`dstat {{5}} {{4}}`\n\n- Display CPU and memory statistics only:\n\n`dstat --cpu --mem`\n\n- List all available dstat plugins:\n\n`dstat --list`\n\n- Display the process using the most memory and most CPU:\n\n`dstat --top-mem --top-cpu`\n\n- Display battery percentage and remaining battery time:\n\n`dstat --battery --battery-remain`\n"
 },
 {
   "command": "manpath",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "man(1)\t\t\t\t\t\t\t\t\tman(1)\n\n\n\nNAME\n       man - format and display the on-line manual pages\n\nSYNOPSIS\n       man  [-acdfFhkKtwW]  [--path]  [-m system] [-p string] [-C config_file]\n       [-M pathlist] [-P pager] [-B browser] [-H htmlpager] [-S  section_list]\n       [section] name ...\n\n\nDESCRIPTION\n       man formats and displays the on-line manual pages.  If you specify sec-\n       tion, man only looks in that section of the manual.  name  is  normally\n       the  name of the manual page, which is typically the name of a command,\n       function, or file.  However, if name contains  a  slash\t(/)  then  man\n       interprets  it  as a file specification, so that you can do man ./foo.5\n       or even man /cd/foo/bar.1.gz.\n\n       See below for a description of where man  looks\tfor  the  manual  page\n       files.\n\n\nOPTIONS\n       -C  config_file\n\t      Specify  the  configuration  file  to  use; the default is /pri-\n\t      vate/etc/man.conf.  (See man.conf(5).)\n\n       -M  path\n\t      Specify the list of directories to search for man pages.\t Sepa-\n\t      rate  the directories with colons.  An empty list is the same as\n\t      not specifying -M at all.  See SEARCH PATH FOR MANUAL PAGES.\n\n       -P  pager\n\t      Specify which pager to use.  This option overrides the  MANPAGER\n\t      environment  variable,  which  in turn overrides the PAGER vari-\n\t      able.  By default, man uses /usr/bin/less -is.\n\n       -B     Specify which browser to use on HTML files.  This  option  over-\n\t      rides  the  BROWSER  environment\tvariable. By default, man uses\n\t      /usr/bin/less-is,\n\n       -H     Specify a command that renders HTML files as text.  This\toption\n\t      overrides  the  HTMLPAGER  environment variable. By default, man\n\t      uses /bin/cat,\n\n       -S  section_list\n\t      List is a colon separated list of  manual  sections  to  search.\n\t      This option overrides the MANSECT environment variable.\n\n       -a     By default, man will exit after displaying the first manual page\n\t      it finds.  Using this option forces man to display all the  man-\n\t      ual pages that match name, not just the first.\n\n       -c     Reformat\tthe  source man page, even when an up-to-date cat page\n\t      exists.  This can be meaningful if the cat  page\twas  formatted\n\t      for  a screen with a different number of columns, or if the pre-\n\t      formatted page is corrupted.\n\n       -d     Don't actually display the man  pages,  but  do  print  gobs  of\n\t      debugging information.\n\n       -D     Both display and print debugging info.\n\n       -f     Equivalent to whatis.\n\n       -F or --preformat\n\t      Format only - do not display.\n\n       -h     Print a help message and exit.\n\n       -k     Equivalent to apropos.\n\n       -K     Search  for  the\tspecified  string in *all* man pages. Warning:\n\t      this is probably very slow!  It  helps  to  specify  a  section.\n\t      (Just  to  give  a  rough idea, on my machine this takes about a\n\t      minute per 500 man pages.)\n\n       -m  system\n\t      Specify an alternate set of man pages to\tsearch\tbased  on  the\n\t      system name given.\n\n       -p  string\n\t      Specify  the  sequence  of  preprocessors to run before nroff or\n\t      troff.  Not all installations will have a full set of preproces-\n\t      sors.   Some of the preprocessors and the letters used to desig-\n\t      nate them are: eqn (e), grap (g), pic (p), tbl (t), vgrind  (v),\n\t      refer  (r).   This  option  overrides the MANROFFSEQ environment\n\t      variable.\n\n       -t     Use /usr/bin/groff -Tps -mandoc -c to format  the  manual  page,\n\t      passing  the  output  to\tstdout.   The default output format of\n\t      /usr/bin/groff -Tps -mandoc -c is Postscript, refer to the  man-\n\t      ual  page  of /usr/bin/groff -Tps -mandoc -c for ways to pick an\n\t      alternate format.\n\n       Depending on the selected  format  and  the  availability  of  printing\n       devices,  the  output  may  need  to  be  passed through some filter or\n       another before being printed.\n\n       -w or --path\n\t      Don't actually display the man pages, but  do  print  the  loca-\n\t      tion(s) of the files that would be formatted or displayed. If no\n\t      argument is given: display (on stdout) the list  of  directories\n\t      that  is\tsearched by man for man pages. If manpath is a link to\n\t      man, then \"manpath\" is equivalent to \"man --path\".\n\n       -W     Like -w, but print file names one per line,  without  additional\n\t      information.   This is useful in shell commands like man -aW man\n\t      | xargs ls -l\n\n\nCAT PAGES\n       Man will try to save the formatted man pages, in order to save  format-\n       ting time the next time these pages are needed.\tTraditionally, format-\n       ted versions of pages in DIR/manX are saved in DIR/catX, but other map-\n       pings   from   man   dir   to   cat  dir  can  be  specified  in  /pri-\n       vate/etc/man.conf.  No cat pages are saved when the required cat direc-\n       tory  does  not\texist.\tNo cat pages are saved when they are formatted\n       for a line length different from 80.   No  cat  pages  are  saved  when\n       man.conf contains the line NOCACHE.\n\n       It is possible to make man suid to a user man. Then, if a cat directory\n       has owner man and mode 0755 (only writable by man), and the  cat  files\n       have  owner  man  and  mode  0644 or 0444 (only writable by man, or not\n       writable at all), no ordinary user can change  the  cat\tpages  or  put\n       other  files  in the cat directory. If man is not made suid, then a cat\n       directory should have mode 0777 if all users should be  able  to  leave\n       cat pages there.\n\n       The  option  -c\tforces\treformatting a page, even if a recent cat page\n       exists.\n\n\nHTML PAGES\n       Man will find HTML pages if they live in directories named as  expected\n       to  be  \".html\", thus a valid name for an HTML version of the ls(1) man\n       page would be /usr/share/man/htmlman1/ls.1.html.\n\n\nSEARCH PATH FOR MANUAL PAGES\n       man uses a sophisticated method of finding manual page files, based  on\n       the   invocation   options   and   environment\tvariables,  the  /pri-\n       vate/etc/man.conf configuration file, and some built in conventions and\n       heuristics.\n\n       First  of  all, when the name argument to man contains a slash (/), man\n       assumes it is a file specification itself, and there  is  no  searching\n       involved.\n\n       But in the normal case where name doesn't contain a slash, man searches\n       a variety of directories for a file that could be a manual page for the\n       topic named.\n\n       If  you\tspecify  the -M pathlist option, pathlist is a colon-separated\n       list of the directories that man searches.\n\n       If you don't specify -M but set the MANPATH environment\tvariable,  the\n       value  of  that\tvariable  is  the  list  of  the  directories that man\n       searches.\n\n       If you don't specify an explicit path list  with  -M  or  MANPATH,  man\n       develops  its  own path list based on the contents of the configuration\n       file /private/etc/man.conf.  The MANPATH statements in  the  configura-\n       tion  file  identify  particular  directories  to include in the search\n       path.\n\n       Furthermore, the MANPATH_MAP statements add to the search path  depend-\n       ing  on your command search path (i.e. your PATH environment variable).\n       For each directory that may be in  the  command\tsearch\tpath,  a  MAN-\n       PATH_MAP  statement  specifies  a directory that should be added to the\n       search path for manual page files.  man looks at the PATH variable  and\n       adds the corresponding directories to the manual page file search path.\n       Thus, with the proper use of MANPATH_MAP, when you  issue  the  command\n       man  xyz,  you  get a manual page for the program that would run if you\n       issued the command xyz.\n\n       In addition, for each directory in the command search path (we'll  call\n       it  a  \"command\tdirectory\")  for  which  you do not have a MANPATH_MAP\n       statement, man automatically looks for a manual page directory \"nearby\"\n       namely as a subdirectory in the command directory itself or in the par-\n       ent directory of the command directory.\n\n       You can disable the automatic \"nearby\" searches by  including  a  NOAU-\n       TOPATH statement in /private/etc/man.conf.\n\n       In  each  directory in the search path as described above, man searches\n       for a file named topic.section, with an optional suffix on the  section\n       number  and  possibly  a compression suffix.  If it doesn't find such a\n       file, it then looks in any subdirectories named manN or catN where N is\n       the  manual section number.  If the file is in a catN subdirectory, man\n       assumes it is a formatted manual page file (cat page).  Otherwise,  man\n       assumes it is unformatted.  In either case, if the filename has a known\n       compression suffix (like .gz), man assumes it is gzipped.\n\n       If you want to see where (or if) man would find the manual page\tfor  a\n       particular topic, use the --path (-w) option.\n\n\nENVIRONMENT\n       MANPATH\n\t      If  MANPATH is set, man uses it as the path to search for manual\n\t      page files.  It overrides the configuration file and  the  auto-\n\t      matic  search  path,  but  is  overridden  by  the -M invocation\n\t      option.  See SEARCH PATH FOR MANUAL PAGES.\n\n       MANPL  If MANPL is set, its value is used as the display  page  length.\n\t      Otherwise, the entire man page will occupy one (long) page.\n\n       MANROFFSEQ\n\t      If  MANROFFSEQ is set, its value is used to determine the set of\n\t      preprocessors run before running nroff or  troff.   By  default,\n\t      pages are passed through the tbl preprocessor before nroff.\n\n       MANSECT\n\t      If  MANSECT  is set, its value is used to determine which manual\n\t      sections to search.\n\n       MANWIDTH\n\t      If MANWIDTH is set, its value is\tused  as  the  width  manpages\n\t      should  be displayed.  Otherwise the pages may be displayed over\n\t      the whole width of your screen.\n\n       MANPAGER\n\t      If MANPAGER is set, its value is used as the name of the program\n\t      to  use to display the man page.\tIf not, then PAGER is used. If\n\t      that has no value either, /usr/bin/less -is is used.\n\n       BROWSER\n\t      The name of a browser to use for displaying HTML\tmanual\tpages.\n\t      If it is not set, /usr/bin/less -is is used.\n\n       HTMLPAGER\n\t      The  command to use for rendering HTML manual pages as text.  If\n\t      it is not set, /bin/cat is used.\n\n       LANG   If LANG is set, its value defines the name of  the  subdirectory\n\t      where  man first looks for man pages. Thus, the command `LANG=dk\n\t      man 1 foo' will cause man to  look  for  the  foo  man  page  in\n\t      .../dk/man1/foo.1,  and  if  it cannot find such a file, then in\n\t      .../man1/foo.1, where ... is a directory on the search path.\n\n       NLSPATH, LC_MESSAGES, LANG\n\t      The environment variables NLSPATH and LC_MESSAGES (or LANG  when\n\t      the  latter  does not exist) play a role in locating the message\n\t      catalog.\t(But the English messages are  compiled  in,  and  for\n\t      English no catalog is required.)\tNote that programs like col(1)\n\t      called by man also use e.g. LC_CTYPE.\n\n       PATH   PATH helps determine the search path for manual page files.  See\n\t      SEARCH PATH FOR MANUAL PAGES.\n\n       SYSTEM SYSTEM is used to get the default alternate system name (for use\n\t      with the -m option).\n\nBUGS\n       The -t option only works if a troff-like program is installed.\n       If you see blinking  \\255  or  <AD>  instead  of  hyphens,  put\t`LESS-\n       CHARSET=latin1' in your environment.\n\nTIPS\n       If you add the line\n\n\t (global-set-key  [(f1)]  (lambda () (interactive) (manual-entry (cur-\n       rent-word))))\n\n       to your .emacs file, then hitting F1 will give you the man page for the\n       library call at the current cursor position.\n\n       To  get\ta  plain  text\tversion  of a man page, without backspaces and\n       underscores, try\n\n\t # man foo | col -b > foo.mantxt\n\nAUTHOR\n       John W. Eaton was the  original\tauthor\tof  man.   Zeyd  M.  Ben-Halim\n       released  man  1.2,  and  Andries Brouwer followed up with versions 1.3\n       thru 1.5p.  Federico  Lucifredi\t<flucifredi@acm.org>  is  the  current\n       maintainer.\n\nSEE ALSO\n       apropos(1), whatis(1), less(1), groff(1), man.conf(5).\n\n\n\n\t\t\t      September 19, 2005\t\t\tman(1)\n",
   "tldr_summary": "# manpath\n\n> Determine the search path for manual pages.\n\n- Display the search path used to find man pages:\n\n`manpath`\n\n- Show the entire global manpath:\n\n`manpath --global`\n"
 },
 {
   "command": "qsub",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# qsub\n\n> Submits a script to the queue management system TORQUE.\n\n- Submit a script with default settings (depends on TORQUE settings):\n\n`qsub {{script.sh}}`\n\n- Submit a script with a specified wallclock runtime limit of 1 hour, 2 minutes and 3 seconds:\n\n`qsub -l walltime={{1}}:{{2}}:{{3}} {{script.sh}}`\n\n- Submit a script that is executed on 2 nodes using 4 cores per node:\n\n`qsub -l nodes={{2}}:ppn={{4}} {{script.sh}}`\n\n- Submit a script to a specific queue. Note that different queues can have different maximum and minimum runtime limits:\n\n`qsub -q {{queue_name}} {{script.sh}}`\n"
 },
 {
   "command": "lsmod",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lsmod\n\n> Shows the status of linux kernel modules.\n> See also `modprobe`, which loads kernel modules.\n\n- List all currently loaded kernel modules:\n\n`lsmod`\n"
 },
 {
   "command": "vncviewer",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# vncviewer\n\n> Launches a VNC (Virtual Network Computing) client.\n\n- Launch a VNC client which connects to a host on a given display:\n\n`vncviewer {{host}}:{{display_number}}`\n\n- Launch in full-screen mode:\n\n`vncviewer -FullScreen {{host}}:{{display_number}}`\n\n- Launch a VNC client with a specific screen geometry:\n\n`vncviewer --geometry {{width}}x{{height}} {{host}}:{{display_number}}`\n\n- Launch a VNC client which connects to a host on a given port:\n\n`vncviewer {{host}}::{{port}}`\n"
 },
 {
   "command": "photorec",
   "doc_url": "https://www.cgsecurity.org/wiki/PhotoRec",
   "doc_text": "\n\n\nPhotoRec - CGSecurity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCookies help us deliver our services. By using our services, you agree to our use of cookies. More information \n\n\n\n\n\nPhotoRec \nFrom CGSecurity \n\n\t\t\t\t\tJump to:\t\t\t\t\tnavigation, \t\t\t\t\tsearch\n\n\n English  中文  Deutsch  Español  Français  Magyar  Italiano  Русский  Türkçe\n\n\n\n\n Latest stable version\n\n\n\n7.1\n\n\n\nJuly 7, 2019\n\n\n\n\n\nPhotoRec, Digital Picture and File Recovery\n\nPhotoRec is file data recovery software designed to recover lost files including video, documents and archives from hard disks, CD-ROMs, and lost pictures (thus the Photo Recovery name) from digital camera memory. PhotoRec ignores the file system and goes after the underlying data, so it will still work even if your media's file system has been severely damaged or reformatted.\nPhotoRec is free - this open source multi-platform application is distributed under GNU General Public License (GPLV v2+). PhotoRec is a companion program to TestDisk, an application for recovering lost partitions on a wide variety of file systems and making non-bootable disks bootable again.\nYou can download them from this link.\nFor more safety, PhotoRec uses read-only access to handle the drive or memory card you are about to recover lost data from.\nImportant: As soon as a picture or file is accidentally deleted, or you discover any missing, do NOT save any more pictures or files to that memory device or hard disk drive; otherwise you may overwrite your lost data. This means that while using PhotoRec, you must not choose to write the recovered files to the same partition they were stored on.\n\nContents\n\n1 Operating systems\n2 File systems\n3 Media\n4 Known file formats\n5 How PhotoRec works\n6 Other topics\n7 Problems?\n\n\nOperating systems\nPhotoRec runs under\n\nDOS/Windows 9x\nWindows 10/8.1/8/7/Vista/XP, Windows Server 2016/2012/2008/2003\nLinux\nFreeBSD, NetBSD, OpenBSD\nSun Solaris\nMac OS X\nand can be compiled on almost every Unix system.\n Download TestDisk & PhotoRec\n\nFile systems\nPhotoRec ignores the file system; this way it works even if the file system is severely damaged.\nIt can recover lost files from at least \n\nFAT\nNTFS\nexFAT\next2/ext3/ext4 filesystem\nHFS+\nReiserFS includes some special optimizations centered around tails, a name for files and end portions of files that are smaller than a filesystem block. In order to increase performance, ReiserFS is able to store files inside the b*tree leaf nodes themselves, rather than storing the data somewhere else on the disk and pointing to it. Unfortunately, PhotoRec isn't able to deal with this - that's why it doesn't work well with ReiserFS.\n\nMedia\nPhotoRec works with hard disks, CD-ROMs, memory cards (CompactFlash, Memory Stick, Secure Digital/SD, SmartMedia, Microdrive, MMC, etc.), USB memory drives, DD raw image, EnCase E01 image, etc.\nPhotoRec has been successfully tested with various portable media players including iPod and the following Digital Cameras:\n\nCanon EOS 10D, 60D, 80D, 300D\nCasio Exilim EX-Z 750\nFujifilm X-T10\nHP PhotoSmart 620, 850, 935\nNikon CoolPix 775, 950, 5700\nOlympus C350N, C860L, Mju 400 Digital, Stylus 300\nSony Alpha DSLR, DSC-P9, NEX-6\nPentax K20D\nPraktica DCZ-3.4\nKnown file formats\nPhotoRec searches for known file headers. If there is no data fragmentation, which is often the case, it can recover the whole file.\nPhotoRec recognizes and recovers numerous file formats including ZIP, Office, PDF, HTML, JPEG and various graphics file formats.\nThe whole  list of file formats recovered by PhotoRec contains more than 480 file extensions (about 300 file families).\nWant to know if PhotoRec can recover your files ? Upload a sample file via the PhotoRec online checker (BETA).\n\nHow PhotoRec works\nFAT, NTFS, ext2/ext3/ext4 file systems store files in data blocks (also called clusters under Windows). The cluster or block size remains at a constant number of sectors after being initialized during the formatting of the file system. In general, most operating systems try to store the data in a contiguous way so as to minimize data fragmentation. The seek time of mechanical drives is significant for writing and reading data to/from a hard disk, so that's why it's important to keep the fragmentation to a minimum level.\nWhen a file is deleted, the meta-information about this file (file name, date/time, size, location of the first data block/cluster, etc.) is lost; for example, in an ext3/ext4 file system, the names of deleted files are still present, but the location of the first data block is removed. This means the data is still present on the file system, but only until some or all of it is overwritten by new file data.\nTo recover these lost files, PhotoRec first tries to find the data block (or cluster) size. If the file system is not corrupted, this value can be read from the superblock (ext2/ext3/ext4) or volume boot record (FAT, NTFS). Otherwise, PhotoRec reads the media, sector by sector, searching for the first ten files, from which it calculates the block/cluster size from their locations. Once this block size is known, PhotoRec reads the media block by block (or cluster by cluster). Each block is checked against a signature database which comes with the program and has grown in the type of files it can recover ever since PhotoRec's first version came out.\nFor example, PhotoRec identifies a JPEG file when a block begins with:\n\n0xff, 0xd8, 0xff, 0xe0\n0xff, 0xd8, 0xff, 0xe1\nor 0xff, 0xd8, 0xff, 0xfe\nIf PhotoRec has already started to recover a file, it stops its recovery, checks the consistency of the file when possible and starts to save the new file (which it determined from the signature it found).\nIf the data is not fragmented, the recovered file should be either identical to or larger than the original file in size. In some cases, PhotoRec can learn the original file size from the file header, so the recovered file is truncated to the correct size. If, however, the recovered file ends up being smaller than its header specifies, it is discarded. Some files, such as *.MP3 types, are data streams. In this case, PhotoRec parses the recovered data, then stops the recovery when the stream ends.\nWhen a file is recovered successfully, PhotoRec checks the previous data blocks to see if a file signature was found but the file wasn't able to be successfully recovered (that is, the file was too small), and it tries again. This way, some fragmented files can be successfully recovered.\n\nOther topics\ntestdisk.pdf More than 60 pages about data recovery using TestDisk & PhotoRec and other tools\nWorking with CD-R/CR-RW/DVD/floppy...\nPhotoRec Step By Step\nRecover data from an iPhone\nHow to help \nAfter Using PhotoRec: Some ideas to sort recovered files\nPhotoRec FAQ\nScripted run: Running PhotoRec without user interaction (Batch mode).\nDevelopers How to contribute code to TestDisk & PhotoRec\nProblems?\nDon't hesitate to visit the PhotoRec forum if you have\n\nsome difficulties using PhotoRec,\nsome ideas to improve it\nIf there is a file format you would like to be added, feel free to contact the developer Christophe GRENIER.\n\n\n\n\n\n \n\t\t\t\t\t\tRetrieved from \"https://www.cgsecurity.org/mw/index.php?title=PhotoRec&oldid=9035\"\t\t\t\t\t\nCategory: Data Recovery \n\n\n\nNavigation menu\n\n\nPersonal tools\n\nLog in \n\n\n\nNamespaces\n\nPage \n\n\n\n\nVariants\n\n\n\n\n\n\n\n\n\nViews\n\nReadView source \n\n\n\nMore\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Recovery\n\n\nTestDiskPhotoRecdownloadForum \n\n\n\nDonate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nPassword recovery\n\n\nCmosPwdLilo PasswordChntpw for dos \n\n\n\nSecurity\n\n\nPublications \n\n\n\nMisc\n\n\nMon CV (FR)PGP Public KeyEuro coinsRollerLinks \n\n\n\nShare\n\n \n\n\n\n\n\n\n\n\n\n\n This page was last edited on 23 July 2019, at 10:50.\nContent is available under GNU Free Documentation License 1.2 unless otherwise noted.\n\n\nAbout CGSecurity\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# photorec\n\n> Deleted file recovery tool.\n> It is recommended to write recovered files to a disk separate to the one being recovered from.\n> More information: <https://www.cgsecurity.org/wiki/PhotoRec>.\n\n- Run PhotoRec on a specific device:\n\n`sudo photorec {{/dev/sdb}}`\n\n- Run PhotoRec on a disk image (image.dd):\n\n`sudo photorec {{path/to/image.dd}}`\n"
 },
 {
   "command": "scanimage",
   "doc_url": "http://sane-project.org/man/scanimage.1.html",
   "doc_text": "\n\nscanimage.1\n\n\nscanimage.1\n\n\n\nscanimage(1)             SANE Scanner Access Now Easy             scanimage(1)\n\n\n\nNAME\n       scanimage - scan an image\n\n\n\nSYNOPSIS\n       scanimage  [-d|--device-name  dev]  [--format format] [-i|--icc-profile\n       profile]   [-L|--list-devices]   [-f|--formatted-device-list    format]\n       [-b|--batch  [=format]]  [--batch-start  start]  [--batch-count  count]\n       [--batch-increment  increment]   [--batch-double]   [--accept-md5-only]\n       [-p|--progress]    [-o|--output-file]    [-n|--dont-scan]   [-T|--test]\n       [-A|--all-options]   [-h|--help]    [-v|--verbose]    [-B|--buffer-size\n       [=size]] [-V|--version] [device-specific-options]\n\n\n\nDESCRIPTION\n       scanimage  is  a  command-line  interface  to control image acquisition\n       devices such as flatbed scanners or cameras.  The device is  controlled\n       via  command-line  options.   After  command-line processing, scanimage\n       normally proceeds to acquire an image.  The image data  is  written  to\n       standard  output  in  one of the PNM (portable aNyMaP) formats (PBM for\n       black-and-white images, PGM for grayscale images,  and  PPM  for  color\n       images), TIFF format (black-and-white, grayscale or color), PNG format,\n       or JPEG format (compression level 75).  scanimage accesses image acqui-\n       sition devices through the SANE (Scanner Access Now Easy) interface and\n       can thus support any device for which there exists a SANE backend  (try\n       apropos sane- to get a list of available backends).\n\n\n\nEXAMPLES\n       To get a list of devices:\n\n         scanimage -L\n\n       To scan with default settings to the file image.pnm:\n\n         scanimage >image.pnm\n\n       To  scan 100x100 mm to the file image.tiff (-x and -y may not be avail-\n       able with all devices):\n\n         scanimage -x 100 -y 100 --format=tiff >image.tiff\n\n       To print all available options:\n\n         scanimage -h\n\n\n\nOPTIONS\n       Parameters are separated by a blank from single-character options (e.g.\n       -d   epson)   and   by   a   \"=\"  from  multi-character  options  (e.g.\n       --device-name=epson).\n\n       The -d or --device-name options must be followed by a SANE  device-name\n       like  `epson:/dev/sg0'  or  `hp:/dev/usbscanner0'.  A (partial) list of\n       available devices can be obtained with the --list-devices  option  (see\n       below).   If  no device-name is specified explicitly, scanimage reads a\n       device-name from the environment variable SANE_DEFAULT_DEVICE.  If this\n       variable is not set, scanimage will attempt to open the first available\n       device.\n\n       The --format format option selects how image data is written  to  stan-\n       dard  output or the file specified by the --output-file option.  format\n       can be pnm, tiff, png, or jpeg.  If --format is not specified,  PNM  is\n       written by default.\n\n       The -i or --icc-profile option is used to include an ICC profile into a\n       TIFF file.\n\n       The -L or --list-devices option requests a (partial)  list  of  devices\n       that are available.  The list is not complete since some devices may be\n       available, but are not listed in any of the configuration files  (which\n       are typically stored in directory /usr/local/etc/sane.d).  This is par-\n       ticularly the case when accessing scanners through the network.   If  a\n       device is not listed in a configuration file, the only way to access it\n       is by its full device name.  You may need to consult your system admin-\n       istrator to find out the names of such devices.\n\n       The   -f   or   --formatted-device-list   option   works   similar   to\n       --list-devices, but requires a format string.  scanimage  replaces  the\n       placeholders %d %v %m %t %i %n with the device name, vendor name, model\n       name, scanner type, an index number and newline respectively. The  com-\n       mand\n\n              scanimage  -f  \"  scanner number %i device %d is a %t, model %m,\n              produced by %v \"\n\n       will produce something like:\n\n              scanner number 0  device sharp:/dev/sg1 is  a  flatbed  scanner,\n              model JX250 SCSI, produced by SHARP\n\n       The  --batch* options provide the features for scanning documents using\n       document feeders.  --batch [format] is used to specify  the  format  of\n       the  filename  that each page will be written to.  Each page is written\n       out to a single file.  If format  is  not  specified,  the  default  of\n       out%d.pnm  (or  out%d.tif for --format tiff, out%d.png for --format png\n       or out%d.jpg for -- format jpeg) will be used.  This option  is  incom-\n       patible  with  the  --output-path  option.  format is given as a printf\n       style string with one integer parameter.  --batch-start  start  selects\n       the  page  number  to  start  naming  files with. If this option is not\n       given, the counter will start at 1.  --batch-count count specifies  the\n       number  of pages to attempt to scan.  If not given, scanimage will con-\n       tinue scanning until the scanner returns a state other  than  OK.   Not\n       all  scanners  with  document feeders signal when the ADF is empty, use\n       this command to work around them.  With --batch-increment increment you\n       can  change  the  amount that the number in the filename is incremented\n       by.  Generally this is used when you are  scanning  double-sided  docu-\n       ments  on  a  single-sided document feeder.  A specific command is pro-\n       vided to aid this: --batch-double will automatically set the  increment\n       to  2.   --batch-prompt  will ask for pressing RETURN before scanning a\n       page. This can be used for scanning multiple pages without an automatic\n       document feeder.\n\n       The  --accept-md5-only  option only accepts user authorization requests\n       that support MD5 security. The SANE network daemon (saned)  is  capable\n       of doing such requests. See saned(8).\n\n       The  -p  or --progress option requests that scanimage prints a progress\n       counter. It shows how much image data of the current image has  already\n       been received by scanimage (in percent).\n\n       The  -o or --output-file option requests that scanimage saves the scan-\n       ning output to the given path. This option  is  incompatible  with  the\n       --batch  option.  The  program will try to guess --format from the file\n       name.  If that is not possible, it will  print  an  error  message  and\n       exit.\n\n       The  -n  or  --dont-scan  option  requests that scanimage only sets the\n       options provided by the user but doesn't actually perform a scan.  This\n       option can be used to e.g. turn off the scanner's lamp (if supported by\n       the backend).\n\n       The -T or --test option requests that scanimage performs a  few  simple\n       sanity  tests to make sure the backend works as defined by the SANE API\n       (in particular the sane_read function is exercised by this test).\n\n       The -A or --all-options option requests that scanimage lists all avail-\n       able options exposed the backend, including button options.  The infor-\n       mation is printed on standard output and no scan will be done.\n\n       The -h or --help options request help information.  The information  is\n       printed on standard output and in this case, no attempt will be made to\n       acquire an image.\n\n       The -v or --verbose options increase the verbosity of the operation  of\n       scanimage.   The option may be specified repeatedly, each time increas-\n       ing the verbosity level.\n\n       The -B option without argument changes the input buffer size  from  the\n       default  32KB  to  1MB.   For finer grained control, use --buffer-size=\n       followed by the number of KB.\n\n       The -V or --version option requests that scanimage prints  the  program\n       and  package  name, the version number of the SANE distribution that it\n       came with and the version of the backend that it loads. Usually  that's\n       the  dll  backend. If more information about the version numbers of the\n       backends are necessary, the DEBUG variable for the dll backend  can  be\n       used. Example: SANE_DEBUG_DLL=3 scanimage -L.\n\n       As  you  might  imagine,  much of the power of scanimage comes from the\n       fact that it can control any SANE backend.  Thus, the exact set of com-\n       mand-line  options  depends on the capabilities of the selected device.\n       To see the options for a device named dev, invoke scanimage via a  com-\n       mand-line of the form:\n\n              scanimage --help --device-name dev\n\n       The  documentation for the device-specific options printed by --help is\n       best explained with a few examples:\n\n        -l 0..218mm [0]\n           Top-left x position of scan area.\n\n              The description above shows that option  -l  expects  an  option\n              value in the range from 0 to 218 mm.  The value in square brack-\n              ets indicates that the current option value is 0 mm. Most  back-\n              ends  provide  similar  geometry options for top-left y position\n              (-t), width (-x) and height of scan-area (-y).\n\n        --brightness -100..100% [0]\n           Controls the brightness of the acquired image.\n\n              The description above shows that option --brightness expects  an\n              option  value  in the range from -100 to 100 percent.  The value\n              in square brackets indicates that the current option value is  0\n              percent.\n\n        --default-enhancements\n           Set default values for enhancement controls.\n\n              The  description  above shows that option --default-enhancements\n              has no option value.  It should be thought of as having an imme-\n              diate  effect  at  the  point  of  the  command-line at which it\n              appears.  For example, since this option resets the --brightness\n              option,  the  option-pair --brightness 50 --default-enhancements\n              would effectively be a no-op.\n\n        --mode Lineart|Gray|Color [Gray]\n           Selects the scan mode (e.g., lineart or color).\n\n              The description above shows that option --mode accepts an  argu-\n              ment  that  must  be one of the strings Lineart, Gray, or Color.\n              The value in the square bracket indicates  that  the  option  is\n              currently set to Gray.  For convenience, it is legal to abbrevi-\n              ate the string values as long as they remain unique.  Also,  the\n              case  of  the spelling doesn't matter.  For example, option set-\n              ting --mode col is identical to --mode Color.\n\n        --custom-gamma[=(yes|no)] [inactive]\n           Determines whether a builtin or a custom gamma-table\n           should be used.\n\n              The description above shows that option  --custom-gamma  expects\n              either no option value, a \"yes\" string, or a \"no\" string.  Spec-\n              ifying the option with no  value  is  equivalent  to  specifying\n              \"yes\".   The  value in square-brackets indicates that the option\n              is not currently active.  That is, attempting to set the  option\n              would  result in an error message.  The set of available options\n              typically depends on the settings of other options.   For  exam-\n              ple,  the  --custom-gamma  table  might  be  active  only when a\n              grayscale or color scan-mode has been requested.\n\n              Note that the --help option is processed only  after  all  other\n              options  have been processed.  This makes it possible to see the\n              option settings for a particular mode by specifying  the  appro-\n              priate  mode-options along with the --help option.  For example,\n              the command-line:\n\n              scanimage --help --mode color\n\n              would print the option settings that  are  in  effect  when  the\n              color-mode is selected.\n\n        --gamma-table 0..255,...\n           Gamma-correction table.  In color mode this option\n           equally affects the red, green, and blue channels\n           simultaneously (i.e., it is an intensity gamma table).\n\n              The  description  above  shows that option --gamma-table expects\n              zero or more values in the range 0 to 255.  For example, a legal\n              value  for this option would be \"3,4,5,6,7,8,9,10,11,12\".  Since\n              it's cumbersome to specify long vectors in this form,  the  same\n              can  be  expressed  by  the abbreviated form \"[0]3-[9]12\".  What\n              this means is that the first vector element is  set  to  3,  the\n              9-th element is set to 12 and the values in between are interpo-\n              lated linearly.  Of course, it is possible to  specify  multiple\n              such  linear segments.  For example, \"[0]3-[2]3-[6]7,[7]10-[9]6\"\n              is   equivalent   to   \"3,3,3,4,5,6,7,10,8,6\".    The    program\n              gamma4scanimage  can  be used to generate such gamma tables (see\n              gamma4scanimage(1) for details).\n\n        --filename <string> [/tmp/input.ppm]\n           The filename of the image to be loaded.\n\n              The description above is an example of an option that  takes  an\n              arbitrary string value (which happens to be a filename).  Again,\n              the value in brackets show that the option is current set to the\n              filename /tmp/input.ppm.\n\n\n\nENVIRONMENT\n       SANE_DEFAULT_DEVICE\n              The default device-name.\n\n\n\nFILES\n       /usr/local/etc/sane.d\n              This  directory holds various configuration files.  For details,\n              please refer to the manual pages listed below.\n\n       ~/.sane/pass\n              This file contains lines of the form\n\n              user:password:resource\n\n              scanimage uses this information  to  answer  user  authorization\n              requests  automatically.  The file must have 0600 permissions or\n              stricter. You should use  this  file  in  conjunction  with  the\n              --accept-md5-only  option  to  avoid  server-side  attacks.  The\n              resource may contain any character but is limited to 127 charac-\n              ters.\n\n\n\nSEE ALSO\n       sane(7),    gamma4scanimage(1),   xscanimage(1),   xcam(1),   xsane(1),\n       scanadf(1), sane-dll(5), sane-net(5), sane-\"backendname\"(5)\n\n\n\nAUTHOR\n       David Mosberger, Andreas Beck, Gordon Matzigkeit, Caskey  Dickson,  and\n       many  others.   For questions and comments contact the sane-devel mail-\n       inglist (see http://www.sane-project.org/mailing-lists.html).\n\n\n\nBUGS\n       For vector options, the help output currently has no indication  as  to\n       how many elements a vector-value should have.\n\n                                  10 Jul 2008                     scanimage(1)\n\n\n\nMan(1) output converted with\nman2html\n\n\n",
   "man_entry": "",
   "tldr_summary": "# scanimage\n\n> Scan images with the Scanner Access Now Easy API.\n> More information: <http://sane-project.org/man/scanimage.1.html>.\n\n- List available scanners to ensure the target device is connected and recognized:\n\n`scanimage -L`\n\n- Scan an image and save it to a file:\n\n`scanimage --format={{pnm|tiff|png|jpeg}} > {{path/to/new_image}}`\n"
 },
 {
   "command": "mpstat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mpstat\n\n> Report CPU statistics.\n\n- Display CPU statistics every 2 seconds:\n\n`mpstat {{2}}`\n\n- Display 5 reports, one by one, at 2 second intervals:\n\n`mpstat {{2}} {{5}}`\n\n- Display 5 reports, one by one, from a given processor, at 2 second intervals:\n\n`mpstat -P {{0}} {{2}} {{5}}`\n"
 },
 {
   "command": "dbus-daemon",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dbus-daemon\n\n> The D-Bus message daemon, allowing multiple programs to exchange messages.\n\n- Run the daemon with a configuration file:\n\n`dbus-daemon --config-file {{path/to/file}}`\n\n- Run the daemon with the standard per-login-session message bus configuration:\n\n`dbus-daemon --session`\n\n- Run the daemon with the standard systemwide message bus configuration:\n\n`dbus-daemon --system`\n\n- Set the address to listen on and override the configuration value for it:\n\n`dbus-daemon --address {{address}}`\n\n- Output the process id to `stdout`:\n\n`dbus-daemon --print-pid`\n\n- Force the message bus to write to the system log for messages:\n\n`dbus-daemon --syslog`\n"
 },
 {
   "command": "iostat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nIOSTAT(8)\t\t  BSD System Manager's Manual\t\t     IOSTAT(8)\n\nNAME\n     iostat -- report I/O statistics\n\nSYNOPSIS\n     iostat [-CUdKIoT?] [-c count] [-n devs] [-w wait] [drives]\n\nDESCRIPTION\n     Iostat displays kernel I/O statistics on terminal, device and cpu opera-\n     tions.  The first statistics that are printed are averaged over the sys-\n     tem uptime.  To get information about the current activity, a suitable\n     wait time should be specified, so that the subsequent sets of printed\n     statistics will be averaged over that time.\n\n     The options are as follows:\n\n     -?    Display a usage statement and exit.\n\n     -C    Display CPU statistics.  This is on by default, unless -d is speci-\n\t   fied.\n\n     -c    Repeat the display count times.  If no wait interval is specified,\n\t   the default is 1 second.\n\n     -d    Display only device statistics.  If this flag is turned on, only\n\t   device statistics will be displayed, unless -C or -U or -T is also\n\t   specfied to enable the display of CPU, load average or TTY statis-\n\t   tics.\n\n     -I    Display total statstics for a given time period, rather than aver-\n\t   age statistics for each second during that time period.\n\n     -K    In the blocks transferred display (-o), display block count in\n\t   kilobytes rather then the device native block size.\n\n     -n    Display up to devs number of devices.  iostat will display fewer\n\t   devices if there aren't devs devices present.\n\n     -o    Display old-style iostat device statistics.\tSectors per second,\n\t   transfers per second, and miliseconds per seek are displayed.  If\n\t   -I is specified, total blocks/sectors, total transfers, and\n\t   miliseconds per seek are displayed.\n\n     -T    Display TTY statistics.  This is on by default, unless -d is speci-\n\t   fied.\n\n     -U    Display system load averages.  This is on by default, unless -d is\n\t   specified.\n\n     -w    Pause wait seconds between each display.  If no repeat count is\n\t   specified, the default is infinity.\n\n     Iostat displays its information in the following format:\n\n     tty\n\t   tin\t   characters read from terminals\n\t   tout    characters written to terminals\n\n     devices\n\t   Device operations.  The header of the field is the device name and\n\t   unit number.  iostat will display as many devices as will fit in a\n\t   standard 80 column screen, or the maximum number of devices in the\n\t   system, whichever is smaller.  If -n is specified on the command\n\t   line, iostat will display the smaller of the requested number of\n\t   devices, and the maximum number of devices in the system.  To force\n\t   iostat to display specific drives, their names may be supplied on\n\t   the command line.  iostat will not display more devices than will\n\t   fit in an 80 column screen, unless the -n argument is given on the\n\t   command line to specify a maximum number of devices to display, or\n\t   the list of specified devices exceeds 80 columns.  If fewer devices\n\t   are specified on the command line than will fit in an 80 column\n\t   screen, iostat will show only the specified devices.\n\n\t   The standard iostat device display shows the following statistics:\n\n\t   KB/t    kilobytes per transfer\n\t   tps\t   transfers per second\n\t   MB/s    megabytes per second\n\n\t   The standard iostat device display, with the -I flag specified,\n\t   shows the following statistics:\n\n\t   KB/t    kilobytes per transfer\n\t   xfrs    total number of transfers\n\t   MB\t   total number of megabytes transferred\n\n\t   The old-style iostat display (using -o) shows the following statis-\n\t   tics:\n\n\t   sps\t   sectors transferred per second\n\t   tps\t   transfers per second\n\t   msps    average milliseconds per transaction\n\n\t   The old-style iostat display, with the -I flag specified, shows the\n\t   following statistics:\n\n\t   blk\t   total blocks/sectors transferred\n\t   xfr\t   total transfers\n\t   msps    average milliseconds per transaction\n\n     cpu\n\t   us\t   % of cpu time in user mode\n\t   sy\t   % of cpu time in system mode\n\t   id\t   % of cpu time in idle mode\n\nEXAMPLES\n\t   iostat -w 1 disk0 disk2\n\n     Display statistics for the first and third disk devices device every sec-\n     ond ad infinitum.\n\n\t   iostat -c 2\n\n     Display the statistics for the first four devices in the system twice,\n     with a one second display interval.\n\n\t   iostat -Iw 3\n\n     Display total statistics every three seconds ad infinitum.\n\n\t   iostat -odICTw 2 -c 9\n\n     Display total statistics using the old-style output format 9 times, with\n     a two second interval between each measurement/display.  The -d flag gen-\n     erally disables the TTY and CPU displays, but since the -T and -C flags\n     are given, the TTY and CPU displays will be displayed.\n\nSEE ALSO\n     fstat(1), netstat(1), nfsstat(1), ps(1), pstat(8)\n\n     The sections starting with ``Interpreting system activity'' in Installing\n     and Operating 4.3BSD.\n\nHISTORY\n     This version of iostat first appeared in FreeBSD 3.0.\n\nBSD\t\t\t      September 27, 2001\t\t\t   BSD\n",
   "tldr_summary": "# iostat\n\n> Report statistics for devices and partitions.\n\n- Display a report of CPU and disk statistics since system startup:\n\n`iostat`\n\n- Display a report of CPU and disk statistics with units converted to megabytes:\n\n`iostat -m`\n\n- Display CPU statistics:\n\n`iostat -c`\n\n- Display disk statistics with disk names (including LVM):\n\n`iostat -N`\n\n- Display extended disk statistics with disk names for device \"sda\":\n\n`iostat -xN {{sda}}`\n\n- Display incremental reports of CPU and disk statistics every 2 seconds:\n\n`iostat {{2}}`\n"
 },
 {
   "command": "nethogs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# nethogs\n\n> Monitor bandwidth usage per process.\n\n- Start nethogs as root (default device is eth0):\n\n`sudo nethogs`\n\n- Monitor bandwidth on specific device:\n\n`sudo nethogs {{device}}`\n\n- Monitor bandwidth on multiple devices:\n\n`sudo nethogs {{device1}} {{device2}}`\n\n- Specify refresh rate:\n\n`sudo nethogs -t {{seconds}}`\n"
 },
 {
   "command": "ldconfig",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ldconfig\n\n> Configure symlinks and cache for shared library dependencies.\n\n- Update symlinks and rebuild the cache (usually run when a new library is installed):\n\n`sudo ldconfig`\n\n- Update the symlinks for a given directory:\n\n`sudo ldconfig -n {{path/to/directory}}`\n\n- Print the libraries in the cache and check whether a given library is present:\n\n`ldconfig -p | grep {{library_name}}`\n"
 },
 {
   "command": "f5fpc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# f5fpc\n\n> A proprietry commercial SSL VPN client by BIG-IP Edge.\n\n- Open a new VPN connection:\n\n`sudo f5fpc --start`\n\n- Open a new VPN connection to a specific host:\n\n`sudo f5fpc --start --host {{host.example.com}}`\n\n- Specify a username (user will be prompted for a password):\n\n`sudo f5fpc --start --host {{host.example.com}} --username {{user}}`\n\n- Show the current VPN status:\n\n`sudo f5fpc --info`\n\n- Shutdown the VPN connection:\n\n`sudo f5fpc --stop`\n"
 },
 {
   "command": "vrms",
   "doc_url": "https://debian.pages.debian.net/vrms/",
   "doc_text": "The Virtual Richard M. Stallman (vrms) package\nIn the early 1980's Richard M.\nStallman created the GNU project,\nwhose goal was to provide the world with a Free Operating System\n(with the word \"Free\" with the same meaning as in \"Freedom\").\nSince then, a lot of Free Software was developed and entire\noperating systems based only on Free Software were\ncreated.  Unfortunately, some data is still stored in a format\nthat is proprietary, secret and non-standard, made by corporations\nthat want to retain control over the users of the software that\ngenerates such data.\nThis, of course, is meant to keep the users following the newer\nversions of the software that \"control\" the users' data (so that\nthe users can still have access to their own creations).\nAlso, unfortunately, most of the time, the software for\nmanipulating such data is not Free in the sense desired by Richard\nStallman. Software that does not allow all the freedoms stipulated\nby Richard Stallman is called non-free software.\nThe vrms program provides the facility for users\nof Debian-based Operating\nSystems (like, e.g., Ubuntu)\nto detect if their systems have any non-free software installed,\nso that the users can keep their installations only with software\nthat doesn't pose any legal problems.\nThe package is now maintained (on\nDebian's salsa system) by\na team of developers including Bdale\nGarbee (one of the original authors),\nRogério Brito and\nHolger Levsen, with\nthe help of many contributers.\nThe source code is maintained with a version control system called\nGit. Anybody can\nobtain the source code for the vrms package from salsa.debian.org\nand any collaboration is highly appreciated.\nThis page was made using Free Software\nonly.  Free Software is much more than zero-cost\nsoftware!\nLast updated: 2018-10-15\nby Holger Levsen.",
   "man_entry": "",
   "tldr_summary": "# vrms\n\n> Report non-free packages installed on Debian-based OSes.\n> More information: <https://debian.pages.debian.net/vrms/>.\n\n- List non-free and contrib packages (and their description):\n\n`vrms`\n\n- Only output the package names:\n\n`vrms --sparse`\n"
 },
 {
   "command": "sv",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# sv\n\n> Control a running runsv service.\n\n- Start a service:\n\n`sudo sv up {{path/to/service}}`\n\n- Stop a service:\n\n`sudo sv down {{path/to/service}}`\n\n- Get service status:\n\n`sudo sv status {{path/to/service}}`\n"
 },
 {
   "command": "pkginfo",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pkginfo\n\n> Query the package database on a CRUX system.\n\n- List installed packages and their versions:\n\n`pkginfo -i`\n\n- List files owned by a package:\n\n`pkginfo -l {{package_name}}`\n\n- List the owner(s) of files matching a pattern:\n\n`pkginfo -o {{pattern}}`\n\n- Print the footprint of a file:\n\n`pkginfo -f {{file}}`\n"
 },
 {
   "command": "netstat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nNETSTAT(1)\t\t  BSD General Commands Manual\t\t    NETSTAT(1)\n\nNAME\n     netstat -- show network status\n\nSYNOPSIS\n     netstat [-AaLlnW] [-f address_family | -p protocol]\n     netstat [-gilns] [-v] [-f address_family] [-I interface]\n     netstat -i | -I interface [-w wait] [-c queue] [-abdgqRtS]\n     netstat -s [-s] [-f address_family | -p protocol] [-w wait]\n     netstat -i | -I interface -s [-f address_family | -p protocol]\n     netstat -m [-m]\n     netstat -r [-Aaln] [-f address_family]\n     netstat -rs [-s]\n\nDESCRIPTION\n     The netstat command symbolically displays the contents of various net-\n     work-related data structures.  There are a number of output formats,\n     depending on the options for the information presented.  The first form\n     of the command displays a list of active sockets for each protocol.  The\n     second form presents the contents of one of the other network data struc-\n     tures according to the option selected. Using the third form, with a wait\n     interval specified, netstat will continuously display the information\n     regarding packet traffic on the configured network interfaces.  The\n     fourth form displays statistics for the specified protocol or address\n     family. If a wait interval is specified, the protocol information over\n     the last interval seconds will be displayed.  The fifth form displays\n     per-interface statistics for the specified protocol or address family.\n     The sixth form displays mbuf(9) statistics.  The seventh form displays\n     routing table for the specified address family.  The eighth form displays\n     routing statistics.\n\n     The options have the following meaning:\n\n     -A    With the default display, show the address of any protocol control\n\t   blocks associated with sockets and the flow hash; used for debug-\n\t   ging.\n\n     -a    With the default display, show the state of all sockets; normally\n\t   sockets used by server processes are not shown. With the routing\n\t   table display (option -r, as described below), show protocol-cloned\n\t   routes (routes generated by a RTF_PRCLONING parent route); normally\n\t   these routes are not shown.\n\n     -b    With the interface display (option -i, as described below), show\n\t   the number of bytes in and out.\n\n     -c queue\n\t   With the queue statistics (option -q, as described below), show\n\t   only those for the specified queue.\n\n     -d    With either interface display (option -i or an interval, as\n\t   described below), show the number of dropped packets.\n\n     -f address_family\n\t   Limit statistics or address control block reports to those of the\n\t   specified address family.  The following address families are rec-\n\t   ognized: inet, for AF_INET, inet6, for AF_INET6 and unix, for\n\t   AF_UNIX.\n\n     -g    Show information related to multicast (group address) membership.\n\t   If the -s option is also present, show extended interface group\n\t   management statistics.  If the -v option is specified, show link-\n\t   layer memberships; they are suppressed by default.  Source lists\n\t   for each group will also be printed.  Specifiying -v twice will\n\t   print the control plane timers for each interface and the source\n\t   list counters for each group.  If the -i is specified, only that\n\t   interface will be shown.  If the -f is specified, only information\n\t   for the address family will be displayed.\n\n     -I interface\n\t   Show information about the specified interface; used with a wait\n\t   interval as described below.  If the -s option is present, show\n\t   per-interface protocol statistics on the interface for the speci-\n\t   fied address_family or protocol, or for all protocol families.\n\n     -i    Show the state of interfaces which have been auto-configured\n\t   (interfaces statically configured into a system, but not located at\n\t   boot time are not shown).  If the -a options is also present, mul-\n\t   ticast addresses currently in use are shown for each Ethernet\n\t   interface and for each IP interface address.  Multicast addresses\n\t   are shown on separate lines following the interface address with\n\t   which they are associated.  If the -s option is present, show per-\n\t   interface statistics on all interfaces for the specified\n\t   address_family or protocol, or for all protocol families.\n\n     -L    Show the size of the various listen queues.\tThe first count shows\n\t   the number of unaccepted connections.  The second count shows the\n\t   amount of unaccepted incomplete connections.  The third count is\n\t   the maximum number of queued connections.\n\n     -l    Print full IPv6 address.\n\n     -m    Show statistics recorded by the memory management routines (the\n\t   network stack manages a private pool of memory buffers). More\n\t   detailed information about the buffers, which includes their cache\n\t   related statistics, can be obtained by using -mm or -m -m option.\n\n     -n    Show network addresses as numbers (normally netstat interprets\n\t   addresses and attempts to display them symbolically).  This option\n\t   may be used with any of the display formats.\n\n     -p protocol\n\t   Show statistics about protocol, which is either a well-known name\n\t   for a protocol or an alias for it.  Some protocol names and aliases\n\t   are listed in the file /etc/protocols.  The special protocol name\n\t   ``bdg'' is used to show bridging statistics.  A null response typi-\n\t   cally means that there are no interesting numbers to report.  The\n\t   program will complain if protocol is unknown or if there is no sta-\n\t   tistics routine for it.\n\n     -q    Show network interface send queue statistics.  By default all\n\t   queues are displayed, unless specified with -c.  This option\n\t   requires specifying an interface with -I option.  More detailed\n\t   information about the queues, which includes their queueing algo-\n\t   rithm related statistics, can be obtained by using -qq or -q -q\n\t   option.\n\n     -r    Show the routing tables.  Use with -a to show protocol-cloned\n\t   routes.  When -s is also present, show routing statistics instead.\n\t   When -l is also present, netstat assumes more columns are there and\n\t   the maximum transmission unit.  More detailed information about the\n\t   route metrics are displayed with -ll for TCP round trip times -lll\n\t   for all metrics.  Use the -z flags to display only entries with\n\t   non-zero RTT values.  (``mtu'') are also displayed.\n\n     -R    Show reachability information.  Use with -i to show link-layer\n\t   reachability information for a given interface.\n\n     -s    Show per-protocol statistics.  If this option is repeated, counters\n\t   with a value of zero are suppressed.  For security reasons, root\n\t   privileges are required to read TCP statistics and in the absence\n\t   of such privileges all TCP counters will be reported as zero.\n\n     -S    Show interface link status and interface state information about\n\t   the specified interface.  This option requires specifying an inter-\n\t   face with -I option.\n\n     -v    Increase verbosity level.\n\n     -W    In certain displays, avoid truncating addresses even if this causes\n\t   some fields to overflow.\n\n     -w wait\n\t   Show network interface or protocol statistics at intervals of wait\n\t   seconds.\n\n     -x    Show extended link-layer reachability information in addition to\n\t   that shown by the -R flag.\n\nOUTPUT\n     The default display, for active sockets, shows the local and remote\n     addresses, send and receive queue sizes (in bytes), protocol, and the\n     internal state of the protocol.  Address formats are of the form\n     ``host.port'' or ``network.port'' if a socket's address specifies a net-\n     work but no specific host address.  If known, the host and network\n     addresses are displayed symbolically according to the databases\n     /etc/hosts and /etc/networks, respectively.  If a symbolic name for an\n     address is unknown, or if the -n option is specified, the address is\n     printed numerically, according to the address family.  For more informa-\n     tion regarding the Internet ``dot format'', refer to inet(3)).  Unspeci-\n     fied, or ``wildcard'', addresses and ports appear as ``*''.\n\n     Internet domain socket states:\n\n     CLOSED:  The socket is not in use.\n\n     LISTEN:  The socket is listening for incoming connections.  Unconnected\n     listening sockets like these are only displayed when using the -a option.\n\n     SYN_SENT:\tThe socket is actively trying to establish a connection to a\n     remote peer.\n\n     SYN_RCVD:\tThe socket has passively received a connection request from a\n     remote peer.\n\n     ESTABLISHED:  The socket has an established connection between a local\n     application and a remote peer.\n\n     CLOSE_WAIT:  The socket connection has been closed by the remote peer,\n     and the system is waiting for the local application to close its half of\n     the connection.\n\n     LAST_ACK:\tThe socket connection has been closed by the remote peer, the\n     local application has closed its half of the connection, and the system\n     is waiting for the remote peer to acknowledge the close.\n\n     FIN_WAIT_1:  The socket connection has been closed by the local\n     application, the remote peer has not yet acknowledged the close, and the\n     system is waiting for it to close its half of the connection.\n\n     FIN_WAIT_2:  The socket connection has been closed by the local\n     application, the remote peer has acknowledged the close, and the system\n     is waiting for it to close its half of the connection.\n\n     CLOSING:  The socket connection has been closed by the local application\n     and the remote peer simultaneously, and the remote peer has not yet\n     acknowledged the close attempt of the local application.\n\n     TIME_WAIT:  The socket connection has been closed by the local\n     application, the remote peer has closed its half of the connection, and\n     the system is waiting to be sure that the remote peer received the last\n     acknowledgement.\n\n     The interface display provides a table of cumulative statistics regarding\n     packets transferred, errors, and collisions.  The network addresses of\n     the interface and the maximum transmission unit (``mtu'') are also dis-\n     played.\n\n     The routing table display indicates the available routes and their sta-\n     tus.  Each route consists of a destination host or network and a gateway\n     to use in forwarding packets.  The flags field shows a collection of\n     information about the route stored as binary choices.  The individual\n     flags are discussed in more detail in the route(8) and route(4) manual\n     pages.  The mapping between letters and flags is:\n\n     1\t     RTF_PROTO1       Protocol specific routing flag #1\n     2\t     RTF_PROTO2       Protocol specific routing flag #2\n     3\t     RTF_PROTO3       Protocol specific routing flag #3\n     B\t     RTF_BLACKHOLE    Just discard packets (during updates)\n     b\t     RTF_BROADCAST    The route represents a broadcast address\n     C\t     RTF_CLONING      Generate new routes on use\n     c\t     RTF_PRCLONING    Protocol-specified generate new routes on use\n     D\t     RTF_DYNAMIC      Created dynamically (by redirect)\n     G\t     RTF_GATEWAY      Destination requires forwarding by intermediary\n     H\t     RTF_HOST\t      Host entry (net otherwise)\n     I\t     RTF_IFSCOPE      Route is associated with an interface scope\n     i\t     RTF_IFREF\t      Route is holding a reference to the interface\n     L\t     RTF_LLINFO       Valid protocol to link address translation\n     M\t     RTF_MODIFIED     Modified dynamically (by redirect)\n     m\t     RTF_MULTICAST    The route represents a multicast address\n     R\t     RTF_REJECT       Host or net unreachable\n     r\t     RTF_ROUTER       Host is a default router\n     S\t     RTF_STATIC       Manually added\n     U\t     RTF_UP\t      Route usable\n     W\t     RTF_WASCLONED    Route was generated as a result of cloning\n     X\t     RTF_XRESOLVE     External daemon translates proto to link address\n     Y\t     RTF_PROXY\t      Proxying; cloned routes will not be scoped\n\n     Direct routes are created for each interface attached to the local host;\n     the gateway field for such entries shows the address of the outgoing\n     interface.  The refcnt field gives the current number of active uses of\n     the route.  Connection oriented protocols normally hold on to a single\n     route for the duration of a connection while connectionless protocols\n     obtain a route while sending to the same destination.  The use field pro-\n     vides a count of the number of packets sent using that route.  The inter-\n     face entry indicates the network interface utilized for the route.  A\n     route which is marked with the RTF_IFSCOPE flag is instantiated for the\n     corresponding interface.  A cloning route which is marked with the\n     RTF_PROXY flag will not generate new routes that are associated with its\n     interface scope.\n\n     When netstat is invoked with the -w option and a wait interval argument,\n     it displays a running count of statistics related to network interfaces\n     or protocols.  An obsolete version of this option used a numeric parame-\n     ter with no option, and is currently supported for backward compatibil-\n     ity.  By default, this display summarizes information for all interfaces.\n     Information for a specific interface may be displayed with the -I option.\n\nSEE ALSO\n     nfsstat(1), ps(1), inet(4), unix(4), hosts(5), networks(5), protocols(5),\n     route(8), services(5), iostat(8),\n\nHISTORY\n     The netstat command appeared in 4.2BSD.\n\n     IPv6 support was added by WIDE/KAME project.\n\nBUGS\n     The notion of errors is ill-defined.\n\nDarwin\t\t\t\t June 15, 2001\t\t\t\tDarwin\n",
   "tldr_summary": "# netstat\n\n> Displays network-related information such as open connections, open socket ports, etc.\n\n- List all ports:\n\n`netstat -a`\n\n- List all listening ports:\n\n`netstat -l`\n\n- List listening TCP ports:\n\n`netstat -t`\n\n- Display PID and program names:\n\n`netstat -p`\n\n- List information continuously:\n\n`netstat -c`\n\n- List routes and do not resolve IP to hostname:\n\n`netstat -rn`\n\n- List listening TCP and UDP ports (+ user and process if you're root):\n\n`netstat -lepunt`\n\n- Print the routing table:\n\n`netstat -nr`\n"
 },
 {
   "command": "xtrlock",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xtrlock\n\n> Lock the X display until the user supplies their password.\n\n- Lock the display and show a padlock instead of the cursor:\n\n`xtrlock`\n\n- Display a blank screen as well as the padlock cursor:\n\n`xtrlock -b`\n\n- Fork the xtrlock process and return immediately:\n\n`xtrlock -f`\n"
 },
 {
   "command": "eject",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# eject\n\n> Eject cds, floppy disks and tape drives.\n\n- Display the default device:\n\n`eject -d`\n\n- Eject the default device:\n\n`eject`\n\n- Eject a specific device (the default order is cd-rom, scsi, floppy and tape):\n\n`eject {{/dev/cdrom}}`\n\n- Toggle whether a device's tray is open or closed:\n\n`eject -T {{/dev/cdrom}}`\n\n- Eject a cd drive:\n\n`eject -r {{/dev/cdrom}}`\n\n- Eject a floppy drive:\n\n`eject -f {{/mnt/floppy}}`\n\n- Eject a tape drive:\n\n`eject -q {{/mnt/tape}}`\n"
 },
 {
   "command": "a2dissite",
   "doc_url": "https://manpages.debian.org/buster/apache2/a2dissite.8.en.html",
   "doc_text": "\n\n\n\na2dissite(8) — apache2 — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / apache2\n     \n     \n     \n     / a2dissite(8)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXIT STATUS\n\n\nEXAMPLES\n\n\nFILES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.4.38-3+deb10u3\n\n\nbuster-backports 2.4.43-1~bpo10+1\n\n\ntesting 2.4.43-1\n\n\nunstable 2.4.43-1\n\n\n\n\n\n\nScroll to navigation\n\n\n\nA2ENSITE(8)\nSystem Manager's Manual\nA2ENSITE(8)\n\n\n\n\nNAME¶\na2ensite, a2dissite - enable or disable an apache2 site / virtual host\n\n\nSYNOPSIS¶\na2ensite [ [-q|--quiet] site]\na2dissite [ [-q|--quiet] site]\n\n\nDESCRIPTION¶\nThis manual page documents briefly the a2ensite and a2dissite\n  commands.\na2ensite is a script that enables the specified site (which\n    contains a <VirtualHost> block) within the apache2\n    configuration. It does this by creating symlinks within\n    /etc/apache2/sites-enabled. Likewise, a2dissite disables a\n    site by removing those symlinks. It is not an error to enable a site which\n    is already enabled, or to disable one which is already disabled.\nApache treats the very first virtual host enabled specially as\n    every request not matching any actual directive is being redirected there.\n    Thus it should be called 000-default in order to sort before the\n    remaining hosts to be loaded first.\n\n\nOPTIONS¶\n\n-q, --quiet\nDon't show informative messages.\n-m, --maintmode\nEnables the maintainer mode, that is the program invocation is effectuated\n      automatically by a maintainer script. This switch should not be used by\n      end users.\n-p, --purge\nWhen disabling a module, purge all traces of the module in the internal\n      state data base.\n\n\n\nEXIT STATUS¶\na2ensite and a2dissite exit with status 0 if all sites are\n  processed successfully, 1 if errors occur, 2 if an invalid option was used.\n\n\nEXAMPLES¶\na2dissite 000-default\nDisables the default site.\n\n\nFILES¶\n\n/etc/apache2/sites-available\nDirectory with files giving information on available sites.\n/etc/apache2/sites-enabled\nDirectory with links to the files in sites-available for enabled\n      sites.\n\n\n\nSEE ALSO¶\napache2ctl(8).\n\n\nAUTHOR¶\nThis manual page was written by Stefan Fritsch <sf@debian.org> (based on\n  the a2enmod manual page by Daniel Stone <daniel@sfarc.net>) for the\n  Debian GNU/Linux distribution.\n\n\n\n\n8 June 2007\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\na2dissite.8.en.gz (from apache2 2.4.38-3+deb10u3)\n\n\n\n\nSource last updated:\n\n\n2019-04-07T18:15:40Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:05:57Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# a2dissite\n\n> Disable an Apache virtual host on Debian-based OSes.\n> More information: <https://manpages.debian.org/buster/apache2/a2dissite.8.en.html>.\n\n- Disable a virtual host:\n\n`sudo a2dissite {{virtual_host}}`\n\n- Don't show informative messages:\n\n`sudo a2dissite --quiet {{virtual_host}}`\n"
 },
 {
   "command": "create_ap",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# create_ap\n\n> Create an AP (Access Point) at any channel.\n\n- Create an open network with no passphrase:\n\n`create_ap {{wlan0}} {{eth0}} {{access_point_ssid}}`\n\n- Use a WPA + WPA2 passphrase:\n\n`create_ap {{wlan0}} {{eth0}} {{access_point_ssid}} {{passphrase}}`\n\n- Create an access point without Internet sharing:\n\n`create_ap -n {{wlan0}} {{acces_point_ssid}} {{passphrase}}`\n\n- Create a bridged network with Internet sharing:\n\n`create_ap -m bridge {{wlan0}} {{eth0}} {{access_point_ssid}} {{passphrase}}`\n\n- Create a bridged network with Internet sharing and a pre-configured bridge interface:\n\n`create_ap -m bridge {{wlan0}} {{br0}} {{access_point_ssid}} {{passphrase}}`\n\n- Create an access port for Internet sharing from the same WiFi interface:\n\n`create_ap {{wlan0}} {{wlan0}} {{access_point_ssid}} {{passphrase}}`\n\n- Choose a different WiFi adapter driver:\n\n`create_ap --driver {{wifi_adapter}} {{wlan0}} {{eth0}} {{access_point_ssid}} {{passphrase}}`\n"
 },
 {
   "command": "vgs",
   "doc_url": "https://man7.org/linux/man-pages/man8/vgs.8.html",
   "doc_text": "\n\n\n\n\nvgs(8) - Linux manual page\n\n\n\n\n\n\n\n\n\nman7.org > Linux > man-pages\n\n\n\nLinux/UNIX system programming training\n\n\n\n\n\n\nvgs(8) — Linux manual page\n\n\n\n\nNAME | SYNOPSIS | DESCRIPTION | USAGE | OPTIONS | VARIABLES | ENVIRONMENT VARIABLES | NOTES | SEE ALSO | COLOPHON\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nVGS(8)                     System Manager's Manual                    VGS(8)\n\nNAME          top\n       vgs - Display information about volume groups\n\nSYNOPSIS          top\n       vgs\n           [ option_args ]\n           [ position_args ]\n\nDESCRIPTION          top\n       vgs produces formatted output about VGs.\n\nUSAGE          top\n       vgs\n           [ -a|--all ]\n           [ -o|--options String ]\n           [ -S|--select String ]\n           [ -O|--sort String ]\n           [    --aligned ]\n           [    --binary ]\n           [    --configreport log|vg|lv|pv|pvseg|seg ]\n           [    --foreign ]\n           [    --ignorelockingfailure ]\n           [    --logonly ]\n           [    --nameprefixes ]\n           [    --noheadings ]\n           [    --nosuffix ]\n           [    --readonly ]\n           [    --reportformat basic|json ]\n           [    --rows ]\n           [    --separator String ]\n           [    --shared ]\n           [    --unbuffered ]\n           [    --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E ]\n           [    --unquoted ]\n           [ COMMON_OPTIONS ]\n           [ VG|Tag ... ]\n\n       Common options for lvm:\n           [ -d|--debug ]\n           [ -h|--help ]\n           [ -q|--quiet ]\n           [ -t|--test ]\n           [ -v|--verbose ]\n           [ -y|--yes ]\n           [    --commandprofile String ]\n           [    --config String ]\n           [    --driverloaded y|n ]\n           [    --lockopt String ]\n           [    --longhelp ]\n           [    --nolocking ]\n           [    --profile String ]\n           [    --version ]\n\nOPTIONS          top\n       --aligned\n              Use with --separator to align the output columns\n\n       -a|--all\n              List all VGs. Equivalent to not specifying any VGs.\n\n       --binary\n              Use binary values \"0\" or \"1\" instead of descriptive literal\n              values for columns that have exactly two valid values to\n              report (not counting the \"unknown\" value which denotes that\n              the value could not be determined).\n\n       --commandprofile String\n              The command profile to use for command configuration.  See\n              lvm.conf(5) for more information about profiles.\n\n       --config String\n              Config settings for the command. These override lvm.conf\n              settings.  The String arg uses the same format as lvm.conf, or\n              may use section/field syntax.  See lvm.conf(5) for more\n              information about config.\n\n       --configreport log|vg|lv|pv|pvseg|seg\n              See lvmreport(7).\n\n       -d|--debug ...\n              Set debug level. Repeat from 1 to 6 times to increase the\n              detail of messages sent to the log file and/or syslog (if\n              configured).\n\n       --driverloaded y|n\n              If set to no, the command will not attempt to use device-\n              mapper.  For testing and debugging.\n\n       --foreign\n              Report/display foreign VGs that would otherwise be skipped.\n              See lvmsystemid(7) for more information about foreign VGs.\n\n       -h|--help\n              Display help text.\n\n       --ignorelockingfailure\n              Allows a command to continue with read-only metadata\n              operations after locking failures.\n\n       --lockopt String\n              Used to pass options for special cases to lvmlockd.  See\n              lvmlockd(8) for more information.\n\n       --logonly\n              Suppress command report and display only log report.\n\n       --longhelp\n              Display long help text.\n\n       --nameprefixes\n              Add an \"LVM2_\" prefix plus the field name to the output.\n              Useful with --noheadings to produce a list of field=value\n              pairs that can be used to set environment variables (for\n              example, in udev rules).\n\n       --noheadings\n              Suppress the headings line that is normally the first line of\n              output.  Useful if grepping the output.\n\n       --nolocking\n              Disable locking.\n\n       --nosuffix\n              Suppress the suffix on output sizes. Use with --units (except\n              h and H) if processing the output.\n\n       -o|--options String\n              Comma-separated, ordered list of fields to display in columns.\n              String arg syntax is: [+|-|#]Field1[,Field2 ...]  The prefix +\n              will append the specified fields to the default fields, - will\n              remove the specified fields from the default fields, and #\n              will compact specified fields (removing them when empty for\n              all rows.)  Use -o help to view the list of all available\n              fields.  Use separate lists of fields to add, remove or\n              compact by repeating the -o option: -o+field1,field2 -o-\n              field3,field4 -o#field5.  These lists are evaluated from left\n              to right.  Use field name lv_all to view all LV fields, vg_all\n              all VG fields, pv_all all PV fields, pvseg_all all PV segment\n              fields, seg_all all LV segment fields, and pvseg_all all PV\n              segment columns.  See the lvm.conf report section for more\n              config options.  See lvmreport(7) for more information about\n              reporting.\n\n       --profile String\n              An alias for --commandprofile or --metadataprofile, depending\n              on the command.\n\n       -q|--quiet ...\n              Suppress output and log messages. Overrides --debug and\n              --verbose.  Repeat once to also suppress any prompts with\n              answer 'no'.\n\n       --readonly\n              Run the command in a special read-only mode which will read\n              on-disk metadata without needing to take any locks. This can\n              be used to peek inside metadata used by a virtual machine\n              image while the virtual machine is running. No attempt will be\n              made to communicate with the device-mapper kernel driver, so\n              this option is unable to report whether or not LVs are\n              actually in use.\n\n       --reportformat basic|json\n              Overrides current output format for reports which is defined\n              globally by the report/output_format setting in lvm.conf.\n              basic is the original format with columns and rows.  If there\n              is more than one report per command, each report is prefixed\n              with the report name for identification. json produces report\n              output in JSON format. See lvmreport(7) for more information.\n\n       --rows\n              Output columns as rows.\n\n       -S|--select String\n              Select objects for processing and reporting based on specified\n              criteria.  The criteria syntax is described by --select help\n              and lvmreport(7).  For reporting commands, one row is\n              displayed for each object matching the criteria.  See\n              --options help for selectable object fields.  Rows can be\n              displayed with an additional \"selected\" field (-o selected)\n              showing 1 if the row matches the selection and 0 otherwise.\n              For non-reporting commands which process LVM entities, the\n              selection is used to choose items to process.\n\n       --separator String\n              String to use to separate each column. Useful if grepping the\n              output.\n\n       --shared\n              Report/display shared VGs that would otherwise be skipped when\n              lvmlockd is not being used on the host.  See lvmlockd(8) for\n              more information about shared VGs.\n\n       -O|--sort String\n              Comma-separated ordered list of columns to sort by. Replaces\n              the default selection. Precede any column with - for a reverse\n              sort on that column.\n\n       -t|--test\n              Run in test mode. Commands will not update metadata.  This is\n              implemented by disabling all metadata writing but nevertheless\n              returning success to the calling function. This may lead to\n              unusual error messages in multi-stage operations if a tool\n              relies on reading back metadata it believes has changed but\n              hasn't.\n\n       --unbuffered\n              Produce output immediately without sorting or aligning the\n              columns properly.\n\n       --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E\n              All sizes are output in these units: human-(r)eadable with '<'\n              rounding indicator, (h)uman-readable, (b)ytes, (s)ectors,\n              (k)ilobytes, (m)egabytes, (g)igabytes, (t)erabytes,\n              (p)etabytes, (e)xabytes.  Capitalise to use multiples of 1000\n              (S.I.) instead of 1024.  Custom units can be specified, e.g.\n              --units 3M.\n\n       --unquoted\n              When used with --nameprefixes, output values in the\n              field=value pairs are not quoted.\n\n       -v|--verbose ...\n              Set verbose level. Repeat from 1 to 4 times to increase the\n              detail of messages sent to stdout and stderr.\n\n       --version\n              Display version information.\n\n       -y|--yes\n              Do not prompt for confirmation interactively but always assume\n              the answer yes. Use with extreme caution.  (For automatic no,\n              see -qq.)\n\nVARIABLES          top\n       VG\n              Volume Group name.  See lvm(8) for valid names.\n\n       Tag\n              Tag name.  See lvm(8) for information about tag names and\n              using tags in place of a VG, LV or PV.\n\n       String\n              See the option description for information about the string\n              content.\n\n       Size[UNIT]\n              Size is an input number that accepts an optional unit.  Input\n              units are always treated as base two values, regardless of\n              capitalization, e.g. 'k' and 'K' both refer to 1024.  The\n              default input unit is specified by letter, followed by |UNIT.\n              UNIT represents other possible input units: bBsSkKmMgGtTpPeE.\n              b|B is bytes, s|S is sectors of 512 bytes, k|K is kilobytes,\n              m|M is megabytes, g|G is gigabytes, t|T is terabytes, p|P is\n              petabytes, e|E is exabytes.  (This should not be confused with\n              the output control --units, where capital letters mean\n              multiple of 1000.)\n\nENVIRONMENT VARIABLES          top\n       See lvm(8) for information about environment variables used by lvm.\n       For example, LVM_VG_NAME can generally be substituted for a required\n       VG parameter.\n\nNOTES          top\n       The vg_attr bits are:\n\n       1  Permissions: (w)riteable, (r)ead-only\n\n       2  Resi(z)eable\n\n       3  E(x)ported\n\n       4  (p)artial: one or more physical volumes belonging to the volume\n          group are missing from the system\n\n       5  Allocation policy: (c)ontiguous, c(l)ing, (n)ormal, (a)nywhere\n\n       6  (c)lustered, (s)hared\n\nSEE ALSO          top\n       lvm(8) lvm.conf(5) lvmconfig(8)\n\n       pvchange(8) pvck(8) pvcreate(8) pvdisplay(8) pvmove(8) pvremove(8)\n       pvresize(8) pvs(8) pvscan(8)\n\n       vgcfgbackup(8) vgcfgrestore(8) vgchange(8) vgck(8) vgcreate(8)\n       vgconvert(8) vgdisplay(8) vgexport(8) vgextend(8) vgimport(8)\n       vgimportclone(8) vgmerge(8) vgmknodes(8) vgreduce(8) vgremove(8)\n       vgrename(8) vgs(8) vgscan(8) vgsplit(8)\n\n       lvcreate(8) lvchange(8) lvconvert(8) lvdisplay(8) lvextend(8)\n       lvreduce(8) lvremove(8) lvrename(8) lvresize(8) lvs(8) lvscan(8)\n\n       lvm-fullreport(8) lvm-lvpoll(8) lvm2-activation-generator(8)\n       blkdeactivate(8) lvmdump(8)\n\n       dmeventd(8) lvmpolld(8) lvmlockd(8) lvmlockctl(8) cmirrord(8)\n       lvmdbusd(8)\n\n       lvmsystemid(7) lvmreport(7) lvmraid(7) lvmthin(7) lvmcache(7)\n\nCOLOPHON          top\n       This page is part of the lvm2 (Logical Volume Manager 2) project.\n       Information about the project can be found at \n       â¨http://www.sourceware.org/lvm2/â©.  If you have a bug report for this\n       manual page, see â¨https://github.com/lvmteam/lvm2/issuesâ©.  This page\n       was obtained from the tarball\n       https://github.com/lvmteam/lvm2/archive/v2_03_10.tar.gz fetched from\n       â¨https://github.com/lvmteam/lvm2/releasesâ© on 2020-08-13.  If you\n       discover any rendering problems in this HTML version of the page, or\n       you believe there is a better or more up-to-date source for the page,\n       or you have corrections or improvements to the information in this\n       COLOPHON (which is not part of the original manual page), send a mail\n       to man-pages@man7.org\n\nRed Hat, Inc.         LVM TOOLS 2.03.10(2) (2020-08-09)               VGS(8)\n\n\nPages that refer to this page: \n    lvmreport(7),  \n    lvmsystemid(7),  \n    fullreport(8),  \n    lvchange(8),  \n    lvconvert(8),  \n    lvcreate(8),  \n    lvdisplay(8),  \n    lvextend(8),  \n    lvm(8),  \n    lvm-config(8),  \n    lvmconfig(8),  \n    lvmdiskscan(8),  \n    lvm-dumpconfig(8),  \n    lvm-fullreport(8),  \n    lvm-lvpoll(8),  \n    lvpoll(8),  \n    lvreduce(8),  \n    lvremove(8),  \n    lvrename(8),  \n    lvresize(8),  \n    lvs(8),  \n    lvscan(8),  \n    pvchange(8),  \n    pvck(8),  \n    pvcreate(8),  \n    pvdisplay(8),  \n    pvmove(8),  \n    pvremove(8),  \n    pvresize(8),  \n    pvs(8),  \n    pvscan(8),  \n    vgcfgbackup(8),  \n    vgcfgrestore(8),  \n    vgchange(8),  \n    vgck(8),  \n    vgconvert(8),  \n    vgcreate(8),  \n    vgdisplay(8),  \n    vgexport(8),  \n    vgextend(8),  \n    vgimport(8),  \n    vgimportclone(8),  \n    vgmerge(8),  \n    vgmknodes(8),  \n    vgreduce(8),  \n    vgremove(8),  \n    vgrename(8),  \n    vgs(8),  \n    vgscan(8),  \n    vgsplit(8)\n\n\n\n\n\n\n\n\n            HTML rendering created 2020-08-13\n            by Michael Kerrisk, \n            author of \n            The Linux Programming Interface, \n            maintainer of the \n            Linux man-pages project.\n        \n\n            For details of in-depth\n            Linux/UNIX system programming training courses\n            that I teach, look here.\n        \n\n            Hosting by jambit GmbH.\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# vgs\n\n> Display information about LVM volume groups.\n> More information: https://man7.org/linux/man-pages/man8/vgs.8.html .\n\n- Display information about volume groups:\n\n`vgs`\n\n- Display all volume groups:\n\n`vgs -a`\n\n- Change default display to show more details:\n\n`vgs -v`\n\n- Display only specific fields:\n\n`vgs -o {{field_name_1}},{{field_name_2}}`\n\n- Append field to default display:\n\n`vgs -o +{{field_name}}`\n\n- Suppress heading line:\n\n`vgs --noheadings`\n\n- Use separator to separate fields:\n\n`vgs --separator =`\n"
 },
 {
   "command": "ifdown",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ifdown\n\n> Disable network interfaces.\n\n- Disable interface eth0:\n\n`ifdown {{eth0}}`\n\n- Disable all interfaces which are enabled:\n\n`ifdown -a`\n"
 },
 {
   "command": "rtorrent",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rtorrent\n\n> Download torrents over the command line.\n\n- Add a torrent file or magnet to be downloaded:\n\n`rtorrent {{torrent_or_magnet}}`\n\n- Start the download:\n\n`<Ctrl>S`\n\n- View details about downloading torrent:\n\n`->`\n\n- Close rtorrent safely:\n\n`<Ctrl>Q`\n"
 },
 {
   "command": "trap",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# trap\n\n> Automatically execute commands after receiving signals by processes or the operating system.\n> Can be used to perform cleanups for interruptions by the user or other actions.\n\n- List available signals to set traps for:\n\n`trap -l`\n\n- List active traps for the current shell:\n\n`trap -p`\n\n- Set a trap to execute commands when one or more signals are detected:\n\n`trap 'echo \"Caught signal {{SIGHUP}}\"' {{SIGHUP}}`\n\n- Remove active traps:\n\n`trap - {{SIGHUP}} {{SIGINT}}`\n"
 },
 {
   "command": "fstrim",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# fstrim\n\n> Discard unused blocks on a mounted filesystem.\n> Only supported by flash memory devices such as SSDs and microSD cards.\n\n- Trim unused blocks on all mounted partitions that support it:\n\n`sudo fstrim --all`\n\n- Trim unused blocks on a specified partition:\n\n`sudo fstrim {{/}}`\n\n- Display statistics after trimming:\n\n`sudo fstrim --verbose {{/}}`\n"
 },
 {
   "command": "ifup",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ifup\n\n> Tool used to enable network interfaces.\n\n- Enable interface eth0:\n\n`ifup {{eth0}}`\n\n- Enable all the interfaces defined with \"auto\" in /etc/network/interfaces:\n\n`ifup -a`\n"
 },
 {
   "command": "speedometer",
   "doc_url": "http://excess.org/speedometer",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# speedometer\n\n> Python script that shows a network traffic graph in the terminal.\n> More information: <http://excess.org/speedometer>.\n\n- Show graph for a specific interface:\n\n`speedometer -r {{eth0}} -t {{eth0}}`\n"
 },
 {
   "command": "phar",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "PHAR(1) \t\t\t User Commands\t\t\t       PHAR(1)\n\n\n\nNAME\n       phar, phar.phar - PHAR (PHP archive) command line tool\n\nSYNOPSIS\n       phar <command> [options] ...\n\n\nDESCRIPTION\n       The PHAR file format provides a way to put entire PHP applications into\n       a single file called a \"phar\" (PHP Archive) for easy  distribution  and\n       installation.\n\n       With the phar command you can create, update or extract PHP archives.\n\n       Commands: add compress delete extract help help-list info list meta-del\n       meta-get meta-set pack sign stub-get stub-set tree version\n\n\nadd command\n       Add entries to a PHAR package.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       ...\t      Any number of input files and directories. If -i\tis  in\n\t\t      use  then  ONLY  files  and  matching  the given regular\n\t\t      expression are being packed. If -x is given  then  files\n\t\t      matching that regular expression are NOT being packed.\n\n       Optional arguments:\n\n       -a alias       Provide an alias name for the phar file.\n\n       -c algo\t      Compression algorithm (see COMPRESSION )\n\n       -i regex       Specifies a regular expression for input files.\n\n       -l level       Number  of  preceding  subdirectories to strip from file\n\t\t      entries\n\n       -x regex       Regular expression for input files to exclude.\n\n\ncompress command\n       Compress or uncompress all files or a selected entry.\n\n       Required arguments:\n\n       -c algo\t      Compression algorithm (see COMPRESSION )\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -e entry       Name of entry to work on\t(must  include\tPHAR  internal\n\t\t      directory name if any).\n\n\ndelete command\n       Delete entry from a PHAR archive\n\n       Required arguments:\n\n       -e entry       Name  of\tentry  to  work on (must include PHAR internal\n\t\t      directory name if any).\n\n       -f file\t      Specifies the phar file to work on.\n\n\nextract command\n       Extract a PHAR package to a directory.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -i regex       Specifies a regular expression for input files.\n\n       -x regex       Regular expression for input files to exclude.\n\n       ...\t      Directory to extract to (defaults to '.').\n\n\n\nhelp command\n       This help or help for a selected command.\n\n       Optional arguments:\n\n       ...\t      Optional command to retrieve help for.\n\n\nhelp-list command\n       Lists available commands.\n\n\ninfo command\n       Get information about a PHAR package.\n\n       By using -k it is possible to return a single value.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -k index       Subscription index to work on.\n\n\nlist command\n       List contents of a PHAR archive.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -i regex       Specifies a regular expression for input files.\n\n       -x regex       Regular expression for input files to exclude.\n\n\n\nmeta-del command\n       Delete meta information of a PHAR entry or a PHAR package.\n\n       If -k is given then the metadata is expected to be  an  array  and  the\n       given index is being deleted.\n\n       If something was deleted the return value is 0 otherwise it is 1.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -e entry       Name  of\tentry  to  work on (must include PHAR internal\n\t\t      directory name if any).\n\n       -k index       Subscription index to work on.\n\n\nmeta-get command\n       Get meta information of a PHAR entry or a PHAR  package\tin  serialized\n       from. If no output file is specified for meta data then stdout is being\n       used.  You can also specify a particular index using -k. In  that  case\n       the  metadata  is  expected  to\tbe an array and the value of the given\n       index is returned using echo rather than using serialize. If that index\n       does not exist or no meta data is present then the return value is 1.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -e entry       Name  of\tentry  to  work on (must include PHAR internal\n\t\t      directory name if any).\n\n       -k index       Subscription index to work on.\n\n\nmeta-set command\n       Set meta data of a PHAR entry or a PHAR package using serialized input.\n       If  no  input file is specified for meta data then stdin is being used.\n       You can also specify a particular index using  -k.  In  that  case  the\n       metadata is expected to be an array and the value of the given index is\n       being set.  If the metadata is not present or empty a new array will be\n       created.   If  the metadata is present and a flat value then the return\n       value is 1. Also using -k the input is been taken directly rather  then\n       being serialized.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       -m meta\t      Meta data to store with entry (serialized php data).\n\n       Optional arguments:\n\n       -e entry       Name  of\tentry  to  work on (must include PHAR internal\n\t\t      directory name if any).\n\n       -k index       Subscription index to work on.\n\n\npack command\n       Pack files into a PHAR archive.\n\n       When using -s <stub>, then the stub file is  being  excluded  from  the\n       list  of input files/dirs.To create an archive that contains PEAR class\n       PHP_Archive then point -p argument to PHP/Archive.php.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       ...\t      Any number of input files and directories. If -i\tis  in\n\t\t      use  then  ONLY  files  and  matching  the given regular\n\t\t      expression are being packed. If -x is given  then  files\n\t\t      matching that regular expression are NOT being packed.\n\n       Optional arguments:\n\n       -a alias       Provide an alias name for the phar file.\n\n       -b bang\t      Hash-bang    line    to\t start\t the   archive\t (e.g.\n\t\t      #!/usr/bin/php).\tThe hash mark itself '#!' and the new-\n\t\t      line character are optional.\n\n       -c algo\t      Compression algorithm (see COMPRESSION )\n\n       -h hash\t      Selects the hash algorithm (see HASH )\n\n       -i regex       Specifies a regular expression for input files.\n\n       -l level       Number  of  preceding  subdirectories to strip from file\n\t\t      entries\n\n       -p loader      Location of  PHP_Archive\tclass  file  (pear  list-files\n\t\t      PHP_Archive).You\tcan  use '0' or '1' to locate it auto-\n\t\t      matically using the mentioned pear command.  When  using\n\t\t      '0'  the\tcommand does not error out when the class file\n\t\t      cannot be located.  This\tswitch\talso  adds  some  code\n\t\t      around  the  stub  so that class PHP_Archive gets regis-\n\t\t      tered  as  phar://  stream  wrapper  if  necessary.  And\n\t\t      finally this switch will add the file phar.inc from this\n\t\t      package and load it to ensure class Phar is present.\n\n       -s stub\t      Select the stub file.\n\n       -x regex       Regular expression for input files to exclude.\n\n       -y key\t      Private key for OpenSSL signing.\n\n\nsign command\n       Set signature hash algorithm.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       -h hash\t      Selects the hash algorithm (see HASH )\n\n       Optional arguments:\n\n       -y key\t      Private key for OpenSSL signing.\n\n\nstub-get command\n       Get the stub of a PHAR file. If no output file  is  specified  as  stub\n       then stdout is being used.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -s stub\t      Select the stub file.\n\n\nstub-set command\n       Set the stub of a PHAR file. If no input file is specified as stub then\n       stdin is being used.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -b bang\t      Hash-bang   line\t to   start    the    archive\t (e.g.\n\t\t      #!/usr/bin/php).\tThe hash mark itself '#!' and the new-\n\t\t      line character are optional.\n\n       -p loader      Location of  PHP_Archive\tclass  file  (pear  list-files\n\t\t      PHP_Archive).You\tcan  use '0' or '1' to locate it auto-\n\t\t      matically using the mentioned pear command.  When  using\n\t\t      '0'  the\tcommand does not error out when the class file\n\t\t      cannot be located.  This\tswitch\talso  adds  some  code\n\t\t      around  the  stub  so that class PHP_Archive gets regis-\n\t\t      tered  as  phar://  stream  wrapper  if  necessary.  And\n\t\t      finally this switch will add the file phar.inc from this\n\t\t      package and load it to ensure class Phar is present.\n\n       -s stub\t      Select the stub file.\n\n\n\ntree command\n       Get a directory tree for a PHAR archive.\n\n       Required arguments:\n\n       -f file\t      Specifies the phar file to work on.\n\n       Optional arguments:\n\n       -i regex       Specifies a regular expression for input files.\n\n       -x regex       Regular expression for input files to exclude.\n\n\nversion command\n       Get information about the PHAR environment and the tool version.\n\n\n\nCOMPRESSION\n       Algorithms:\n\n       0\t      No compression\n\n       none\t      No compression\n\n       auto\t      Automatically select compression algorithm\n\n       gz\t      GZip compression\n\n       gzip\t      GZip compression\n\n       bz2\t      BZip2 compression\n\n       bzip2\t      BZip2 compression\n\n\nHASH\n       Algorithms:\n\n\n\n\t\t      md5\t     MD5\n\n       sha1\t      SHA1\n\n       sha256\t      SHA256\n\n       sha512\t      SHA512\n\n       openssl\t      OpenSSL\n\n\nSEE ALSO\n       For a more or less complete description of PHAR look here:\n       http://php.net/phar\n\n\nBUGS\n       You can view the list of known bugs or report any  new  bug  you\n       found at:\n       http://bugs.php.net\n\nAUTHORS\n       The PHP Group: Thies C. Arntzen, Stig Bakken, Andi Gutmans, Ras-\n       mus Lerdorf, Sam Ruby, Sascha Schumann, Zeev Suraski,  Jim  Win-\n       stead, Andrei Zmievski.\n\n       Work  for  the  PHP  archive  was done by Gregory Beaver, Marcus\n       Boerger.\n\n       A List of active developers can be found here:\n       http://www.php.net/credits.php\n\n       And last but not least PHP was developed with the help of a huge\n       amount of contributors all around the world.\n\nVERSION INFORMATION\n       This manpage describes phar, version 7.1.33.\n\nCOPYRIGHT\n       Copyright (C) 1997-2018 The PHP Group\n\n       This  source file is subject to version 3.01 of the PHP license,\n       that is bundled with this package in the file  LICENSE,\tand  is\n       available through the world-wide-web at the following url:\n       http://www.php.net/license/3_01.txt\n\n       If  you did not receive a copy of the PHP license and are unable\n       to obtain it through the world-wide-web, please send a  note  to\n       license@php.net so we can mail you a copy immediately.\n\n\n\nThe PHP Group\t\t\t     2018\t\t\t       PHAR(1)\n",
   "tldr_summary": "# phar\n\n> Create, update or extract PHP archives (PHAR).\n\n- Add space-separated files or directories to a Phar file:\n\n`phar add -f {{path/to/phar_file}} {{files_or_directories}}`\n\n- Display the contents of a Phar file:\n\n`phar list -f {{path/to/phar_file}}`\n\n- Delete the specified file or directory from a Phar file:\n\n`phar delete -f {{path/to/phar_file}} -e {{file_or_directory}}`\n\n- Display full usage information and available hashing/compression algorithms:\n\n`phar help`\n\n- Compress or uncompress files and directories in a Phar file:\n\n`phar compress -f {{path/to/phar_file}} -c {{algorithm}}`\n\n- Get information about a Phar file:\n\n`phar info -f {{path/to/phar_file}}`\n\n- Sign a Phar file with a specific hash algorithm:\n\n`phar sign -f {{path/to/phar_file}} -h {{algorithm}}`\n\n- Sign a Phar file with an OpenSSL private key:\n\n`phar sign -f {{path/to/phar_file}} -h openssl -y {{path/to/private_key}}`\n"
 },
 {
   "command": "nmtui",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# nmtui\n\n> Text user interface for controlling NetworkManager.\n> Use arrow keys to navigate, enter to select an option.\n\n- Open the user interface:\n\n`nmtui`\n\n- Show a list of available connections, with the option to activate or deactivate them:\n\n`nmtui connect`\n\n- Connect to a given network:\n\n`nmtui connect {{name|uuid|device|SSID}}`\n\n- Edit/Add/Delete a given network:\n\n`nmtui edit {{name|id}}`\n\n- Set the system hostname:\n\n`nmtui hostname`\n"
 },
 {
   "command": "alpine",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# alpine\n\n> An email client and Usenet newsgroup program with a pico/nano-inspired interface.\n> Supports most modern email services through IMAP.\n\n- Open alpine normally:\n\n`alpine`\n\n- Open alpine directly to the message composition screen to send an email to a given email address:\n\n`alpine {{email@example.net}}`\n\n- Quit alpine:\n\n`'q' then 'y'`\n"
 },
 {
   "command": "file",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nFILE(1) \t\t  BSD General Commands Manual\t\t       FILE(1)\n\nNAME\n     file -- determine file type\n\nSYNOPSIS\n     file [-bcdDhiIkLnNprsvz] [--extension] [--mime-encoding] [--mime-type]\n\t  [-f namefile] [-m magicfiles] [-P name=value] [-M magicfiles] file\n     file -C [-m magicfiles]\n     file [--help]\n\nDESCRIPTION\n     This manual page documents version 5.04 of the file command.\n\n     file tests each argument in an attempt to classify it.  There are three\n     sets of tests, performed in this order: filesystem tests, magic tests,\n     and language tests.  The first test that succeeds causes the file type to\n     be printed.\n\n     The type printed will usually contain one of the words text (the file\n     contains only printing characters and a few common control characters and\n     is probably safe to read on an ASCII terminal), executable (the file con-\n     tains the result of compiling a program in a form understandable to some\n     UNIX kernel or another), or data meaning anything else (data is usually\n     ``binary'' or non-printable).  Exceptions are well-known file formats\n     (core files, tar archives) that are known to contain binary data.\tWhen\n     modifying magic files or the program itself, make sure to preserve these\n     keywords.\tUsers depend on knowing that all the readable files in a\n     directory have the word ``text'' printed.\tDon't do as Berkeley did and\n     change ``shell commands text'' to ``shell script''.\n\n     The filesystem tests are based on examining the return from a stat(2)\n     system call.  The program checks to see if the file is empty, or if it's\n     some sort of special file.  Any known file types appropriate to the sys-\n     tem you are running on (sockets, symbolic links, or named pipes (FIFOs)\n     on those systems that implement them) are intuited if they are defined in\n     the system header file <sys/stat.h>.\n\n     The magic tests are used to check for files with data in particular fixed\n     formats.  The canonical example of this is a binary executable (compiled\n     program) a.out file, whose format is defined in <elf.h>, <a.out.h> and\n     possibly <exec.h> in the standard include directory.  These files have a\n     ``magic number'' stored in a particular place near the beginning of the\n     file that tells the UNIX operating system that the file is a binary exe-\n     cutable, and which of several types thereof.  The concept of a ``magic''\n     has been applied by extension to data files.  Any file with some invari-\n     ant identifier at a small fixed offset into the file can usually be\n     described in this way.  The information identifying these files is read\n     from the compiled magic file /usr/share/file/magic.mgc, or the files in\n     the directory /usr/share/file/magic if the compiled file does not exist.\n\n     If a file does not match any of the entries in the magic file, it is\n     examined to see if it seems to be a text file.  ASCII, ISO-8859-x, non-\n     ISO 8-bit extended-ASCII character sets (such as those used on Macintosh\n     and IBM PC systems), UTF-8-encoded Unicode, UTF-16-encoded Unicode, and\n     EBCDIC character sets can be distinguished by the different ranges and\n     sequences of bytes that constitute printable text in each set.  If a file\n     passes any of these tests, its character set is reported.\tASCII,\n     ISO-8859-x, UTF-8, and extended-ASCII files are identified as ``text''\n     because they will be mostly readable on nearly any terminal; UTF-16 and\n     EBCDIC are only ``character data'' because, while they contain text, it\n     is text that will require translation before it can be read.  In addi-\n     tion, file will attempt to determine other characteristics of text-type\n     files.  If the lines of a file are terminated by CR, CRLF, or NEL,\n     instead of the Unix-standard LF, this will be reported.  Files that con-\n     tain embedded escape sequences or overstriking will also be identified.\n\n     Once file has determined the character set used in a text-type file, it\n     will attempt to determine in what language the file is written.  The lan-\n     guage tests look for particular strings (cf.  <names.h>) that can appear\n     anywhere in the first few blocks of a file.  For example, the keyword .br\n     indicates that the file is most likely a troff(1) input file, just as the\n     keyword struct indicates a C program.  These tests are less reliable than\n     the previous two groups, so they are performed last.  The language test\n     routines also test for some miscellany (such as tar(1) archives).\n\n     Any file that cannot be identified as having been written in any of the\n     character sets listed above is simply said to be ``data''.\n\nOPTIONS\n     --apple\n\t     Causes the file command to output the file type and creator code\n\t     as used by older MacOS versions. The code consists of eight let-\n\t     ters, the first describing the file type, the latter the creator.\n\n     -b, --brief\n\t     Do not prepend filenames to output lines (brief mode).\n\n     -C, --compile\n\t     Write a magic.mgc output file that contains a pre-parsed version\n\t     of the magic file or directory.\n\n     -c, --checking-printout\n\t     Cause a checking printout of the parsed form of the magic file.\n\t     This is usually used in conjunction with the -m flag to debug a\n\t     new magic file before installing it.\n\n     -C, --compile\n\t     Write a magic.mgc output file that contains a pre-parsed version\n\t     of the magic file or directory.\n\n     -d      Apply the default system tests; this is the default behavior\n\t     unless -M is specified.\n\n     -D      Print debugging messages.\n\n     -E      On filesystem errors (file not found etc), instead of handling\n\t     the error as regular output as POSIX mandates and keep going,\n\t     issue an error message and exit.\n\n     -e, --exclude testname\n\t     Exclude the test named in testname from the list of tests made to\n\t     determine the file type.  Valid test names are:\n\n\t     apptype   EMX application type (only on EMX).\n\n\t     ascii     Various types of text files (this test will try to\n\t\t       guess the text encoding, irrespective of the setting of\n\t\t       the `encoding' option).\n\n\t     encoding  Different text encodings for soft magic tests.\n\n\t     tokens    Ignored for backwards compatibility.\n\n\t     cdf       Prints details of Compound Document Files.\n\n\t     compress  Checks for, and looks inside, compressed files.\n\n\t     elf       Prints ELF file details, provided soft magic tests are\n\t\t       enabled and the elf magic is found.\n\n\t     soft      Consults magic files.\n\n\t     tar       Examines tar files.\n\n     --extension\n\t     Print a slash-separated list of valid extensions for the file\n\t     type found.\n\n     -F, --separator separator\n\t     Use the specified string as the separator between the filename\n\t     and the file result returned.  Defaults to `:'.\n\n     -f, --files-from namefile\n\t     Read the names of the files to be examined from namefile (one per\n\t     line) before the argument list.  Either namefile or at least one\n\t     filename argument must be present; to test the standard input,\n\t     use `-' as a filename argument.  Please note that namefile is\n\t     unwrapped and the enclosed filenames are processed when this\n\t     option is encountered and before any further options processing\n\t     is done.  This allows one to process multiple lists of files with\n\t     different command line arguments on the same file invocation.\n\t     Thus if you want to set the delimiter, you need to do it before\n\t     you specify the list of files, like: ``-F @ -f namefile'',\n\t     instead of: ``-f namefile -F @''.\n\n     -h, --no-dereference\n\t     option causes symlinks not to be followed (on systems that sup-\n\t     port symbolic links).\n\n     -i      If the file is a regular file, do not classify its contents.\n\n     -I, --mime\n\t     Causes the file command to output mime type strings rather than\n\t     the more traditional human readable ones.\tThus it may say\n\t     `text/plain; charset=us-ascii' rather than ``ASCII text''.\n\n     --mime-type, --mime-encoding\n\t     Like -I, but print only the specified element(s).\n\n     -k, --keep-going\n\t     Don't stop at the first match, keep going.  Subsequent matches\n\t     will be have the string `\\012- ' prepended.  (If you want a new-\n\t     line, see the -r option.)\tThe magic pattern with the highest\n\t     strength (see the -l option) comes first.\n\n     -l, --list\n\t     Shows a list of patterns and their strength sorted descending by\n\t     magic(4) strength which is used for the matching (see also the -k\n\t     option).\n\n     -L, --dereference\n\t     option causes symlinks to be followed, as the like-named option\n\t     in ls(1) (on systems that support symbolic links).  This is the\n\t     default behavior.\n\n     -m, --magic-file list\n\t     Specify an alternate list of files and directories containing\n\t     magic.  This can be a single item, or a colon-separated list.  If\n\t     a compiled magic file is found alongside a file or directory, it\n\t     will be used instead.\n\n     -M list\n\t     Like -m, except that the default rules are not applied unless -d\n\t     is specified.\n\n     -n, --no-buffer\n\t     Force stdout to be flushed after checking each file.  This is\n\t     only useful if checking a list of files.  It is intended to be\n\t     used by programs that want filetype output from a pipe.\n\n     -p, --preserve-date\n\t     On systems that support utime(3) or utimes(2), attempt to pre-\n\t     serve the access time of files analyzed, to pretend that file\n\t     never read them.\n\n     -P, --parameter name=value\n\t     Set various parameter limits.\n\n\t\t   Name \tDefault    Explanation\n\t\t   indir\t15\t   recursion limit for indirect magic\n\t\t   name \t30\t   use count limit for name/use magic\n\t\t   elf_notes\t256\t   max ELF notes processed\n\t\t   elf_phnum\t128\t   max ELF program sections processed\n\t\t   elf_shnum\t32768\t   max ELF sections processed\n\t\t   regex\t8192\t   length limit for regex searches\n\n     -r, --raw\n\t     No operation, included for historical compatibility.\n\n     -s, --special-files\n\t     Normally, file only attempts to read and determine the type of\n\t     argument files which stat(2) reports are ordinary files.  This\n\t     prevents problems, because reading special files may have pecu-\n\t     liar consequences.  Specifying the -s option causes file to also\n\t     read argument files which are block or character special files.\n\t     This is useful for determining the filesystem types of the data\n\t     in raw disk partitions, which are block special files.  This\n\t     option also causes file to disregard the file size as reported by\n\t     stat(2) since on some systems it reports a zero size for raw disk\n\t     partitions.\n\n     -v, --version\n\t     Print the version of the program and exit.\n\n     -z, --uncompress\n\t     Try to look inside compressed files.\n\n     -Z, --uncompress-noreport\n\t     Try to look inside compressed files, but report information about\n\t     the contents only not the compression.\n\n     -0, --print0\n\t     Output a null character `\\0' after the end of the filename.  Nice\n\t     to cut(1) the output.  This does not affect the separator, which\n\t     is still printed.\n\n     --help  Print a help message and exit.\n\nFILES\n     /usr/share/file/magic.mgc\tDefault compiled list of magic.\n     /usr/share/file/magic\tDirectory containing default magic files.\n\nENVIRONMENT\n     The environment variable MAGIC can be used to set the default magic file\n     name.  file adds ``.mgc'' to the value of this variable as appropriate.\n     However, file has to exist in order for file.mime to be considered.\n\nLEGACY DESCRIPTION\n     In legacy mode, the -D, -I, and -M options do not exist.\n\n     The -d, -i, and -r options behave differently.  The -d option provides\n     debugging information (same as -D in conformance mode).  The -i option\n     displays mime type information (same as -I in conformance mode).  The -r\n     option will disable the translation of unprintable characters (by\n     default, this translation is already disabled in conformance mode).\n\n     Furthermore, the -h option becomes the default symlink behavior (don't\n     follow symlinks) unless POSIXLY_CORRECT is set.\n\n     For more information about legacy mode, see compat(5).\n\nSEE ALSO\n     hexdump(1), od(1), strings(1), magic(5), otool(1), compat(5)\n\nSTANDARDS CONFORMANCE\n     This program conforms to Version 3 of the Single UNIX Specification\n     (``SUSv3'').  Its behavior is mostly compatible with the System V program\n     of the same name.\tThis version knows more magic, however, so it will\n     produce different (albeit more accurate) output in many cases.\n\n     The one significant difference between this version and System V is that\n     this version treats any white space as a delimiter, so that spaces in\n     pattern strings must be escaped.  For example,\n\n\t   >10\t   string  language impress\t   (imPRESS data)\n\n     in an existing magic file would have to be changed to\n\n\t   >10\t   string  language\\ impress\t   (imPRESS data)\n\n     In addition, in this version, if a pattern string contains a backslash,\n     it must be escaped.  For example\n\n\t   0\t   string\t   \\begindata\t   Andrew Toolkit document\n\n     in an existing magic file would have to be changed to\n\n\t   0\t   string\t   \\\\begindata\t   Andrew Toolkit document\n\n     SunOS releases 3.2 and later from Sun Microsystems include a file command\n     derived from the System V one, but with some extensions.  This version\n     differs from Sun's only in minor ways.  It includes the extension of the\n     `&' operator, used as, for example,\n\n\t   >16\t   long&0x7fffffff >0\t\t   not stripped\n\nMAGIC DIRECTORY\n     The magic file entries have been collected from various sources, mainly\n     USENET, and contributed by various authors.  Christos Zoulas (address\n     below) will collect additional or corrected magic file entries.  A con-\n     solidation of magic file entries will be distributed periodically.\n\n     The order of entries in the magic file is significant.  Depending on what\n     system you are using, the order that they are put together may be incor-\n     rect.  If your old file command uses a magic file, keep the old magic\n     file around for comparison purposes (rename it to\n     /usr/share/file/magic.orig).\n\nEXAMPLES\n\t   $ file file.c file /dev/{wd0a,hda}\n\t   file.c:   C program text\n\t   file:     ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV),\n\t\t     dynamically linked (uses shared libs), stripped\n\t   /dev/wd0a: block special (0/0)\n\t   /dev/hda: block special (3/0)\n\n\t   $ file -s /dev/wd0{b,d}\n\t   /dev/wd0b: data\n\t   /dev/wd0d: x86 boot sector\n\n\t   $ file -s /dev/hda{,1,2,3,4,5,6,7,8,9,10}\n\t   /dev/hda:   x86 boot sector\n\t   /dev/hda1:  Linux/i386 ext2 filesystem\n\t   /dev/hda2:  x86 boot sector\n\t   /dev/hda3:  x86 boot sector, extended partition table\n\t   /dev/hda4:  Linux/i386 ext2 filesystem\n\t   /dev/hda5:  Linux/i386 swap file\n\t   /dev/hda6:  Linux/i386 swap file\n\t   /dev/hda7:  Linux/i386 swap file\n\t   /dev/hda8:  Linux/i386 swap file\n\t   /dev/hda9:  empty\n\t   /dev/hda10: empty\n\n\t   $ file -i file.c file /dev/{wd0a,hda}\n\t   file.c:\ttext/x-c\n\t   file:\tapplication/x-executable\n\t   /dev/hda:\tapplication/x-not-regular-file\n\t   /dev/wd0a:\tapplication/x-not-regular-file\n\n\nHISTORY\n     There has been a file command in every UNIX since at least Research\n     Version 4 (man page dated November, 1973).  The System V version intro-\n     duced one significant major change: the external list of magic types.\n     This slowed the program down slightly but made it a lot more flexible.\n\n     This program, based on the System V version, was written by Ian Darwin\n     <ian@darwinsys.com> without looking at anybody else's source code.\n\n     John Gilmore revised the code extensively, making it better than the\n     first version.  Geoff Collyer found several inadequacies and provided\n     some magic file entries.  Contributions of the `&' operator by Rob McMa-\n     hon, <cudcv@warwick.ac.uk>, 1989.\n\n     Guy Harris, <guy@netapp.com>, made many changes from 1993 to the present.\n\n     Primary development and maintenance from 1990 to the present by Christos\n     Zoulas <christos@astron.com>.\n\n     Altered by Chris Lowth <chris@lowth.com>, 2000: handle the -I option to\n     output mime type strings, using an alternative magic file and internal\n     logic.\n\n     Altered by Eric Fischer <enf@pobox.com>, July, 2000, to identify charac-\n     ter codes and attempt to identify the languages of non-ASCII files.\n\n     Altered by Reuben Thomas <rrt@sc3d.org>, 2007-2011, to improve MIME sup-\n     port, merge MIME and non-MIME magic, support directories as well as files\n     of magic, apply many bug fixes, update and fix a lot of magic, improve\n     the build system, improve the documentation, and rewrite the Python bind-\n     ings in pure Python.\n\n     The list of contributors to the `magic' directory (magic files) is too\n     long to include here.  You know who you are; thank you.  Many contribu-\n     tors are listed in the source files.\n\nLEGAL NOTICE\n     Copyright (c) Ian F. Darwin, Toronto, Canada, 1986-1999.  Covered by the\n     standard Berkeley Software Distribution copyright; see the file COPYING\n     in the source distribution.\n\n     The files tar.h and is_tar.c were written by John Gilmore from his pub-\n     lic-domain tar(1) program, and are not covered by the above license.\n\nRETURN CODE\n     file returns 0 on success, and non-zero on error.\n\nBUGS\n     Please report bugs and send patches to the bug tracker at\n     http://bugs.gw.com/ or the mailing list at <file@mx.gw.com> (visit\n     http://mx.gw.com/mailman/listinfo/file first to subscribe).\n\nTODO\n     Fix output so that tests for MIME and APPLE flags are not needed all over\n     the place, and actual output is only done in one place.  This needs a\n     design.  Suggestion: push possible outputs on to a list, then pick the\n     last-pushed (most specific, one hopes) value at the end, or use a default\n     if the list is empty.  This should not slow down evaluation.\n\n     The handling of MAGIC_CONTINUE and printing \\012- between entries is\n     clumsy and complicated; refactor and centralize.\n\n     Some of the encoding logic is hard-coded in encoding.c and can be moved\n     to the magic files if we had a !:charset annotation\n\n     Continue to squash all magic bugs.  See Debian BTS for a good source.\n\n     Store arbitrarily long strings, for example for %s patterns, so that they\n     can be printed out.  Fixes Debian bug #271672.  This can be done by allo-\n     cating strings in a string pool, storing the string pool at the end of\n     the magic file and converting all the string pointers to relative offsets\n     from the string pool.\n\n     Add syntax for relative offsets after current level (Debian bug #466037).\n\n     Make file -ki work, i.e. give multiple MIME types.\n\n     Add a zip library so we can peek inside Office2007 documents to print\n     more details about their contents.\n\n     Add an option to print URLs for the sources of the file descriptions.\n\n     Combine script searches and add a way to map executable names to MIME\n     types (e.g. have a magic value for !:mime which causes the resulting\n     string to be looked up in a table).  This would avoid adding the same\n     magic repeatedly for each new hash-bang interpreter.\n\n     When a file descriptor is available, we can skip and adjust the buffer\n     instead of the hacky buffer management we do now.\n\n     Fix ``name'' and ``use'' to check for consistency at compile time (dupli-\n     cate ``name'', ``use'' pointing to undefined ``name'' ).  Make ``name'' /\n     ``use'' more efficient by keeping a sorted list of names.\tSpecial-case ^\n     to flip endianness in the parser so that it does not have to be escaped,\n     and document it.\n\n     If the offsets specified internally in the file exceed the buffer size (\n     HOWMANY variable in file.h), then we don't seek to that offset, but we\n     give up.  It would be better if buffer managements was done when the file\n     descriptor is available so move around the file.  One must be careful\n     though because this has performance (and thus security considerations).\n\nAVAILABILITY\n     You can obtain the original author's latest version by anonymous FTP on\n     ftp.astron.com in the directory /pub/file/file-X.YZ.tar.gz.\n\nBSD\t\t\t       October 19, 2016 \t\t\t   BSD\n",
   "tldr_summary": "# file\n\n> Determine file type.\n\n- Give a description of the type of the specified file. Works fine for files with no file extension:\n\n`file {{filename}}`\n\n- Look inside a zipped file and determine the file type(s) inside:\n\n`file -z {{foo.zip}}`\n\n- Allow file to work with special or device files:\n\n`file -s {{filename}}`\n\n- Don't stop at first file type match; keep going until the end of the file:\n\n`file -k {{filename}}`\n\n- Determine the mime encoding type of a file:\n\n`file -i {{filename}}`\n"
 },
 {
   "command": "mdadm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mdadm\n\n> RAID management utility.\n\n- Create array:\n\n`mdadm --create {{/path/to/raid_device_file}} --level {{raid_level}} --raid-devices {{number_of_disks}} {{/path/to/disk_device_file}}`\n\n- Stop array:\n\n`mdadm -S {{/path/to/raid_device_file}}`\n\n- Mark disk as failed:\n\n`mdadm {{/path/to/raid_device_file}} -f {{/path/to/disk_device_file}}`\n\n- Remove disk:\n\n`mdadm {{/path/to/raid_device_file}} -r {{/path/to/disk_device_file}}`\n\n- Add disk to array:\n\n`mdadm {{/path/to/raid_device_file}} -a {{/path/to/disk_device_file}}`\n\n- Show RAID info:\n\n`mdadm -D {{/path/to/raid_device_file}}`\n"
 },
 {
   "command": "nsenter",
   "doc_url": "https://github.com/jpetazzo/nsenter/",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - jpetazzo/nsenter\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    This repository has been archived by the owner. It is now read-only.\n  \n\n\n\n\n\n\njpetazzo\n\n/\n\nnsenter\n\nArchived\n\n\n\n\n\n\n    Watch\n \n      88\n    \n\n\n\n\n      Star\n\n\n      2.4k\n    \n\n\n\n\n          Fork\n\n\n        259\n      \n\n\n\n\n\n\n\n            Apache-2.0 License\n        \n\n\n\n\n2.4k\n        stars\n \n\n259\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n0\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\njpetazzo\n\nUpdate link + intro\n\n\n\n…\n\n\n\n93c0856\n\nMay 27, 2020\n\n\n\n\n\nUpdate link + intro\n\nThe PaaS under the hood blog post was taken down, so I'm putting\na link to a conference talk about the same topic instead.\n\nAlso clarifying in the intro paragraph that this is not maintained\nanymore.\n\n93c0856\n\n\n\nGit stats\n\n\n\n\n\n82\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\nDockerfile\n\n\n \n\n\n \n\n\n\n\n\n\n\nLICENSE\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\ndocker-enter\n\n\n \n\n\n \n\n\n\n\n\n\n\nimportenv.c\n\n\n \n\n\n \n\n\n\n\n\n\n\ninstaller\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\nLooking to start a shell inside a Docker container?\nStarting from Docker 1.3 you can use Docker exec to enter a Docker container. Example:\ndocker exec -it CONTAINER_NAME /bin/bash\n\nThere are differences between nsenter and docker exec; namely, nsenter doesn't enter the cgroups, and therefore evades resource limitations. The potential benefit of this would be debugging and external audit, but  for remote access, docker exec is the current recommended approach.\nImportant notice: this repository was useful in the early days of Docker, because nsenter was missing from major distributions back then. nsenter was written in early 2013, and included in util-linux release 2.23. If we look at Ubuntu LTS releases, trusty (14.04) shipped util-linux 2.20, and xenial (16.04) shipped 2.27. In other words, if you were using Ubuntu LTS, you had to wait until 2016 to get nsenter through the main, official packages. That being said, all modern distros now ship with nsenter, and this repository is no longer useful, except for historical or curiosity purposes. It is no longer maintained.\nnsenter in a can\nThis is a small Docker recipe to build nsenter easily and install it in your\nsystem.\nWhat is nsenter?\nIt is a small tool allowing to enter into namespaces. Technically,\nit can enter existing namespaces, or spawn a process into a new set of\nnamespaces. \"What are those namespaces you're blabbering about?\"\nWe are talking about container namespaces.\nnsenter can do many useful things, but the main reason why I'm so\nexcited about it is because it lets you enter into a Docker container.\nWhy build nsenter in a container?\nThis is because my preferred distros (Debian and Ubuntu) ship with an\noutdated version of util-linux (the package that should contain nsenter).\nTherefore, if you need nsenter on those distros, you have to juggle with\nAPT repository, or compile from source, or… Ain't nobody got time for that.\nI'm going to make a very bold assumption: if you landed here, it's because\nyou want to enter a Docker container. Therefore, you won't mind if my\nmethod to build nsenter uses Docker itself.\nHow do I install nsenter with this?\nIf you want to install nsenter into /usr/local/bin, just do this:\ndocker run --rm -v /usr/local/bin:/target jpetazzo/nsenter\n\nThe jpetazzo/nsenter container will detect that /target is a\nmountpoint, and it will copy the nsenter binary into it.\nIf you don't trust me, and prefer to extract the nsenter binary,\nrather than allowing my container to potentially wreak havoc into\nyour system's $PATH, you can also do this:\ndocker run --rm jpetazzo/nsenter cat /nsenter > /tmp/nsenter && chmod +x /tmp/nsenter\n\nThen do whatever you want with the binary in /tmp/nsenter.\nHow do I use nsenter?\nFirst, figure out the PID of the container you want to enter:\nPID=$(docker inspect --format {{.State.Pid}} <container_name_or_ID>)\n\nThen enter the container:\nnsenter --target $PID --mount --uts --ipc --net --pid\n\nWhat's that docker-enter thing?\nIt's just a small shell script that wraps up the steps described above into\na tiny helper. It takes the name or ID of a container and optionally the name\nof a program to execute inside the namespace. If no command is specified a\nshell will be invoked instead.\n# list the root filesystem\ndocker-enter my_awesome_container ls -la\n\nDocker toolbox usage for OS X or Windows user\nSSH to the Docker Toolbox virtual machine\ndocker-machine ssh default\n\nInstall nsenter, docker-enter, and importenv into the VM\ndocker run --rm -v /usr/local/bin:/target jpetazzo/nsenter\n\nYou can also install nsenter to another folder. In that case, you will\nneed to specify the full path of nsenter to run it.\ndocker run --rm -v /tmp:/target jpetazzo/nsenter\n\nUsing nsenter\nList running containers:\ndocker ps\n\nIdentify the ID of the container that you want to get into; and retrieve\nits associated PID:\nPID=$(docker inspect --format {{.State.Pid}} 08a2a025e05f)\n\nEnter the container:\nsudo nsenter --target $PID --mount --uts --ipc --net --pid\n\nRemember to run those commands in the Docker Toolbox virtual machine; not\nin your host environment.\nUsing docker-enter\nWith docker-enter, you don't need to lookup the container PID.\nYou can get a shell inside the container:\ndocker-enter 08a2a025e05f\n\nOr run commands directly:\ndocker-enter 08a2a025e05f ls /var/log\ndocker-enter 08a2a025e05f df -h\n\ndocker-enter with boot2docker\nIf you are using boot2docker, you can use the function below, to:\n\ninstall nsenter and docker-enter into boot2docker's /var/lib/boot2docker/ directory,\nso they survive restarts.\nexecute docker-enter inside of boot2docker combined with ssh\n\ndocker-enter() {\n  boot2docker ssh '[ -f /var/lib/boot2docker/nsenter ] || docker run --rm -v /var/lib/boot2docker/:/target jpetazzo/nsenter'\n  boot2docker ssh -t sudo /var/lib/boot2docker/docker-enter \"$@\"\n}\n\nYou can use it directly from your host (OS X/Windows), no need to ssh into boot2docker.\nCaveats\n\nThis only works on Intel 64 bits platforms. It should be relatively\neasy to adapt to other architectures, though.\nnsenter still needs to run from the host; it cannot run inside a\ncontainer (yet).\n\n\n\n\n\n\n\n\n\nAbout\n\n      No description, website, or topics provided.\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        Apache-2.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\nNo releases published\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 25\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 14 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\nShell\n51.8%\n\n\n\n\n\nC\n31.1%\n\n\n\n\n\nDockerfile\n17.1%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# nsenter\n\n> Run a new command in a running process' namespace.\n> Particularly useful for docker images or chroot jails.\n> More information: <https://github.com/jpetazzo/nsenter/>.\n\n- Run command in existing processes network namespace:\n\n`nsenter -t {{pid}} -n {{command}} {{command_arguments}}`\n\n- Run a new command in an existing processes ps-table namespace:\n\n`nsenter -t {{pid}} -p {{command}} {{command_arguments}}`\n\n- Run command in existing processes IPC namespace:\n\n`nsenter -t {{pid}} -i {{command}} {{command_arguments}}`\n"
 },
 {
   "command": "ndctl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ndctl\n\n> Utility for managing Non-Volatile DIMMs.\n\n- Create an 'fsdax' mode namespace:\n\n`ndctl create-namespace --mode={{fsdax}}`\n\n- Change the mode of a namespace to 'raw':\n\n`ndctl create-namespace --reconfigure={{namespaceX.Y}} --mode={{raw}}`\n\n- Check a sector mode namespace for consistency, and repair if needed:\n\n`ndctl check-namespace --repair {{namespaceX.Y}}`\n\n- List all namespaces, regions, and buses (including disabled ones):\n\n`ndctl list --namespaces --regions --buses --idle`\n\n- List a specific namespace and include lots of additional information:\n\n`ndctl list -vvv --namespace={{namespaceX.Y}}`\n\n- Run a monitor to watch for SMART health events for NVDIMMs on the 'ACPI.NFIT' bus:\n\n`ndctl monitor --bus={{ACPI.NFIT}}`\n\n- Remove a namespace (when applicable) or reset it to an initial state:\n\n`ndctl destroy-namespace --force {{namespaceX.Y}}`\n"
 },
 {
   "command": "dpkg-query",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dpkg-query\n\n> A tool that shows information about installed packages.\n\n- List all installed packages:\n\n`dpkg-query -l`\n\n- List installed packages matching a pattern:\n\n`dpkg-query -l '{{pattern}}'`\n\n- List all files installed by a package:\n\n`dpkg-query -L {{package_name}}`\n\n- Show information about a package:\n\n`dpkg-query -s {{package_name}}`\n"
 },
 {
   "command": "xsetwacom",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xsetwacom\n\n> Command line tool to change settings for Wacom pen tablets at runtime.\n\n- List all the available wacom devices. The device name is in the first column:\n\n`xsetwacom list`\n\n- Set Wacom area to specific screen. Get name of the screen with `xrandr`:\n\n`xsetwacom set \"{{device_name}}\" MapToOutput {{screen}}`\n\n- Set mode to relative (like a mouse) or absolute (like a pen) mode:\n\n`xsetwacom set \"{{device_name}}\" Mode \"{{Relative|Absolute}}\"`\n\n- Rotate the input (useful for tablet-PC when rotating screen) by 0|90|180|270 degrees from \"natural\" rotation:\n\n`xsetwacom set \"{{device_name}}\" Rotate {{none|half|cw|ccw}}`\n\n- Set button to only work when the tip of the pen is touching the tablet:\n\n`xsetwacom set \"{{device_name}}\" TabletPCButton \"on\"`\n"
 },
 {
   "command": "setfacl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# setfacl\n\n> Set file access control lists (ACL).\n\n- Modify ACL of a file for user with read and write access:\n\n`setfacl -m u:{{username}}:rw {{file}}`\n\n- Modify default ACL of a file for all users:\n\n`setfacl -d -m u::rw {{file}}`\n\n- Remove ACL of a file for an user:\n\n`setfacl -x u:{{username}} {{file}}`\n\n- Remove all ACL entries of a file:\n\n`setfacl -b {{file}}`\n"
 },
 {
   "command": "sshuttle",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# sshuttle\n\n> Transparent proxy server that tunnels traffic over an SSH connection.\n> Doesn't require root or any special setup on the remote SSH server, though root access on the local machine is prompted for.\n\n- Forward all IPv4 TCP traffic via a remote SSH server:\n\n`sshuttle --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}`\n\n- Also forward all DNS traffic to the server's default DNS resolver:\n\n`sshuttle --dns --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}`\n\n- Forward all traffic except that which is bound for a specific subnet:\n\n`sshuttle --remote={{username}}@{{sshserver}} {{0.0.0.0/0}} --exclude {{192.168.0.1/24}}`\n\n- Use the tproxy method to forward all IPv4 and IPv6 traffic:\n\n`sshuttle --method=tproxy --remote={{username}}@{{sshserver}} {{0.0.0.0/0}} {{::/0}} --exclude={{your_local_ip_address}} --exclude={{ssh_server_ip_address}}`\n"
 },
 {
   "command": "eyeD3",
   "doc_url": "https://eyed3.readthedocs.io/en/latest/",
   "doc_text": " \n\n\n\nWelcome to eyeD3 — eyeD3 0.9.4 documentation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n eyeD3\n          \n\n          \n          \n\n                latest\n              \n\n\n\n\n\n\n\n\n\n\nInstallation\n\n\nâeyeD3â Command Line Tool\nPlugins\neyed3 module\nCompliance\nContributing\nAuthors\n\n\nRelease History\n\n\n\n\n\n\n\neyeD3\n\n\n\n\n\nDocs »\nWelcome to eyeD3\n\n Edit on GitHub\n\n\n\n\n\n\n\nWelcome to eyeD3Â¶\n\nStatusÂ¶\n\n\n\n\n\n\n\n\nAboutÂ¶\neyeD3 is a Python tool for working with audio files, specifically MP3 files\ncontaining ID3 metadata (i.e. song info).\nIt provides a command-line tool (eyeD3) and a Python library\n(import eyed3) that can be used to write your own applications or\nplugins that are callable from the command-line tool.\nFor example, to set some song information in an mp3 file called\nsong.mp3:\n$ eyeD3 -a Integrity -A \"Humanity Is The Devil\" -t \"Hollow\" -n 2 song.mp3\n\n\nWith this command weâve set the artist (-a/--artist), album\n(-A/--album), title (-t/--title), and track number\n(-n/--track-num) properties in the ID3 tag of the file. This is the\nstandard interface that eyeD3 has always had in the past, therefore it\nis also the default plugin when no other is specified.\nThe results of this command can be seen by running the eyeD3 with no\noptions.\n$ eyeD3 song.mp3\nsong.mp3      [ 3.06 MB ]\n-------------------------------------------------------------------------\nID3 v2.4:\ntitle: Hollow\nartist: Integrity\nalbum: Humanity Is The Devil\nalbum artist: None\ntrack: 2\n-------------------------------------------------------------------------\n\n\nThe same can be accomplished using Python.\nimport eyed3\n\naudiofile = eyed3.load(\"song.mp3\")\naudiofile.tag.artist = \"Token Entry\"\naudiofile.tag.album = \"Free For All Comp LP\"\naudiofile.tag.album_artist = \"Various Artists\"\naudiofile.tag.title = \"The Edge\"\naudiofile.tag.track_num = 3\n\naudiofile.tag.save()\n\n\neyeD3 is written and maintained by Travis Shirk and is licensed under\nversion 3 of the GPL.\n\n\nFeaturesÂ¶\n\nPython package (import eyed3) for writing applications and plugins.\neyeD3 : Command-line tool driver script that supports plugins.\nEasy ID3 editing/viewing of audio metadata from the command-line.\nPlugins for: Tag to string formatting (display), album fixing (fixup),\ncover art downloading (art), collection stats (stats),\nand json/yaml/jabber/nfo output formats, and more included.\nSupport for ID3 versions 1.x, 2.2 (read-only), 2.3, and 2.4.\nSupport for the MP3 audio format exposing details such as play time, bit\nrate, sampling frequency, etc.\nAbstract design allowing future support for different audio formats and\nmetadata containers.\n\n\n\nGet StartedÂ¶\nPython >= 3.6 is required.\nFor installation instructions or more complete documentation see\nhttp://eyeD3.nicfit.net/\nPlease post feedback and/or defects on the issue tracker, or mailing list.\n\nInstallationÂ¶\nStable releases of eyeD3 are best installed via pip or easy_install;\nor you may download TGZ or ZIP source archives from a couple of official\nlocations. Detailed instructions and links may be found on the\nInstallation page.\nOtherwise, if you want to live on the edge, you can pull down the source code\nfrom the Git repository at GitHub. The Installation page has\ndetails for how to access the source code.\n\n\n\n\nDocumentationÂ¶\n\n\nâeyeD3â Command Line Tool\nPlugins\nConfiguration Files\nCustom Plugins\n\n\nPlugins\nart(work) plugin\nclassic - Tag Viewer/Editor\ndisplay - Display tag information by pattern\nExtract Plugin\nfixup - Music directory fixer\nitunes-podcast - Convert files so iTunes recognizes them as podcasts\nJSON Plugin\ngenres - ID3 Genre List\nlameinfo (xing) - Lame (Xing) Header Information\nMime-types Plugin\nnfo - (I)NFO File Generator\npymod - Use simple python modules as eyeD3 plugins\nstats - Music Collection Statistics\nxep-118 - Jabber (XMPP) Tune Format\nYAML Plugin\n\n\neyed3 module\neyed3 package\n\n\nCompliance\nID3\n\n\nContributing\nTypes of Contributions\nGet Started!\nPull Request Guidelines\n\n\nAuthors\n\n\n\n\n\n\nChangeLogÂ¶\nChanges made to eyeD3 and the projectâs release history can be found in the\nRelease History.\n\n\nReferencesÂ¶\n\nID3 v1.x Specification\nID3 v2.4 Structure and\nFrames\nID3 v2.3 Specification\nID3 v2.2 Specification\nISO 8601 Date and Time\nISO 639-2 Language Codes\nMusicBrainz Tag Mappings\nMP3 Headers\n\n\n\nIndices and tablesÂ¶\n\nIndex\nModule Index\nSearch Page\n\n\n\n\n\n\n\n\nNext \n\n\n\n\n        © Copyright 2002-2020, Travis Shirk\n      \n        \n          Revision 3eaa919b.\n        \n\n\n  Built with Sphinx using a theme provided by Read the Docs. \n\n\n\n\n\n\n\n\n Read the Docs\n      v: latest\n      \n\n\n\nVersions\nmaster\nlatest\n\n\nDownloads\npdf\nhtml\nepub\n\n\nOn Read the Docs\n\nProject Home\n\n\nBuilds\n\n\n\n      Free document hosting provided by Read the Docs.\n\n    \n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# eyeD3\n\n> Read and manipulate metadata of MP3 files.\n> More information: <https://eyed3.readthedocs.io/en/latest/>.\n\n- View information about an MP3 file:\n\n`eyeD3 {{filename.mp3}}`\n\n- Set the title of an MP3 file:\n\n`eyeD3 --title {{\"A Title\"}} {{filename.mp3}}`\n\n- Set the album of all the MP3 files in a directory:\n\n`eyeD3 --album {{\"Album Name\"}} {{*.mp3}}`\n\n- Set the front cover art for an MP3 file:\n\n`eyeD3 --add-image {{front_cover.jpeg}}:FRONT_COVER: {{filename.mp3}}`\n"
 },
 {
   "command": "perl-rename",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rename\n\n> Rename multiple files.\n> NOTE: this page refers to the command from the `perl-rename` Arch Linux package.\n\n- Rename files using a Perl Common Regular Expression (substitute 'foo' with 'bar' wherever found):\n\n`rename {{'s/foo/bar/'}} {{*}}`\n\n- Dry-run - display which renames would occur without performing them:\n\n`rename -n {{'s/foo/bar/'}} {{*}}`\n\n- Force renaming even if the operation would remove existing destination files:\n\n`rename -f {{'s/foo/bar/'}} {{*}}`\n\n- Convert filenames to lower case (use `-f` in case-insensitive filesystems to prevent \"already exists\" errors):\n\n`rename 'y/A-Z/a-z/' {{*}}`\n\n- Replace whitespace with underscores:\n\n`rename 's/\\s+/_/g' {{*}}`\n"
 },
 {
   "command": "xman",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xman\n\n> Manual page viewer for X Window System.\n\n- Start xman in three-button window:\n\n`xman`\n\n- Open the manual page output stored in a given file:\n\n`xman -helpfile {{filename}}`\n\n- Show both manual page and directory:\n\n`xman -bothshown`\n"
 },
 {
   "command": "nologin",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nNOLOGIN(8)\t\t  BSD System Manager's Manual\t\t    NOLOGIN(8)\n\nNAME\n     nologin -- politely refuse a login\n\nSYNOPSIS\n     nologin\n\nDESCRIPTION\n     The nologin utility displays a message that an account is not available\n     and exits non-zero.  It is intended as a replacement shell field for\n     accounts that have been disabled.\n\n     To disable all logins, investigate nologin(5).\n\nSEE ALSO\n     login(1), nologin(5)\n\nHISTORY\n     The nologin utility appeared in 4.4BSD.\n\nBSD\t\t\t\t June 19, 1993\t\t\t\t   BSD\n",
   "tldr_summary": "# nologin\n\n> Alternative shell that prevents a user from logging in.\n\n- Set a user's login shell to `nologin` to prevent the user from logging in:\n\n`chsh -s {{user}} nologin`\n\n- Customize message for users with the login shell of `nologin`:\n\n`echo \"{{declined_login_message}}\" > /etc/nologin.txt`\n"
 },
 {
   "command": "apt-mark",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apt-mark\n\n> Utility to change the status of installed packages.\n\n- Mark a package as automatically installed:\n\n`sudo apt-mark auto {{package_name}}`\n\n- Hold a package at its current version and prevent updates to it:\n\n`sudo apt-mark hold {{package_name}}`\n\n- Allow a package to be updated again:\n\n`sudo apt-mark unhold {{package_name}}`\n\n- Show manually installed packages:\n\n`apt-mark showmanual`\n\n- Show held packages that aren't being updated:\n\n`apt-mark showhold`\n"
 },
 {
   "command": "vmstat",
   "doc_url": "https://linux.die.net/man/8/vmstat",
   "doc_text": "\n\nvmstat(8): Report virtual memory statistics - Linux man page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvmstat(8) - Linux man page\nName\nvmstat - Report virtual memory statistics\nSynopsis\n\n\n\n\n\nvmstat [-a] [-n] [-t] [-S unit] [delay [ count]]\nvmstat [-s] [-n] [-S unit]\nvmstat [-m] [-n] [delay [ count]]\nvmstat [-d] [-n] [delay [ count]]\nvmstat [-p disk partition] [-n] [delay [ count]]\nvmstat [-f]\nvmstat [-V]\nDescription\nvmstat reports information about processes, memory, paging, block IO, traps, and cpu activity.\nThe first report produced gives averages since the last reboot. Additional reports give information on a sampling period of length delay. The process\nand memory reports are instantaneous in either case.\n\nOptions\n\nThe -a switch displays active/inactive memory, given a 2.5.41 kernel or better.\nThe -f switch displays the number of forks since boot. This includes the fork, vfork, and clone system calls, and is equivalent to the total number\nof tasks created. Each process is represented by one or more tasks, depending on thread usage. This display does not repeat.\nThe -t switch adds timestamp to the output.\nThe -m switch displays slabinfo.\nThe -n switch causes the header to be displayed only once rather than periodically.\nThe -s switch displays a table of various event counters and memory statistics. This display does not repeat.\ndelay is the delay between updates in seconds. If no delay is specified, only one report is printed with the average values since boot.\n\ncount is the number of updates. If no count is specified and delay is defined, count defaults to infinity.\nThe -d reports disk statistics (2.5.70 or above required)\nThe -w enlarges field width for big memory sizes\nThe -p followed by some partition name for detailed statistics (2.5.70 or above required)\nThe -S followed by k or K or m or M switches outputs between 1000, 1024, 1000000, or 1048576 bytes\nThe -V switch results in displaying version information.\n\nField Description For Vm Mode\nProcs\n\n\nr: The number of processes waiting for run time.\nb: The number of processes in uninterruptible sleep.\n\nMemory\n\n\nswpd: the amount of virtual memory used.\nfree: the amount of idle memory.\nbuff: the amount of memory used as buffers.\ncache: the amount of memory used as cache.\ninact: the amount of inactive memory. (-a option)\nactive: the amount of active memory. (-a option)\n\nSwap\n\n\nsi: Amount of memory swapped in from disk (/s).\nso: Amount of memory swapped to disk (/s).\n\nIO\n\n\nbi: Blocks received from a block device (blocks/s).\nbo: Blocks sent to a block device (blocks/s).\n\nSystem\n\n\nin: The number of interrupts per second, including the clock.\ncs: The number of context switches per second.\n\nCPU\n\nThese are percentages of total CPU time.\nus: Time spent running non-kernel code. (user time, including nice time)\nsy: Time spent running kernel code. (system time)\nid: Time spent idle. Prior to Linux 2.5.41, this includes IO-wait time.\nwa: Time spent waiting for IO. Prior to Linux 2.5.41, included in idle.\nst: Time stolen from a virtual machine. Prior to Linux 2.6.11, unknown.\n\nField Description For Disk Mode\nReads\n\n\ntotal: Total reads completed successfully\nmerged: grouped reads (resulting in one I/O)\nsectors: Sectors read successfully\nms: milliseconds spent reading\n\nWrites\n\n\ntotal: Total writes completed successfully\nmerged: grouped writes (resulting in one I/O)\nsectors: Sectors written successfully\nms: milliseconds spent writing\n\nIO\n\n\ncur: I/O in progress\ns: seconds spent for I/O\n\nField Description For Disk Partition Mode\nreads: Total number of reads issued to this partition\nread sectors: Total read sectors for partition\nwrites : Total number of writes issued to this partition\nrequested writes: Total number of write requests made for partition\nField Description For Slab Mode\ncache: Cache name\nnum: Number of currently active objects\ntotal: Total number of available objects\nsize: Size of each object\npages: Number of pages with at least one active object\ntotpages: Total number of allocated pages\npslab: Number of pages per slab\nNotes\nvmstat does not require special permissions.\nThese reports are intended to help identify system bottlenecks. Linux vmstat does not count itself as a running process.\nAll linux blocks are currently 1024 bytes. Old kernels may report blocks as 512 bytes, 2048 bytes, or 4096 bytes.\nSince procps 3.1.9, vmstat lets you choose units (k, K, m, M) default is K (1024 bytes) in the default mode\nvmstat uses slabinfo 1.1 FIXME\nFiles\n/proc/meminfo\n/proc/stat\n/proc/*/stat\nSee Also\niostat(1), sar(1), mpstat(1), ps(1), top(1), free(1)\nBugs\nDoes not tabulate the block io per device or count the number of system calls.\nAuthors\nWritten by Henry Ware <al172@yfn.ysu.edu>.\nFabian FrÃ©dÃ©rick <ffrederick@users.sourceforge.net> (diskstat, slab, partitions...)\n\nReferenced By\ncifsiostat(1),\ncpupower-monitor(1),\npidstat(1),\nslabtop(1),\nsmem(8),\ntcpstat(1),\nvmtouch(8)\n\n\n\n\n\n\n\n\nSite Search\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nlinux docs\nlinux man pages\npage load time\n\n\nToys\nworld sunlight\nmoon phase\ntrace explorer\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# vmstat\n\n> Report information about processes, memory, paging, block IO, traps, disks and CPU activity.\n> More information: <https://linux.die.net/man/8/vmstat>.\n\n- Display virtual memory statistics:\n\n`vmstat`\n\n- Display reports every 2 seconds for 5 times:\n\n`vmstat {{2}} {{5}}`\n"
 },
 {
   "command": "findmnt",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# findmnt\n\n> Find your filesystem.\n\n- List all mounted filesystems:\n\n`findmnt`\n\n- Search for a device:\n\n`findmnt {{/dev/sdb1}}`\n\n- Search for a mountpoint:\n\n`findmnt {{/}}`\n\n- Find filesystems in specific type:\n\n`findmnt -t {{ext4}}`\n\n- Find filesystems with specific label:\n\n`findmnt LABEL={{BigStorage}}`\n"
 },
 {
   "command": "openrc",
   "doc_url": "https://wiki.gentoo.org/wiki/OpenRC",
   "doc_text": "\n\n\nOpenRC - Gentoo Wiki\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\t\tJump to:\t\tcontent\n\n\n\n\n\n\n\n Get Gentoo!\n\n\n gentoo.org sites \n\n\n gentoo.org\n Wiki\n Bugs\n Forums\n Packages\n\n Planet\n Archives\n Gitweb\n CVS sources\n\n Infra Status\n\n\n\n\n\n\n\n\nWiki\n\n\n\n\n\n\n\n\n\nToggle navigation\n\n\n\n\n\n\n\nMain pageRecent changesHelp \nGentoo \nGentoo Projects \n \nDocumentation \nGentoo HandbookGentoo FAQFeatured DocumentsTopicsCore systemHardwareSoftwareDesktopServer & SecurityProject & Community \n \n\n\n Tools \n\nWhat links hereRelated changesSpecial pagesPrintable versionPermanent linkPage informationBrowse properties \n\n\n\n\n\t\t\t\tUser\t\t\t\t\n\n\nCreate accountLog in \n\n\n\n\n\n\n\n\n\n\nToggle navigation\n\n\n\n\n\n\n\nPageDiscussion \n\n\n\n \n\n\n\nView source\nmore \n\nHistory \n\n\n\n\n\n\n\n\n\n\n\n\nOpenRC\n\n\nFrom Gentoo Wiki\n\n\n\n\t\t\t\t\t\t\t\tJump to:\t\t\t\t\t\t\t\tnavigation, \t\t\t\t\t\t\t\tsearch\n\n\nResources\nProject\nWikipedia\nPackage information\nGitHub\nArticle status\nThis article has some todo items:\nBusybox specific init.d files\n\nOpenRC is a dependency-based init system that maintains compatibility with the system provided init program, normally located in /sbin/init. It does not function as a replacement for the /sbin/init file. OpenRC is 100% compatible with Gentoo init scripts, which means a solution can be found to run the dozens of daemons in the main Gentoo repository. OpenRC, however, is not designed to be exclusively used by Gentoo Linux and can be used on other distributions and BSD systems.\n\nContents\n\n1 Features\n\n1.1 OpenRC Busybox integration\n1.2 Replacing init\n\n1.2.1 busybox\n1.2.2 openrc-init\n\n\n1.3 Daemon supervision\n1.4 Busybox specific init.d files\n1.5 Replacing udev with mdev\n1.6 Replacing udev with eudev\n\n\n2 Configuration\n\n2.1 Files\n2.2 Network management\n2.3 Dependency behavior\n2.4 Selecting a specific runlevel at boot\n\n\n3 Usage\n\n3.1 Runlevels\n3.2 Listing\n\n3.2.1 Named runlevels\n3.2.2 Stacked runlevels\n\n\n3.3 Prefix\n3.4 Hotplug\n3.5 Manually recovering crashed services\n3.6 Automatic respawning crashed services\n3.7 CGroups support\n3.8 Chroot support\n\n\n4 systemd compatibility\n\n4.1 logind\n4.2 tmpfiles.d\n\n\n5 See also\n\n\nFeatures\nOpenRC provides a number of features touted as innovative by recent init systems like systemd or upstart (wikipedia), such as:\n\ncgroups support,\nprocess supervision,\nparallel startup of services, and\nhardware initiated initscripts run.\nIt does this without requiring large layout changes to accommodate radically different designs and dependencies.\n\n TipSee the comparison of init systems article for more information on init systems.\nOpenRC Busybox integration\nBusybox can be used to replace most of the userspace utilities needed by OpenRC (init, shell, awk and other POSIX tools), by using a complete Busybox as shell for OpenRC all the calls that normally would cause a fork/exec would be spared, improving the overall speed. This process is not yet streamlined.\nPlease note that there are currently many Busybox applets that are incompatible with OpenRC. See bug #529086 for details.\n\nReplacing init\nIn order to set a specific runlevel from the bootloader the variable softlevel= should be used.\n\nbusybox\nThe SysV-init /etc/inittab file provided by Gentoo is not compatible with the Busybox init.\n\nFILE /etc/inittabExample inittab compatible with Busybox init::sysinit:/sbin/openrc sysinit\n::wait:/sbin/openrc boot\n::wait:/sbin/openrc\nopenrc-init\nOpenRC has its own init system called openrc-init. See OpenRC/openrc-init for details.\n\nDaemon supervision\nOpenRC has its own process supervisor. See OpenRC/supervise-daemon for details. \nAlternatively Skarnet's S6 is also supported by OpenRC. See S6 for details.\n\nBusybox specific init.d files\nTODO: busybox provides a number of applets that could be used to replace third party software like acpid or dhcp/dhcpcd.\n\nReplacing udev with mdev\nSee mdev.\n\nReplacing udev with eudev\nOlder Gentoo installs were using udev as the main virtual/udev provider.  Based on bug #575718 it was changed to eudev. However, the rc service is still /etc/init.d/udev.\n\nConfiguration\nFiles\n/etc/rc.conf\nThe global OpenRC configuration file.\nNetwork management\nOpenRC can be used with one of several network managers or even with none, see Network manager.\n\nDependency behavior\nChanging the default dependencies of init scripts, might be needed to fit more complex setups. See /etc/rc.conf for how to change the default behavior; notice the rc_depend_strict option. In addition, next networking examples show how flexible OpenRC can be.\n\nMultiple network interfaces (example)\nThe SSH service must come up with the internal network, for instance eth0 and never wlan0.\nOverrule the \"net\" dependency from /etc/init.d/sshd, and refine it to depend on \"net.eth0\":\n\nFILE /etc/conf.d/sshdrc_need=\"!net net.eth0\"\n\nMultiple network interfaces in multiple runlevels (example)\nThe SSH service must start with eth0 (not wlan0) in \"default\" runlevel, but in \"office\" runlevel it must start with wlan0 (not eth0).\nKeep the default:\n\nFILE /etc/rc.conf#rc_depend_strict=\"YES\"\n\nMake additional symlinks to sshd with the network interface names:\n\nroot #ln -s sshd /etc/init.d/sshd.eth0\nroot #ln -s sshd /etc/init.d/sshd.wlan0\n\nSettings are read from /etc/conf.d/sshd.eth0 and /etc/conf.d/sshd.wlan0 now:\n\nroot #cp /etc/conf.d/sshd /etc/conf.d/sshd.eth0\nroot #cp /etc/conf.d/sshd /etc/conf.d/sshd.wlan0\n\nAdd the dependencies:\n\nroot #echo 'rc_need=\"!net net.eth0\"' >> /etc/conf.d/sshd.eth0\nroot #echo 'rc_need=\"!net net.wlan0\"' >> /etc/conf.d/sshd.wlan0\n\nIn this example net.eth0 and net.wlan0 read their settings from /etc/conf.d/net, or /etc/conf.d/net.office depending on the active runlevel. Add all runscripts to the different runlevels:\n\nroot #rc-update add sshd.eth0 default\nroot #rc-update add sshd.wlan0 office\nroot #rc-update add net.eth0 default office\nroot #rc-update add net.wlan0 default office\n\nTo switch between \"default\" runlevel and \"office\" runlevel without rebooting the computer, change to \"nonetwork\" runlevel in between. The network interfaces will be stopped this way, and re-read their runlevel specific configuration. This works best when \"nonetwork\" is a stacked runlevel in both the \"default\" and \"office\" runlevels, and the display manager and other non-network services are added to the \"nonetwork\" runlevel only.\n\ndefault runlevel <---> nonetwork runlevel <---> office runlevel\nroot #rc nonetwork && rc office\nroot #rc nonetwork && rc default\n\nSelecting a specific runlevel at boot\nOpenRC reads the kernel command-line used at boot time, and will start the runlevel specified by the \"softlevel\" parameter if provided, instead of 'default'.\nFor instance, you can choose whether to boot into the 'default' or 'nonetwork' runlevels with the following example grub.conf configuration:\n\nFILE /boot/grub/grub.confExample grub.conf (GRUB Legacy)title=Regular Start-up\n\nkernel (hd0,0)/boot/kernel-3.7.10-gentoo-r1 root=/dev/sda3\n\ntitle=Start without Networking\n\nkernel (hd0,0)/boot/kernel-3.7.10-gentoo-r1 root=/dev/sda3 softlevel=nonetwork\nUsage\nRunlevels\nOpenRC can be controlled and configured using openrc, rc-update and rc-status commands.\nDelete a service from default runlevel, where <service> is the name of the service to be removed:\n\nroot #rc-update delete <service> default\nListing\nListing commands do not need to be ran as root.\nUse rc-update show -v to display all available init scripts and their current runlevel (if they have been added to one):\n\nuser $rc-update show -v\nRunning rc-update or rc-update show will display only the init scripts that have been added to a runlevel.\nAlternatively, the rc-status command can be used with the --servicelist (-s) option to view the state of all services:\n\nuser $rc-status --servicelist\nNamed runlevels\nOpenRC runlevels are directories living in /etc/runlevels to create additional runlevels is enough to issue:\n\nroot #install -d /etc/runlevels/$runlevel\nStacked runlevels\nIs possible manage variants using rc-update -s.\nAn usage example for using stacked runlevel on laptop to group networking services based on location is at OpenRC/StackedRunlevel.\n\nPrefix\nGentoo Prefix installs Gentoo within an offset, known as a prefix, allowing users to install Gentoo in another location in the filesystem hierarchy, hence avoiding conflicts. Next to this offset, Gentoo Prefix runs unprivileged, meaning no root user or rights are required to use it.\nBy using an offset (the \"prefix\" location), it is possible for many \"alternative\" user groups to benefit from a large part of the packages in the Gentoo Linux Portage tree. Currently users of the following systems successfully run Gentoo Prefix: Mac OS X on PPC and x86, Linux on x86, x86_64 and ia64, Solaris 10 on Sparc, Sparc/64, x86 and x86_64, FreeBSD on x86, AIX on PPC, Interix on x86, Windows on x86 (with the help of Interix), HP-UX on PARISC and ia64. \nOpenRC runscript already support prefix-installed daemons, during the Summer of Code 2012 work will be done to implement full secondary/session daemon behavior to complete the overall feature set provided by Prefix.\nOpenRC/Prefix, a tutorial for trying it out.\n\nHotplug\nOpenRC can be triggered by external events, such as new hardware from udev. See OpenRC/Event Driven for details.\n\nManually recovering crashed services\nIf you have a process that crashes upon start you will see the following when you go to check it's status.\n\nroot #/etc/init.d/docker status\n* status: crashed\n\nroot #/etc/init.d/docker start\n* WARNING: docker has already been started\n\nroot #/etc/init.d/docker stop\n* Caching service dependencies ...                                                                                                  [ ok ]\n* Stopping docker ...\n* Failed to stop docker                                                                                                             [ !! ]\n* ERROR: docker failed to stop\n\n\nTo remedy this situation you will need to zap the process which in the following example is the docker service.\n\nroot #/etc/init.d/docker zap\nAutomatic respawning crashed services\nOpenRC can return state of services to runlevel setting state, to provide stateful init scripts and automatic respawning. What you need is to run openrc (for default runlevel). Crashed services start and manual run services will stop. To prevent this you can run openrc -n (--not-stop)\nBy default openrc will attempt just to start crashed services, not restart. This сontrolled by rc_crashed_stop (default NO) and rc_crashed_start (default YES) options in /etc/rc.conf.\n\nCGroups support\nOpenRC starting with version 0.12 has extended cgroups support. See OpenRC/CGroups for details.\n\nChroot support\nroot #mkdir /lib64/rc/init.d\nroot #ln -s /lib64/rc/init.d /run/openrc\nroot #touch /run/openrc/softlevel\nroot #emerge --oneshot sys-apps/openrc\n\nFILE /etc/rc.confOpenRC config filerc_sys=\"prefix\"\nrc_controller_cgroups=\"NO\"\nrc_depend_strict=\"NO\"\nrc_need=\"!net !dev !udev-mount !sysfs !checkfs !fsck !netmount !logger !clock !modules\"\n\nIf you find that you are getting\n\n * WARNING: <service> is already starting\nmessages attempting to start a service, you may need to run\n\nroot #rc-update --update\nsystemd compatibility\nlogind\nAs some setups require systemd-logind. Elogind can be a suitable replacement as a standalone logind running with OpenRC.\n\ntmpfiles.d\nsystemd has a special tmpfiles.d file syntax for managing temporary files. sys-apps/opentmpfiles provides a tmpfiles.d interpreter for OpenRC.\nBoth can also be used to manage volatile entries in /sys or /proc.\n\nSee also\nGentoo AMD64 Handbook - Initscript system\nOpenRC/Baselayout 1 to 2 migration — provides instructions on migrating from baselayout-1 to baselayout-2 using OpenRC.\n\n\n\n\n\nRetrieved from \"https://wiki.gentoo.org/index.php?title=OpenRC&oldid=884343\"\nCategories: Todo articlesOpenRC \n\n\n\n\n\n\n\n\n\n\n This page was last edited on 19 July 2020, at 22:31.Privacy policyAbout Gentoo WikiDisclaimers \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2001–2020 Gentoo Foundation, Inc.\n\n\t\t\t\t\t\tGentoo is a trademark of the Gentoo Foundation, Inc.\n\t\t\t\t\t\tThe contents of this document, unless otherwise expressly stated, are licensed under the\n\t\t\t\t\t\tCC-BY-SA-3.0 license.\n\t\t\t\t\t\tThe Gentoo Name and Logo Usage Guidelines apply.\n\t\t\t\t\t\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# openrc\n\n> The OpenRC service manager.\n> See also `rc-status`, `rc-update`, and `rc-service`.\n> More information: <https://wiki.gentoo.org/wiki/OpenRC>.\n\n- Change to a specific runlevel:\n\n`sudo openrc {{runlevel_name}}`\n\n- Change to a specific runlevel, but don't stop any existing services:\n\n`sudo openrc --no-stop {{runlevel_name}}`\n"
 },
 {
   "command": "fc-pattern",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "FC-PATTERN(1)\t\t\t\t\t\t\t FC-PATTERN(1)\n\n\n\nNAME\n       fc-pattern - parse and show pattern\n\nSYNOPSIS\n       fc-pattern  [ -cdVh ]  [ --config ]  [ --default ]  [  [ -f format ]  [\n       --format format ]  ]  [ --version ]  [ --help ]\n\n\t[ pattern  [ element... ]   ]\n\nDESCRIPTION\n       fc-pattern parses pattern (empty pattern  by  default)  and  shows  the\n       parsed  result.\tIf --config is given, config substitution is performed\n       on the pattern before being displayed.  If --default is given,  default\n       substitution is performed on the pattern before being displayed.\n\n       If any elements are specified, only those are printed.\n\nOPTIONS\n       This  program  follows  the  usual  GNU\tcommand line syntax, with long\n       options starting with  two  dashes  (`-').  A  summary  of  options  is\n       included below.\n\n       -c     Perform config substitution on pattern.\n\n       -d     Perform default substitution on pattern.\n\n       -f     Format output according to the format specifier format.\n\n       -V     Show version of the program and exit.\n\n       -h     Show summary of options.\n\n       pattern\n\t      Parses and displays pattern (uses empty pattern by default).\n\n       element\n\t      If set, the element property is displayed for parsed pattern.\n\nSEE ALSO\n       FcNameParse(3)  FcConfigSubstitute(3) FcDefaultSubstitute(3) FcPattern-\n       Print(3)  FcPatternFormat(3)  fc-cat(1)\tfc-cache(1)   fc-list(1)   fc-\n       match(1) fc-query(1) fc-scan(1)\n\n       The  fontconfig\tuser's\tguide, in HTML format: /usr/share/doc/fontcon-\n       fig/fontconfig-user.html.\n\nAUTHOR\n       This manual page was updated by Behdad Esfahbod <behdad@behdad.org>.\n\n\n\n\t\t\t\t Apr 20, 2010\t\t\t FC-PATTERN(1)\n",
   "tldr_summary": "# fc-pattern\n\n> Shows information about a font matching a pattern.\n\n- Display default information about a font:\n\n`fc-pattern -d '{{DejaVu Serif}}'`\n"
 },
 {
   "command": "nmcli-connection",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# nmcli connection\n\n> Connection management with NetworkManager.\n\n- List all NetworkManager connections (shows name, uuid, type and device):\n\n`nmcli connection`\n\n- Activate a connection by specifying an uuid:\n\n`nmcli connection up uuid {{uuid}}`\n\n- Deactivate a connection:\n\n`nmcli connection down uuid {{uuid}}`\n\n- Create an auto-configured dual stack connection:\n\n`nmcli connection add ifname {{interface_name}} type {{ethernet}} ipv4.method {{auto}} ipv6.method {{auto}}`\n\n- Create a static IPv6-only connection:\n\n`nmcli connection add ifname {{interface_name}} type {{ethernet}} ip6 {{2001:db8::2/64}} gw6 {{2001:db8::1}} ipv6.dns {{2001:db8::1}} ipv4.method {{ignore}}`\n\n- Create a static IPv4-only connection:\n\n`nmcli connection add ifname {{interface_name}} type {{ethernet}} ip4 {{10.0.0.7/8}} gw4 {{10.0.0.1}} ipv4.dns {{10.0.0.1}} ipv6.method {{ignore}}`\n"
 },
 {
   "command": "blkid",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# blkid\n\n> Lists all recognized partitions and their Universally Unique Identifier (UUID).\n\n- List all partitions:\n\n`sudo blkid`\n\n- List all partitions in a table, including current mountpoints:\n\n`sudo blkid -o list`\n"
 },
 {
   "command": "swapoff",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# swapoff\n\n> Disables device or file for swapping.\n\n- Disable a given swap partition:\n\n`swapoff {{/dev/sdb7}}`\n\n- Disable a given swap file:\n\n`swapoff {{path/to/file}}`\n\n- Disable all swap areas:\n\n`swapoff -a`\n\n- Disable swap by label of a device or file:\n\n`swapoff -L {{swap1}}`\n"
 },
 {
   "command": "lastlog",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nUTMP(5) \t\t    BSD File Formats Manual\t\t       UTMP(5)\n\nNAME\n     utmp, wtmp, lastlog -- login records (DEPRECATED)\n\nSYNOPSIS\n     #include <utmp.h>\n\nDESCRIPTION\n     The interfaces in file <utmp.h> are all DEPRECATED and are only provided\n     for compatibility with previous releases of Mac OS X.  See pututxline(3)\n     and utmpx(5) for the supported interfaces.\n\n     <utmp.h> declares the structures used to record information about current\n     users in the file utmp, logins and logouts in the file wtmp, and last\n     logins in the file lastlog.  The time stamps of date changes, shutdowns\n     and reboots are also logged in the wtmp file.\n\n     These files can grow rapidly on busy systems, daily or weekly rotation is\n     recommended.  If any of these files do not exist, it is not created.\n     These files must be created manually and are normally maintained in\n     either the script /etc/daily or the script /etc/weekly.  (See cron(8).)\n\n\t   #define _PATH_UTMP\t   \"/var/run/utmp\"\n\t   #define _PATH_WTMP\t   \"/var/log/wtmp\"\n\t   #define _PATH_LASTLOG   \"/var/log/lastlog\"\n\n\t   #define UT_NAMESIZE\t   8\n\t   #define UT_LINESIZE\t   8\n\t   #define UT_HOSTSIZE\t   16\n\n\t   struct lastlog {\n\t\t   time_t  ll_time;\n\t\t   char    ll_line[UT_LINESIZE];\n\t\t   char    ll_host[UT_HOSTSIZE];\n\t   };\n\n\t   struct utmp {\n\t\t   char    ut_line[UT_LINESIZE];\n\t\t   char    ut_name[UT_NAMESIZE];\n\t\t   char    ut_host[UT_HOSTSIZE];\n\t\t   time_t  ut_time;\n\t   };\n\n     Each time a user logs in, the login program looks up the user's UID in\n     the file lastlog. If it is found, the timestamp of the last time the user\n     logged in, the terminal line and the hostname are written to the standard\n     output. (Providing the login is not quiet, see login(1).)\tThe login pro-\n     gram then records the new login time in the file lastlog.\n\n     After the new lastlog record is written , the file utmp is opened and the\n     utmp record for the user inserted.  This record remains there until the\n     user logs out at which time it is deleted.  The utmp file is used by the\n     programs rwho(1), users(1), w(1), and who(1).\n\n     Next, the login program opens the file wtmp, and appends the user's utmp\n     record.  The same utmp record, with an updated time stamp is later\n     appended to the file when the user logs out. (See launchd(8).)  The wtmp\n     file is used by the programs last(1) and ac(8).\n\n     In the event of a date change, a shutdown or reboot, the following items\n     are logged in the wtmp file.\n\n     reboot\n     shutdown\t A system reboot or shutdown has been initiated.  The charac-\n\t\t ter `~' is placed in the field ut_line, and reboot or\n\t\t shutdown in the field ut_name.  (See shutdown(8) and\n\t\t reboot(8).)\n\n     date\t The system time has been manually or automatically updated.\n\t\t (See date(1).)  The command name date is recorded in the\n\t\t field ut_name.  In the field ut_line, the character `|' indi-\n\t\t cates the time prior to the change, and the character `{'\n\t\t indicates the new time.\n\nFILES\n     (These files no longer exist in 10.5 or later.)\n\n     /var/run/utmp     The utmp file.\n     /var/log/wtmp     The wtmp file.\n     /var/log/lastlog  The lastlog file.\n\nSEE ALSO\n     last(1), login(1), who(1), ac(8), launchd(8)\n\nHISTORY\n     A utmp and wtmp file format appeared in Version 6 AT&T UNIX.  The lastlog\n     file format appeared in 3.0BSD.\n\n4th Berkeley Distribution\tMarch 17, 1994\t     4th Berkeley Distribution\n",
   "tldr_summary": "# lastlog\n\n> Show the most recent login of all users or of a given user.\n\n- Display the most recent login of all users:\n\n`lastlog`\n\n- Display lastlog record of the specified user:\n\n`lastlog -u {{username}}`\n\n- Display records before than 7 days:\n\n`lastlog -b {{7}}`\n\n- Display records more recent than 3 days:\n\n`lastlog -t {{3}}`\n"
 },
 {
   "command": "pvs",
   "doc_url": "https://www.man7.org/linux/man-pages/man8/pvs.8.html",
   "doc_text": "\n\n\n\n\npvs(8) - Linux manual page\n\n\n\n\n\n\n\n\n\nman7.org > Linux > man-pages\n\n\n\nLinux/UNIX system programming training\n\n\n\n\n\n\npvs(8) — Linux manual page\n\n\n\n\nNAME | SYNOPSIS | DESCRIPTION | USAGE | OPTIONS | VARIABLES | ENVIRONMENT VARIABLES | NOTES | SEE ALSO | COLOPHON\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nPVS(8)                     System Manager's Manual                    PVS(8)\n\nNAME          top\n       pvs - Display information about physical volumes\n\nSYNOPSIS          top\n       pvs\n           [ option_args ]\n           [ position_args ]\n\nDESCRIPTION          top\n       pvs produces formatted output about PVs.\n\nUSAGE          top\n       pvs\n           [ -a|--all ]\n           [ -o|--options String ]\n           [ -S|--select String ]\n           [ -O|--sort String ]\n           [    --segments ]\n           [    --aligned ]\n           [    --binary ]\n           [    --configreport log|vg|lv|pv|pvseg|seg ]\n           [    --foreign ]\n           [    --ignorelockingfailure ]\n           [    --logonly ]\n           [    --nameprefixes ]\n           [    --noheadings ]\n           [    --nosuffix ]\n           [    --readonly ]\n           [    --reportformat basic|json ]\n           [    --rows ]\n           [    --separator String ]\n           [    --shared ]\n           [    --unbuffered ]\n           [    --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E ]\n           [    --unquoted ]\n           [ COMMON_OPTIONS ]\n           [ PV|Tag ... ]\n\n       Common options for lvm:\n           [ -d|--debug ]\n           [ -h|--help ]\n           [ -q|--quiet ]\n           [ -t|--test ]\n           [ -v|--verbose ]\n           [ -y|--yes ]\n           [    --commandprofile String ]\n           [    --config String ]\n           [    --driverloaded y|n ]\n           [    --lockopt String ]\n           [    --longhelp ]\n           [    --nolocking ]\n           [    --profile String ]\n           [    --version ]\n\nOPTIONS          top\n       --aligned\n              Use with --separator to align the output columns\n\n       -a|--all\n              Show information about devices that have not been initialized\n              by LVM, i.e. they are not PVs.\n\n       --binary\n              Use binary values \"0\" or \"1\" instead of descriptive literal\n              values for columns that have exactly two valid values to\n              report (not counting the \"unknown\" value which denotes that\n              the value could not be determined).\n\n       --commandprofile String\n              The command profile to use for command configuration.  See\n              lvm.conf(5) for more information about profiles.\n\n       --config String\n              Config settings for the command. These override lvm.conf\n              settings.  The String arg uses the same format as lvm.conf, or\n              may use section/field syntax.  See lvm.conf(5) for more\n              information about config.\n\n       --configreport log|vg|lv|pv|pvseg|seg\n              See lvmreport(7).\n\n       -d|--debug ...\n              Set debug level. Repeat from 1 to 6 times to increase the\n              detail of messages sent to the log file and/or syslog (if\n              configured).\n\n       --driverloaded y|n\n              If set to no, the command will not attempt to use device-\n              mapper.  For testing and debugging.\n\n       --foreign\n              Report/display foreign VGs that would otherwise be skipped.\n              See lvmsystemid(7) for more information about foreign VGs.\n\n       -h|--help\n              Display help text.\n\n       --ignorelockingfailure\n              Allows a command to continue with read-only metadata\n              operations after locking failures.\n\n       --lockopt String\n              Used to pass options for special cases to lvmlockd.  See\n              lvmlockd(8) for more information.\n\n       --logonly\n              Suppress command report and display only log report.\n\n       --longhelp\n              Display long help text.\n\n       --nameprefixes\n              Add an \"LVM2_\" prefix plus the field name to the output.\n              Useful with --noheadings to produce a list of field=value\n              pairs that can be used to set environment variables (for\n              example, in udev rules).\n\n       --noheadings\n              Suppress the headings line that is normally the first line of\n              output.  Useful if grepping the output.\n\n       --nolocking\n              Disable locking.\n\n       --nosuffix\n              Suppress the suffix on output sizes. Use with --units (except\n              h and H) if processing the output.\n\n       -o|--options String\n              Comma-separated, ordered list of fields to display in columns.\n              String arg syntax is: [+|-|#]Field1[,Field2 ...]  The prefix +\n              will append the specified fields to the default fields, - will\n              remove the specified fields from the default fields, and #\n              will compact specified fields (removing them when empty for\n              all rows.)  Use -o help to view the list of all available\n              fields.  Use separate lists of fields to add, remove or\n              compact by repeating the -o option: -o+field1,field2 -o-\n              field3,field4 -o#field5.  These lists are evaluated from left\n              to right.  Use field name lv_all to view all LV fields, vg_all\n              all VG fields, pv_all all PV fields, pvseg_all all PV segment\n              fields, seg_all all LV segment fields, and pvseg_all all PV\n              segment columns.  See the lvm.conf report section for more\n              config options.  See lvmreport(7) for more information about\n              reporting.\n\n       --profile String\n              An alias for --commandprofile or --metadataprofile, depending\n              on the command.\n\n       -q|--quiet ...\n              Suppress output and log messages. Overrides --debug and\n              --verbose.  Repeat once to also suppress any prompts with\n              answer 'no'.\n\n       --readonly\n              Run the command in a special read-only mode which will read\n              on-disk metadata without needing to take any locks. This can\n              be used to peek inside metadata used by a virtual machine\n              image while the virtual machine is running. No attempt will be\n              made to communicate with the device-mapper kernel driver, so\n              this option is unable to report whether or not LVs are\n              actually in use.\n\n       --reportformat basic|json\n              Overrides current output format for reports which is defined\n              globally by the report/output_format setting in lvm.conf.\n              basic is the original format with columns and rows.  If there\n              is more than one report per command, each report is prefixed\n              with the report name for identification. json produces report\n              output in JSON format. See lvmreport(7) for more information.\n\n       --rows\n              Output columns as rows.\n\n       --segments\n              Produces one line of output for each contiguous allocation of\n              space on each PV, showing the start (pvseg_start) and length\n              (pvseg_size) in units of physical extents.\n\n       -S|--select String\n              Select objects for processing and reporting based on specified\n              criteria.  The criteria syntax is described by --select help\n              and lvmreport(7).  For reporting commands, one row is\n              displayed for each object matching the criteria.  See\n              --options help for selectable object fields.  Rows can be\n              displayed with an additional \"selected\" field (-o selected)\n              showing 1 if the row matches the selection and 0 otherwise.\n              For non-reporting commands which process LVM entities, the\n              selection is used to choose items to process.\n\n       --separator String\n              String to use to separate each column. Useful if grepping the\n              output.\n\n       --shared\n              Report/display shared VGs that would otherwise be skipped when\n              lvmlockd is not being used on the host.  See lvmlockd(8) for\n              more information about shared VGs.\n\n       -O|--sort String\n              Comma-separated ordered list of columns to sort by. Replaces\n              the default selection. Precede any column with - for a reverse\n              sort on that column.\n\n       -t|--test\n              Run in test mode. Commands will not update metadata.  This is\n              implemented by disabling all metadata writing but nevertheless\n              returning success to the calling function. This may lead to\n              unusual error messages in multi-stage operations if a tool\n              relies on reading back metadata it believes has changed but\n              hasn't.\n\n       --unbuffered\n              Produce output immediately without sorting or aligning the\n              columns properly.\n\n       --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E\n              All sizes are output in these units: human-(r)eadable with '<'\n              rounding indicator, (h)uman-readable, (b)ytes, (s)ectors,\n              (k)ilobytes, (m)egabytes, (g)igabytes, (t)erabytes,\n              (p)etabytes, (e)xabytes.  Capitalise to use multiples of 1000\n              (S.I.) instead of 1024.  Custom units can be specified, e.g.\n              --units 3M.\n\n       --unquoted\n              When used with --nameprefixes, output values in the\n              field=value pairs are not quoted.\n\n       -v|--verbose ...\n              Set verbose level. Repeat from 1 to 4 times to increase the\n              detail of messages sent to stdout and stderr.\n\n       --version\n              Display version information.\n\n       -y|--yes\n              Do not prompt for confirmation interactively but always assume\n              the answer yes. Use with extreme caution.  (For automatic no,\n              see -qq.)\n\nVARIABLES          top\n       PV\n              Physical Volume name, a device path under /dev.  For commands\n              managing physical extents, a PV positional arg generally\n              accepts a suffix indicating a range (or multiple ranges) of\n              physical extents (PEs). When the first PE is omitted, it\n              defaults to the start of the device, and when the last PE is\n              omitted it defaults to end.  Start and end range (inclusive):\n              PV[:PE-PE]...  Start and length range (counting from 0):\n              PV[:PE+PE]...\n\n       Tag\n              Tag name.  See lvm(8) for information about tag names and\n              using tags in place of a VG, LV or PV.\n\n       String\n              See the option description for information about the string\n              content.\n\n       Size[UNIT]\n              Size is an input number that accepts an optional unit.  Input\n              units are always treated as base two values, regardless of\n              capitalization, e.g. 'k' and 'K' both refer to 1024.  The\n              default input unit is specified by letter, followed by |UNIT.\n              UNIT represents other possible input units: bBsSkKmMgGtTpPeE.\n              b|B is bytes, s|S is sectors of 512 bytes, k|K is kilobytes,\n              m|M is megabytes, g|G is gigabytes, t|T is terabytes, p|P is\n              petabytes, e|E is exabytes.  (This should not be confused with\n              the output control --units, where capital letters mean\n              multiple of 1000.)\n\nENVIRONMENT VARIABLES          top\n       See lvm(8) for information about environment variables used by lvm.\n       For example, LVM_VG_NAME can generally be substituted for a required\n       VG parameter.\n\nNOTES          top\n       The pv_attr bits are:\n\n       1  (d)uplicate, (a)llocatable, (u)sed\n\n       2  e(x)ported\n\n       3  (m)issing\n\nSEE ALSO          top\n       lvm(8) lvm.conf(5) lvmconfig(8)\n\n       pvchange(8) pvck(8) pvcreate(8) pvdisplay(8) pvmove(8) pvremove(8)\n       pvresize(8) pvs(8) pvscan(8)\n\n       vgcfgbackup(8) vgcfgrestore(8) vgchange(8) vgck(8) vgcreate(8)\n       vgconvert(8) vgdisplay(8) vgexport(8) vgextend(8) vgimport(8)\n       vgimportclone(8) vgmerge(8) vgmknodes(8) vgreduce(8) vgremove(8)\n       vgrename(8) vgs(8) vgscan(8) vgsplit(8)\n\n       lvcreate(8) lvchange(8) lvconvert(8) lvdisplay(8) lvextend(8)\n       lvreduce(8) lvremove(8) lvrename(8) lvresize(8) lvs(8) lvscan(8)\n\n       lvm-fullreport(8) lvm-lvpoll(8) lvm2-activation-generator(8)\n       blkdeactivate(8) lvmdump(8)\n\n       dmeventd(8) lvmpolld(8) lvmlockd(8) lvmlockctl(8) cmirrord(8)\n       lvmdbusd(8)\n\n       lvmsystemid(7) lvmreport(7) lvmraid(7) lvmthin(7) lvmcache(7)\n\nCOLOPHON          top\n       This page is part of the lvm2 (Logical Volume Manager 2) project.\n       Information about the project can be found at \n       â¨http://www.sourceware.org/lvm2/â©.  If you have a bug report for this\n       manual page, see â¨https://github.com/lvmteam/lvm2/issuesâ©.  This page\n       was obtained from the tarball\n       https://github.com/lvmteam/lvm2/archive/v2_03_10.tar.gz fetched from\n       â¨https://github.com/lvmteam/lvm2/releasesâ© on 2020-08-13.  If you\n       discover any rendering problems in this HTML version of the page, or\n       you believe there is a better or more up-to-date source for the page,\n       or you have corrections or improvements to the information in this\n       COLOPHON (which is not part of the original manual page), send a mail\n       to man-pages@man7.org\n\nRed Hat, Inc.         LVM TOOLS 2.03.10(2) (2020-08-09)               PVS(8)\n\n\nPages that refer to this page: \n    lvmreport(7),  \n    fullreport(8),  \n    lvchange(8),  \n    lvconvert(8),  \n    lvcreate(8),  \n    lvdisplay(8),  \n    lvextend(8),  \n    lvm(8),  \n    lvm-config(8),  \n    lvmconfig(8),  \n    lvmdiskscan(8),  \n    lvm-dumpconfig(8),  \n    lvm-fullreport(8),  \n    lvm-lvpoll(8),  \n    lvpoll(8),  \n    lvreduce(8),  \n    lvremove(8),  \n    lvrename(8),  \n    lvresize(8),  \n    lvs(8),  \n    lvscan(8),  \n    pvchange(8),  \n    pvck(8),  \n    pvcreate(8),  \n    pvdisplay(8),  \n    pvmove(8),  \n    pvremove(8),  \n    pvresize(8),  \n    pvs(8),  \n    pvscan(8),  \n    vgcfgbackup(8),  \n    vgcfgrestore(8),  \n    vgchange(8),  \n    vgck(8),  \n    vgconvert(8),  \n    vgcreate(8),  \n    vgdisplay(8),  \n    vgexport(8),  \n    vgextend(8),  \n    vgimport(8),  \n    vgimportclone(8),  \n    vgmerge(8),  \n    vgmknodes(8),  \n    vgreduce(8),  \n    vgremove(8),  \n    vgrename(8),  \n    vgs(8),  \n    vgscan(8),  \n    vgsplit(8)\n\n\n\n\n\n\n\n\n            HTML rendering created 2020-08-13\n            by Michael Kerrisk, \n            author of \n            The Linux Programming Interface, \n            maintainer of the \n            Linux man-pages project.\n        \n\n            For details of in-depth\n            Linux/UNIX system programming training courses\n            that I teach, look here.\n        \n\n            Hosting by jambit GmbH.\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# pvs\n\n> Display information about LVM physical volumes.\n> More information: <https://www.man7.org/linux/man-pages/man8/pvs.8.html>.\n\n- Display information about physical volumes:\n\n`pvs`\n\n- Display non-physical volumes:\n\n`pvs -a`\n\n- Change default display to show more details:\n\n`pvs -v`\n\n- Display only specific fields:\n\n`pvs -o {{field_name_1}},{{field_name_2}}`\n\n- Append field to default display:\n\n`pvs -o +{{field_name}}`\n\n- Suppress heading line:\n\n`pvs --noheadings`\n\n- Use separator to separate fields:\n\n`pvs --separator {{special_character}}`\n"
 },
 {
   "command": "lslocks",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lslocks\n\n> List local system locks.\n\n- List all local system locks:\n\n`lslocks`\n\n- List locks with defined column headers:\n\n`lslocks --output {{PID}},{{COMMAND}},{{PATH}}`\n\n- List locks producing a raw output (no columns), and without column headers:\n\n`lslocks --raw --noheadings`\n\n- List locks by PID input:\n\n`lslocks --pid {{PID}}`\n\n- List locks with json output to `stdout`:\n\n`lslocks --json`\n"
 },
 {
   "command": "pasuspender",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pasuspender\n\n> Temporarily suspends `pulseaudio` while another command is running to allow access to alsa.\n\n- Suspend pulseaudio while running `jackd`:\n\n`pasuspender -- {{jackd -d alsa --device hw:0}}`\n"
 },
 {
   "command": "timeshift",
   "doc_url": "https://github.com/teejee2008/timeshift",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - teejee2008/timeshift: System restore tool for Linux. Creates filesystem snapshots using rsync+hardlinks, or BTRFS snapshots. Supports scheduled snapshots, multiple backup levels, and exclude filters. Snapshots can be restored while system is running or from Live CD/USB.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nteejee2008\n\n/\n\ntimeshift\n\n\n\n\n\n\n\n    Watch\n \n      72\n    \n\n\n\n\n      Star\n\n\n      2.3k\n    \n\n\n\n\n          Fork\n\n\n        194\n      \n\n\n\n\n\n        System restore tool for Linux. Creates filesystem snapshots using rsync+hardlinks, or BTRFS snapshots. Supports scheduled snapshots, multiple backup levels, and exclude filters. Snapshots can be restored while system is running or from Live CD/USB.\n      \n\n\n\n            View license\n        \n\n\n\n\n2.3k\n        stars\n \n\n194\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n305\n \n\n\n\nPull requests\n17\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n15\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nteejee2008\n\nMerge remote-tracking branch 'origin/master'\n\n\n\n…\n\n\n\n2e2a291\n\nSep 8, 2020\n\n\n\n\n\nMerge remote-tracking branch 'origin/master'\n\n\n2e2a291\n\n\n\nGit stats\n\n\n\n\n\n884\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github/ISSUE_TEMPLATE\n\n\n\nUpdate issue templates\n\n\n\nSep 8, 2020\n\n\n\n\n\n\n\ndebian\n\n\n\nv20.03\n\n\n\nMar 5, 2020\n\n\n\n\n\n\n\nfiles\n\n\n\nInclude default config file in package; Install to /etc/timeshift.json;\n\n\n\nSep 24, 2017\n\n\n\n\n\n\n\nicons\n\n\n\nInstaller: Fixed libgee dependency for arch; Updated main icon; Added…\n\n\n\nOct 7, 2016\n\n\n\n\n\n\n\nimages\n\n\n\nUpdated README; Added section on supported system types;\n\n\n\nNov 5, 2017\n\n\n\n\n\n\n\nman\n\n\n\nFix build error\n\n\n\nAug 11, 2019\n\n\n\n\n\n\n\npo\n\n\n\nMerge pull request #601 from marcuscf/master\n\n\n\nMay 13, 2020\n\n\n\n\n\n\n\nrelease\n\n\n\nFedora: Added 'psmisc' dependency for installer\n\n\n\nApr 7, 2018\n\n\n\n\n\n\n\nsrc\n\n\n\nv20.03\n\n\n\nMar 5, 2020\n\n\n\n\n\n\n\n.bzrignore\n\n\n\nAdded and updated translations\n\n\n\nNov 5, 2017\n\n\n\n\n\n\n\n.gitignore\n\n\n\nMinor changes\n\n\n\nFeb 9, 2020\n\n\n\n\n\n\n\nAUTHORS\n\n\n\nInitial release\n\n\n\nOct 5, 2013\n\n\n\n\n\n\n\nBUILD_CONFIG\n\n\n\nUpdate build scripts; Use the new Sanity installer;\n\n\n\nSep 17, 2017\n\n\n\n\n\n\n\nCOPYING\n\n\n\nInitial release\n\n\n\nOct 5, 2013\n\n\n\n\n\n\n\nINSTALL\n\n\n\nUpdated build scripts\n\n\n\nOct 15, 2017\n\n\n\n\n\n\n\nLICENSE.md\n\n\n\nUpdated build scripts\n\n\n\nOct 15, 2017\n\n\n\n\n\n\n\nNOTES\n\n\n\nUpdated build scripts\n\n\n\nOct 15, 2017\n\n\n\n\n\n\n\nREADME.md\n\n\n\nUpdated support message\n\n\n\nSep 8, 2020\n\n\n\n\n\n\n\n_config.yml\n\n\n\nSet theme jekyll-theme-cayman\n\n\n\nOct 6, 2017\n\n\n\n\n\n\n\nbuild-deb.sh\n\n\n\nCheck existence necessary executables\n\n\n\nMar 26, 2018\n\n\n\n\n\n\n\nbuild-installers.sh\n\n\n\nCheck existence necessary executables\n\n\n\nMar 26, 2018\n\n\n\n\n\n\n\nbuild-source.sh\n\n\n\nCheck existence necessary executables\n\n\n\nMar 26, 2018\n\n\n\n\n\n\n\nmakefile\n\n\n\nFix build error\n\n\n\nAug 11, 2019\n\n\n\n\n\n\n\nmakepot\n\n\n\nupdate translation template & complete German translation\n\n\n\nNov 13, 2018\n\n\n\n\n\n\n\nmerge-launchpad-translations.sh\n\n\n\nAdded a script for merging launchpad translations\n\n\n\nFeb 3, 2018\n\n\n\n\n\n\n\ntimeshift.geany\n\n\n\nUpdate support section in README\n\n\n\nSep 8, 2020\n\n\n\n\n\n\n\ntimeshift.pot\n\n\n\nMinor changes\n\n\n\nFeb 9, 2020\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\nTimeshift\nTimeshift for Linux is an application that provides functionality similar to the System Restore feature in Windows and the Time Machine tool in Mac OS. Timeshift protects your system by taking incremental snapshots of the file system at regular intervals. These snapshots can be restored at a later date to undo all changes to the system.\nIn RSYNC mode, snapshots are taken using rsync and hard-links. Common files are shared between snapshots which saves disk space. Each snapshot is a full system backup that can be browsed with a file manager.\nIn BTRFS mode, snapshots are taken using the in-built features of the BTRFS filesystem. BTRFS snapshots are supported only on BTRFS systems having an Ubuntu-type subvolume layout (with @ and @home subvolumes).\nTimeshift is similar to applications like rsnapshot, BackInTime and TimeVault but with different goals. It is designed to protect only system files and settings. User files such as documents, pictures and music are excluded. This ensures that your files remains unchanged when you restore your system to an earlier date. If you need a tool to backup your documents and files please take a look at the excellent BackInTime application which is more configurable and provides options for saving user files.\n\nFeatures\nMinimal Setup\n\n\nTimeshift requires very little setup. Just install it, run it for the first time and take the first snapshot. Cron job can be enabled for taking automatic snapshots of the system at regular intervals. The backup levels can be selected from the Settings window.\n\n\nSnapshots are saved by default on the system (root) partition in path /timeshift. Other linux partitions can also be selected. For best results the snapshots should be saved to an external (non-system) partition.\n\n\n\nMultiple Snapshot Levels\n\n\nMultiple levels of snapshots can be enabled - Hourly, Daily, Weekly, Monthly and Boot\n\n\nNumber of snapshots to retain can be specified for each level\n\n\nBoot snapshots provide an additional level of backup and are created every time the system starts. Boot snapshots are created with a delay of 10 mins so that system startup is not affected.\n\n\n\nRsync & BTRFS Snapshots\n\n\nSupports rsync snapshots on all systems\n\n\nSupports BTRFS snapshots on BTRFS systems\n\n\nIt is strongly recommended to use BTRFS snapshots on systems that are installed on BTRFS partition. BTRFS snapshots are perfect byte-for-byte copies of the system. Nothing is excluded. BTRFS snapshots can be created and restored in seconds, and have very low overhead in terms of disk space.\n\n\nUser Data is Excluded by Default\nTimeshift is designed to protect system files and settings. It is NOT a backup tool and is not meant to protect user data. Entire contents of users' home directories are excluded by default. This has two advantages:\n\nYou don't need to worry about your documents getting overwritten when you restore a previous snapshot to recover the system.\nYour music and video collection in your home directory will not waste space on the backup device.\n\nYou can selectively include items for backup from the Settings window. Selecting the option \"Include hidden items\" from the Users tab will backup and restore the .hidden files and directories in your home folder. These folders contain user-specific config files and can be included in snapshots if required.\nNote: It is not recommended to include user data in backups as it will be overwritten when you restore the snapshot.\n\n\nBetter Snapshots & Rotation\n\nUnlike similar tools that are scheduled to take backups at a fixed time of the day, Timeshift is designed to run once every hour and take snapshots only when a snapshot is due. This is more suitable for desktop users who keep their laptops and desktops switched on for few hours daily. Scheduling snapshots at a fixed time on such users will result in missed backups since the system may not be running when the snapshot is scheduled to run. By running once every hour and creating snapshots when due, Timeshift ensures that backups are not missed.\nApplications like rsnapshot rotate a snapshot to the next level by creating a hard-linked copy. Creating a hard-linked copy may seem like a good idea but it is still a waste of disk space, since only files can be hard-linked and not directories. The duplicated directory structure can take up as much as 100 MB of space. Timeshift avoids this wastage by using tags for maintaining backup levels. Each snapshot will have only one copy on disk and is tagged as \"daily\", \"monthly\", etc. The snapshot location will have a set of folders for each backup level (\"Monthly\", \"Daily\", etc) with symbolic links pointing to the actual snapshots tagged with the level.\n\nSystem Restore\n\n\nSnapshots can be restored by selecting a snapshot from the main window and clicking Restore button on the toolbar.\n\n\nSnapshots can be restored either from the running system (online restore) or from another system that has Timeshift installed on it (offline restore).\n\n\nIf the main system is not bootable, then it is possible to boot from an Ubuntu Live CD, install Timeshift on the live system, and restore a snapshot on the main system.\n\n\nRestoring backups from the running system requires a reboot to complete the restore process.\n\n\n\nCross-Distribution Restore\n\nYou can also Timeshift across distributions. Let's say you are currently using Xubuntu and decide to try out Linux Mint. You install Linux Mint on your system and try it out for a week before deciding to go back to Xubuntu. Using Timeshift you can simply restore the last week's snapshot to get your Xubuntu system back. Timeshift will take care of things like reinstalling the bootloader and other details.\nSince installing a new linux distribution also formats your root partition you need to save your snapshots on a separate linux partition for this to work.\nIt is recommended to include hidden items in home directory by selecting the option \"Include  Hidden Items\" from Settings > Users.\n\nSupported System Configurations\n\n\nNormal - OS installed on non-encrypted partitions\n\n\nLUKS Encrypted - OS installed on LUKS-encrypted partitions\n\n\nLVM2 - OS installed on LVM2 volumes (with or without LUKS)\n\n\nBTRFS - OS installed on BTRFS volumes (with or without LUKS)\n\nOnly Ubuntu-type layouts with @ and @home subvolumes are supported\n@ and @home subvolumes may be on same or different BTRFS volumes\n@ may be on BTRFS volume and /home may be mounted on non-BTRFS partition\nOther layouts are not supported\n\n\n\nGRUB2 - Bootloader must be GRUB2. GRUB legacy and other bootloaders are not supported.\n\n\nEFI - EFI systems are supported. Make sure that /boot/efi partition is selected for mounting before restoring snapshots (application will do it automatically).\n\n\nEncrypted Home - For users with encrypted home, files in /home/.ecryptfs/$USER will be backed-up and restored. The decrypted contents in $HOME will be excluded. This avoids the security risk of decrypted contents becoming available outside the user's home directory.\n\n\nEncrypted Private Directory - For users with encrypted Private directory, the encrypted files in $HOME/.Private, as well as the decrypted files in $HOME/Private, will be excluded (as it contains user data). Filters added by user to include files from $HOME/.Private or $HOME/Private will be ignored.\n\n\nDocker & Containers - Docker and containerized systems are not supported. Running Timeshift on such systems will have unpredictable results.\n\n\nInstallation\nUbuntu-based Distributions\nUbuntu, Linux Mint, Elementary OS, etc.\nPackages are available in the Launchpad PPA for supported Ubuntu releases.\nRun the following commands in a terminal window:\nsudo add-apt-repository -y ppa:teejee2008/timeshift\nsudo apt-get update\nsudo apt-get install timeshift\nDEB packages are available on Releases page for older Ubuntu releases which have reached end-of-life.\nFedora\nsudo dnf update\nsudo dnf install timeshift\nInstaller can be used on the following distribution types:\n\nDebian based - Debian, Ubuntu, Linux Mint, Elementary OS, etc (supports apt)\nArch based - Arch Linux, Manjaro, etc (supports pacman)\n\nUnInstall\nRun the following command in a terminal window:\nsudo apt-get remove timeshift\n\nor\nsudo timeshift-uninstall\n\nRemember to delete all snapshots before un-installing. Otherwise the snapshots continue to occupy space on your system.  To delete all snapshots, run the application, select all snapshots from the list (CTRL+A) and click the Delete button on the toolbar. This will delete all snapshots and remove the /timeshift folder in the root directory.\nIf you used the installer to install Timeshift, you can remove the installed files with following command:\nsudo timeshift-uninstall\n\nKnown Issues & Limitations\nBTRFS volumes\nBTRFS volumes must have an Ubuntu-type layout with @ and @home subvolumes. Other layouts are not supported. Systems having the @ subvolume and having /home on a non-BTRFS partition are also supported.\nDisk Space\nTimeshift requires a lot of disk space to keep snapshot data. The device selected as snapshot device must have sufficient free space to store the snapshots that will be created.\nIf the backup device is running out of space, try the following steps:\n\nReduce the number of backup levels - Uncheck the backup levels and keep only one selected\nReduce the number of snapshots that are kept - In the Schedule tab set the number of snapshots to 5 or less.\nYou can also disable scheduled snapshots completely and create snapshots manually when required\n\nBootloader & EFI\n\nOnly those systems are supported which use GRUB2 bootloader. Trying to create and restore snapshots on a system using older versions of GRUB will result in a non-bootable system.\nEFI systems are fully supported. Ensure that the /boot/efi partition is mapped while restoring a snapshot. It will be mapped automatically if detected.\nIf you are restoring from Live CD/USB, and your installed system uses EFI mode, then you must boot from Live CD/USB in EFI mode.\n\nSupport\nIf you use Linux Mint and need support for an issue please use the Linux Mint support forums\nIssues reported on the Issue Tracker will be fixed during the next update. Please do not expect a response as the tracker is checked once a year when the app is being updated.\nDisclaimer\nThis program is free for personal and commercial use and comes with absolutely no warranty. You use this program entirely at your own risk. The author will not be liable for any damages arising from the use of this program. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\nContribute\nYou can contribute to this project in various ways:\n\nSubmitting ideas, and reporting issues in the tracker\nTranslating this application to other languages\nContributing code changes by fixing issues and submitting a pull request\nMaking a donation via PayPal or bitcoin\n\nDonate\nTimeshift is a non-commercial application. I work on it during my free time based on my requirements and interest. If you wish to support this project, you can make a donation for $10 or more via PayPal. Your contributions will help keep the project alive.\nPayPal\n\nBitcoin ~ You can send bitcoins at this address or by scanning the QR code below:\n1KdEyJjkuEW8aZWjenf4x5uEeHo9VTYqio\n\n\n\n\n\n\n\n\n\nAbout\n\n      System restore tool for Linux. Creates filesystem snapshots using rsync+hardlinks, or BTRFS snapshots. Supports scheduled snapshots, multiple backup levels, and exclude filters. Snapshots can be restored while system is running or from Live CD/USB.\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n      15\n\n\n\n\n\nv20.03\n\n          Latest\n \nMar 5, 2020\n\n \n\n        + 14 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 45\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 34 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\nVala\n98.0%\n\n\n\n\n\nShell\n1.2%\n\n\n\n\n\nMakefile\n0.8%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# timeshift\n\n> System restore utility.\n> More information: <https://github.com/teejee2008/timeshift>.\n\n- List snapshots:\n\n`sudo timeshift --list`\n\n- Create a new snapshot (if scheduled):\n\n`sudo timeshift --check`\n\n- Create a new snapshot (even if not scheduled):\n\n`sudo timeshift --create`\n\n- Restore a snapshot (selecting which snapshot to restore interactively):\n\n`sudo timeshift --restore`\n\n- Restore a specific snapshot:\n\n`sudo timeshift --restore --snapshot '{{snapshot}}'`\n\n- Delete a specific snapshot:\n\n`sudo timeshift --delete --snapshot '{{snapshot}}'`\n"
 },
 {
   "command": "add-apt-repository",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# add-apt-repository\n\n> Manages apt repository definitions.\n\n- Add a new apt repository:\n\n`add-apt-repository {{repository_spec}}`\n\n- Remove an apt repository:\n\n`add-apt-repository --remove {{repository_spec}}`\n\n- Update the package cache after adding a repository:\n\n`add-apt-repository --update {{repository_spec}}`\n\n- Enable source packages:\n\n`add-apt-repository --enable-source {{repository_spec}}`\n"
 },
 {
   "command": "guix-package",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# guix package\n\n> Install, upgrade and remove Guix packages, or rollback to previous configurations.\n\n- Install a new package:\n\n`guix package -i {{package_name}}`\n\n- Remove a package:\n\n`guix package -r {{package_name}}`\n\n- Search the package database for a regular expression:\n\n`guix package -s \"{{search_pattern}}\"`\n\n- List installed packages:\n\n`guix package -I`\n\n- List generations:\n\n`guix package -l`\n\n- Roll back to the previous generation:\n\n`guix package --roll-back`\n"
 },
 {
   "command": "playerctl",
   "doc_url": "https://github.com/altdesktop/playerctl",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - altdesktop/playerctl: 🎧 mpris command-line controller and library for vlc, audacious, bmp, cmus, spotify and others.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naltdesktop\n\n/\n\nplayerctl\n\n\n\n\n\n\n\n    Watch\n \n      25\n    \n\n\n\n\n      Star\n\n\n      1.1k\n    \n\n\n\n\n          Fork\n\n\n        57\n      \n\n\n\n\n\n🎧 mpris command-line controller and library for vlc, audacious, bmp, cmus, spotify and others.\n      \n\n\n\ndubstepdish.com/index.php/2018/10/21/playerctl-at-version-2-0/\n\n\n\n\n\n            LGPL-3.0 License\n        \n\n\n\n\n1.1k\n        stars\n \n\n57\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n15\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nbranches\n\n\n\n16\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nacrisci\n\nMerge pull request #185 from erzoe/master\n\n\n\n…\n\n\n\n9b49fd7\n\nAug 17, 2020\n\n\n\n\n\nMerge pull request #185 from erzoe/master\n\nreadme: required plugin in Quod Libet\n\n9b49fd7\n\n\n\nGit stats\n\n\n\n\n\n404\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github/ISSUE_TEMPLATE\n\n\n\nUpdate issue templates\n\n\n\nJun 14, 2019\n\n\n\n\n\n\n\ndata\n\n\n\nfix invalid free in listing system players\n\n\n\nMay 15, 2020\n\n\n\n\n\n\n\ndoc\n\n\n\nupdate man page for emoji function\n\n\n\nJan 29, 2020\n\n\n\n\n\n\n\nexamples\n\n\n\nformat the project\n\n\n\nJan 15, 2020\n\n\n\n\n\n\n\nplayerctl\n\n\n\nadd tests for playerctld shift error conditions\n\n\n\nJun 4, 2020\n\n\n\n\n\n\n\ntest\n\n\n\nadd tests for playerctld shift error conditions\n\n\n\nJun 4, 2020\n\n\n\n\n\n\n\n.clang-format\n\n\n\nclang-format the project\n\n\n\nSep 26, 2018\n\n\n\n\n\n\n\n.dockerignore\n\n\n\nfix dockerignore format\n\n\n\nJun 22, 2019\n\n\n\n\n\n\n\n.flake8\n\n\n\nrefactor tests\n\n\n\nJan 25, 2020\n\n\n\n\n\n\n\n.gitignore\n\n\n\nAdd a basic test suit\n\n\n\nMay 1, 2019\n\n\n\n\n\n\n\n.travis.yml\n\n\n\nAdd a basic test suit\n\n\n\nMay 1, 2019\n\n\n\n\n\n\n\nCHANGELOG.md\n\n\n\nbump to version 2.2.1\n\n\n\nAug 8, 2020\n\n\n\n\n\n\n\nCONTRIBUTORS\n\n\n\nCONTRIBUTORS: add myself\n\n\n\nMay 22, 2018\n\n\n\n\n\n\n\nCOPYING\n\n\n\nRelicense under LGPL\n\n\n\nApr 27, 2014\n\n\n\n\n\n\n\nDockerfile\n\n\n\nfix invalid free in listing system players\n\n\n\nMay 15, 2020\n\n\n\n\n\n\n\nMakefile\n\n\n\nrefactor tests\n\n\n\nJan 25, 2020\n\n\n\n\n\n\n\nREADME.md\n\n\n\nreadme: required plugin in Quod Libet\n\n\n\nAug 16, 2020\n\n\n\n\n\n\n\nfpm-packages.sh\n\n\n\ncreate dist packages is post release script\n\n\n\nAug 9, 2020\n\n\n\n\n\n\n\nletter-to-spotify-support.md\n\n\n\nadd letter to spotify customer support\n\n\n\nMay 20, 2020\n\n\n\n\n\n\n\nmeson.build\n\n\n\nbump to version 2.2.1\n\n\n\nAug 8, 2020\n\n\n\n\n\n\n\nmeson_options.txt\n\n\n\ndont install bash completions by default\n\n\n\nJan 31, 2020\n\n\n\n\n\n\n\npytest.ini\n\n\n\nAdd a basic test suit\n\n\n\nMay 1, 2019\n\n\n\n\n\n\n\nrequirements.txt\n\n\n\ntest: update to dbus-next 0.1.1\n\n\n\nJun 2, 2019\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\nPlayerctl\nFor true players only: vlc, audacious, bmp, xmms2, spotify and others.\nAbout\nPlayerctl is a command-line utility and library for controlling media players that implement the MPRIS D-Bus Interface Specification. Playerctl makes it easy to bind player actions, such as play and pause, to media keys. You can also get metadata about the playing track such as the artist and title for integration into statusline generators or other command-line tools.\nFor more advanced users, Playerctl provides an introspectable library available in your favorite scripting language that allows more detailed control like the ability to subscribe to media player events or get metadata such as artist and title for the playing track.\nChat\nUsing the CLI\nplayerctl [--version] [--list-all] [--all-players] [--player=NAME] [--ignore-player=IGNORE] [--format=FORMAT] COMMAND\n\nHere is a list of available commands:\n\n\n\nCommand\nDescription\n\n\n\n\nplay\nCommand the player to play.\n\n\npause\nCommand the player to pause\n\n\nplay-pause\nCommand the player to toggle between play/pause.\n\n\nstop\nCommand the player to stop.\n\n\nnext\nCommand the player to skip to the next track.\n\n\nprevious\nCommand the player to skip to the previous track.\n\n\nposition [OFFSET][+/-]\nCommand the player to go to the position or seek forward or backward OFFSET in seconds.\n\n\nvolume [LEVEL][+/-]\nPrint or set the volume to LEVEL from 0.0 to 1.0.\n\n\nstatus\nGet the play status of the player. Either \"Playing\", \"Paused\", or \"Stopped\".\n\n\nmetadata [KEY...]\nPrint the metadata for the current track. If KEY is passed, print only those values from the metadata.\n\n\nopen [URI]\nCommand for the player to open a given URI. Can be either a file path or a remote URL.\n\n\nloop [STATUS]\nPrint or set the loop status. Either \"None\", \"Track\", or \"Playlist\".\n\n\nshuffle [STATUS]\nPrint or set the shuffle status. Either \"On\", \"Off\".\n\n\n\nSelecting Players to Control\nWithout specifying any players to control, Playerctl will act on the first player it can find.\nYou can list the names of players that are available to control that are running on the system with playerctl --list-all.\nIf you'd only like to control certain players, you can pass the names of those players separated by commas with the --player flag. Playerctl will select the first instance of a player in that list that supports the command. To control all players in the list, you can use the --all-players flag.\nSimilarly, you can ignore players by passing their names with the --ignore-player flag.\nThe special player name %any can be used in the list of selected players once to match any player not in the list. This can be used to prioritize or deprioritize players.\nExamples:\n# Command the first instance of VLC to play\nplayerctl --player=vlc play\n\n# Command all players to stop\nplayerctl --all-players stop\n\n# Command VLC to go to the next track if it's running. If it's not, send the\n# command to Spotify.\nplayerctl --player=vlc,spotify next\n\n# Get the status of the first player that is not Gwenview.\nplayerctl --ignore-player=Gwenview status\n\n# Command any player to play, but select Chromium last\nplayerctl --player=%any,chromium play\n\n# Command any player to play, but select VLC first\nplayerctl --player=vlc,%any play\nSelecting the Most Recent Player\nPlayerctl comes with a service called playerctld you can use that monitors the activity of media players to select the one with the most recent activity. To use it, simply pass playerctld as the selected player to Playerctl and the service should start automatically (if it doesn't, see the troubleshooting section).\n# Command the most recent player to play\nplayerctl --player=playerctld play\n\nPrinting Properties and Metadata\nYou can pass a format string with the --format argument to print properties in a specific format. Pass the variable you want to print in the format string between double braces like {{ VARIABLE }}. The variables available are either the name of the query command, or anything in the metadata map which can be viewed with playerctl metadata. You can use this to integrate playerctl into a statusline generator.\nFor a simple \"now playing\" banner:\nplayerctl metadata --format \"Now playing: {{ artist }} - {{ album }} - {{ title }}\"\n# prints 'Now playing: Lana Del Rey - Born To Die - Video Games'\nIncluded in the template language are some built-in variables and helper functions for common formatting that you can call on template variables.\n# Prints 'Total length: 3:23'\nplayerctl metadata --format \"Total length: {{ duration(mpris:length) }}\"\n\n# Prints 'At position: 1:16'\nplayerctl position --format \"At position: {{ duration(position) }}\"\n\n# Prints 'Artist in lowercase: lana del rey'\nplayerctl metadata --format \"Artist in lowercase: {{ lc(artist) }}\"\n\n# Prints 'STATUS: PLAYING'\nplayerctl status --format \"STATUS: {{ uc(status) }}\"\n\n\n\nFunction\nArgument\nDescription\n\n\n\n\nlc\nstring\nConvert the string to lowercase.\n\n\nuc\nstring\nConvert the string to uppercase.\n\n\nduration\nint\nConvert the duration to hh:mm:ss format.\n\n\nmarkup_escape\nstring\nEscape XML markup characters in the string.\n\n\ndefault\nany, any\nPrint the first value if it is present, or else print the second.\n\n\nemoji\nstatus or volume\nTry to convert the variable to an emoji representation.\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nplayerName\nThe name of the current player.\n\n\nposition\nThe position of the current track in microseconds\n\n\nstatus\nThe playback status of the current player\n\n\nvolume\nThe volume from 0.0 to 1.0\n\n\nalbum\nThe album of the current track.\n\n\nartist\nThe artist of the current track.\n\n\ntitle\nThe title of the current track.\n\n\n\nFollowing changes\nYou can pass the --follow flag to query commands to block, wait for players to connect, and print the query whenever it changes. If players are passed with --player, players earlier in the list will be preferred in the order they appear unless --all-players is passed. When no player can support the query, such as when all the players exit, a newline will be printed. For example, to be notified of information about the latest currently playing track for your media players, use:\nplayerctl metadata --format '{{ playerName }}: {{ artist }} - {{ title }} {{ duration(position) }}|{{ duration(mpris:length) }}' --follow\nUsing the Library\nTo use a scripting library, find your favorite language from this list and install the bindings library. Documentation for the library is hosted here. For examples on how to use the library, see the examples folder.\nExample Python Script\nThis example uses the Python bindings.\n#!/usr/bin/env python3\n\nfrom gi.repository import Playerctl, GLib\n\nplayer = Playerctl.Player('vlc')\n\n\ndef on_metadata(player, metadata):\n    if 'xesam:artist' in metadata.keys() and 'xesam:title' in metadata.keys():\n        print('Now playing:')\n        print('{artist} - {title}'.format(\n            artist=metadata['xesam:artist'][0], title=metadata['xesam:title']))\n\n\ndef on_play(player, status):\n    print('Playing at volume {}'.format(player.props.volume))\n\n\ndef on_pause(player, status):\n    print('Paused the song: {}'.format(player.get_title()))\n\n\nplayer.connect('status::playing', on_play)\nplayer.connect('status::paused', on_pause)\nplayer.connect('metadata', on_metadata)\n\n# start playing some music\nplayer.play()\n\nif player.get_artist() == 'Lana Del Rey':\n    # I meant some good music!\n    player.next()\n\n# wait for events\nmain = GLib.MainLoop()\nmain.run()\nFor a more complete example which is capable of listening to when players start and exit, see player-manager.py from the official examples.\nTroubleshooting\nDebug Logging\nTo enable debug logging, set the environment variable G_MESSAGES_DEBUG=playerctl. It's helpful to include a debug log when you report issues.\nNo Players Found\nIf you are using Quod Libet as your music player you need to install/activate a plugin for it.\nIn Quod Libet open the window File -> Plugins and select the plugin called MPRIS D-Bus Support.\nSome players like Spotify require certain DBus environment variables to be set which are normally set within the session manager. If you're not using a session manager or it does not set these variables automatically (like xinit), launch your desktop environment wrapped in a dbus-launch command. For example, in your .xinitrc file, use this to start your WM:\nexec dbus-launch --autolaunch=$(cat /var/lib/dbus/machine-id) i3\n\nPlayerctld Autostart Issues\nIf playerctld does not autostart and you use xinit and systemd, you might need this fix to enable DBus activation to work correctly:\nsystemctl --user import-environment DISPLAY XAUTHORITY\n\nif which dbus-update-activation-environment >/dev/null 2>&1; then\n        dbus-update-activation-environment DISPLAY XAUTHORITY\nfi\n\nInstalling\nFirst, check and see if Playerctl is available from your package manager (if it is not, get someone to host a package for you) and also check the releases page on github.\nFedora\nplayerctl is available for Fedora 28 or later:\nsudo dnf install playerctl\n\nMageia, openSUSE\nplayerctl is available for Mageia and openSUSE via this COPR repository. First, install the repository file for your distribution from COPR. Then, install playerctl with your package manager of choice.\nGuix\nplayerctl is available as a Guix package which can be installed on any Linux distribution after installing Guix:\nguix install playerctl\n\nCompile from source\nUsing the cli and library requires GLib (which is a dependency of almost all of these players as well, so you probably already have it). You can use the library in almost any programming language with the associated introspection binding library.\nAdditionally, you also need the following build dependencies:\ngobject-introspection for building introspection data (configurable with the introspection meson option)\ngtk-doc for building documentation (configurable with the gtk-doc meson option)\nFedora users also need to install redhat-rpm-config\nTo generate and build the project to contribute to development and install playerctl to /:\nmeson mesonbuild\nsudo ninja -C mesonbuild install\n\nNote that you need meson >= 0.50.0 installed. In case your distro only has an older version of meson in its repository you can install the newest version via pip:\npip3 install meson\n\nAlso keep in mind that gtk-doc and gobject-introspection are enabled by default, you can disable them with -Dintrospection=false and -Dgtk-doc=false.\nIf you don't want to install playerctl to / you can install it elsewhere by exporting DESTDIR before invoking ninja, e.g.:\nexport PREFIX=\"/usr/local\"\nmeson --prefix=\"${PREFIX}\" --libdir=\"${PREFIX}/lib\" mesonbuild\nexport DESTDIR=\"$(pwd)/install\"\nninja -C mesonbuild install\n\nYou can use it later on by exporting the following variables:\nexport LD_LIBRARY_PATH=\"$DESTDIR/${PREFIX}/lib/:$LD_LIBRARY_PATH\"\nexport GI_TYPELIB_PATH=\"$DESTDIR/${PREFIX}/lib/:$GI_TYPELIB_PATH\"\nexport PATH=\"$DESTDIR/${PREFIX}/bin:$PATH\"\n\nResources\nCheck out the following articles about Playerctl:\n\n2 new apps for music tweakers on Fedora Workstation - Fedora Magazine\nPlayerctl at Version 2.0\n\nRelated projects from the maker of Playerctl:\n\naltdesktop/python-dbus-next - The DBus library used in the Playerctl test suite.\naltdesktop/playerbm - A CLI bookmark utility for audiobooks and podcasts.\ndbusjs/mpris-service - MPRIS implementation for JavaScript targeting Electron apps.\n\nLicense\nThis work is available under the GNU Lesser General Public License (See COPYING).\nCopyright © 2014, Tony Crisci\n\n\n\n\n\n\n\n\nAbout\n\n🎧 mpris command-line controller and library for vlc, audacious, bmp, cmus, spotify and others.\n    \n\n\n\ndubstepdish.com/index.php/2018/10/21/playerctl-at-version-2-0/\n\n\nTopics\n\n\n\n  mpris\n\n\n  cli\n\n\n  vlc\n\n\n  mediaplayer\n\n\n  c\n\n\n  cmus\n\n\n  mopidy\n\n\n  audacious\n\n\n  rhythmbox\n\n\n  mpd\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        LGPL-3.0 License\n    \n\n\n\n\n\n\n\n    Releases\n      16\n\n\n\n\n\nVersion 2.2.1\n\n          Latest\n \nAug 8, 2020\n\n \n\n        + 15 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 24\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 13 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\nC\n83.7%\n\n\n\n\n\nPython\n12.4%\n\n\n\n\n\nMeson\n2.1%\n\n\n\n\n\nShell\n1.2%\n\n\n\n\n\nOther\n0.6%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# playerctl\n\n> Utility to control different media players.\n> More information: <https://github.com/altdesktop/playerctl>.\n\n- Toggle play:\n\n`playerctl play-pause`\n\n- Next media:\n\n`playerctl next`\n\n- Previous media:\n\n`playerctl previous`\n\n- List all players:\n\n`playerctl --list-all`\n\n- Send a command to a specific player:\n\n`playerctl --player={{player_name}} {{command}}`\n\n- Send a command to all players:\n\n`playerctl --all-players {{command}}`\n\n- Show now playing:\n\n`playerctl metadata --format \"Now playing: {{artist}} - {{album}} - {{title}}\"`\n"
 },
 {
   "command": "lsb_release",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lsb_release\n\n> Provides certain LSB (Linux Standard Base) and distribution-specific information.\n\n- Print all available information:\n\n`lsb_release -a`\n\n- Print a description (usually the full name) of the operating system:\n\n`lsb_release -d`\n\n- Print only the operating system name (ID), suppressing the field name:\n\n`lsb_release -i -s`\n\n- Print the release number and codename of the distribution, suppressing the field names:\n\n`lsb_release -rcs`\n"
 },
 {
   "command": "opkg",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# opkg\n\n> A lightweight package manager used to install OpenWrt packages.\n\n- Install a package:\n\n`opkg install {{package}}`\n\n- Remove a package:\n\n`opkg remove {{package}}`\n\n- Update the list of available packages:\n\n`opkg update`\n\n- Upgrade all the installed packages:\n\n`opkg upgrade`\n\n- Upgrade one or more specific package(s):\n\n`opkg upgrade {{package(s)}}`\n\n- Display informations for a specific package:\n\n`opkg info {{package}}`\n\n- List all the available packages:\n\n`opkg list`\n"
 },
 {
   "command": "usermod",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# usermod\n\n> Modifies a user account.\n\n- Change a user's name:\n\n`usermod -l {{newname}} {{user}}`\n\n- Add user to supplementary groups (mind the whitespace):\n\n`usermod -a -G {{group1,group2}} {{user}}`\n\n- Create a new home directory for a user and move their files to it:\n\n`usermod -m -d {{/path/to/home}} {{user}}`\n"
 },
 {
   "command": "run-mailcap",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# run-mailcap\n\n> Run MailCap Programs.\n> Run mailcap view, see, edit, compose, print - execute programs via entries in the mailcap file (or any of its aliases) will use the given action to process each mime-type/file.\n\n- Individual actions/programs on run-mailcap can be invoked with action flag:\n\n`run-mailcap --action=ACTION [--option[=value]]`\n\n- In simple language:\n\n`run-mailcap --action=ACTION {{filename}}`\n\n- Turn on extra information:\n\n`run-mailcap --action=ACTION --debug {{filename}}`\n\n- Ignore any \"copiousoutput\" directive and forward output to standard output:\n\n`run-mailcap --action=ACTION --nopager {{filename}}`\n\n- Display the found command without actually executing it:\n\n`run-mailcap --action=ACTION --norun {{filename}}`\n"
 },
 {
   "command": "lynis",
   "doc_url": "https://cisofy.com/documentation/lynis/",
   "doc_text": "Lynis Installation and Usage Guide - CISOfySolutionsDemoPricingSupportAboutHomeSupportLynis documentationLynis DocumentationInstallation and Usage\nFirst time user of Lynis? Get Started\nWant to read this document offline, or as a PDF? Use the printer icon in the right corner for easy access.Table of ContentsLynis Installation and UsageIntroductionInstallationUsing LynisBasicsCommands, Options, and ArgumentsSuggestions and WarningsBehind the scenesProfilesHostIDsLynis ConfigurationLynis PluginsLynis EnterpriseLynis Enterprise APILynis Enterprise (self-hosted)Lynis CollectorLynisIntroductionLynis is an open source security tool. It helps with auditing systems running UNIX-alike systems (Linux, macOS, BSD), and providing guidance for system hardening and compliance testing. This document contains the basics to use the software.InstallationThe installation of Lynis is explained in the Get Started guide.Using LynisBasicsBy running 'lynis' the program is started and will provide the basic parameters available. If you manually extracted Lynis (or used Git), then use './lynis' to start the program from the local directory.The most common command to start Lynis is using audit system command. This still start the security scan.\nTo run Lynis you should meet one requirement: have write access to /tmp (temporary files)Commands, Options, and ArgumentsIntroductionThe behavior of programs can influenced with commands, arguments, and options. These terms are often mixed up, so we start with a quick introduction.Commands tell the program what to do. An option tells the program how to do it. If an argument is used, it tell on what it applies. Arguments usually follow an option, like a filename, or a target.Example$ ./lynis audit system --quick --auditor \"The Auditor\"In this example we tell Lynis to audit (command), with the target system (argument). By using the --quick (option), we tell it not to wait. We used --auditor (option) and defined it as \"The Auditor\" (argument).Lynis CommandsThe Lynis tool requires a minimum amount of parameters to run. If you are using it for the first time, just run lynis and see what output it provides.$ ./lynisWithout any commands, Lynis will display its status, together with suggestions on how to start.AuditThe audit command tells Lynis to perform an audit.Targets include:system - audit the host systemdockerfile - audit a dockerfileShowThe show command informs Lynis to share information, like help or the value of something.Examples:help - show help and tipsprofiles - show discovered audit profilessettings - show active settingsversion - show Lynis versionParametersIn the table below, the most commonly used parameters are listed.ParameterAbbreviatedDescription--auditor \"Name\" Assign an auditor name to the audit (report)--checkall-cStart the check--check-update Check if Lynis is up-to-date--cronjob Run Lynis as cronjob (includes -c -Q)--help-hShows valid parameters--manpage View man page--nocolors Do not use any colors--pentest Perform a penetration test scan (non-privileged)--quick-QDon't wait for user input, except on errors--quiet Only show warnings (includes --quick, but doesn't wait)--reverse-colors Use a different color scheme for light backgrounds--version-VCheck program version (and quit)TipsIf Lynis is not installed as package (with included man page), use --man or nroff -man ./lynis.8For systems where the shell background is light, use --nocolors or --reverse-colorsUse lynis show options to see all available parameters of LynisProfilesLynis uses profiles to have a set of predefined options for your operating system and preferences. If you don't provide a profile (--profile <name>), the default profile (default.prf) will be used. You are advised to copy the default.prf and adjust it to your needs.With the usage of profiles, you can make a template/baseline for different types of systems.Examples:Profile per operating system (Debian Linux, RedHat Linux, OpenBSD)Profile per system roles (mail server, web server)Profile per security level (low, medium, high level)HostIDsDuring the security audit, Lynis attempts to assign two identifiers to the system. They can be compared as fingerprints and can be used in other tools and to link data to an existing system.Identifiers: hostid and hostid2The first identifier is named hostid and has a length of 40 characters. The MAC address of the system is typically used its data input. The second identifier is hostid2. It is 64 characters long and typically uses a public SSH key a data input.lynis show hostidsOverriding the identifiersIn case your system can not generate the host identifiers automatically, then you can specify them in your custom profile (custom.prf). This can also be useful when systems are short-lived, yet you want to link the same data to such instance.lynis configure settings hostid=$(head -c 64 /dev/random | sha1sum | awk '{print $1}'):hostid2=$(head -c 64 /dev/random | sha256sum | awk '{print $1}')One-liner to generate both IDs and add them to the configurationImportant notesOnly override the host identifiers when really neededMake sure that the identifiers are unique for every individual systemWhen using this option, both values for hostid and hostid2 need to be set in the profileScreen output\nWhile Lynis scans a system it will perform single target tests and output the result of every (performed) test to the screen. Every\nscan result has to be interpreted by the auditor and (re)checked what it means.\nBehind most tests, it will output [OK] or [WARNING], where the first one is considered an expected (good) result, the second\none unexpected. However, keep in mind that a result saying \"[OK]\" does NOT always mean the scanned target is correctly configured, safe (security wise) or a best practice.\nOn the opposite, every \"[WARNING]\" doesn't have to be 'bad', since systems (and their requirements) are different. However, as auditor you are adviced to pay attention to them and check what influence the test has on your system or policy. \n\nActions you can take after getting a warning:\n- Fix the problem\nRead the log file about the technical background (often it contains a suggestion at the test), consult internet sources\nand documentation about what the impact of the change can be.\n- Disable the test (whitelisting)\nWithin the scan profile, tests can be completely disabled (option test_skip_always).\nWhen you have a test which gives a warning and you are not interested in the result of that particular test, you can ingore it.For example:\nYou have only one DNS server configured on your workstation. A test\nshows a warning and reveals that it expects at least two working name servers. In\nsuch case you can choose not to get informed about it and disable the test. Extend the option test_skip_always\nin your scanning profile with the test number (which can be found in the log file or at the end of the Lynis screen output).\n After every scan, the auditor should consult the log file (/var/log/lynis.log) and interpreter the results. If tests are displayed as a \"[WARNING]\",\nthe log file will  give the reason why a warning was displayed. In most cases a \"Suggestion:\" line will be present, to assist in resolving the issue or give more information what was tested (or expected).Suggestions and WarningsThe screen output, as outlined in previous section, will provide the status of most tests on screen. During the audit proces, Lynis will gather\nany possible suggestion or warning. These results will be grouped and displayed at the bottom of screen output. Usually warnings are events which really need\nan action.Suggestions on the other hand could indicate room for improvement. It's common to find much more suggestions than warnings. This does not imply\nthat because there are many suggestions (and no warnings) that a system is properly secured!To determine what has been checked together with the related suggestion/warning, the test identifier is displayed on the same line (between brackets). Open\nthe lynis log file (/var/log/lynis.log) and search for this identifier.Plugins\nLynis plugins are extensions to the Lynis core. Where normal Lynis controls perform individual tests and share the outcome, plugins will usually just gather information. This information is\nthen collected and processed in bulk. The big benefit is that is quicker and more powerful. For example security intelligence can be applied by collecting data and correlating it on the central\nnode.Plugin phases\nLynis has modular support to extend basic functionality by using plugins. Plugins are executed in several phases:Plugins: Phase 1\nPlugins which do use hooks into existing tests, or gather data for later processing, will use phase 1 to initialize. Some tests which are part of the plugin will then finish in phase 2.Plugins: Phase 2\nAfter running all tests, plugins get a last chance to do their job. For example parse discovered elements on the system, like a virtual host within Apache.\n\nPlugins which can be used standalone (e.g. no hooks, no input from existing tests), can be executed in phase 1. No need for a phase 2 component.Enabling plugins:\nPlugins can be enabled by using the plugin option within the profile.\nExample: plugin=<custom_myplugin>Plugin directory\nThe directory in which plugins can be stored is determined by Lynis. By default it tries a few paths (/usr/local/lynis/plugins /usr/local/share/lynis/plugins /usr/share/lynis/plugins and /etc/lynis/plugins). If these directories\nare not found, then the local work directory is being used. To use a different directory, use the --plugin-dir parameter, followed by the directory name.Custom plugins\nWhen creating personal plugins, you are adviced to add a personal prefix and making the file name unique (ie. custom_myplugin). This prevents the file\nbeing overwritten at a new release. If you just want an invidual test, you are advised to use the custom_test file instead, as plugins have a different goal.\nIf you consider writing a plugin, we ask you to contact us to determine the possibilities.5. Reporting and Logging\nLynis supports one report format, which can be used to gather results and display them in a custom or (more) friendly\npresentation. The report file can also be used to compare scan results from the past with a current scan. Lynis Enterprise on the other hand has much more possibilities\nto display data, including extended reports in several formats.\nContents of report file:\n- Remarks: #<remark>\n- Section: [<section name>]\n- Option/value: <option name>=<value of option>\nWhen an option may have multiple values (like installed packages for example), brackets ([]) are added. Example: installed_package[]=Package-1.0.0Logging\nWhen a system is scanned and results are displayed, additional debugging information will be added to the log file (default: /var/log/lynis.log). For advanced testers\nthis information will be useful to see what the program did in the background or where anomalies showed up (and often why).\nInformation in the log file:\n- Time of an action/event\n- Reason(s) why a test failed or will be skipped\n- Output of (internal) tests and sub tests\n- Suggestions about configuration options or how to fix/improve things\n- Threat/impact scoreRemark: the log file\nwill be purged every scan. If you need debugging or logging information for previous scans, schedule log rotation or make a backup before running Lynis again.6. Integration with Lynis EnterpriseLynis data can be uploaded via the --upload option. For companies using multiple systems, the Lynis Collector is usually the preferred option. This\nspecific tool has more capabilities and features to deal with batches of data. Both the --upload parameter and Lynis Collector, are meant to upload data to the central node.Upload via LynisAdd the license key in in the scan profile (default.prf or your customized profile). After adjusting, use the --upload parameter to upload the data after scanning.For data uploads, the cURL utility is being used. For environments which require a proxy, the profile allows you to define any options given to cURL, like --proxy.\nIn case a self-signed certificate is being used on the central node, you can disable full certificate checking with the --insecure option.Upload via Lynis CollectorAn alternative option is to use Lynis Collector. This tool allows uploads from a central machine with an internet connection available. This way other machines within the network don't need direct access.\nLynis Collector is available for customers in the downloads section. See part II for more details about this component.Part II: Lynis CollectorIntroductionThe Collector component within the Lynis suite, is a supporting tool. It collects reports from many systems and uploads it in one batch. It is available to users\nof the Enterprise solution. Only one Collector is usually needed within the network.See the Lynis Collector documentation for full details.Part III: Lynis EnterpriseIntroductionRequirementsTo use Lynis Enterprise, you need a license key and an active user account. An account can be created during the ordering process or before.\nManagement happens with a web based solution. No external plugins have to be installed to work with our solution.For auditing purposes, Lynis needs to be configured on the systems that are to be audited. Optionally the Lynis Collector can be used\nto collect data, then upload it to the central system.Please refer to Section I and Section II to install and configure these components.14. Account ManagementAn account on the Lynis Enterprise service provides access to the systems and configuration of a company. Each account can be linked only\nto one company.15. Management of systemsAdding new systemDuring the life cycle of a system, it can be easily added by uploading the data to Lynis Enterprise. If the unique ID of the system is not known\nyet, the system will be added to the pool of machines.RemovingWhen a system is being decommissioned, the absence of new scan data will be noticed and a related event will be raised. If the system is to\nbe removed altogether, select the system and use the delete icon (  ).16. Security hardening\nOne of the main components of Lynis and Lynis Enterprise is to provide guidance in security hardening of systems. Per system the related\nsecurity controls are listed. The Enterprise edition includes an implementation plan, customized to your environment. This way help\nis provided to select which controls.17. Compliance and Baselines\nBaselines provide a means to check for a defined policy and report about the compliance with the policy. Each system can be linked\nto a baseline of choice.18. Change managementMore details will follow later19. Event handling\nEvents within the Lynis Enterprise solution are used to inform the administrator(s) about a specific activity. This includes exceeding\na warning threshold or for example missing data. Usually an event is a call to action and check the related component.20. Software upgrades\nSince Lynis will be often updated to support new tests and software, performing regular updates is advised. Depending on the installation\nmethod there are two options to stay up-to-date:Option 1. Using software packages\nIf the platform(s) used provides an up-to-date Lynis package, it could be used as part of your software upgrade strategy.In case the\nvendor maintains only \"stable\" releases, they will usually not release newer versions of Lynis, until the next OS release. Then you\nmight consider creating a Lynis package yourself. See the Tips section on how to create a package.Option 2. No install\nInstead of installing Lynis at all, a cronjob could be used to fetch the latest Lynis package from an internal server (e.g. HTTP/FTP/SCP/NFS). The cronjob\nfirst extracts the tarball into a temporary directory. Then it runs Lynis from there, and before cleaning up, it sends the data to the Lynis Collector.Updating to a new release would mean the administrator will test the new version first on a few systems and then upload it to the central location. From that very moment\nall systems will be using the latest version.Tips and SuggestionsStaying up-to-date\nStaying up-to-date with software is important to have access to the latest functionality and make sure that known bugs have been\nsolved. Since Lynis is an auditing tool, it's possibly even more important to keep up with the latest version. Right now we\ndon't provie auto-updating yet. We believe strongly that people should test software releases before applying them into production.\nTo get notified when new releases are available, the following options are available:Notification list\nAt our Downloads page you can subscribe to the notification list. When a new release is available, you get an email with the changes.\nTwitter\nFollow founder Michael Boelen (@mboelen) and our company @cisofy_isLynis --check-update\nFor monitoring purposes or to notify yourself, it's possible to parse the output of Lynis while it checks for the latest version. If the output is \"Outdated\", a new version is available.\nBackground information: Lynis uses DNS to check for the latest version by using a TXT record query.Building your own packages\nFor companies or individuals who prefer their own packages, there is a lynis.spec file available. Building a RPM is very easy due to the low number of dependencies\nof Lynis and consists of the following steps:Package creation:\nTo create a custom package for installation on your machine(s):\n- Download lynis.spec file (see project page)\n- Adjust version number and if needed, paths\n- Run 'rpmbuild -ta lynis-version.tar.gz' to build the RPM package\n- Install package by running: rpm -ivh <filename>Error: You have to be root (or equivalent) to perform an audit. Please su(do) and try again.Lynis needs to be executed as root for a full audit. Change to the root and execute Lynis again. Sudo might work as well. If you don't have root permissions, use the --pentest option.Error: Change ownership of ./include/const and ./include/functions to 'root'To protect alteration of the files, Lynis perform a few security checks. If the related files are not owned by root, or their permissions are not strict enough, Lynis will\nshow this on screen, including the commands to fix it. Usually it is caused because files were untarred by a user other than root.Part V: Support\nLynis is tested on the most common operating systems. The documentation (README, FAQ) and the debugging information in the log file usually provides\nthe answer to most questions (or problems). Bugs can be reported by contacting us. Commercial support is available.Part VI: Frequently Asked QuestionsIs Lynis really free?\nYes, Lynis is open source and free to use. By default it comes without warranties or support, as described in the Lynis package. If you prefer support,\nthen integration with Lynis Enterprise is better suitable for your needs.Is Lynis restricted in functionality, compared to Enterprise version?\nThere are no limitations regarding functionality. Lynis is also part of the Enterprise version, therefore it has full functionality.\nCompanies benefit from using the Enterprise version, as it includes additional plugins.What systems are supported?\nAll common systems based on Unix/Linux are supported. Examples include Linux, AIX, *BSD, HP-UX, macOS and Solaris.\n\nFor package management are the following tools supported:\n- dpkg/apt, pacman, pkg_info, RPM, YUM, zypperWhat is the difference between Lynis and Lynis Enterprise?Lynis is an open source auditing tool, focused on auditing single Linux or Unix based systems.Lynis Enterprise is a centralized auditing system, with additional reporting, ready-to-use hardening scripts, monitoring and dashboards. Primary benefits is saving time by automation and always having up-to-date reports at hand.Product comparisonCan I create my own tests?\nSure you can! Lynis has a test category named \"custom\" (filename tests_custom). If this file exists, it will execute your own defined tests.\nWhile creating your own tests is totally fine, please consider if others could benefit from them as well by sharing them with us. We accept most\ntests and give you the appropriate credit (or keep it anonymous if preferred).The colors used are hard to read with my white background, how can I solve this?Disable color usage or use the --reverse-colors optionWhat is the difference between a normal test and a plugin?\nWhile both are similiar in what they can do, a test has the main goal of performing a check and directly form a conclusion (something is present or not, the outcome is good or bad etc). The\npurpose of plugins is to collect data for later use. In particular the Lynis Enterprise solution will use plugins to collect extra data which will be later analyzed. One example would be\nto determine exceptions or outliers. It would not make sense to have everyone build up databases of data, while all information is already centrally stored.Is it possible to become reseller of Lynis?Yes. Please contact us for the possibilites.How can I verify the downloadsAfter downloading, test the file to confirm the integrity of the download. The related SHA1 and SHA256 hash are provided on the website as well. Depending on your OS, this\ncan be performed with the command sha1, sha1sum or with openssl.\n $ sha1sum lynis-version.tar.gz\n $ sha256sum lynis-version.tar.gz\n $ sha1 lynis-version.tar.gz\n $ sha256 lynis-version.tar.gz\n $ openssl sha1 lynis-version.tar.gz\n $ openssl sha256 lynis-version.tar.gz\nThe resulting hash displayed should be the same as on the website. If not, try downloading it on another machine or via a browser, to confirm the download\nwas not corrupted. If the hash still shows a different value, please contact us.4. Verification - SignatureIf you have GnuPG installed on your system, you can download our public key (https://cisofy.com/files/cisofy-software.pub) and the related signature of the download itself. The signature itself\nis a file with the extension .asc.\n$ wget https://cisofy.com/files/cisofy-software.pub\n$ gpg --import cisofy-software.pub\n$ gpg --list-keys --fingerprint\n/home/user/.gnupg/pubring.gpg\n------------------------\npub   4096R/D5B79251 2014-11-04 [expires: 2030-10-31]\n      Key fingerprint = 73AC 9FC5 5848 E977 024D  1A61 429A 566F D5B7 9251\nuid                  CISOfy (Software Signing Key) <security@cisofy.com>\nsub   4096R/6E8847E1 2014-11-04 [expires: 2030-10-31]\nVerify that the results are the same as listed above. Next step is verifying the download:\n$ gpg --verify lynis-version.tar.gz.asc lynis-version.tar.gz\ngpg: Signature made Wed 05 Nov 2014 12:39:26 AM CET using RSA key ID D5B79251\ngpg: Good signature from \"CISOfy (Software Signing Key) <security@cisofy.com>\"\ngpg: WARNING: This key is not certified with a trusted signature!\ngpg:          There is no indication that the signature belongs to the owner.\nPrimary key fingerprint: 73AC 9FC5 5848 E977 024D  1A61 429A 566F D5B7 9251\nNote: The warning is displayed as the system simply does not not know if it is trusted. As there is no central authority to validate, you can mark the key as trusted yourself.\nBefore doing so, we have some tips to make sure you are using the right key:Compare the key output you get, with the results on this pageCheck DNS entry cisofy-software-key.cisofy.com, it should give the same fingerprint.\n$ host -t txt cisofy-software-key.cisofy.com\ncisofy-software-key.cisofy.com descriptive text \"Key fingerprint =\n73AC 9FC5 5848 E977 024D  1A61 429A 566F D5B7 9251\"\n\n$ gpg --edit-key security@cisofy.com\ngpg (GnuPG) 1.4.16; Copyright (C) 2013 Free Software Foundation, Inc.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\npub  4096R/D5B79251  created: 2014-11-04  expires: 2030-10-31  usage: SC\n                     trust: unknown       validity: unknown\nsub  4096R/6E8847E1  created: 2014-11-04  expires: 2030-10-31  usage: E\n[ unknown] (1). CISOfy (Software Signing Key) <security@cisofy.com>\n\ngpg> trust\npub  4096R/D5B79251  created: 2014-11-04  expires: 2030-10-31  usage: SC\n                     trust: unknown       validity: unknown\nsub  4096R/6E8847E1  created: 2014-11-04  expires: 2030-10-31  usage: E\n[ unknown] (1). CISOfy (Software Signing Key) <security@cisofy.com>\n\nPlease decide how far you trust this user to correctly verify other users' keys\n(by looking at passports, checking fingerprints from different sources, etc.)\n\n  1 = I don't know or won't say\n  2 = I do NOT trust\n  3 = I trust marginally\n  4 = I trust fully\n  5 = I trust ultimately\n  m = back to the main menu\n\nYour decision? 5\nDo you really want to set this key to ultimate trust? (y/N) y\n\npub  4096R/D5B79251  created: 2014-11-04  expires: 2030-10-31  usage: SC\n                     trust: ultimate      validity: unknown\nsub  4096R/6E8847E1  created: 2014-11-04  expires: 2030-10-31  usage: E\n[ unknown] (1). CISOfy (Software Signing Key) <security@cisofy.com>\nPlease note that the shown key validity is not necessarily correct\nunless you restart the program.\n\ngpg> quitNow the key has be marked as being trusted and the related warning will be gone when verifying our downloads.Note: ultimate trust is the most extensive type of trust in a key. You may also use option 4 (I trust fully).Lynis is copyrighted by Michael Boelen, CISOfy, and licensed under the GPLv3 license.SolutionsSoftwareLynisDownloadsDocumentationLynis EnterpriseFeaturesDemoTopicsComplianceCommunityLynis on GitHubSoftware packagesLinux Audit BlogDocumentation and QuestionsSupportFrequently Asked Questions@cisofy_isAbout CISOfyCISOfy is an independent software company with solutions in the field of information security. Bootstrapped since 2013 and a focus on the long term.About UsContactLegalPrivacySecuritySitemapOur privacy promises:No tracking code on our websiteLimited external scriptsReduced data collection",
   "man_entry": "",
   "tldr_summary": "# lynis\n\n> System and security auditing tool.\n> More information: <https://cisofy.com/documentation/lynis/>.\n\n- Check that Lynis is up-to-date:\n\n`sudo lynis update info`\n\n- Run a security audit of the system:\n\n`sudo lynis audit system`\n\n- Run a security audit of a Dockerfile:\n\n`sudo lynis audit dockerfile {{path/to/dockerfile}}`\n"
 },
 {
   "command": "update-rc.d",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# update-rc.d\n\n> Install and remove services which are System-V style init script links.\n> Init scripts are in the /etc/init.d/.\n\n- Install a service:\n\n`update-rc.d {{mysql}} defaults`\n\n- Enable a service:\n\n`update-rc.d {{mysql}} enable`\n\n- Disable a service:\n\n`update-rc.d {{mysql}} disable`\n\n- Forcibly remove a service:\n\n`update-rc.d -f {{mysql}} remove`\n"
 },
 {
   "command": "vmware-checkvm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# vmware-checkvm\n\n> Checks to see if the current host is a VMWare VM or not.\n\n- Return the current VMWare software version (exit status determines whether the system is a VM or not):\n\n`vmware-checkvm`\n\n- Return the VMWare hardware version:\n\n`vmware-checkvm -h`\n"
 },
 {
   "command": "smbpasswd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# smbpasswd\n\n> Change a user's SMB password.\n> Samba users must also have a local Unix account.\n\n- Change the current user's SMB password:\n\n`smbpasswd`\n\n- Add a specified user to Samba and set password(user should already exist in system):\n\n`smbpasswd -a {{username}}`\n\n- Modify an existing Samba user's password:\n\n`smbpasswd {{username}}`\n\n- Delete a Samba user:\n\n`smbpasswd -x {{username}}`\n"
 },
 {
   "command": "do-release-upgrade",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# do-release-upgrade\n\n> The Ubuntu release upgrader.\n\n- Upgrade to the latest release:\n\n`sudo do-release-upgrade`\n\n- Upgrade to the latest development release:\n\n`sudo do-release-upgrade --devel-release`\n\n- Upgrade to the latest proposed release:\n\n`sudo do-release-upgrade --proposed`\n"
 },
 {
   "command": "archey",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# archey\n\n> Simple tool for stylishly displaying system information.\n\n- Show system information:\n\n`archey`\n"
 },
 {
   "command": "nixos-rebuild",
   "doc_url": "https://nixos.org/nixos/manual/#sec-changing-config",
   "doc_text": "\n\nNixOS - NixOS 20.03 manual\n\n\n\n\n\n\n\n\n\n\n\n\n\nNixOS\n\n\n\n\n\n\n\n Features\n Download\n Learn\n Community\n Governance\n Donate \n\n\n\n\nNixOS ManualVersion 20.03\n  Appendix A. Configuration Options →Table of ContentsPrefaceI. Installation1. Obtaining NixOS2. Installing NixOS3. Changing the Configuration4. Upgrading NixOSII. Configuration5. Configuration Syntax6. Package Management7. User Management8. File Systems9. X Window System10. Xfce Desktop Environment11. Networking12. Linux Kernel13. Pantheon Desktop14. Matomo15. Nextcloud16. Grocy17. Prometheus exporters18. WeeChat19. Taskserver20. Matrix21. Gitlab22. Trezor23. Emacs24. Flatpak25. PostgreSQL26. FoundationDB27. Hiding process information28. SSL/TLS Certificates with ACME29. Oh my ZSH30. Plotinus31. Digital Bitbox32. Input Methods33. Profiles34. KubernetesIII. Administration35. Service Management36. Rebooting and Shutting Down37. User Sessions38. Control Groups39. Logging40. Cleaning the Nix Store41. Container Management42. TroubleshootingIV. Development43. Getting the Sources44. Writing NixOS Modules45. Building Specific Parts of NixOS46. Writing NixOS Documentation47. Building Your Own NixOS CD48. NixOS Tests49. Testing the Installer50. ReleasesA. Configuration OptionsB. Release NotesPreface\n  This manual describes how to install, use and extend NixOS, a Linux\n  distribution based on the purely functional package management system\n  Nix, that is composed\n  using modules and packages defined in the\n  Nixpkgs project.\n \n  Additional information regarding the Nix package manager and the Nixpkgs\n  project can be found in respectively the\n  Nix manual and the\n  Nixpkgs manual.\n \n  If you encounter problems, please report them on the\n  Discourse or\n  on the \n#nixos channel on Freenode. Bugs should be\n  reported in\n  NixOS’\n  GitHub issue tracker.\n Note: \n   Commands prefixed with # have to be run as root, either\n   requiring to login as root user or temporarily switching to it using\n   sudo for example.\n  Part I. Installation\n   This section describes how to obtain, install, and configure NixOS for\n   first-time use.\n  Table of Contents1. Obtaining NixOS2. Installing NixOS3. Changing the Configuration4. Upgrading NixOSChapter 1. Obtaining NixOS\n  NixOS ISO images can be downloaded from the\n  NixOS download\n  page. There are a number of installation options. If you happen to\n  have an optical drive and a spare CD, burning the image to CD and booting\n  from that is probably the easiest option. Most people will need to prepare a\n  USB stick to boot from. Section 2.5.1, “Booting from a USB Drive” describes the\n  preferred method to prepare a USB stick. A number of alternative methods are\n  presented in the\n  NixOS\n  Wiki.\n \n  As an alternative to installing NixOS yourself, you can get a running NixOS\n  system through several other means:\n  \n     Using virtual appliances in Open Virtualization Format (OVF) that can be\n     imported into VirtualBox. These are available from the\n     NixOS download\n     page.\n    \n     Using AMIs for Amazon’s EC2. To find one for your region and instance\n     type, please refer to the\n     list\n     of most recent AMIs.\n    \n     Using NixOps, the NixOS-based cloud deployment tool, which allows you to\n     provision VirtualBox and EC2 NixOS instances from declarative\n     specifications. Check out the\n     NixOps homepage for\n     details.\n    \nChapter 2. Installing NixOSTable of Contents2.1. Booting the system2.2. Partitioning and formatting2.3. Installing2.4. Installation summary2.5. Additional installation notes2.1. Booting the system\n   NixOS can be installed on BIOS or UEFI systems. The procedure for a UEFI\n   installation is by and large the same as a BIOS installation. The\n   differences are mentioned in the steps that follow.\n  \n   The installation media can be burned to a CD, or now more commonly, \"burned\"\n   to a USB drive (see Section 2.5.1, “Booting from a USB Drive”).\n  \n   The installation media contains a basic NixOS installation. When it’s\n   finished booting, it should have detected most of your hardware.\n  \n   The NixOS manual is available on virtual console 8 (press Alt+F8 to access)\n   or by running nixos-help.\n  \n   You are logged-in automatically as nixos.\n   The nixos user account has an empty password so you\n   can use sudo without a password.\n  \n   If you downloaded the graphical ISO image, you can run systemctl\n   start display-manager to start the desktop environment. If you want to continue on the\n   terminal, you can use loadkeys to switch to your\n   preferred keyboard layout. (We even provide neo2 via loadkeys de\n   neo!)\n  2.1.1. Networking in the installer\n    The boot process should have brought up networking (check ip\n    a). Networking is necessary for the installer, since it will\n    download lots of stuff (such as source tarballs or Nixpkgs channel\n    binaries). It’s best if you have a DHCP server on your network. Otherwise\n    configure networking manually using ifconfig.\n   \n    To manually configure the network on the graphical installer, first disable\n    network-manager with systemctl stop NetworkManager.\n   \n    To manually configure the wifi on the minimal installer, run\n    wpa_supplicant -B -i interface -c <(wpa_passphrase 'SSID'\n    'key').\n   \n    If you would like to continue the installation from a different machine you\n    need to activate the SSH daemon via systemctl start\n    sshd. You then must set a password for either root or\n    nixos with passwd to be able to login.\n   2.2. Partitioning and formatting\n   The NixOS installer doesn’t do any partitioning or formatting, so you need\n   to do that yourself.\n  \n   The NixOS installer ships with multiple partitioning tools. The examples\n   below use parted, but also provides\n   fdisk, gdisk,\n   cfdisk, and cgdisk.\n  \n   The recommended partition scheme differs depending if the computer uses\n   Legacy Boot or UEFI.\n  2.2.1. UEFI (GPT)\n    Here's an example partition scheme for UEFI, using\n    /dev/sda as the device.\n    Note: \n      You can safely ignore parted's informational message\n      about needing to update /etc/fstab.\n     \n\n\n       Create a GPT partition table.\n# parted /dev/sda -- mklabel gpt\n\n       Add the root partition. This will fill the disk\n       except for the end part, where the swap will live, and the space left in\n       front (512MiB) which will be used by the boot partition.\n# parted /dev/sda -- mkpart primary 512MiB -8GiB\n\n       Next, add a swap partition. The size required will\n       vary according to needs, here a 8GiB one is created.\n# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%\nNote: \n         The swap partition size rules are no different than for other Linux\n         distributions.\n        \n\n       Finally, the boot partition. NixOS by default uses\n       the ESP (EFI system partition) as its /boot\n       partition. It uses the initially reserved 512MiB at the start of the\n       disk.\n# parted /dev/sda -- mkpart ESP fat32 1MiB 512MiB\n# parted /dev/sda -- set 3 boot on\n\n\n    Once complete, you can follow with\n    Section 2.2.3, “Formatting”.\n   2.2.2. Legacy Boot (MBR)\n    Here's an example partition scheme for Legacy Boot, using\n    /dev/sda as the device.\n    Note: \n      You can safely ignore parted's informational message\n      about needing to update /etc/fstab.\n     \n\n\n       Create a MBR partition table.\n# parted /dev/sda -- mklabel msdos\n\n       Add the root partition. This will fill the the disk\n       except for the end part, where the swap will live.\n# parted /dev/sda -- mkpart primary 1MiB -8GiB\n\n       Finally, add a swap partition. The size required\n       will vary according to needs, here a 8GiB one is created.\n# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%\nNote: \n         The swap partition size rules are no different than for other Linux\n         distributions.\n        \n\n\n    Once complete, you can follow with\n    Section 2.2.3, “Formatting”.\n   2.2.3. Formatting\n    Use the following commands:\n    \n       For initialising Ext4 partitions: mkfs.ext4. It is\n       recommended that you assign a unique symbolic label to the file system\n       using the option -L label,\n       since this makes the file system configuration independent from device\n       changes. For example:\n\n# mkfs.ext4 -L nixos /dev/sda1\n\n       For creating swap partitions: mkswap. Again it’s\n       recommended to assign a label to the swap partition: -L\n       label. For example:\n\n# mkswap -L swap /dev/sda2\n\n         UEFI systems\n        \n          For creating boot partitions: mkfs.fat. Again\n          it’s recommended to assign a label to the boot partition:\n          -n label. For example:\n\n# mkfs.fat -F 32 -n boot /dev/sda3\n\n       For creating LVM volumes, the LVM commands, e.g.,\n       pvcreate, vgcreate, and\n       lvcreate.\n      \n       For creating software RAID devices, use mdadm.\n      \n2.3. Installing\n     Mount the target file system on which NixOS should be installed on\n     /mnt, e.g.\n\n# mount /dev/disk/by-label/nixos /mnt\n\n\n       UEFI systems\n      \n        Mount the boot file system on /mnt/boot, e.g.\n\n# mkdir -p /mnt/boot\n# mount /dev/disk/by-label/boot /mnt/boot\n\n\n     If your machine has a limited amount of memory, you may want to activate\n     swap devices now (swapon\n     device). The installer (or rather,\n     the build actions that it may spawn) may need quite a bit of RAM,\n     depending on your configuration.\n\n# swapon /dev/sda2\n\n     You now need to create a file\n     /mnt/etc/nixos/configuration.nix that specifies the\n     intended configuration of the system. This is because NixOS has a\n     declarative configuration model: you create or edit a\n     description of the desired configuration of your system, and then NixOS\n     takes care of making it happen. The syntax of the NixOS configuration file\n     is described in Chapter 5, Configuration Syntax, while a list\n     of available configuration options appears in\n     Appendix A, Configuration Options. A minimal example is shown in\n     Example 2.4, “NixOS Configuration”.\n    \n     The command nixos-generate-config can generate an\n     initial configuration file for you:\n\n# nixos-generate-config --root /mnt\n     You should then edit /mnt/etc/nixos/configuration.nix\n     to suit your needs:\n\n# nano /mnt/etc/nixos/configuration.nix\n\n     If you’re using the graphical ISO image, other editors may be available\n     (such as vim). If you have network access, you can also\n     install other editors — for instance, you can install Emacs by running\n     nix-env -f '<nixpkgs>' -iA emacs.\n    \n       BIOS systems\n      \n        You must set the option\n        boot.loader.grub.device to specify on which disk\n        the GRUB boot loader is to be installed. Without it, NixOS cannot boot.\n       \n       UEFI systems\n      \n        You must set the option\n        boot.loader.systemd-boot.enable to\n        true. nixos-generate-config\n        should do this automatically for new configurations when booted in UEFI\n        mode.\n       \n        You may want to look at the options starting with\n        boot.loader.efi\n        and\n        boot.loader.systemd\n        as well.\n       \n     If there are other operating systems running on the machine before\n     installing NixOS, the boot.loader.grub.useOSProber\n     option can be set to true to automatically add them to\n     the grub menu.\n    \n     If you need to configure networking for your machine the configuration\n     options are described in Chapter 11, Networking. In particular,\n     while wifi is supported on the installation image, it is not enabled by\n     default in the configuration generated by\n     nixos-generate-config.\n    \n     Another critical option is fileSystems, specifying the\n     file systems that need to be mounted by NixOS. However, you typically\n     don’t need to set it yourself, because\n     nixos-generate-config sets it automatically in\n     /mnt/etc/nixos/hardware-configuration.nix from your\n     currently mounted file systems. (The configuration file\n     hardware-configuration.nix is included from\n     configuration.nix and will be overwritten by future\n     invocations of nixos-generate-config; thus, you\n     generally should not modify it.) Additionally, you may want to look at\n     Hardware\n     configuration for known-hardware at this point or after\n     installation.\n\n    Note: \n      Depending on your hardware configuration or type of file system, you may\n      need to set the option boot.initrd.kernelModules to\n      include the kernel modules that are necessary for mounting the root file\n      system, otherwise the installed system will not be able to boot. (If this\n      happens, boot from the installation media again, mount the target file\n      system on /mnt, fix\n      /mnt/etc/nixos/configuration.nix and rerun\n      nixos-install.) In most cases,\n      nixos-generate-config will figure out the required\n      modules.\n     \n     Do the installation:\n\n# nixos-install\n     This will install your system based on the configuration you provided.\n     If anything fails due to a configuration problem or any other issue\n     (such as a network outage while downloading binaries from the NixOS\n     binary cache), you can re-run nixos-install after\n     fixing your configuration.nix.\n    \n     As the last step, nixos-install will ask you to set the\n     password for the root user, e.g.\n\nsetting root password...\nEnter new UNIX password: ***\nRetype new UNIX password: ***\nNote: \n       For unattended installations, it is possible to use\n       nixos-install --no-root-passwd in order to disable\n       the password prompt entirely.\n      \n\n     If everything went well:\n\n# reboot\n\n     You should now be able to boot into the installed NixOS. The GRUB boot\n     menu shows a list of available configurations\n     (initially just one). Every time you change the NixOS configuration (see\n     Changing Configuration\n     ), a new item is added to the menu. This allows you to easily roll back to\n     a previous configuration if something goes wrong.\n    \n     You should log in and change the root password with\n     passwd.\n    \n     You’ll probably want to create some user accounts as well, which can be\n     done with useradd:\n\n$ useradd -c 'Eelco Dolstra' -m eelco\n$ passwd eelco\n\n     You may also want to install some software. For instance,\n\n$ nix-env -qaP \\*\n     shows what packages are available, and\n\n$ nix-env -f '<nixpkgs>' -iA w3m\n     installs the w3m browser.\n    2.4. Installation summary\n   To summarise, Example 2.3, “Commands for Installing NixOS on /dev/sda” shows a typical\n   sequence of commands for installing NixOS on an empty hard drive (here\n   /dev/sda). Example 2.4, “NixOS Configuration” shows a\n   corresponding configuration Nix expression.\n  Example 2.1. Example partition schemes for NixOS on /dev/sda (MBR)\n# parted /dev/sda -- mklabel msdos\n# parted /dev/sda -- mkpart primary 1MiB -8GiB\n# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%Example 2.2. Example partition schemes for NixOS on /dev/sda (UEFI)\n# parted /dev/sda -- mklabel gpt\n# parted /dev/sda -- mkpart primary 512MiB -8GiB\n# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%\n# parted /dev/sda -- mkpart ESP fat32 1MiB 512MiB\n# parted /dev/sda -- set 3 boot onExample 2.3. Commands for Installing NixOS on /dev/sda\n    With a partitioned disk.\n\n# mkfs.ext4 -L nixos /dev/sda1\n# mkswap -L swap /dev/sda2\n# swapon /dev/sda2\n# mkfs.fat -F 32 -n boot /dev/sda3        # (for UEFI systems only)\n# mount /dev/disk/by-label/nixos /mnt\n# mkdir -p /mnt/boot                      # (for UEFI systems only)\n# mount /dev/disk/by-label/boot /mnt/boot # (for UEFI systems only)\n# nixos-generate-config --root /mnt\n# nano /mnt/etc/nixos/configuration.nix\n# nixos-install\n# reboot\nExample 2.4. NixOS Configuration\n{ config, pkgs, ... }: {\n  imports = [\n    # Include the results of the hardware scan.\n    ./hardware-configuration.nix\n  ];\n\n  boot.loader.grub.device = \"/dev/sda\";   # (for BIOS systems only)\n  boot.loader.systemd-boot.enable = true; # (for UEFI systems only)\n\n  # Note: setting fileSystems is generally not\n  # necessary, since nixos-generate-config figures them out\n  # automatically in hardware-configuration.nix.\n  #fileSystems.\"/\".device = \"/dev/disk/by-label/nixos\";\n\n  # Enable the OpenSSH server.\n  services.sshd.enable = true;\n}\n2.5. Additional installation notes2.5.1. Booting from a USB Drive\n  For systems without CD drive, the NixOS live CD can be booted from a USB\n  stick. You can use the dd utility to write the image:\n  dd if=path-to-image\n  of=/dev/sdX. Be careful about specifying\n  the correct drive; you can use the lsblk command to get a\n  list of block devices.\n  On macOS\n\n$ diskutil list\n[..]\n/dev/diskN (external, physical):\n   #:                       TYPE NAME                    SIZE       IDENTIFIER\n[..]\n$ diskutil unmountDisk diskN\nUnmount of all volumes on diskN was successful\n$ sudo dd if=nix.iso of=/dev/rdiskN\n\n    Using the 'raw' rdiskN device instead of\n    diskN completes in minutes instead of hours. After\n    dd completes, a GUI dialog \"The disk you inserted was\n    not readable by this computer\" will pop up, which can be ignored.\n   \n\n  The dd utility will write the image verbatim to the drive,\n  making it the recommended option for both UEFI and non-UEFI installations.\n 2.5.2. Booting from the “netboot” media (PXE)\n  Advanced users may wish to install NixOS using an existing PXE or iPXE setup.\n \n  These instructions assume that you have an existing PXE or iPXE\n  infrastructure and simply want to add the NixOS installer as another option.\n  To build the necessary files from a recent version of nixpkgs, you can run:\n \nnix-build -A netboot nixos/release.nix\n\n  This will create a result directory containing: *\n  bzImage – the Linux kernel * initrd\n  – the initrd file * netboot.ipxe – an example ipxe\n  script demonstrating the appropriate kernel command line arguments for this\n  image\n \n  If you’re using plain PXE, configure your boot loader to use the\n  bzImage and initrd files and have it\n  provide the same kernel command line arguments found in\n  netboot.ipxe.\n \n  If you’re using iPXE, depending on how your HTTP/FTP/etc. server is\n  configured you may be able to use netboot.ipxe unmodified,\n  or you may need to update the paths to the files to match your server’s\n  directory layout\n \n  In the future we may begin making these files available as build products\n  from hydra at which point we will update this documentation with instructions\n  on how to obtain them either for placing on a dedicated TFTP server or to\n  boot them directly over the internet.\n 2.5.3. Installing in a VirtualBox guest\n  Installing NixOS into a VirtualBox guest is convenient for users who want to\n  try NixOS without installing it on bare metal. If you want to use a pre-made\n  VirtualBox appliance, it is available at\n  the downloads\n  page. If you want to set up a VirtualBox guest manually, follow these\n  instructions:\n \n    Add a New Machine in VirtualBox with OS Type \"Linux / Other Linux\"\n   \n    Base Memory Size: 768 MB or higher.\n   \n    New Hard Disk of 8 GB or higher.\n   \n    Mount the CD-ROM with the NixOS ISO (by clicking on CD/DVD-ROM)\n   \n    Click on Settings / System / Processor and enable PAE/NX\n   \n    Click on Settings / System / Acceleration and enable \"VT-x/AMD-V\"\n    acceleration\n   \n    Click on Settings / Display / Screen and select VBoxVGA as Graphics Controller\n   \n    Save the settings, start the virtual machine, and continue installation\n    like normal\n   \n  There are a few modifications you should make in configuration.nix. Enable\n  booting:\n \nboot.loader.grub.device = \"/dev/sda\";\n\n  Also remove the fsck that runs at startup. It will always fail to run,\n  stopping your boot until you press *.\n \nboot.initrd.checkJournalingFS = false;\n\n  Shared folders can be given a name and a path in the host system in the\n  VirtualBox settings (Machine / Settings / Shared Folders, then click on the\n  \"Add\" icon). Add the following to the\n  /etc/nixos/configuration.nix to auto-mount them. If you do\n  not add \"nofail\", the system will no boot properly. The\n  same goes for disabling rngd which is normally used to get\n  randomness but this does not work in virtual machines.\n \n{ config, pkgs, ...} :\n{\n  security.rngd.enable = false; // otherwise vm will not boot\n  ...\n\n  fileSystems.\"/virtualboxshare\" = {\n    fsType = \"vboxsf\";\n    device = \"nameofthesharedfolder\";\n    options = [ \"rw\" \"nofail\" ];\n  };\n}\n\n  The folder will be available directly under the root directory.\n 2.5.4. Installing from another Linux distribution\n  Because Nix (the package manager) & Nixpkgs (the Nix packages collection)\n  can both be installed on any (most?) Linux distributions, they can be used to\n  install NixOS in various creative ways. You can, for instance:\n \n    Install NixOS on another partition, from your existing Linux distribution\n    (without the use of a USB or optical device!)\n   \n    Install NixOS on the same partition (in place!), from your existing\n    non-NixOS Linux distribution using NIXOS_LUSTRATE.\n   \n    Install NixOS on your hard drive from the Live CD of any Linux\n    distribution.\n   \n  The first steps to all these are the same:\n \n    Install the Nix package manager:\n   \n    Short version:\n   \n$ curl https://nixos.org/nix/install | sh\n$ . $HOME/.nix-profile/etc/profile.d/nix.sh # …or open a fresh shell\n    More details in the\n    \n    Nix manual\n\n    Switch to the NixOS channel:\n   \n    If you've just installed Nix on a non-NixOS distribution, you will be on\n    the nixpkgs channel by default.\n   \n$ nix-channel --list\nnixpkgs https://nixos.org/channels/nixpkgs-unstable\n    As that channel gets released without running the NixOS tests, it will be\n    safer to use the nixos-* channels instead:\n   \n$ nix-channel --add https://nixos.org/channels/nixos-version nixpkgs\n    You may want to throw in a nix-channel --update for good\n    measure.\n   \n    Install the NixOS installation tools:\n   \n    You'll need nixos-generate-config and\n    nixos-install and we'll throw in some man pages and\n    nixos-enter just in case you want to chroot into your\n    NixOS partition. They are installed by default on NixOS, but you don't have\n    NixOS yet..\n   $ nix-env -iE \"_: with import <nixpkgs/nixos> { configuration = {}; }; with config.system.build; [ nixos-generate-config nixos-install nixos-enter manual.manpages ]\"Note: \n     The following 5 steps are only for installing NixOS to another partition.\n     For installing NixOS in place using NIXOS_LUSTRATE,\n     skip ahead.\n    \n    Prepare your target partition:\n   \n    At this point it is time to prepare your target partition. Please refer to\n    the partitioning, file-system creation, and mounting steps of\n    Chapter 2, Installing NixOS\n\n    If you're about to install NixOS in place using\n    NIXOS_LUSTRATE there is nothing to do for this step.\n   \n    Generate your NixOS configuration:\n   $ sudo `which nixos-generate-config` --root /mnt\n    You'll probably want to edit the configuration files. Refer to the\n    nixos-generate-config step in\n    Chapter 2, Installing NixOS for more\n    information.\n   \n    Consider setting up the NixOS bootloader to give you the ability to boot on\n    your existing Linux partition. For instance, if you're using GRUB and your\n    existing distribution is running Ubuntu, you may want to add something like\n    this to your configuration.nix:\n   \nboot.loader.grub.extraEntries = ''\n  menuentry \"Ubuntu\" {\n    search --set=ubuntu --fs-uuid 3cc3e652-0c1f-4800-8451-033754f68e6e\n    configfile \"($ubuntu)/boot/grub/grub.cfg\"\n  }\n'';\n    (You can find the appropriate UUID for your partition in\n    /dev/disk/by-uuid)\n   \n    Create the nixbld group and user on your original\n    distribution:\n   \n$ sudo groupadd -g 30000 nixbld\n$ sudo useradd -u 30000 -g nixbld -G nixbld nixbld\n    Download/build/install NixOS:\n   Warning: \n     Once you complete this step, you might no longer be able to boot on\n     existing systems without the help of a rescue USB drive or similar.\n    $ sudo PATH=\"$PATH\" NIX_PATH=\"$NIX_PATH\" `which nixos-install` --root /mnt\n    Again, please refer to the nixos-install step in\n    Chapter 2, Installing NixOS for more information.\n   \n    That should be it for installation to another partition!\n   \n    Optionally, you may want to clean up your non-NixOS distribution:\n   \n$ sudo userdel nixbld\n$ sudo groupdel nixbld\n    If you do not wish to keep the Nix package manager installed either, run\n    something like sudo rm -rv ~/.nix-* /nix and remove the\n    line that the Nix installer added to your ~/.profile.\n   Note: \n     The following steps are only for installing NixOS in place using\n     NIXOS_LUSTRATE:\n    \n    Generate your NixOS configuration:\n   $ sudo `which nixos-generate-config` --root /\n    Note that this will place the generated configuration files in\n    /etc/nixos. You'll probably want to edit the\n    configuration files. Refer to the nixos-generate-config\n    step in Chapter 2, Installing NixOS for more\n    information.\n   \n    You'll likely want to set a root password for your first boot using the\n    configuration files because you won't have a chance to enter a password\n    until after you reboot. You can initalize the root password to an empty one\n    with this line: (and of course don't forget to set one once you've rebooted\n    or to lock the account with sudo passwd -l root if you\n    use sudo)\n   \nusers.users.root.initialHashedPassword = \"\";\n\n    Build the NixOS closure and install it in the system\n    profile:\n   $ nix-env -p /nix/var/nix/profiles/system -f '<nixpkgs/nixos>' -I nixos-config=/etc/nixos/configuration.nix -iA system\n    Change ownership of the /nix tree to root (since your\n    Nix install was probably single user):\n   $ sudo chown -R 0.0 /nix\n    Set up the /etc/NIXOS and\n    /etc/NIXOS_LUSTRATE files:\n   \n/etc/NIXOS officializes that this is now a NixOS\n    partition (the bootup scripts require its presence).\n   \n/etc/NIXOS_LUSTRATE tells the NixOS bootup scripts to\n    move everything that's in the root partition to\n    /old-root. This will move your existing distribution out\n    of the way in the very early stages of the NixOS bootup. There are\n    exceptions (we do need to keep NixOS there after all), so the NixOS\n    lustrate process will not touch:\n   \n      The /nix directory\n     \n      The /boot directory\n     \n      Any file or directory listed in /etc/NIXOS_LUSTRATE\n      (one per line)\n     Note\n     Support for NIXOS_LUSTRATE was added in NixOS 16.09.\n     The act of \"lustrating\" refers to the wiping of the existing distribution.\n     Creating /etc/NIXOS_LUSTRATE can also be used on NixOS\n     to remove all mutable files from your root partition (anything that's not\n     in /nix or /boot gets \"lustrated\" on\n     the next boot.\n    \n     lustrate /ˈlʌstreɪt/ verb.\n    \n     purify by expiatory sacrifice, ceremonial washing, or some other ritual\n     action.\n    \n    Let's create the files:\n   \n$ sudo touch /etc/NIXOS\n$ sudo touch /etc/NIXOS_LUSTRATE\n\n    Let's also make sure the NixOS configuration files are kept once we reboot\n    on NixOS:\n   \n$ echo etc/nixos | sudo tee -a /etc/NIXOS_LUSTRATE\n\n    Finally, move the /boot directory of your current\n    distribution out of the way (the lustrate process will take care of the\n    rest once you reboot, but this one must be moved out now because NixOS\n    needs to install its own boot files:\n   Warning: \n     Once you complete this step, your current distribution will no longer be\n     bootable! If you didn't get all the NixOS configuration right, especially\n     those settings pertaining to boot loading and root partition, NixOS may\n     not be bootable either. Have a USB rescue device ready in case this\n     happens.\n    \n$ sudo mv -v /boot /boot.bak &&\nsudo /nix/var/nix/profiles/system/bin/switch-to-configuration boot\n\n    Cross your fingers, reboot, hopefully you should get a NixOS prompt!\n   \n    If for some reason you want to revert to the old distribution, you'll need\n    to boot on a USB rescue disk and do something along these lines:\n   \n# mkdir root\n# mount /dev/sdaX root\n# mkdir root/nixos-root\n# mv -v root/* root/nixos-root/\n# mv -v root/nixos-root/old-root/* root/\n# mv -v root/boot.bak root/boot  # We had renamed this by hand earlier\n# umount root\n# reboot\n    This may work as is or you might also need to reinstall the boot loader\n   \n    And of course, if you're happy with NixOS and no longer need the old\n    distribution:\n   sudo rm -rf /old-root\n    It's also worth noting that this whole process can be automated. This is\n    especially useful for Cloud VMs, where provider do not provide NixOS. For\n    instance,\n    nixos-infect\n    uses the lustrate process to convert Digital Ocean droplets to NixOS from\n    other distributions automatically.\n   2.5.5. Installing behind a proxy\n  To install NixOS behind a proxy, do the following before running\n  nixos-install.\n \n    Update proxy configuration in\n    /mnt/etc/nixos/configuration.nix to keep the internet\n    accessible after reboot.\n   \nnetworking.proxy.default = \"http://user:password@proxy:port/\";\nnetworking.proxy.noProxy = \"127.0.0.1,localhost,internal.domain\";\n\n    Setup the proxy environment variables in the shell where you are running\n    nixos-install.\n   \n# proxy_url=\"http://user:password@proxy:port/\"\n# export http_proxy=\"$proxy_url\"\n# export HTTP_PROXY=\"$proxy_url\"\n# export https_proxy=\"$proxy_url\"\n# export HTTPS_PROXY=\"$proxy_url\"\nNote: \n   If you are switching networks with different proxy configurations, use the\n   nesting.clone option in\n   configuration.nix to switch proxies at runtime. Refer to\n   Appendix A, Configuration Options for more information.\n  Chapter 3. Changing the Configuration\n  The file /etc/nixos/configuration.nix contains the\n  current configuration of your machine. Whenever you’ve\n  changed something in that file, you\n  should do\n\n# nixos-rebuild switch\n\n  to build the new configuration, make it the default configuration for\n  booting, and try to realise the configuration in the running system (e.g., by\n  restarting system services).\n  Warning: \n    This command doesn't start/stop user\n    services automatically. nixos-rebuild only runs a\n    daemon-reload for each user with running user services.\n   \nWarning: \n   These commands must be executed as root, so you should either run them from\n   a root shell or by prefixing them with sudo -i.\n  \n  You can also do\n\n# nixos-rebuild test\n\n  to build the configuration and switch the running system to it, but without\n  making it the boot default. So if (say) the configuration locks up your\n  machine, you can just reboot to get back to a working configuration.\n \n  There is also\n\n# nixos-rebuild boot\n\n  to build the configuration and make it the boot default, but not switch to it\n  now (so it will only take effect after the next reboot).\n \n  You can make your configuration show up in a different submenu of the GRUB 2\n  boot screen by giving it a different profile name, e.g.\n\n# nixos-rebuild switch -p test\n\n  which causes the new configuration (and previous ones created using\n  -p test) to show up in the GRUB submenu “NixOS - Profile\n  'test'”. This can be useful to separate test configurations from\n  “stable” configurations.\n \n  Finally, you can do\n\n$ nixos-rebuild build\n\n  to build the configuration but nothing more. This is useful to see whether\n  everything compiles cleanly.\n \n  If you have a machine that supports hardware virtualisation, you can also\n  test the new configuration in a sandbox by building and running a QEMU\n  virtual machine that contains the desired configuration.\n  Just do\n\n$ nixos-rebuild build-vm\n$ ./result/bin/run-*-vm\n\n  The VM does not have any data from your host system, so your existing user\n  accounts and home directories will not be available unless you have set\n  mutableUsers = false. Another way is to temporarily add\n  the following to your configuration:\n\nusers.users.your-user.initialHashedPassword = \"test\";\n\nImportant: delete the $hostname.qcow2 file if you have\n  started the virtual machine at least once without the right users, otherwise\n  the changes will not get picked up. You can forward ports on the host to the\n  guest. For instance, the following will forward host port 2222 to guest port\n  22 (SSH):\n\n$ QEMU_NET_OPTS=\"hostfwd=tcp::2222-:22\" ./result/bin/run-*-vm\n\n  allowing you to log in via SSH (assuming you have set the appropriate\n  passwords or SSH authorized keys):\n\n$ ssh -p 2222 localhost\n\nChapter 4. Upgrading NixOSTable of Contents4.1. Automatic Upgrades\n  The best way to keep your NixOS installation up to date is to use one of the\n  NixOS channels. A channel is a Nix mechanism for\n  distributing Nix expressions and associated binaries. The NixOS channels are\n  updated automatically from NixOS’s Git repository after certain tests have\n  passed and all packages have been built. These channels are:\n  \nStable channels, such as\n     nixos-20.03.\n     These only get conservative bug fixes and package upgrades. For instance,\n     a channel update may cause the Linux kernel on your system to be upgraded\n     from 4.19.34 to 4.19.38 (a minor bug fix), but not from\n     4.19.x to 4.20.x (a\n     major change that has the potential to break things). Stable channels are\n     generally maintained until the next stable branch is created.\n    \n     The unstable channel,\n     nixos-unstable.\n     This corresponds to NixOS’s main development branch, and may thus see\n     radical changes between channel updates. It’s not recommended for\n     production systems.\n    \nSmall channels, such as\n     nixos-20.03-small\n     or\n     nixos-unstable-small.\n     These are identical to the stable and unstable channels described above,\n     except that they contain fewer binary packages. This means they get\n     updated faster than the regular channels (for instance, when a critical\n     security patch is committed to NixOS’s source tree), but may require\n     more packages to be built from source than usual. They’re mostly\n     intended for server environments and as such contain few GUI applications.\n    \n  To see what channels are available, go to\n  https://nixos.org/channels. (Note that the URIs of the\n  various channels redirect to a directory that contains the channel’s latest\n  version and includes ISO images and VirtualBox appliances.) Please note that\n  during the release process, channels that are not yet released will be\n  present here as well. See the Getting NixOS page\n  https://nixos.org/nixos/download.html to find the newest\n  supported stable release.\n \n  When you first install NixOS, you’re automatically subscribed to the NixOS\n  channel that corresponds to your installation source. For instance, if you\n  installed from a 20.03 ISO, you will be subscribed to the\n  nixos-20.03 channel. To see which NixOS channel you’re\n  subscribed to, run the following as root:\n\n# nix-channel --list | grep nixos\nnixos https://nixos.org/channels/nixos-unstable\n\n  To switch to a different NixOS channel, do\n\n# nix-channel --add https://nixos.org/channels/channel-name nixos\n\n  (Be sure to include the nixos parameter at the end.) For\n  instance, to use the NixOS 20.03 stable channel:\n\n# nix-channel --add https://nixos.org/channels/nixos-20.03 nixos\n\n  If you have a server, you may want to use the “small” channel instead:\n\n# nix-channel --add https://nixos.org/channels/nixos-20.03-small nixos\n\n  And if you want to live on the bleeding edge:\n\n# nix-channel --add https://nixos.org/channels/nixos-unstable nixos\n\n\n  You can then upgrade NixOS to the latest version in your chosen channel by\n  running\n\n# nixos-rebuild switch --upgrade\n\n  which is equivalent to the more verbose nix-channel --update nixos;\n  nixos-rebuild switch.\n Note: \n   Channels are set per user. This means that running  nix-channel\n   --add as a non root user (or without sudo) will not affect\n   configuration in /etc/nixos/configuration.nix\nWarning: \n   It is generally safe to switch back and forth between channels. The only\n   exception is that a newer NixOS may also have a newer Nix version, which may\n   involve an upgrade of Nix’s database schema. This cannot be undone easily,\n   so in that case you will not be able to go back to your original channel.\n  4.1. Automatic Upgrades\n   You can keep a NixOS system up-to-date automatically by adding the following\n   to configuration.nix:\n\nsystem.autoUpgrade.enable = true;\nsystem.autoUpgrade.allowReboot = true;\n\n   This enables a periodically executed systemd service named\n   nixos-upgrade.service. If the allowReboot\n   option is false, it runs nixos-rebuild switch\n   --upgrade to upgrade NixOS to the latest version in the current\n   channel. (To see when the service runs, see systemctl list-timers.)\n   If allowReboot is true, then the\n   system will automatically reboot if the new generation contains a different\n   kernel, initrd or kernel modules.\n   You can also specify a channel explicitly, e.g.\n\nsystem.autoUpgrade.channel = https://nixos.org/channels/nixos-20.03;\n\nPart II. Configuration\n   This chapter describes how to configure various aspects of a NixOS machine\n   through the configuration file\n   /etc/nixos/configuration.nix. As described in\n   Chapter 3, Changing the Configuration, changes to this file only take\n   effect after you run nixos-rebuild.\n  Table of Contents5. Configuration Syntax6. Package Management7. User Management8. File Systems9. X Window System10. Xfce Desktop Environment11. Networking12. Linux Kernel13. Pantheon Desktop14. Matomo15. Nextcloud16. Grocy17. Prometheus exporters18. WeeChat19. Taskserver20. Matrix21. Gitlab22. Trezor23. Emacs24. Flatpak25. PostgreSQL26. FoundationDB27. Hiding process information28. SSL/TLS Certificates with ACME29. Oh my ZSH30. Plotinus31. Digital Bitbox32. Input Methods33. Profiles34. KubernetesChapter 5. Configuration SyntaxTable of Contents5.1. NixOS Configuration File5.2. Abstractions5.3. Modularity5.4. Syntax Summary\n  The NixOS configuration file\n  /etc/nixos/configuration.nix is actually a Nix\n  expression, which is the Nix package manager’s purely functional\n  language for describing how to build packages and configurations. This means\n  you have all the expressive power of that language at your disposal,\n  including the ability to abstract over common patterns, which is very useful\n  when managing complex systems. The syntax and semantics of the Nix language\n  are fully described in the\n  Nix\n  manual, but here we give a short overview of the most important\n  constructs useful in NixOS configuration files.\n 5.1. NixOS Configuration File\n  The NixOS configuration file generally looks like this:\n\n{ config, pkgs, ... }:\n\n{ option definitions\n}\n\n  The first line ({ config, pkgs, ... }:) denotes that this\n  is actually a function that takes at least the two arguments\n  config and pkgs. (These are explained\n  later.) The function returns a set of option definitions\n  ({ ... }). These definitions\n  have the form name =\n  value, where\n  name is the name of an option and\n  value is its value. For example,\n\n{ config, pkgs, ... }:\n\n{ services.httpd.enable = true;\n  services.httpd.adminAddr = \"alice@example.org\";\n  services.httpd.virtualHosts.localhost.documentRoot = \"/webroot\";\n}\n\n  defines a configuration with three option definitions that together enable\n  the Apache HTTP Server with /webroot as the document\n  root.\n \n  Sets can be nested, and in fact dots in option names are shorthand for\n  defining a set containing another set. For instance,\n  services.httpd.enable defines a set named\n  services that contains a set named\n  httpd, which in turn contains an option definition named\n  enable with value true. This means that\n  the example above can also be written as:\n\n{ config, pkgs, ... }:\n\n{ services = {\n    httpd = {\n      enable = true;\n      adminAddr = \"alice@example.org\";\n      virtualHosts = {\n        localhost = {\n          documentRoot = \"/webroot\";\n        };\n      };\n    };\n  };\n}\n\n  which may be more convenient if you have lots of option definitions that\n  share the same prefix (such as services.httpd).\n \n  NixOS checks your option definitions for correctness. For instance, if you\n  try to define an option that doesn’t exist (that is, doesn’t have a\n  corresponding option declaration),\n  nixos-rebuild will give an error like:\n\nThe option `services.httpd.enable' defined in `/etc/nixos/configuration.nix' does not exist.\n\n  Likewise, values in option definitions must have a correct type. For\n  instance, services.httpd.enable must be a Boolean\n  (true or false). Trying to give it a\n  value of another type, such as a string, will cause an error:\n\nThe option value `services.httpd.enable' in `/etc/nixos/configuration.nix' is not a boolean.\n\n\n  Options have various types of values. The most important are:\n  \n     Strings\n    \n      Strings are enclosed in double quotes, e.g.\n\nnetworking.hostName = \"dexter\";\n\n      Special characters can be escaped by prefixing them with a backslash\n      (e.g. \\\").\n     \n      Multi-line strings can be enclosed in double single\n      quotes, e.g.\n\nnetworking.extraHosts =\n  ''\n    127.0.0.2 other-localhost\n    10.0.0.1 server\n  '';\n\n      The main difference is that it strips from each line a number of spaces\n      equal to the minimal indentation of the string as a whole (disregarding\n      the indentation of empty lines), and that characters like\n      \" and \\ are not special (making it\n      more convenient for including things like shell code). See more info\n      about this in the Nix manual\n      here.\n     \n     Booleans\n    \n      These can be true or false, e.g.\n\nnetworking.firewall.enable = true;\nnetworking.firewall.allowPing = false;\n\n\n     Integers\n    \n      For example,\n\nboot.kernel.sysctl.\"net.ipv4.tcp_keepalive_time\" = 60;\n\n      (Note that here the attribute name\n      net.ipv4.tcp_keepalive_time is enclosed in quotes to\n      prevent it from being interpreted as a set named net\n      containing a set named ipv4, and so on. This is\n      because it’s not a NixOS option but the literal name of a Linux kernel\n      setting.)\n     \n     Sets\n    \n      Sets were introduced above. They are name/value pairs enclosed in braces,\n      as in the option definition\n\nfileSystems.\"/boot\" =\n  { device = \"/dev/sda1\";\n    fsType = \"ext4\";\n    options = [ \"rw\" \"data=ordered\" \"relatime\" ];\n  };\n\n\n     Lists\n    \n      The important thing to note about lists is that list elements are\n      separated by whitespace, like this:\n\nboot.kernelModules = [ \"fuse\" \"kvm-intel\" \"coretemp\" ];\n\n      List elements can be any other type, e.g. sets:\n\nswapDevices = [ { device = \"/dev/disk/by-label/swap\"; } ];\n\n\n     Packages\n    \n      Usually, the packages you need are already part of the Nix Packages\n      collection, which is a set that can be accessed through the function\n      argument pkgs. Typical uses:\n\nenvironment.systemPackages =\n  [ pkgs.thunderbird\n    pkgs.emacs\n  ];\n\nservices.postgresql.package = pkgs.postgresql_10;\n\n      The latter option definition changes the default PostgreSQL package used\n      by NixOS’s PostgreSQL service to 10.x. For more information on\n      packages, including how to add new ones, see\n      Section 6.1.2, “Adding Custom Packages”.\n     \n5.2. Abstractions\n  If you find yourself repeating yourself over and over, it’s time to\n  abstract. Take, for instance, this Apache HTTP Server configuration:\n\n{\n  services.httpd.virtualHosts =\n    { \"blog.example.org\" = {\n        documentRoot = \"/webroot/blog.example.org\";\n        adminAddr = \"alice@example.org\";\n        forceSSL = true;\n        enableACME = true;\n        enablePHP = true;\n      };\n      \"wiki.example.org\" = {\n        documentRoot = \"/webroot/wiki.example.org\";\n        adminAddr = \"alice@example.org\";\n        forceSSL = true;\n        enableACME = true;\n        enablePHP = true;\n      };\n    };\n}\n\n  It defines two virtual hosts with nearly identical configuration; the only\n  difference is the document root directories. To prevent this\n  duplication, we can use a let:\n\nlet\n  commonConfig =\n    { adminAddr = \"alice@example.org\";\n      forceSSL = true;\n      enableACME = true;\n    };\nin\n{\n  services.httpd.virtualHosts =\n    { \"blog.example.org\" = (commonConfig // { documentRoot = \"/webroot/blog.example.org\"; });\n      \"wiki.example.org\" = (commonConfig // { documentRoot = \"/webroot/wiki.example.com\"; });\n    };\n}\n\n  The let commonConfig = ...\n  defines a variable named commonConfig. The\n  // operator merges two attribute sets, so the\n  configuration of the second virtual host is the set\n  commonConfig extended with the document root option.\n \n  You can write a let wherever an expression is allowed.\n  Thus, you also could have written:\n\n{\n  services.httpd.virtualHosts =\n    let commonConfig = ...; in\n    { \"blog.example.org\" = (commonConfig // { ... })\n      \"wiki.example.org\" = (commonConfig // { ... })\n    };\n}\n\n  but not { let commonConfig = ...; in\n  ...; } since attributes (as opposed to\n  attribute values) are not expressions.\n \nFunctions provide another method of abstraction. For\n  instance, suppose that we want to generate lots of different virtual hosts,\n  all with identical configuration except for the document root. This can be done\n  as follows:\n\n{\n  services.httpd.virtualHosts =\n    let\n      makeVirtualHost = webroot:\n        { documentRoot = webroot;\n          adminAddr = \"alice@example.org\";\n          forceSSL = true;\n          enableACME = true;\n        };\n    in\n      { \"example.org\" = (makeVirtualHost \"/webroot/example.org\");\n        \"example.com\" = (makeVirtualHost \"/webroot/example.com\");\n        \"example.gov\" = (makeVirtualHost \"/webroot/example.gov\");\n        \"example.nl\" = (makeVirtualHost \"/webroot/example.nl\");\n      };\n}\n\n  Here, makeVirtualHost is a function that takes a single\n  argument webroot and returns the configuration for a virtual\n  host. That function is then called for several names to produce the list of\n  virtual host configurations.\n 5.3. Modularity\n  The NixOS configuration mechanism is modular. If your\n  configuration.nix becomes too big, you can split it into\n  multiple files. Likewise, if you have multiple NixOS configurations (e.g. for\n  different computers) with some commonality, you can move the common\n  configuration into a shared file.\n \n  Modules have exactly the same syntax as\n  configuration.nix. In fact,\n  configuration.nix is itself a module. You can use other\n  modules by including them from configuration.nix, e.g.:\n\n{ config, pkgs, ... }:\n\n{ imports = [ ./vpn.nix ./kde.nix ];\n  services.httpd.enable = true;\n  environment.systemPackages = [ pkgs.emacs ];\n  ...\n}\n\n  Here, we include two modules from the same directory,\n  vpn.nix and kde.nix. The latter\n  might look like this:\n\n{ config, pkgs, ... }:\n\n{ services.xserver.enable = true;\n  services.xserver.displayManager.sddm.enable = true;\n  services.xserver.desktopManager.plasma5.enable = true;\n}\n\n  Note that both configuration.nix and\n  kde.nix define the option\n  environment.systemPackages. When multiple modules\n  define an option, NixOS will try to merge the\n  definitions. In the case of environment.systemPackages,\n  that’s easy: the lists of packages can simply be concatenated. The value in\n  configuration.nix is merged last, so for list-type\n  options, it will appear at the end of the merged list. If you want it to\n  appear first, you can use mkBefore:\n\nboot.kernelModules = mkBefore [ \"kvm-intel\" ];\n\n  This causes the kvm-intel kernel module to be loaded\n  before any other kernel modules.\n \n  For other types of options, a merge may not be possible. For instance, if two\n  modules define services.httpd.adminAddr,\n  nixos-rebuild will give an error:\n\nThe unique option `services.httpd.adminAddr' is defined multiple times, in `/etc/nixos/httpd.nix' and `/etc/nixos/configuration.nix'.\n\n  When that happens, it’s possible to force one definition take precedence\n  over the others:\n\nservices.httpd.adminAddr = pkgs.lib.mkForce \"bob@example.org\";\n\n\n  When using multiple modules, you may need to access configuration values\n  defined in other modules. This is what the config function\n  argument is for: it contains the complete, merged system configuration. That\n  is, config is the result of combining the configurations\n  returned by every module\n  [1]\n  . For example, here is a module that adds some packages to\n  environment.systemPackages only if\n  services.xserver.enable is set to\n  true somewhere else:\n\n{ config, pkgs, ... }:\n\n{ environment.systemPackages =\n    if config.services.xserver.enable then\n      [ pkgs.firefox\n        pkgs.thunderbird\n      ]\n    else\n      [ ];\n}\n\n\n  With multiple modules, it may not be obvious what the final value of a\n  configuration option is. The command nixos-option allows you\n  to find out:\n\n$ nixos-option services.xserver.enable\ntrue\n\n$ nixos-option boot.kernelModules\n[ \"tun\" \"ipv6\" \"loop\" ... ]\n\n  Interactive exploration of the configuration is possible using nix\n  repl, a read-eval-print loop for Nix expressions. A typical use:\n\n$ nix repl '<nixpkgs/nixos>'\n\nnix-repl> config.networking.hostName\n\"mandark\"\n\nnix-repl> map (x: x.hostName) config.services.httpd.virtualHosts\n[ \"example.org\" \"example.gov\" ]\n\n\n  While abstracting your configuration, you may find it useful to generate\n  modules using code, instead of writing files. The example below would have\n  the same effect as importing a file which sets those options.\n\n{ config, pkgs, ... }:\n\nlet netConfig = { hostName }: {\n  networking.hostName = hostName;\n  networking.useDHCP = false;\n};\n\nin\n\n{ imports = [ (netConfig \"nixos.localdomain\") ]; }\n\n5.4. Syntax Summary\n  Below is a summary of the most important syntactic constructs in the Nix\n  expression language. It’s not complete. In particular, there are many other\n  built-in functions. See the\n  Nix\n  manual for the rest.\n ExampleDescriptionBasic values\n\"Hello world\"\nA string\"${pkgs.bash}/bin/sh\"\nA string containing an expression (expands to \"/nix/store/hash-bash-version/bin/sh\")true, false\nBooleans123\nAn integer./foo.png\nA path (relative to the containing Nix expression)Compound values\n{ x = 1; y = 2; }\nA set with attributes named x and y\n{ foo.bar = 1; }\nA nested set, equivalent to { foo = { bar = 1; }; }\nrec { x = \"foo\"; y = x + \"bar\"; }\nA recursive set, equivalent to { x = \"foo\"; y = \"foobar\"; }\n[ \"foo\" \"bar\" ]\nA list with two elementsOperators\n\"foo\" + \"bar\"\nString concatenation1 + 2\nInteger addition\"foo\" == \"f\" + \"oo\"\nEquality test (evaluates to true)\"foo\" != \"bar\"\nInequality test (evaluates to true)!true\nBoolean negation{ x = 1; y = 2; }.x\nAttribute selection (evaluates to 1){ x = 1; y = 2; }.z or 3\nAttribute selection with default (evaluates to 3){ x = 1; y = 2; } // { z = 3; }\nMerge two sets (attributes in the right-hand set taking precedence)Control structures\nif 1 + 1 == 2 then \"yes!\" else \"no!\"\nConditional expressionassert 1 + 1 == 2; \"yes!\"\nAssertion check (evaluates to \"yes!\"). See Section 44.4, “Warnings and Assertions” for using assertions in moduleslet x = \"foo\"; y = \"bar\"; in x + y\nVariable definitionwith pkgs.lib; head [ 1 2 3 ]\nAdd all attributes from the given set to the scope\n        (evaluates to 1)Functions (lambdas)\nx: x + 1\nA function that expects an integer and returns it increased by 1(x: x + 1) 100\nA function call (evaluates to 101)let inc = x: x + 1; in inc (inc (inc 100))\nA function bound to a variable and subsequently called by name (evaluates to 103){ x, y }: x + y\nA function that expects a set with required attributes\n        x and y and concatenates\n        them{ x, y ? \"bar\" }: x + y\nA function that expects a set with required attribute\n        x and optional y, using\n        \"bar\" as default value for\n        y\n{ x, y, ... }: x + y\nA function that expects a set with required attributes\n        x and y and ignores any\n        other attributes{ x, y } @ args: x + y\nA function that expects a set with required attributes\n        x and y, and binds the\n        whole set to args\nBuilt-in functions\nimport ./foo.nix\nLoad and return Nix expression in given filemap (x: x + x) [ 1 2 3 ]\nApply a function to every element of a list (evaluates to [ 2 4 6 ])[1] \n    If you’re wondering how it’s possible that the (indirect)\n    result of a function is passed as an\n    input to that same function: that’s because Nix is a\n    “lazy” language — it only computes values when they are needed. This\n    works as long as no individual configuration value depends on itself.\n   Chapter 6. Package ManagementTable of Contents6.1. Declarative Package Management6.2. Ad-Hoc Package Management\n  This section describes how to add additional packages to your system. NixOS\n  has two distinct styles of package management:\n  \nDeclarative, where you declare what packages you want\n     in your configuration.nix. Every time you run\n     nixos-rebuild, NixOS will ensure that you get a\n     consistent set of binaries corresponding to your specification.\n    \nAd hoc, where you install, upgrade and uninstall\n     packages via the nix-env command. This style allows\n     mixing packages from different Nixpkgs versions. It’s the only choice\n     for non-root users.\n    \n6.1. Declarative Package Management\n  With declarative package management, you specify which packages you want on\n  your system by setting the option\n  environment.systemPackages. For instance, adding the\n  following line to configuration.nix enables the Mozilla\n  Thunderbird email application:\n\nenvironment.systemPackages = [ pkgs.thunderbird ];\n\n  The effect of this specification is that the Thunderbird package from Nixpkgs\n  will be built or downloaded as part of the system when you run\n  nixos-rebuild switch.\n Note: \n   Some packages require additional global configuration such as D-Bus or systemd service registration so adding them to environment.systemPackages might not be sufficient. You are advised to check the list of options whether a NixOS module for the package does not exist.\n  \n  You can get a list of the available packages as follows:\n\n$ nix-env -qaP '*' --description\nnixos.firefox   firefox-23.0   Mozilla Firefox - the browser, reloaded\n...\n\n  The first column in the output is the attribute name,\n  such as nixos.thunderbird.\n \n  Note: the nixos prefix tells us that we want to get the\n  package from the nixos channel and works only in CLI tools.\n\n  In declarative configuration use pkgs prefix (variable).\n \n  To “uninstall” a package, simply remove it from\n  environment.systemPackages and run\n  nixos-rebuild switch.\n 6.1.1. Customising Packages\n  Some packages in Nixpkgs have options to enable or disable optional\n  functionality or change other aspects of the package. For instance, the\n  Firefox wrapper package (which provides Firefox with a set of plugins such as\n  the Adobe Flash player) has an option to enable the Google Talk plugin. It\n  can be set in configuration.nix as follows: \n  nixpkgs.config.firefox.enableGoogleTalkPlugin = true; \nWarning: \n   Unfortunately, Nixpkgs currently lacks a way to query available\n   configuration options.\n  \n  Apart from high-level options, it’s possible to tweak a package in almost\n  arbitrary ways, such as changing or disabling dependencies of a package. For\n  instance, the Emacs package in Nixpkgs by default has a dependency on GTK 2.\n  If you want to build it against GTK 3, you can specify that as follows:\n\nenvironment.systemPackages = [ (pkgs.emacs.override { gtk = pkgs.gtk3; }) ];\n\n  The function override performs the call to the Nix\n  function that produces Emacs, with the original arguments amended by the set\n  of arguments specified by you. So here the function argument\n  gtk gets the value pkgs.gtk3, causing\n  Emacs to depend on GTK 3. (The parentheses are necessary because in Nix,\n  function application binds more weakly than list construction, so without\n  them, environment.systemPackages would be a list with\n  two elements.)\n \n  Even greater customisation is possible using the function\n  overrideAttrs. While the override\n  mechanism above overrides the arguments of a package function,\n  overrideAttrs allows changing the\n  attributes passed to mkDerivation.\n  This permits changing any aspect of the package, such as the source code. For\n  instance, if you want to override the source code of Emacs, you can say:\n\nenvironment.systemPackages = [\n  (pkgs.emacs.overrideAttrs (oldAttrs: {\n    name = \"emacs-25.0-pre\";\n    src = /path/to/my/emacs/tree;\n  }))\n];\n\n  Here, overrideAttrs takes the Nix derivation specified by\n  pkgs.emacs and produces a new derivation in which the\n  original’s name and src attribute\n  have been replaced by the given values by re-calling\n  stdenv.mkDerivation. The original attributes are\n  accessible via the function argument, which is conventionally named\n  oldAttrs.\n \n  The overrides shown above are not global. They do not affect the original\n  package; other packages in Nixpkgs continue to depend on the original rather\n  than the customised package. This means that if another package in your\n  system depends on the original package, you end up with two instances of the\n  package. If you want to have everything depend on your customised instance,\n  you can apply a global override as follows:\n\nnixpkgs.config.packageOverrides = pkgs:\n  { emacs = pkgs.emacs.override { gtk = pkgs.gtk3; };\n  };\n\n  The effect of this definition is essentially equivalent to modifying the\n  emacs attribute in the Nixpkgs source tree. Any package in\n  Nixpkgs that depends on emacs will be passed your\n  customised instance. (However, the value pkgs.emacs in\n  nixpkgs.config.packageOverrides refers to the original\n  rather than overridden instance, to prevent an infinite recursion.)\n 6.1.2. Adding Custom Packages\n  It’s possible that a package you need is not available in NixOS. In that\n  case, you can do two things. First, you can clone the Nixpkgs repository, add\n  the package to your clone, and (optionally) submit a patch or pull request to\n  have it accepted into the main Nixpkgs repository. This is described in\n  detail in the Nixpkgs\n  manual. In short, you clone Nixpkgs:\n\n$ git clone https://github.com/NixOS/nixpkgs\n$ cd nixpkgs\n\n  Then you write and test the package as described in the Nixpkgs manual.\n  Finally, you add it to environment.systemPackages, e.g.\n\nenvironment.systemPackages = [ pkgs.my-package ];\n\n  and you run nixos-rebuild, specifying your own Nixpkgs\n  tree:\n\n# nixos-rebuild switch -I nixpkgs=/path/to/my/nixpkgs\n\n  The second possibility is to add the package outside of the Nixpkgs tree. For\n  instance, here is how you specify a build of the\n  GNU Hello\n  package directly in configuration.nix:\n\nenvironment.systemPackages =\n  let\n    my-hello = with pkgs; stdenv.mkDerivation rec {\n      name = \"hello-2.8\";\n      src = fetchurl {\n        url = \"mirror://gnu/hello/${name}.tar.gz\";\n        sha256 = \"0wqd8sjmxfskrflaxywc7gqw7sfawrfvdxd9skxawzfgyy0pzdz6\";\n      };\n    };\n  in\n  [ my-hello ];\n\n  Of course, you can also move the definition of my-hello\n  into a separate Nix expression, e.g.\n\nenvironment.systemPackages = [ (import ./my-hello.nix) ];\n\n  where my-hello.nix contains:\n\nwith import <nixpkgs> {}; # bring all of Nixpkgs into scope\n\nstdenv.mkDerivation rec {\n  name = \"hello-2.8\";\n  src = fetchurl {\n    url = \"mirror://gnu/hello/${name}.tar.gz\";\n    sha256 = \"0wqd8sjmxfskrflaxywc7gqw7sfawrfvdxd9skxawzfgyy0pzdz6\";\n  };\n}\n\n  This allows testing the package easily:\n\n$ nix-build my-hello.nix\n$ ./result/bin/hello\nHello, world!\n\n6.2. Ad-Hoc Package Management\n  With the command nix-env, you can install and uninstall\n  packages from the command line. For instance, to install Mozilla Thunderbird:\n\n$ nix-env -iA nixos.thunderbird\n  If you invoke this as root, the package is installed in the Nix profile\n  /nix/var/nix/profiles/default and visible to all users\n  of the system; otherwise, the package ends up in\n  /nix/var/nix/profiles/per-user/username/profile\n  and is not visible to other users. The -A flag specifies the\n  package by its attribute name; without it, the package is installed by\n  matching against its package name (e.g. thunderbird). The\n  latter is slower because it requires matching against all available Nix\n  packages, and is ambiguous if there are multiple matching packages.\n \n  Packages come from the NixOS channel. You typically upgrade a package by\n  updating to the latest version of the NixOS channel:\n\n$ nix-channel --update nixos\n\n  and then running nix-env -i again. Other packages in the\n  profile are not affected; this is the crucial difference\n  with the declarative style of package management, where running\n  nixos-rebuild switch causes all packages to be updated to\n  their current versions in the NixOS channel. You can however upgrade all\n  packages for which there is a newer version by doing:\n\n$ nix-env -u '*'\n\n\n  A package can be uninstalled using the -e flag:\n\n$ nix-env -e thunderbird\n\n\n  Finally, you can roll back an undesirable nix-env action:\n\n$ nix-env --rollback\n\n\nnix-env has many more flags. For details, see the\n  nix-env(1) manpage or the Nix manual.\n Chapter 7. User Management\n  NixOS supports both declarative and imperative styles of user management. In\n  the declarative style, users are specified in\n  configuration.nix. For instance, the following states\n  that a user account named alice shall exist:\n\nusers.users.alice = {\n  isNormalUser = true;\n  home = \"/home/alice\";\n  description = \"Alice Foobar\";\n  extraGroups = [ \"wheel\" \"networkmanager\" ];\n  openssh.authorizedKeys.keys = [ \"ssh-dss AAAAB3Nza... alice@foobar\" ];\n};\n\n  Note that alice is a member of the\n  wheel and networkmanager groups, which\n  allows her to use sudo to execute commands as\n  root and to configure the network, respectively. Also note\n  the SSH public key that allows remote logins with the corresponding private\n  key. Users created in this way do not have a password by default, so they\n  cannot log in via mechanisms that require a password. However, you can use\n  the passwd program to set a password, which is retained\n  across invocations of nixos-rebuild.\n \n  If you set users.mutableUsers to false, then the\n  contents of /etc/passwd and /etc/group\n  will be congruent to your NixOS configuration. For instance, if you remove a\n  user from users.users and run nixos-rebuild, the user\n  account will cease to exist. Also, imperative commands for managing users and\n  groups, such as useradd, are no longer available. Passwords may still be\n  assigned by setting the user's\n  hashedPassword\n  option. A hashed password can be generated using mkpasswd -m\n  sha-512 after installing the mkpasswd package.\n \n  A user ID (uid) is assigned automatically. You can also specify a uid\n  manually by adding\n\nuid = 1000;\n\n  to the user specification.\n \n  Groups can be specified similarly. The following states that a group named\n  students shall exist:\n\nusers.groups.students.gid = 1000;\n\n  As with users, the group ID (gid) is optional and will be assigned\n  automatically if it’s missing.\n \n  In the imperative style, users and groups are managed by commands such as\n  useradd, groupmod and so on. For\n  instance, to create a user account named alice:\n\n# useradd -m alice\n  To make all nix tools available to this new user use `su - USER` which opens\n  a login shell (==shell that loads the profile) for given user. This will\n  create the ~/.nix-defexpr symlink. So run:\n\n# su - alice -c \"true\"\n  The flag -m causes the creation of a home directory for the\n  new user, which is generally what you want. The user does not have an initial\n  password and therefore cannot log in. A password can be set using the\n  passwd utility:\n\n# passwd alice\nEnter new UNIX password: ***\nRetype new UNIX password: ***\n\n  A user can be deleted using userdel:\n\n# userdel -r alice\n  The flag -r deletes the user’s home directory. Accounts\n  can be modified using usermod. Unix groups can be managed\n  using groupadd, groupmod and\n  groupdel.\n Chapter 8. File SystemsTable of Contents8.1. LUKS-Encrypted File Systems\n  You can define file systems using the fileSystems\n  configuration option. For instance, the following definition causes NixOS to\n  mount the Ext4 file system on device\n  /dev/disk/by-label/data onto the mount point\n  /data:\n\nfileSystems.\"/data\" =\n  { device = \"/dev/disk/by-label/data\";\n    fsType = \"ext4\";\n  };\n\n  Mount points are created automatically if they don’t already exist. For\n  device,\n  it’s best to use the topology-independent device aliases in\n  /dev/disk/by-label and\n  /dev/disk/by-uuid, as these don’t change if the\n  topology changes (e.g. if a disk is moved to another IDE controller).\n \n  You can usually omit the file system type\n  (fsType),\n  since mount can usually detect the type and load the\n  necessary kernel module automatically. However, if the file system is needed\n  at early boot (in the initial ramdisk) and is not ext2,\n  ext3 or ext4, then it’s best to\n  specify fsType to ensure that the kernel module is\n  available.\n Note: \n   System startup will fail if any of the filesystems fails to mount, dropping\n   you to the emergency shell. You can make a mount asynchronous and\n   non-critical by adding\n   options = [\n   \"nofail\" ];.\n  8.1. LUKS-Encrypted File Systems\n  NixOS supports file systems that are encrypted using\n  LUKS (Linux Unified Key Setup). For example, here is how\n  you create an encrypted Ext4 file system on the device\n  /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d:\n\n# cryptsetup luksFormat /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d\n\nWARNING!\n========\nThis will overwrite data on /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d irrevocably.\n\nAre you sure? (Type uppercase yes): YES\nEnter LUKS passphrase: ***\nVerify passphrase: ***\n\n# cryptsetup luksOpen /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d crypted\nEnter passphrase for /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d: ***\n\n# mkfs.ext4 /dev/mapper/crypted\n\n  To ensure that this file system is automatically mounted at boot time as\n  /, add the following to\n  configuration.nix:\n\nboot.initrd.luks.devices.crypted.device = \"/dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d\";\nfileSystems.\"/\".device = \"/dev/mapper/crypted\";\n\n  Should grub be used as bootloader, and /boot is located\n  on an encrypted partition, it is necessary to add the following grub option:\nboot.loader.grub.enableCryptodisk = true;\n8.1.1. FIDO2\n   NixOS also supports unlocking your LUKS-Encrypted file system using a FIDO2 compatible token. In the following example, we will create a new FIDO2 credential\n   and add it as a new key to our existing device /dev/sda2:\n\n   \n# export FIDO2_LABEL=\"/dev/sda2 @ $HOSTNAME\"\n# fido2luks credential \"$FIDO2_LABEL\"\nf1d00200108b9d6e849a8b388da457688e3dd653b4e53770012d8f28e5d3b269865038c346802f36f3da7278b13ad6a3bb6a1452e24ebeeaa24ba40eef559b1b287d2a2f80b7\n\n# fido2luks -i add-key /dev/sda2 f1d00200108b9d6e849a8b388da457688e3dd653b4e53770012d8f28e5d3b269865038c346802f36f3da7278b13ad6a3bb6a1452e24ebeeaa24ba40eef559b1b287d2a2f80b7\nPassword:\nPassword (again):\nOld password:\nOld password (again):\nAdded to key to device /dev/sda2, slot: 2\n\n\n  To ensure that this file system is decrypted using the FIDO2 compatible key, add the following to configuration.nix:\n\nboot.initrd.luks.fido2Support = true;\nboot.initrd.luks.devices.\"/dev/sda2\".fido2.credential = \"f1d00200108b9d6e849a8b388da457688e3dd653b4e53770012d8f28e5d3b269865038c346802f36f3da7278b13ad6a3bb6a1452e24ebeeaa24ba40eef559b1b287d2a2f80b7\";\n\n\n  You can also use the FIDO2 passwordless setup, but for security reasons, you might want to enable it only when your device is PIN protected, such as Trezor.\n\n\nboot.initrd.luks.devices.\"/dev/sda2\".fido2.passwordLess = true;\n\nChapter 9. X Window System\n  The X Window System (X11) provides the basis of NixOS’ graphical user\n  interface. It can be enabled as follows:\n\nservices.xserver.enable = true;\n\n  The X server will automatically detect and use the appropriate video driver\n  from a set of X.org drivers (such as vesa and\n  intel). You can also specify a driver manually, e.g.\n\nservices.xserver.videoDrivers = [ \"r128\" ];\n\n  to enable X.org’s xf86-video-r128 driver.\n \n  You also need to enable at least one desktop or window manager. Otherwise,\n  you can only log into a plain undecorated xterm window.\n  Thus you should pick one or more of the following lines:\n\nservices.xserver.desktopManager.plasma5.enable = true;\nservices.xserver.desktopManager.xfce.enable = true;\nservices.xserver.desktopManager.gnome3.enable = true;\nservices.xserver.desktopManager.mate.enable = true;\nservices.xserver.windowManager.xmonad.enable = true;\nservices.xserver.windowManager.twm.enable = true;\nservices.xserver.windowManager.icewm.enable = true;\nservices.xserver.windowManager.i3.enable = true;\n\n\n  NixOS’s default display manager (the program that\n  provides a graphical login prompt and manages the X server) is LightDM. You\n  can select an alternative one by picking one of the following lines:\n\nservices.xserver.displayManager.sddm.enable = true;\nservices.xserver.displayManager.gdm.enable = true;\n\n\n  You can set the keyboard layout (and optionally the layout variant):\n\nservices.xserver.layout = \"de\";\nservices.xserver.xkbVariant = \"neo\";\n\n\n  The X server is started automatically at boot time. If you don’t want this\n  to happen, you can set:\n\nservices.xserver.autorun = false;\n\n  The X server can then be started manually:\n\n# systemctl start display-manager.service\n\n\n  On 64-bit systems, if you want OpenGL for 32-bit programs such as in Wine,\n  you should also set the following:\n\nhardware.opengl.driSupport32Bit = true;\n\nAuto-login\n  The x11 login screen can be skipped entirely, automatically logging you into\n  your window manager and desktop environment when you boot your computer.\n  \n  This is especially helpful if you have disk encryption enabled. Since you\n  already have to provide a password to decrypt your disk, entering a second\n  password to login can be redundant.\n  \n  To enable auto-login, you need to define your default window manager and\n  desktop environment. If you wanted no desktop environment and i3 as your your\n  window manager, you'd define:\n\nservices.xserver.displayManager.defaultSession = \"none+i3\";\n\n  Every display manager in NixOS supports auto-login, here is an example\n  using lightdm for a user alice:\n\nservices.xserver.displayManager.lightdm.enable = true;\nservices.xserver.displayManager.lightdm.autoLogin.enable = true;\nservices.xserver.displayManager.lightdm.autoLogin.user = \"alice\";\n\n  The options are named identically for all other display managers.\n  Proprietary NVIDIA drivers\n   NVIDIA provides a proprietary driver for its graphics cards that has better\n   3D performance than the X.org drivers. It is not enabled by default because\n   it’s not free software. You can enable it as follows:\n\nservices.xserver.videoDrivers = [ \"nvidia\" ];\n\n   Or if you have an older card, you may have to use one of the legacy drivers:\n\nservices.xserver.videoDrivers = [ \"nvidiaLegacy390\" ];\nservices.xserver.videoDrivers = [ \"nvidiaLegacy340\" ];\nservices.xserver.videoDrivers = [ \"nvidiaLegacy304\" ];\nservices.xserver.videoDrivers = [ \"nvidiaLegacy173\" ];\n\n   You may need to reboot after enabling this driver to prevent a clash with\n   other kernel modules.\n  Proprietary AMD drivers\n   AMD provides a proprietary driver for its graphics cards that has better 3D\n   performance than the X.org drivers. It is not enabled by default because\n   it’s not free software. You can enable it as follows:\n\nservices.xserver.videoDrivers = [ \"ati_unfree\" ];\n\n   You will need to reboot after enabling this driver to prevent a clash with\n   other kernel modules.\n  Note: \n   For recent AMD GPUs you most likely want to keep either the defaults\n   or \"amdgpu\" (both free).\n  Touchpads\n   Support for Synaptics touchpads (found in many laptops such as the Dell\n   Latitude series) can be enabled as follows:\n\nservices.xserver.libinput.enable = true;\n\n   The driver has many options (see Appendix A, Configuration Options). For\n   instance, the following disables tap-to-click behavior:\n\nservices.xserver.libinput.tapping = false;\n\n   Note: the use of services.xserver.synaptics is deprecated\n   since NixOS 17.09.\n  GTK/Qt themes\n   GTK themes can be installed either to user profile or system-wide (via\n   environment.systemPackages). To make Qt 5 applications\n   look similar to GTK2 ones, you can install qt5.qtbase.gtk\n   package into your system environment. It should work for all Qt 5 library\n   versions.\n  Custom XKB layouts\n   It is possible to install custom\n   \n    XKB\n   \n   keyboard layouts using the option\n   \n\n     services.xserver.extraLayouts\n    \n.\n   As a first example, we are going to create a layout based on the basic US\n   layout, with an additional layer to type some greek symbols by pressing the\n   right-alt key.\n  \n   To do this we are going to create a us-greek file\n   with a xkb_symbols section.\n  \nxkb_symbols \"us-greek\"\n{\n  include \"us(basic)\"            // includes the base US keys\n  include \"level3(ralt_switch)\"  // configures right alt as a third level switch\n\n  key <LatA> { [ a, A, Greek_alpha ] };\n  key <LatB> { [ b, B, Greek_beta  ] };\n  key <LatG> { [ g, G, Greek_gamma ] };\n  key <LatD> { [ d, D, Greek_delta ] };\n  key <LatZ> { [ z, Z, Greek_zeta  ] };\n};\n\n   To install the layout, the filepath, a description and the list of\n   languages must be given:\n  \nservices.xserver.extraLayouts.us-greek = {\n  description = \"US layout with alt-gr greek\";\n  languages   = [ \"eng\" ];\n  symbolsFile = /path/to/us-greek;\n}\nNote: \n   The name should match the one given to the\n   xkb_symbols block.\n  \n   The layout should now be installed and ready to use: try it by\n   running setxkbmap us-greek and type\n   <alt>+a. To change the default the usual\n   \n\n     services.xserver.layout\n    \n\n   option can still be used.\n  \n   A layout can have several other components besides\n   xkb_symbols, for example we will define new\n   keycodes for some multimedia key and bind these to some symbol.\n  \n   Use the xev utility from\n   pkgs.xorg.xev to find the codes of the keys of\n   interest, then create a media-key file to hold\n   the keycodes definitions\n  \nxkb_keycodes \"media\"\n{\n <volUp>   = 123;\n <volDown> = 456;\n}\n\n    Now use the newly define keycodes in media-sym:\n  \nxkb_symbols \"media\"\n{\n key.type = \"ONE_LEVEL\";\n key <volUp>   { [ XF86AudioLowerVolume ] };\n key <volDown> { [ XF86AudioRaiseVolume ] };\n}\n\n    As before, to install the layout do\n  \nservices.xserver.extraLayouts.media = {\n  description  = \"Multimedia keys remapping\";\n  languages    = [ \"eng\" ];\n  symbolsFile  = /path/to/media-key;\n  keycodesFile = /path/to/media-sym;\n};\nNote: \n   The function pkgs.writeText <filename> <content>\n    can be useful if you prefer to keep the layout definitions\n   inside the NixOS configuration.\n  \n    Unfortunately, the Xorg server does not (currently) support setting a\n    keymap directly but relies instead on XKB rules to select the matching\n    components (keycodes, types, ...) of a layout. This means that components\n    other than symbols won't be loaded by default. As a workaround, you\n    can set the keymap using setxkbmap at the start of the\n    session with:\n  \nservices.xserver.displayManager.sessionCommands = \"setxkbmap -keycodes media\";\n\n    If you are manually starting the X server, you should set the argument\n    -xkbdir /etc/X11/xkb, otherwise X won't find your layout files.\n    For example with xinit run\n    $ xinit -- -xkbdir /etc/X11/xkb\n\n   To learn how to write layouts take a look at the XKB\n  \n   documentation\n  . More example layouts can also be found\n  \n   here\n  .\n  Chapter 10. Xfce Desktop Environment\n  To enable the Xfce Desktop Environment, set\n\nservices.xserver.desktopManager.xfce.enable = true;\nservices.xserver.displayManager.defaultSession = \"xfce\";\n\n\n  Optionally, picom can be enabled for nice graphical\n  effects, some example settings:\n\nservices.picom = {\n  enable          = true;\n  fade            = true;\n  inactiveOpacity = \"0.9\";\n  shadow          = true;\n  fadeDelta       = 4;\n};\n\n\n  Some Xfce programs are not installed automatically. To install them manually\n  (system wide), put them into your\n  environment.systemPackages from pkgs.xfce.\n Thunar Plugins\n    If you'd like to add extra plugins to Thunar, add them to\n    services.xserver.desktopManager.xfce.thunarPlugins.\n    You shouldn't just add them to environment.systemPackages.\n  Troubleshooting\n   Even after enabling udisks2, volume management might not work. Thunar and/or\n   the desktop takes time to show up. Thunar will spit out this kind of message\n   on start (look at journalctl --user -b).\n\nThunar:2410): GVFS-RemoteVolumeMonitor-WARNING **: remote volume monitor with dbus name org.gtk.Private.UDisks2VolumeMonitor is not supported\n\n   This is caused by some needed GNOME services not running. This is all fixed\n   by enabling \"Launch GNOME services on startup\" in the Advanced tab of the\n   Session and Startup settings panel. Alternatively, you can run this command\n   to do the same thing.\n\n$ xfconf-query -c xfce4-session -p /compat/LaunchGNOME -s true\n\n   A log-out and re-log will be needed for this to take effect.\n  Chapter 11. NetworkingTable of Contents11.1. NetworkManager11.2. Secure Shell Access11.3. IPv4 Configuration11.4. IPv6 Configuration11.5. Firewall11.6. Wireless Networks11.7. Ad-Hoc Configuration\n  This section describes how to configure networking components on your NixOS\n  machine.\n 11.1. NetworkManager\n  To facilitate network configuration, some desktop environments use\n  NetworkManager. You can enable NetworkManager by setting:\n\nnetworking.networkmanager.enable = true;\n\n  some desktop managers (e.g., GNOME) enable NetworkManager automatically for\n  you.\n \n  All users that should have permission to change network settings must belong\n  to the networkmanager group:\n\nusers.users.alice.extraGroups = [ \"networkmanager\" ];\n\n\n  NetworkManager is controlled using either nmcli or\n  nmtui (curses-based terminal user interface). See their\n  manual pages for details on their usage. Some desktop environments (GNOME,\n  KDE) have their own configuration tools for NetworkManager. On XFCE, there is\n  no configuration tool for NetworkManager by default: by enabling programs.nm-applet.enable, the\n  graphical applet will be installed and will launch automatically when the graphical session is started.\n Note\nnetworking.networkmanager and networking.wireless\n   (WPA Supplicant) can be used together if desired. To do this you need to instruct\n   NetworkManager to ignore those interfaces like:\n\nnetworking.networkmanager.unmanaged = [\n   \"*\" \"except:type:wwan\" \"except:type:gsm\"\n];\n\n   Refer to the option description for the exact syntax and references to external documentation.\n  11.2. Secure Shell Access\n  Secure shell (SSH) access to your machine can be enabled by setting:\n\nservices.openssh.enable = true;\n\n  By default, root logins using a password are disallowed. They can be disabled\n  entirely by setting services.openssh.permitRootLogin to\n  \"no\".\n \n  You can declaratively specify authorised RSA/DSA public keys for a user as\n  follows:\n\n\nusers.users.alice.openssh.authorizedKeys.keys =\n  [ \"ssh-dss AAAAB3NzaC1kc3MAAACBAPIkGWVEt4...\" ];\n\n11.3. IPv4 Configuration\n  By default, NixOS uses DHCP (specifically, dhcpcd) to\n  automatically configure network interfaces. However, you can configure an\n  interface manually as follows:\n\nnetworking.interfaces.eth0.ipv4.addresses = [ {\n  address = \"192.168.1.2\";\n  prefixLength = 24;\n} ];\n\n  Typically you’ll also want to set a default gateway and set of name\n  servers:\n\nnetworking.defaultGateway = \"192.168.1.1\";\nnetworking.nameservers = [ \"8.8.8.8\" ];\n\nNote: \n   Statically configured interfaces are set up by the systemd service\n   interface-name-cfg.service.\n   The default gateway and name server configuration is performed by\n   network-setup.service.\n  \n  The host name is set using networking.hostName:\n\nnetworking.hostName = \"cartman\";\n\n  The default host name is nixos. Set it to the empty string\n  (\"\") to allow the DHCP server to provide the host name.\n 11.4. IPv6 Configuration\n  IPv6 is enabled by default. Stateless address autoconfiguration is used to\n  automatically assign IPv6 addresses to all interfaces. You can disable IPv6\n  support globally by setting:\n\nnetworking.enableIPv6 = false;\n\n\n  You can disable IPv6 on a single interface using a normal sysctl (in this\n  example, we use interface eth0):\n\nboot.kernel.sysctl.\"net.ipv6.conf.eth0.disable_ipv6\" = true;\n\n\n  As with IPv4 networking interfaces are automatically configured via DHCPv6.\n  You can configure an interface manually:\n\nnetworking.interfaces.eth0.ipv6.addresses = [ {\n  address = \"fe00:aa:bb:cc::2\";\n  prefixLength = 64;\n} ];\n\n\n  For configuring a gateway, optionally with explicitly specified interface:\n\nnetworking.defaultGateway6 = {\n  address = \"fe00::1\";\n  interface = \"enp0s3\";\n};\n\n\n  See Section 11.3, “IPv4 Configuration” for similar examples and additional\n  information.\n 11.5. Firewall\n  NixOS has a simple stateful firewall that blocks incoming connections and\n  other unexpected packets. The firewall applies to both IPv4 and IPv6 traffic.\n  It is enabled by default. It can be disabled as follows:\n\nnetworking.firewall.enable = false;\n\n  If the firewall is enabled, you can open specific TCP ports to the outside\n  world:\n\nnetworking.firewall.allowedTCPPorts = [ 80 443 ];\n\n  Note that TCP port 22 (ssh) is opened automatically if the SSH daemon is\n  enabled (services.openssh.enable =\n  true). UDP ports can be opened through\n  networking.firewall.allowedUDPPorts.\n \n  To open ranges of TCP ports:\n\nnetworking.firewall.allowedTCPPortRanges = [\n  { from = 4000; to = 4007; }\n  { from = 8000; to = 8010; }\n];\n\n  Similarly, UDP port ranges can be opened through\n  networking.firewall.allowedUDPPortRanges.\n 11.6. Wireless Networks\n  For a desktop installation using NetworkManager (e.g., GNOME), you just have\n  to make sure the user is in the networkmanager group and you can\n  skip the rest of this section on wireless networks.\n \n  NixOS will start wpa_supplicant for you if you enable this setting:\n\nnetworking.wireless.enable = true;\n\n  NixOS lets you specify networks for wpa_supplicant declaratively:\n\nnetworking.wireless.networks = {\n  echelon = {                # SSID with no spaces or special characters\n    psk = \"abcdefgh\";\n  };\n  \"echelon's AP\" = {         # SSID with spaces and/or special characters\n    psk = \"ijklmnop\";\n  };\n  echelon = {                # Hidden SSID\n    hidden = true;\n    psk = \"qrstuvwx\";\n  };\n  free.wifi = {};            # Public wireless network\n};\n\n  Be aware that keys will be written to the nix store in plaintext! When no\n  networks are set, it will default to using a configuration file at\n  /etc/wpa_supplicant.conf. You should edit this file\n  yourself to define wireless networks, WPA keys and so on (see wpa_supplicant.conf(5)).\n \n  If you are using WPA2 you can generate pskRaw key using\n  wpa_passphrase:\n\n$ wpa_passphrase ESSID PSK\nnetwork={\n        ssid=\"echelon\"\n        #psk=\"abcdefgh\"\n        psk=dca6d6ed41f4ab5a984c9f55f6f66d4efdc720ebf66959810f4329bb391c5435\n}\n\n\nnetworking.wireless.networks = {\n  echelon = {\n    pskRaw = \"dca6d6ed41f4ab5a984c9f55f6f66d4efdc720ebf66959810f4329bb391c5435\";\n  };\n}\n\n  or you can use it to directly generate the\n  wpa_supplicant.conf:\n\n# wpa_passphrase ESSID PSK > /etc/wpa_supplicant.conf\n  After you have edited the wpa_supplicant.conf, you need to\n  restart the wpa_supplicant service.\n\n# systemctl restart wpa_supplicant.service\n11.7. Ad-Hoc Configuration\n  You can use networking.localCommands to specify shell\n  commands to be run at the end of network-setup.service.\n  This is useful for doing network configuration not covered by the existing\n  NixOS modules. For instance, to statically configure an IPv6 address:\n\nnetworking.localCommands =\n  ''\n    ip -6 addr add 2001:610:685:1::1/64 dev eth0\n  '';\n\nChapter 12. Linux KernelTable of Contents12.1. Customize your kernel12.2. Developing kernel modules\n  You can override the Linux kernel and associated packages using the option\n  boot.kernelPackages. For instance, this selects the Linux\n  3.10 kernel:\n\nboot.kernelPackages = pkgs.linuxPackages_3_10;\n\n  Note that this not only replaces the kernel, but also packages that are\n  specific to the kernel version, such as the NVIDIA video drivers. This\n  ensures that driver packages are consistent with the kernel.\n \n  The default Linux kernel configuration should be fine for most users. You can\n  see the configuration of your current kernel with the following command:\n\nzcat /proc/config.gz\n\n  If you want to change the kernel configuration, you can use the\n  packageOverrides feature (see\n  Section 6.1.1, “Customising Packages”). For instance, to enable support\n  for the kernel debugger KGDB:\n\nnixpkgs.config.packageOverrides = pkgs:\n  { linux_3_4 = pkgs.linux_3_4.override {\n      extraConfig =\n        ''\n          KGDB y\n        '';\n    };\n  };\n\nextraConfig takes a list of Linux kernel configuration\n  options, one per line. The name of the option should not include the prefix\n  CONFIG_. The option value is typically\n  y, n or m (to build\n  something as a kernel module).\n \n  Kernel modules for hardware devices are generally loaded automatically by\n  udev. You can force a module to be loaded via\n  boot.kernelModules, e.g.\n\nboot.kernelModules = [ \"fuse\" \"kvm-intel\" \"coretemp\" ];\n\n  If the module is required early during the boot (e.g. to mount the root file\n  system), you can use boot.initrd.kernelModules:\n\nboot.initrd.kernelModules = [ \"cifs\" ];\n\n  This causes the specified modules and their dependencies to be added to the\n  initial ramdisk.\n \n  Kernel runtime parameters can be set through\n  boot.kernel.sysctl, e.g.\n\nboot.kernel.sysctl.\"net.ipv4.tcp_keepalive_time\" = 120;\n\n  sets the kernel’s TCP keepalive time to 120 seconds. To see the available\n  parameters, run sysctl -a.\n 12.1. Customize your kernel\n   The first step before compiling the kernel is to generate an appropriate\n   .config configuration. Either you pass your own config\n   via the configfile setting of\n   linuxManualConfig:\n\n  custom-kernel = super.linuxManualConfig {\n    inherit (super) stdenv hostPlatform;\n    inherit (linux_4_9) src;\n    version = \"${linux_4_9.version}-custom\";\n\n    configfile = /home/me/my_kernel_config;\n    allowImportFromDerivation = true;\n  };\n  \n   You can edit the config with this snippet (by default make\n   menuconfig won't work out of the box on nixos):\n\n      nix-shell -E 'with import <nixpkgs> {}; kernelToOverride.overrideAttrs (o: {nativeBuildInputs=o.nativeBuildInputs ++ [ pkgconfig ncurses ];})'\n  \n   or you can let nixpkgs generate the configuration. Nixpkgs generates it via\n   answering the interactive kernel utility make config. The\n   answers depend on parameters passed to\n   pkgs/os-specific/linux/kernel/generic.nix (which you\n   can influence by overriding extraConfig, autoModules,\n   modDirVersion, preferBuiltin, extraConfig).\n\n\n  mptcp93.override ({\n      name=\"mptcp-local\";\n\n      ignoreConfigErrors = true;\n      autoModules = false;\n      kernelPreferBuiltin = true;\n\n      enableParallelBuilding = true;\n\n      extraConfig = ''\n        DEBUG_KERNEL y\n        FRAME_POINTER y\n        KGDB y\n        KGDB_SERIAL_CONSOLE y\n        DEBUG_INFO y\n      '';\n    });\n  \n12.2. Developing kernel modules\n   When developing kernel modules it's often convenient to run edit-compile-run\n   loop as quickly as possible. See below snippet as an example of developing\n   mellanox drivers.\n  \n$ nix-build '<nixpkgs>' -A linuxPackages.kernel.dev\n$ nix-shell '<nixpkgs>' -A linuxPackages.kernel\n$ unpackPhase\n$ cd linux-*\n$ make -C $dev/lib/modules/*/build M=$(pwd)/drivers/net/ethernet/mellanox modules\n# insmod ./drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.ko\nChapter 13. Pantheon DesktopTable of Contents13.1. Enabling Pantheon13.2. Wingpanel and Switchboard plugins13.3. FAQ\n  Pantheon is the desktop environment created for the elementary OS distribution. It is written from scratch in Vala, utilizing GNOME technologies with GTK 3 and Granite.\n 13.1. Enabling Pantheon\n   All of Pantheon is working in NixOS and the applications should be available, aside from a few exceptions. To enable Pantheon, set\n\nservices.xserver.desktopManager.pantheon.enable = true;\n\n   This automatically enables LightDM and Pantheon's LightDM greeter. If you'd like to disable this, set\n\nservices.xserver.displayManager.lightdm.greeters.pantheon.enable = false;\nservices.xserver.displayManager.lightdm.enable = false;\n\n   but please be aware using Pantheon without LightDM as a display manager will break screenlocking from the UI. The NixOS module for Pantheon installs all of Pantheon's default applications. If you'd like to not install Pantheon's apps, set\n\nservices.pantheon.apps.enable = false;\n\n   You can also use environment.pantheon.excludePackages to remove any other app (like geary).\n  13.2. Wingpanel and Switchboard plugins\n   Wingpanel and Switchboard work differently than they do in other distributions, as far as using plugins. You cannot install a plugin globally (like with environment.systemPackages) to start using it. You should instead be using the following options:\n   \nservices.xserver.desktopManager.pantheon.extraWingpanelIndicators\n\nservices.xserver.desktopManager.pantheon.extraSwitchboardPlugs\n\n   to configure the programs with plugs or indicators.\n  \n   The difference in NixOS is both these programs are patched to load plugins from a directory that is the value of an environment variable. All of which is controlled in Nix. If you need to configure the particular packages manually you can override the packages like:\n\nwingpanel-with-indicators.override {\n  indicators = [\n    pkgs.some-special-indicator\n  ];\n};\n\nswitchboard-with-plugs.override {\n  plugs = [\n    pkgs.some-special-plug\n  ];\n};\n\n   please note that, like how the NixOS options describe these as extra plugins, this would only add to the default plugins included with the programs. If for some reason you'd like to configure which plugins to use exactly, both packages have an argument for this:\n\nwingpanel-with-indicators.override {\n  useDefaultIndicators = false;\n  indicators = specialListOfIndicators;\n};\n\nswitchboard-with-plugs.override {\n  useDefaultPlugs = false;\n  plugs = specialListOfPlugs;\n};\n\n   this could be most useful for testing a particular plug-in in isolation.\n  13.3. FAQ\n     I have switched from a different desktop and Pantheon’s theming looks messed up.\n    \n      Open Switchboard and go to: Administration → About → Restore Default Settings → Restore Settings. This will reset any dconf settings to their Pantheon defaults. Note this could reset certain GNOME specific preferences if that desktop was used prior.\n     \n     I cannot enable both GNOME 3 and Pantheon.\n    \n      This is a known issue and there is no known workaround.\n     \n     Does AppCenter work, or is it available?\n    \n      AppCenter has been available since 20.03, but it is of little use. This is because there is no functioning PackageKit backend for Nix 2.0. In the near future you will be able to install Flatpak applications from AppCenter on NixOS. See this issue.\n     Chapter 14. MatomoTable of Contents14.1. Database Setup14.2. Archive Processing14.3. Backup14.4. Issues14.5. Using other Web Servers than nginx\n  Matomo is a real-time web analytics application. This module configures\n  php-fpm as backend for Matomo, optionally configuring an nginx vhost as well.\n \n  An automatic setup is not suported by Matomo, so you need to configure Matomo\n  itself in the browser-based Matomo setup.\n 14.1. Database Setup\n   You also need to configure a MariaDB or MySQL database and -user for Matomo\n   yourself, and enter those credentials in your browser. You can use\n   passwordless database authentication via the UNIX_SOCKET authentication\n   plugin with the following SQL commands:\n\n# For MariaDB\nINSTALL PLUGIN unix_socket SONAME 'auth_socket';\nCREATE DATABASE matomo;\nCREATE USER 'matomo'@'localhost' IDENTIFIED WITH unix_socket;\nGRANT ALL PRIVILEGES ON matomo.* TO 'matomo'@'localhost';\n\n# For MySQL\nINSTALL PLUGIN auth_socket SONAME 'auth_socket.so';\nCREATE DATABASE matomo;\nCREATE USER 'matomo'@'localhost' IDENTIFIED WITH auth_socket;\nGRANT ALL PRIVILEGES ON matomo.* TO 'matomo'@'localhost';\n\n   Then fill in matomo as database user and database name,\n   and leave the password field blank. This authentication works by allowing\n   only the matomo unix user to authenticate as the\n   matomo database user (without needing a password), but no\n   other users. For more information on passwordless login, see\n   https://mariadb.com/kb/en/mariadb/unix_socket-authentication-plugin/.\n  \n   Of course, you can use password based authentication as well, e.g. when the\n   database is not on the same host.\n  14.2. Archive Processing\n   This module comes with the systemd service\n   matomo-archive-processing.service and a timer that\n   automatically triggers archive processing every hour. This means that you\n   can safely\n   \n   disable browser triggers for Matomo archiving  at\n   Administration > System > General Settings.\n  \n   With automatic archive processing, you can now also enable to\n   \n   delete old visitor logs  at Administration > System >\n   Privacy, but make sure that you run systemctl start\n   matomo-archive-processing.service at least once without errors if\n   you have already collected data before, so that the reports get archived\n   before the source data gets deleted.\n  14.3. Backup\n   You only need to take backups of your MySQL database and the\n   /var/lib/matomo/config/config.ini.php file. Use a user\n   in the matomo group or root to access the file. For more\n   information, see\n   https://matomo.org/faq/how-to-install/faq_138/.\n  14.4. Issues\n     Matomo will warn you that the JavaScript tracker is not writable. This is\n     because it's located in the read-only nix store. You can safely ignore\n     this, unless you need a plugin that needs JavaScript tracker access.\n    14.5. Using other Web Servers than nginx\n   You can use other web servers by forwarding calls for\n   index.php and piwik.php to the\n   services.phpfpm.pools.<name>.socket fastcgi unix socket. You can use\n   the nginx configuration in the module code as a reference to what else\n   should be configured.\n  Chapter 15. NextcloudTable of Contents15.1. Basic usage15.2. Pitfalls15.3. Maintainer information\nNextcloud is an open-source,\n  self-hostable cloud platform. The server setup can be automated using\n  services.nextcloud. A\n  desktop client is packaged at pkgs.nextcloud-client.\n 15.1. Basic usage\n   Nextcloud is a PHP-based application which requires an HTTP server\n   (services.nextcloud\n   optionally supports\n   services.nginx)\n   and a database (it's recommended to use\n   services.postgresql).\n  \n   A very basic configuration may look like this:\n{ pkgs, ... }:\n{\n  services.nextcloud = {\n    enable = true;\n    hostName = \"nextcloud.tld\";\n    nginx.enable = true;\n    config = {\n      dbtype = \"pgsql\";\n      dbuser = \"nextcloud\";\n      dbhost = \"/run/postgresql\"; # nextcloud will add /.s.PGSQL.5432 by itself\n      dbname = \"nextcloud\";\n      adminpassFile = \"/path/to/admin-pass-file\";\n      adminuser = \"root\";\n    };\n  };\n\n  services.postgresql = {\n    enable = true;\n    ensureDatabases = [ \"nextcloud\" ];\n    ensureUsers = [\n     { name = \"nextcloud\";\n       ensurePermissions.\"DATABASE nextcloud\" = \"ALL PRIVILEGES\";\n     }\n    ];\n  };\n\n  # ensure that postgres is running *before* running the setup\n  systemd.services.\"nextcloud-setup\" = {\n    requires = [\"postgresql.service\"];\n    after = [\"postgresql.service\"];\n  };\n\n  networking.firewall.allowedTCPPorts = [ 80 443 ];\n}\n\n   The options hostName and nginx.enable\n   are used internally to configure an HTTP server using\n   PHP-FPM\n   and nginx. The config attribute set is\n   used by the imperative installer and all values are written to an additional file\n   to ensure that changes can be applied by changing the module's options.\n  \n   In case the application serves multiple domains (those are checked with\n   $_SERVER['HTTP_HOST'])\n   it's needed to add them to\n   services.nextcloud.config.extraTrustedDomains.\n  \n   Auto updates for Nextcloud apps can be enabled using\n   services.nextcloud.autoUpdateApps.\n15.2. Pitfalls\n   Unfortunately Nextcloud appears to be very stateful when it comes to\n   managing its own configuration. The config file lives in the home directory\n   of the nextcloud user (by default\n   /var/lib/nextcloud/config/config.php) and is also used to\n   track several states of the application (e.g. whether installed or not).\n  \n   All configuration parameters are also stored in\n   /var/lib/nextcloud/config/override.config.php which is generated by\n   the module and linked from the store to ensure that all values from config.php\n   can be modified by the module.\n   However config.php manages the application's state and shouldn't be touched\n   manually because of that.\n  Warning: Don't delete config.php! This file\n   tracks the application's state and a deletion can cause unwanted\n   side-effects!Warning: Don't rerun nextcloud-occ\n   maintenance:install! This command tries to install the application\n   and can cause unwanted side-effects!\n   Nextcloud doesn't allow to move more than one major-version forward. If you're e.g. on\n   v16, you cannot upgrade to v18, you need to upgrade to\n   v17 first. This is ensured automatically as long as the\n   stateVersion is declared properly. In that case\n   the oldest version available (one major behind the one from the previous NixOS\n   release) will be selected by default and the module will generate a warning that reminds\n   the user to upgrade to latest Nextcloud after that deploy.\n  15.3. Maintainer information\n   As stated in the previous paragraph, we must provide a clean upgrade-path for Nextcloud\n   since it cannot move more than one major version forward on a single upgrade. This chapter\n   adds some notes how Nextcloud updates should be rolled out in the future.\n  \n   While minor and patch-level updates are no problem and can be done directly in the\n   package-expression (and should be backported to supported stable branches after that),\n   major-releases should be added in a new attribute (e.g. Nextcloud v19.0.0\n   should be available in nixpkgs as pkgs.nextcloud19).\n   To provide simple upgrade paths it's generally useful to backport those as well to stable\n   branches. As long as the package-default isn't altered, this won't break existing setups.\n   After that, the versioning-warning in the nextcloud-module should be\n   updated to make sure that the\n   package-option selects the latest version\n   on fresh setups.\n  \n   If major-releases will be abandoned by upstream, we should check first if those are needed\n   in NixOS for a safe upgrade-path before removing those. In that case we shold keep those\n   packages, but mark them as insecure in an expression like this (in\n   <nixpkgs/pkgs/servers/nextcloud/default.nix>):\n/* ... */\n{\n  nextcloud17 = generic {\n    version = \"17.0.x\";\n    sha256 = \"0000000000000000000000000000000000000000000000000000\";\n    insecure = true;\n  };\n}\nChapter 16. GrocyTable of Contents16.1. Basic usage16.2. Settings\nGrocy is a web-based self-hosted groceries\n    & household management solution for your home.\n  16.1. Basic usage\n    A very basic configuration may look like this:\n{ pkgs, ... }:\n{\n  services.grocy = {\n    enable = true;\n    hostName = \"grocy.tld\";\n  };\n}\n    This configures a simple vhost using nginx\n    which listens to grocy.tld with fully configured ACME/LE (this can be\n    disabled by setting services.grocy.nginx.enableSSL\n    to false). After the initial setup the credentials admin:admin\n    can be used to login.\n   \n    The application's state is persisted at /var/lib/grocy/grocy.db in a\n    sqlite3 database. The migration is applied when requesting the /-route\n    of the application.\n   16.2. Settings\n    The configuration for grocy is located at /etc/grocy/config.php.\n    By default, the following settings can be defined in the NixOS-configuration:\n{ pkgs, ... }:\n{\n  services.grocy.settings = {\n    # The default currency in the system for invoices etc.\n    # Please note that exchange rates aren't taken into account, this\n    # is just the setting for what's shown in the frontend.\n    currency = \"EUR\";\n\n    # The display language (and locale configuration) for grocy.\n    culture = \"de\";\n\n    calendar = {\n      # Whether or not to show the week-numbers\n      # in the calendar.\n      showWeekNumber = true;\n\n      # Index of the first day to be shown in the calendar (0=Sunday, 1=Monday,\n      # 2=Tuesday and so on).\n      firstDayOfWeek = 2;\n    };\n  };\n}\n\n    If you want to alter the configuration file on your own, you can do this manually with\n    an expression like this:\n{ lib, ... }:\n{\n  environment.etc.\"grocy/config.php\".text = lib.mkAfter ''\n    // Arbitrary PHP code in grocy's configuration file\n  '';\n}\nChapter 17. Prometheus exportersTable of Contents17.1. Configuration17.2. Adding a new exporter17.3. Updating an exporter module\n  Prometheus exporters provide metrics for the\n  prometheus monitoring system.\n 17.1. Configuration\n   One of the most common exporters is the\n   node\n   exporter, it provides hardware and OS metrics from the host it's\n   running on. The exporter could be configured as follows:\n\n  services.prometheus.exporters.node = {\n    enable = true;\n    enabledCollectors = [\n      \"logind\"\n      \"systemd\"\n    ];\n    disabledCollectors = [\n      \"textfile\"\n    ];\n    openFirewall = true;\n    firewallFilter = \"-i br0 -p tcp -m tcp --dport 9100\";\n  };\n\n   It should now serve all metrics from the collectors that are explicitly\n   enabled and the ones that are\n   enabled\n   by default, via http under /metrics. In this\n   example the firewall should just allow incoming connections to the\n   exporter's port on the bridge interface br0 (this would\n   have to be configured seperately of course). For more information about\n   configuration see man configuration.nix or search through\n   the\n   available\n   options.\n  17.2. Adding a new exporter\n   To add a new exporter, it has to be packaged first (see\n   nixpkgs/pkgs/servers/monitoring/prometheus/ for\n   examples), then a module can be added. The postfix exporter is used in this\n   example:\n  \n     Some default options for all exporters are provided by\n     nixpkgs/nixos/modules/services/monitoring/prometheus/exporters.nix:\n    \nenable\n\nport\n\nlistenAddress\n\nextraFlags\n\nopenFirewall\n\nfirewallFilter\n\nuser\n\ngroup\n\n     As there is already a package available, the module can now be added. This\n     is accomplished by adding a new file to the\n     nixos/modules/services/monitoring/prometheus/exporters/\n     directory, which will be called postfix.nix and contains all exporter\n     specific options and configuration:\n\n# nixpgs/nixos/modules/services/prometheus/exporters/postfix.nix\n{ config, lib, pkgs, options }:\n\nwith lib;\n\nlet\n  # for convenience we define cfg here\n  cfg = config.services.prometheus.exporters.postfix;\nin\n{\n  port = 9154; # The postfix exporter listens on this port by default\n\n  # `extraOpts` is an attribute set which contains additional options\n  # (and optional overrides for default options).\n  # Note that this attribute is optional.\n  extraOpts = {\n    telemetryPath = mkOption {\n      type = types.str;\n      default = \"/metrics\";\n      description = ''\n        Path under which to expose metrics.\n      '';\n    };\n    logfilePath = mkOption {\n      type = types.path;\n      default = /var/log/postfix_exporter_input.log;\n      example = /var/log/mail.log;\n      description = ''\n        Path where Postfix writes log entries.\n        This file will be truncated by this exporter!\n      '';\n    };\n    showqPath = mkOption {\n      type = types.path;\n      default = /var/spool/postfix/public/showq;\n      example = /var/lib/postfix/queue/public/showq;\n      description = ''\n        Path at which Postfix places its showq socket.\n      '';\n    };\n  };\n\n  # `serviceOpts` is an attribute set which contains configuration\n  # for the exporter's systemd service. One of\n  # `serviceOpts.script` and `serviceOpts.serviceConfig.ExecStart`\n  # has to be specified here. This will be merged with the default\n  # service confiuration.\n  # Note that by default 'DynamicUser' is 'true'.\n  serviceOpts = {\n    serviceConfig = {\n      DynamicUser = false;\n      ExecStart = ''\n        ${pkgs.prometheus-postfix-exporter}/bin/postfix_exporter \\\n          --web.listen-address ${cfg.listenAddress}:${toString cfg.port} \\\n          --web.telemetry-path ${cfg.telemetryPath} \\\n          ${concatStringsSep \" \\\\\\n  \" cfg.extraFlags}\n      '';\n    };\n  };\n}\n\n\n     This should already be enough for the postfix exporter. Additionally one\n     could now add assertions and conditional default values. This can be done\n     in the 'meta-module' that combines all exporter definitions and generates\n     the submodules:\n     nixpkgs/nixos/modules/services/prometheus/exporters.nix\n17.3. Updating an exporter module\n     Should an exporter option change at some point, it is possible to add\n     information about the change to the exporter definition similar to\n     nixpkgs/nixos/modules/rename.nix:\n\n{ config, lib, pkgs, options }:\n\nwith lib;\n\nlet\n  cfg = config.services.prometheus.exporters.nginx;\nin\n{\n  port = 9113;\n  extraOpts = {\n    # additional module options\n    # ...\n  };\n  serviceOpts = {\n    # service configuration\n    # ...\n  };\n  imports = [\n    # 'services.prometheus.exporters.nginx.telemetryEndpoint' -> 'services.prometheus.exporters.nginx.telemetryPath'\n    (mkRenamedOptionModule [ \"telemetryEndpoint\" ] [ \"telemetryPath\" ])\n\n    # removed option 'services.prometheus.exporters.nginx.insecure'\n    (mkRemovedOptionModule [ \"insecure\" ] ''\n      This option was replaced by 'prometheus.exporters.nginx.sslVerify' which defaults to true.\n    '')\n    ({ options.warnings = options.warnings; })\n  ];\n}\n\nChapter 18. WeeChatTable of Contents18.1. Basic Usage18.2. Re-attaching to WeeChat\nWeeChat is a fast and\n  extensible IRC client.\n 18.1. Basic Usage\n   By default, the module creates a\n   systemd\n   unit which runs the chat client in a detached\n   screen\n   session.\n  \n   This can be done by enabling the weechat service:\n\n{ ... }:\n\n{\n  services.weechat.enable = true;\n}\n\n\n   The service is managed by a dedicated user named weechat\n   in the state directory /var/lib/weechat.\n  18.2. Re-attaching to WeeChat\n   WeeChat runs in a screen session owned by a dedicated user. To explicitly\n   allow your another user to attach to this session, the\n   screenrc needs to be tweaked by adding\n   multiuser\n   support:\n\n{\n  programs.screen.screenrc = ''\n    multiuser on\n    acladd normal_user\n  '';\n}\n\n   Now, the session can be re-attached like this:\n\nscreen -x weechat/weechat-screen\n\n\nThe session name can be changed using\n   services.weechat.sessionName.\nChapter 19. TaskserverTable of Contents19.1. Configuration19.2. The nixos-taskserver tool19.3. Declarative/automatic CA management19.4. Manual CA management\n  Taskserver is the server component of\n  Taskwarrior, a free and\n  open source todo list application.\n \nUpstream documentation:\nhttps://taskwarrior.org/docs/#taskd\n19.1. Configuration\n   Taskserver does all of its authentication via TLS using client certificates,\n   so you either need to roll your own CA or purchase a certificate from a\n   known CA, which allows creation of client certificates. These certificates\n   are usually advertised as “server certificates”.\n  \n   So in order to make it easier to handle your own CA, there is a helper tool\n   called nixos-taskserver which manages the custom CA along\n   with Taskserver organisations, users and groups.\n  \n   While the client certificates in Taskserver only authenticate whether a user\n   is allowed to connect, every user has its own UUID which identifies it as an\n   entity.\n  \n   With nixos-taskserver the client certificate is created\n   along with the UUID of the user, so it handles all of the credentials needed\n   in order to setup the Taskwarrior client to work with a Taskserver.\n  19.2. The nixos-taskserver tool\n   Because Taskserver by default only provides scripts to setup users\n   imperatively, the nixos-taskserver tool is used for\n   addition and deletion of organisations along with users and groups defined\n   by services.taskserver.organisations and as well for\n   imperative set up.\n  \n   The tool is designed to not interfere if the command is used to manually set\n   up some organisations, users or groups.\n  \n   For example if you add a new organisation using nixos-taskserver\n   org add foo, the organisation is not modified and deleted no\n   matter what you define in\n   services.taskserver.organisations, even if you're adding\n   the same organisation in that option.\n  \n   The tool is modelled to imitate the official taskd\n   command, documentation for each subcommand can be shown by using the\n   --help switch.\n  19.3. Declarative/automatic CA management\n   Everything is done according to what you specify in the module options,\n   however in order to set up a Taskwarrior client for synchronisation with a\n   Taskserver instance, you have to transfer the keys and certificates to the\n   client machine.\n  \n   This is done using nixos-taskserver user export $orgname\n   $username which is printing a shell script fragment to stdout\n   which can either be used verbatim or adjusted to import the user on the\n   client machine.\n  \n   For example, let's say you have the following configuration:\n\n{\n  services.taskserver.enable = true;\n  services.taskserver.fqdn = \"server\";\n  services.taskserver.listenHost = \"::\";\n  services.taskserver.organisations.my-company.users = [ \"alice\" ];\n}\n\n   This creates an organisation called my-company with the\n   user alice.\n  \n   Now in order to import the alice user to another machine\n   alicebox, all we need to do is something like this:\n\n$ ssh server nixos-taskserver user export my-company alice | sh\n\n   Of course, if no SSH daemon is available on the server you can also copy\n   & paste it directly into a shell.\n  \n   After this step the user should be set up and you can start synchronising\n   your tasks for the first time with task sync init on\n   alicebox.\n  \n   Subsequent synchronisation requests merely require the command task\n   sync after that stage.\n  19.4. Manual CA management\n   If you set any options within\n   service.taskserver.pki.manual.*,\n   nixos-taskserver won't issue certificates, but you can\n   still use it for adding or removing user accounts.\n  Chapter 20. MatrixTable of Contents20.1. Synapse Homeserver20.2. Element (formerly known as Riot) Web Client\nMatrix is an open standard for\n  interoperable, decentralised, real-time communication over IP. It can be used\n  to power Instant Messaging, VoIP/WebRTC signalling, Internet of Things\n  communication - or anywhere you need a standard HTTP API for publishing and\n  subscribing to data whilst tracking the conversation history.\n \n  This chapter will show you how to set up your own, self-hosted Matrix\n  homeserver using the Synapse reference homeserver, and how to serve your own\n  copy of the Element web client. See the\n  Try\n  Matrix Now! overview page for links to Element Apps for Android and iOS,\n  desktop clients, as well as bridges to other networks and other projects\n  around Matrix.\n 20.1. Synapse Homeserver\nSynapse is\n   the reference homeserver implementation of Matrix from the core development\n   team at matrix.org. The following configuration example will set up a\n   synapse server for the example.org domain, served from\n   the host myhostname.example.org. For more information,\n   please refer to the\n   \n   installation instructions of Synapse .\n\n{ pkgs, ... }:\nlet\n  fqdn =\n    let\n      join = hostName: domain: hostName + optionalString (domain != null) \".${domain}\";\n    in join config.networking.hostName config.networking.domain;\nin {\n  networking = {\n    hostName = \"myhostname\";\n    domain = \"example.org\";\n  };\n  networking.firewall.allowedTCPPorts = [ 80 443 ];\n\n  services.postgresql.enable = true;\n  services.postgresql.initialScript = pkgs.writeText \"synapse-init.sql\" ''\n    CREATE ROLE \"matrix-synapse\" WITH LOGIN PASSWORD 'synapse';\n    CREATE DATABASE \"matrix-synapse\" WITH OWNER \"matrix-synapse\"\n      TEMPLATE template0\n      LC_COLLATE = \"C\"\n      LC_CTYPE = \"C\";\n  '';\n\n  services.nginx = {\n    enable = true;\n    # only recommendedProxySettings and recommendedGzipSettings are strictly required,\n    # but the rest make sense as well\n    recommendedTlsSettings = true;\n    recommendedOptimisation = true;\n    recommendedGzipSettings = true;\n    recommendedProxySettings = true;\n\n    virtualHosts = {\n      # This host section can be placed on a different host than the rest,\n      # i.e. to delegate from the host being accessible as ${config.networking.domain}\n      # to another host actually running the Matrix homeserver.\n      \"${config.networking.domain}\" = {\n        locations.\"= /.well-known/matrix/server\".extraConfig =\n          let\n            # use 443 instead of the default 8448 port to unite\n            # the client-server and server-server port for simplicity\n            server = { \"m.server\" = \"${fqdn}:443\"; };\n          in ''\n            add_header Content-Type application/json;\n            return 200 '${builtins.toJSON server}';\n          '';\n        locations.\"= /.well-known/matrix/client\".extraConfig =\n          let\n            client = {\n              \"m.homeserver\" =  { \"base_url\" = \"https://${fqdn}\"; };\n              \"m.identity_server\" =  { \"base_url\" = \"https://vector.im\"; };\n            };\n          # ACAO required to allow element-web on any URL to request this json file\n          in ''\n            add_header Content-Type application/json;\n            add_header Access-Control-Allow-Origin *;\n            return 200 '${builtins.toJSON client}';\n          '';\n      };\n\n      # Reverse proxy for Matrix client-server and server-server communication\n      ${fqdn} = {\n        enableACME = true;\n        forceSSL = true;\n\n        # Or do a redirect instead of the 404, or whatever is appropriate for you.\n        # But do not put a Matrix Web client here! See the Element web section below.\n        locations.\"/\".extraConfig = ''\n          return 404;\n        '';\n\n        # forward all Matrix API calls to the synapse Matrix homeserver\n        locations.\"/_matrix\" = {\n          proxyPass = \"http://[::1]:8008\"; # without a trailing /\n        };\n      };\n    };\n  };\n  services.matrix-synapse = {\n    enable = true;\n    server_name = config.networking.domain;\n    listeners = [\n      {\n        port = 8008;\n        bind_address = \"::1\";\n        type = \"http\";\n        tls = false;\n        x_forwarded = true;\n        resources = [\n          {\n            names = [ \"client\" \"federation\" ];\n            compress = false;\n          }\n        ];\n      }\n    ];\n  };\n};\n\n\n   If the A and AAAA DNS records on\n   example.org do not point on the same host as the records\n   for myhostname.example.org, you can easily move the\n   /.well-known virtualHost section of the code to the host that\n   is serving example.org, while the rest stays on\n   myhostname.example.org with no other changes required.\n   This pattern also allows to seamlessly move the homeserver from\n   myhostname.example.org to\n   myotherhost.example.org by only changing the\n   /.well-known redirection target.\n  \n   If you want to run a server with public registration by anybody, you can\n   then enable services.matrix-synapse.enable_registration =\n   true;. Otherwise, or you can generate a registration secret with\n   pwgen -s 64 1 and set it with\n   services.matrix-synapse.registration_shared_secret. To\n   create a new user or admin, run the following after you have set the secret\n   and have rebuilt NixOS:\n\n$ nix run nixpkgs.matrix-synapse\n$ register_new_matrix_user -k your-registration-shared-secret http://localhost:8008\nNew user localpart: your-username\nPassword:\nConfirm password:\nMake admin [no]:\nSuccess!\n\n   In the example, this would create a user with the Matrix Identifier\n   @your-username:example.org. Note that the registration\n   secret ends up in the nix store and therefore is world-readable by any user\n   on your machine, so it makes sense to only temporarily activate the\n   registration_shared_secret\n   option until a better solution for NixOS is in place.\n  20.2. Element (formerly known as Riot) Web Client\nElement Web is\n   the reference web client for Matrix and developed by the core team at\n   matrix.org. Element was formerly known as Riot.im, see the\n   Element introductory blog post\n   for more information. The following snippet can be optionally added to the code before\n   to complete the synapse installation with a web client served at\n   https://element.myhostname.example.org and\n   https://element.example.org. Alternatively, you can use the hosted\n   copy at https://app.element.io/,\n   or use other web clients or native client applications. Due to the\n   /.well-known urls set up done above, many clients should\n   fill in the required connection details automatically when you enter your\n   Matrix Identifier. See\n   Try\n   Matrix Now! for a list of existing clients and their supported\n   featureset.\n\n{\n  services.nginx.virtualHosts.\"element.${fqdn}\" = {\n    enableACME = true;\n    forceSSL = true;\n    serverAliases = [\n      \"element.${config.networking.domain}\"\n    ];\n\n    root = pkgs.element-web.override {\n      conf = {\n        default_server_config.\"m.homeserver\" = {\n          \"base_url\" = \"${config.networking.domain}\";\n          \"server_name\" = \"${fqdn}\";\n        };\n      };\n    };\n  };\n}\n\n\n   Note that the Element developers do not recommend running Element and your Matrix\n   homeserver on the same fully-qualified domain name for security reasons. In\n   the example, this means that you should not reuse the\n   myhostname.example.org virtualHost to also serve Element,\n   but instead serve it on a different subdomain, like\n   element.example.org in the example. See the\n   Element\n   Important Security Notes for more information on this subject.\n  Chapter 21. GitlabTable of Contents21.1. Prerequisites21.2. Configuring21.3. Maintenance\n  Gitlab is a feature-rich git hosting service.\n 21.1. Prerequisites\n   The gitlab service exposes only an Unix socket at\n   /run/gitlab/gitlab-workhorse.socket. You need to\n   configure a webserver to proxy HTTP requests to the socket.\n  \n   For instance, the following configuration could be used to use nginx as\n   frontend proxy:\n\nservices.nginx = {\n  enable = true;\n  recommendedGzipSettings = true;\n  recommendedOptimisation = true;\n  recommendedProxySettings = true;\n  recommendedTlsSettings = true;\n  virtualHosts.\"git.example.com\" = {\n    enableACME = true;\n    forceSSL = true;\n    locations.\"/\".proxyPass = \"http://unix:/run/gitlab/gitlab-workhorse.socket\";\n  };\n};\n\n21.2. Configuring\n   Gitlab depends on both PostgreSQL and Redis and will automatically enable\n   both services. In the case of PostgreSQL, a database and a role will be\n   created.\n  \n   The default state dir is /var/gitlab/state. This is where\n   all data like the repositories and uploads will be stored.\n  \n   A basic configuration with some custom settings could look like this:\n\nservices.gitlab = {\n  enable = true;\n  databasePasswordFile = \"/var/keys/gitlab/db_password\";\n  initialRootPasswordFile = \"/var/keys/gitlab/root_password\";\n  https = true;\n  host = \"git.example.com\";\n  port = 443;\n  user = \"git\";\n  group = \"git\";\n  smtp = {\n    enable = true;\n    address = \"localhost\";\n    port = 25;\n  };\n  secrets = {\n    dbFile = \"/var/keys/gitlab/db\";\n    secretFile = \"/var/keys/gitlab/secret\";\n    otpFile = \"/var/keys/gitlab/otp\";\n    jwsFile = \"/var/keys/gitlab/jws\";\n  };\n  extraConfig = {\n    gitlab = {\n      email_from = \"gitlab-no-reply@example.com\";\n      email_display_name = \"Example GitLab\";\n      email_reply_to = \"gitlab-no-reply@example.com\";\n      default_projects_features = { builds = false; };\n    };\n  };\n};\n\n\n   If you're setting up a new Gitlab instance, generate new\n   secrets. You for instance use tr -dc A-Za-z0-9 <\n   /dev/urandom | head -c 128 > /var/keys/gitlab/db to\n   generate a new db secret. Make sure the files can be read by, and\n   only by, the user specified by services.gitlab.user. Gitlab\n   encrypts sensitive data stored in the database. If you're restoring\n   an existing Gitlab instance, you must specify the secrets secret\n   from config/secrets.yml located in your Gitlab\n   state folder.\n  \n   Refer to Appendix A, Configuration Options for all available configuration\n   options for the\n   services.gitlab module.\n  21.3. Maintenance\n   You can run Gitlab's rake tasks with gitlab-rake which\n   will be available on the system when gitlab is enabled. You will have to run\n   the command as the user that you configured to run gitlab with.\n  \n   For example, to backup a Gitlab instance:\n\n$ sudo -u git -H gitlab-rake gitlab:backup:create\n\n   A list of all availabe rake tasks can be obtained by running:\n\n$ sudo -u git -H gitlab-rake -T\n\nChapter 22. Trezor\n  Trezor is an open-source cryptocurrency hardware wallet and security token\n  allowing secure storage of private keys.\n \n  It offers advanced features such U2F two-factor authorization, SSH login\n  through\n  Trezor SSH agent,\n  GPG and a\n  password manager.\n  For more information, guides and documentation, see https://wiki.trezor.io.\n \n  To enable Trezor support, add the following to your configuration.nix:\n\nservices.trezord.enable = true;\n\n  This will add all necessary udev rules and start Trezor Bridge.\n Chapter 23. EmacsTable of Contents23.1. Installing Emacs23.2. Running Emacs as a Service23.3. Configuring Emacs\nEmacs is an\n  extensible, customizable, self-documenting real-time display editor — and\n  more. At its core is an interpreter for Emacs Lisp, a dialect of the Lisp\n  programming language with extensions to support text editing.\n \n  Emacs runs within a graphical desktop environment using the X Window System,\n  but works equally well on a text terminal. Under\n  macOS, a \"Mac port\" edition is available, which\n  uses Apple's native GUI frameworks.\n \nNixpkgs provides a superior environment for\n  running Emacs. It's simple to create custom builds\n  by overriding the default packages. Chaotic collections of Emacs Lisp code\n  and extensions can be brought under control using declarative package\n  management. NixOS even provides a\n  systemd user service for automatically starting the Emacs\n  daemon.\n 23.1. Installing Emacs\n   Emacs can be installed in the normal way for Nix (see\n   Chapter 6, Package Management). In addition, a NixOS\n   service can be enabled.\n  23.1.1. The Different Releases of Emacs\nNixpkgs defines several basic Emacs packages.\n    The following are attributes belonging to the pkgs set:\n    \nemacs\n      , \nemacs25\n\n        The latest stable version of Emacs 25 using the\n        GTK 2\n        widget toolkit.\n       \nemacs25-nox\n\n        Emacs 25 built without any dependency on X11 libraries.\n       \nemacsMacport\n      , \nemacs25Macport\n\n        Emacs 25 with the \"Mac port\" patches, providing a more native look and\n        feel under macOS.\n       \n\n    If those aren't suitable, then the following imitation Emacs editors are\n    also available in Nixpkgs:\n    Zile,\n    mg,\n    Yi,\n    jmacs.\n   23.1.2. Adding Packages to Emacs\n    Emacs includes an entire ecosystem of functionality beyond text editing,\n    including a project planner, mail and news reader, debugger interface,\n    calendar, and more.\n   \n    Most extensions are gotten with the Emacs packaging system\n    (package.el) from\n    Emacs Lisp Package Archive\n    (ELPA),\n    MELPA,\n    MELPA Stable, and\n    Org ELPA. Nixpkgs is\n    regularly updated to mirror all these archives.\n   \n    Under NixOS, you can continue to use\n    package-list-packages and\n    package-install to install packages. You can also\n    declare the set of Emacs packages you need using the derivations from\n    Nixpkgs. The rest of this section discusses declarative installation of\n    Emacs packages through nixpkgs.\n   \n    The first step to declare the list of packages you want in your Emacs\n    installation is to create a dedicated derivation. This can be done in a\n    dedicated emacs.nix file such as:\n    Example 23.1. Nix expression to build Emacs with packages (emacs.nix)\n/*\nThis is a nix expression to build Emacs and some Emacs packages I like\nfrom source on any distribution where Nix is installed. This will install\nall the dependencies from the nixpkgs repository and build the binary files\nwithout interfering with the host distribution.\n\nTo build the project, type the following from the current directory:\n\n$ nix-build emacs.nix\n\nTo run the newly compiled executable:\n\n$ ./result/bin/emacs\n*/\n{ pkgs ? import <nixpkgs> {} }: \n\nlet\n  myEmacs = pkgs.emacs; \n  emacsWithPackages = (pkgs.emacsPackagesGen myEmacs).emacsWithPackages; \nin\n  emacsWithPackages (epkgs: (with epkgs.melpaStablePackages; [ \n    magit          # ; Integrate git <C-x g>\n    zerodark-theme # ; Nicolas' theme\n  ]) ++ (with epkgs.melpaPackages; [ \n    undo-tree      # ; <C-x u> to show the undo tree\n    zoom-frm       # ; increase/decrease font size for all buffers %lt;C-x C-+>\n  ]) ++ (with epkgs.elpaPackages; [ \n    auctex         # ; LaTeX mode\n    beacon         # ; highlight my cursor when scrolling\n    nameless       # ; hide current package name everywhere in elisp code\n  ]) ++ [\n    pkgs.notmuch   # From main packages set \n  ])\n\n \n       The first non-comment line in this file ({ pkgs ? ...\n       }) indicates that the whole file represents a function.\n       \n       The let expression below defines a\n       myEmacs binding pointing to the current stable\n       version of Emacs. This binding is here to separate the choice of the\n       Emacs binary from the specification of the required packages.\n       \n       This generates an emacsWithPackages function. It\n       takes a single argument: a function from a package set to a list of\n       packages (the packages that will be available in Emacs).\n       \n       The rest of the file specifies the list of packages to install. In the\n       example, two packages (magit and\n       zerodark-theme) are taken from MELPA stable.\n       \n       Two packages (undo-tree and\n       zoom-frm) are taken from MELPA.\n       \n       Three packages are taken from GNU ELPA.\n       \nnotmuch is taken from a nixpkgs derivation which\n       contains an Emacs mode.\n      \n\n    The result of this configuration will be an emacs\n    command which launches Emacs with all of your chosen packages in the\n    load-path.\n   \n    You can check that it works by executing this in a terminal:\n\n$ nix-build emacs.nix\n$ ./result/bin/emacs -q\n\n    and then typing M-x package-initialize. Check that you\n    can use all the packages you want in this Emacs instance. For example, try\n    switching to the zerodark theme through M-x load-theme <RET>\n    zerodark <RET> y.\n   Tip\n     A few popular extensions worth checking out are: auctex, company,\n     edit-server, flycheck, helm, iedit, magit, multiple-cursors, projectile,\n     and yasnippet.\n    \n    The list of available packages in the various ELPA repositories can be seen\n    with the following commands:\n    Example 23.2. Querying Emacs packages\nnix-env -f \"<nixpkgs>\" -qaP -A emacsPackages.elpaPackages\nnix-env -f \"<nixpkgs>\" -qaP -A emacsPackages.melpaPackages\nnix-env -f \"<nixpkgs>\" -qaP -A emacsPackages.melpaStablePackages\nnix-env -f \"<nixpkgs>\" -qaP -A emacsPackages.orgPackages\n\n\n    If you are on NixOS, you can install this particular Emacs for all users by\n    adding it to the list of system packages (see\n    Section 6.1, “Declarative Package Management”). Simply modify your file\n    configuration.nix to make it contain:\n    Example 23.3. Custom Emacs in configuration.nix\n{\n environment.systemPackages = [\n   # [...]\n   (import /path/to/emacs.nix { inherit pkgs; })\n  ];\n}\n\n\n    In this case, the next nixos-rebuild switch will take\n    care of adding your emacs to the PATH\n    environment variable (see Chapter 3, Changing the Configuration).\n   \n    If you are not on NixOS or want to install this particular Emacs only for\n    yourself, you can do so by adding it to your\n    ~/.config/nixpkgs/config.nix (see\n    Nixpkgs\n    manual):\n    Example 23.4. Custom Emacs in ~/.config/nixpkgs/config.nix\n{\n  packageOverrides = super: let self = super.pkgs; in {\n    myemacs = import /path/to/emacs.nix { pkgs = self; };\n  };\n}\n\n\n    In this case, the next nix-env -f '<nixpkgs>' -iA\n    myemacs will take care of adding your emacs to the\n    PATH environment variable.\n   23.1.3. Advanced Emacs Configuration\n    If you want, you can tweak the Emacs package itself from your\n    emacs.nix. For example, if you want to have a\n    GTK 3-based Emacs instead of the default GTK 2-based binary and remove the\n    automatically generated emacs.desktop (useful is you\n    only use emacsclient), you can change your file\n    emacs.nix in this way:\n   Example 23.5. Custom Emacs build\n{ pkgs ? import <nixpkgs> {} }:\nlet\n  myEmacs = (pkgs.emacs.override {\n    # Use gtk3 instead of the default gtk2\n    withGTK3 = true;\n    withGTK2 = false;\n  }).overrideAttrs (attrs: {\n    # I don't want emacs.desktop file because I only use\n    # emacsclient.\n    postInstall = (attrs.postInstall or \"\") + ''\n      rm $out/share/applications/emacs.desktop\n    '';\n  });\nin [...]\n\n    After building this file as shown in Example 23.1, “Nix expression to build Emacs with packages (emacs.nix)”, you\n    will get an GTK 3-based Emacs binary pre-loaded with your favorite packages.\n   23.2. Running Emacs as a Service\nNixOS provides an optional\n   systemd service which launches\n   \n   Emacs daemon  with the user's login session.\n  \nSource:\nmodules/services/editors/emacs.nix\n23.2.1. Enabling the Service\n    To install and enable the systemd user service for Emacs\n    daemon, add the following to your configuration.nix:\n\nservices.emacs.enable = true;\nservices.emacs.package = import /home/cassou/.emacs.d { pkgs = pkgs; };\n\n\n    The services.emacs.package option allows a custom\n    derivation to be used, for example, one created by\n    emacsWithPackages.\n   \n    Ensure that the Emacs server is enabled for your user's Emacs\n    configuration, either by customizing the server-mode\n    variable, or by adding (server-start) to\n    ~/.emacs.d/init.el.\n   \n    To start the daemon, execute the following:\n\n$ nixos-rebuild switch  # to activate the new configuration.nix\n$ systemctl --user daemon-reload        # to force systemd reload\n$ systemctl --user start emacs.service  # to start the Emacs daemon\n\n    The server should now be ready to serve Emacs clients.\n   23.2.2. Starting the client\n    Ensure that the emacs server is enabled, either by customizing the\n    server-mode variable, or by adding\n    (server-start) to ~/.emacs.\n   \n    To connect to the emacs daemon, run one of the following:\n\nemacsclient FILENAME\nemacsclient --create-frame  # opens a new frame (window)\nemacsclient --create-frame --tty  # opens a new frame on the current terminal\n\n23.2.3. Configuring the EDITOR variable\n    If services.emacs.defaultEditor is\n    true, the EDITOR variable will be set\n    to a wrapper script which launches emacsclient.\n   \n    Any setting of EDITOR in the shell config files will\n    override services.emacs.defaultEditor. To make sure\n    EDITOR refers to the Emacs wrapper script, remove any\n    existing EDITOR assignment from\n    .profile, .bashrc,\n    .zshenv or any other shell config file.\n   \n    If you have formed certain bad habits when editing files, these can be\n    corrected with a shell alias to the wrapper script:\nalias vi=$EDITOR\n23.2.4. Per-User Enabling of the Service\n    In general, systemd user services are globally enabled\n    by symlinks in /etc/systemd/user. In the case where\n    Emacs daemon is not wanted for all users, it is possible to install the\n    service but not globally enable it:\n\nservices.emacs.enable = false;\nservices.emacs.install = true;\n\n\n    To enable the systemd user service for just the\n    currently logged in user, run:\nsystemctl --user enable emacs\n    This will add the symlink\n    ~/.config/systemd/user/emacs.service.\n   23.3. Configuring Emacs\n   The Emacs init file should be changed to load the extension packages at\n   startup:\n   Example 23.6. Package initialization in .emacs\n(require 'package)\n\n;; optional. makes unpure packages archives unavailable\n(setq package-archives nil)\n\n(setq package-enable-at-startup nil)\n(package-initialize)\n\n\n   After the declarative emacs package configuration has been tested,\n   previously downloaded packages can be cleaned up by removing\n   ~/.emacs.d/elpa (do make a backup first, in case you\n   forgot a package).\n  23.3.1. A Major Mode for Nix Expressions\n    Of interest may be melpaPackages.nix-mode, which\n    provides syntax highlighting for the Nix language. This is particularly\n    convenient if you regularly edit Nix files.\n   23.3.2. Accessing man pages\n    You can use woman to get completion of all available\n    man pages. For example, type M-x woman <RET> nixos-rebuild\n    <RET>.\n23.3.3. Editing DocBook 5 XML Documents\n    Emacs includes\n    nXML,\n    a major-mode for validating and editing XML documents. When editing DocBook\n    5.0 documents, such as this one,\n    nXML needs to be configured with the relevant schema, which is not\n    included.\n   \n    To install the DocBook 5.0 schemas, either add\n    pkgs.docbook5 to\n    environment.systemPackages\n    (NixOS), or run\n    nix-env -f '<nixpkgs>' -iA docbook5\n    (Nix).\n   \n    Then customize the variable rng-schema-locating-files to\n    include ~/.emacs.d/schemas.xml and put the following\n    text into that file:\n    Example 23.7. nXML Schema Configuration (~/.emacs.d/schemas.xml)\n<?xml version=\"1.0\"?>\n<!--\n  To let emacs find this file, evaluate:\n  (add-to-list 'rng-schema-locating-files \"~/.emacs.d/schemas.xml\")\n-->\n<locatingRules xmlns=\"http://thaiopensource.com/ns/locating-rules/1.0\">\n  <!--\n    Use this variation if pkgs.docbook5 is added to environment.systemPackages\n  -->\n  <namespace ns=\"http://docbook.org/ns/docbook\"\n             uri=\"/run/current-system/sw/share/xml/docbook-5.0/rng/docbookxi.rnc\"/>\n  <!--\n    Use this variation if installing schema with \"nix-env -iA pkgs.docbook5\".\n  <namespace ns=\"http://docbook.org/ns/docbook\"\n             uri=\"../.nix-profile/share/xml/docbook-5.0/rng/docbookxi.rnc\"/>\n  -->\n</locatingRules>\n\nChapter 24. Flatpak\nSource:\nmodules/services/desktop/flatpak.nix\n\nUpstream documentation:\nhttps://github.com/flatpak/flatpak/wiki\n\n  Flatpak is a system for building, distributing, and running sandboxed desktop\n  applications on Linux.\n \n  To enable Flatpak, add the following to your\n  configuration.nix:\n\n  services.flatpak.enable = true;\n\n\n  For the sandboxed apps to work correctly, desktop integration portals need to\n  be installed. If you run GNOME, this will be handled automatically for you;\n  in other cases, you will need to add something like the following to your\n  configuration.nix:\n\n  xdg.portal.extraPortals = [ pkgs.xdg-desktop-portal-gtk ];\n\n\n  Then, you will need to add a repository, for example,\n  Flathub,\n  either using the following commands:\n\n$ flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\n$ flatpak update\n\n  or by opening the\n  repository\n  file in GNOME Software.\n \n  Finally, you can search and install programs:\n\n$ flatpak search bustle\n$ flatpak install flathub org.freedesktop.Bustle\n$ flatpak run org.freedesktop.Bustle\n\n  Again, GNOME Software offers graphical interface for these tasks.\n Chapter 25. PostgreSQLTable of Contents25.1. Configuring25.2. Upgrading25.3. Options25.4. Plugins\nSource: modules/services/databases/postgresql.nix\n\nUpstream documentation: http://www.postgresql.org/docs/\n\n  PostgreSQL is an advanced, free relational database.\n\n 25.1. Configuring\n   To enable PostgreSQL, add the following to your configuration.nix:\n\nservices.postgresql.enable = true;\nservices.postgresql.package = pkgs.postgresql_11;\n\n   Note that you are required to specify the desired version of PostgreSQL (e.g. pkgs.postgresql_11). Since upgrading your PostgreSQL version requires a database dump and reload (see below), NixOS cannot provide a default value for services.postgresql.package such as the most recent release of PostgreSQL.\n  \n   By default, PostgreSQL stores its databases in /var/lib/postgresql/$psqlSchema. You can override this using services.postgresql.dataDir, e.g.\n\nservices.postgresql.dataDir = \"/data/postgresql\";\n\n25.2. Upgrading\n   Major PostgreSQL upgrade requires PostgreSQL downtime and a few imperative steps to be called. To simplify this process, use the following NixOS module:\n\n  containers.temp-pg.config.services.postgresql = {\n    enable = true;\n    package = pkgs.postgresql_12;\n    ## set a custom new dataDir\n    # dataDir = \"/some/data/dir\";\n  };\n  environment.systemPackages =\n    let newpg = config.containers.temp-pg.config.services.postgresql;\n    in [\n      (pkgs.writeScriptBin \"upgrade-pg-cluster\" ''\n        set -x\n        export OLDDATA=\"${config.services.postgresql.dataDir}\"\n        export NEWDATA=\"${newpg.dataDir}\"\n        export OLDBIN=\"${config.services.postgresql.package}/bin\"\n        export NEWBIN=\"${newpg.package}/bin\"\n\n        install -d -m 0700 -o postgres -g postgres \"$NEWDATA\"\n        cd \"$NEWDATA\"\n        sudo -u postgres $NEWBIN/initdb -D \"$NEWDATA\"\n\n        systemctl stop postgresql    # old one\n\n        sudo -u postgres $NEWBIN/pg_upgrade \\\n          --old-datadir \"$OLDDATA\" --new-datadir \"$NEWDATA\" \\\n          --old-bindir $OLDBIN --new-bindir $NEWBIN \\\n          \"$@\"\n      '')\n    ];\n\n\n   The upgrade process is:\n  \n     Rebuild nixos configuration with the configuration above added to your configuration.nix. Alternatively, add that into separate file and reference it in imports list.\n    \n     Login as root (sudo su -)\n    \n     Run upgrade-pg-cluster. It will stop old postgresql, initialize new one and migrate old one to new one. You may supply arguments like --jobs 4 and --link to speedup migration process. See https://www.postgresql.org/docs/current/pgupgrade.html for details.\n    \n     Change postgresql package in NixOS configuration to the one you were upgrading to, and change dataDir to the one you have migrated to. Rebuild NixOS. This should start new postgres using upgraded data directory.\n    \n     After upgrade you may want to ANALYZE new db.\n    25.3. Options\n   A complete list of options for the PostgreSQL module may be found here.\n  25.4. Plugins\n   Plugins collection for each PostgreSQL version can be accessed with .pkgs. For example, for pkgs.postgresql_11 package, its plugin collection is accessed by pkgs.postgresql_11.pkgs:\n\n$ nix repl '<nixpkgs>'\n\nLoading '<nixpkgs>'...\nAdded 10574 variables.\n\nnix-repl> postgresql_11.pkgs.<TAB><TAB>\npostgresql_11.pkgs.cstore_fdw        postgresql_11.pkgs.pg_repack\npostgresql_11.pkgs.pg_auto_failover  postgresql_11.pkgs.pg_safeupdate\npostgresql_11.pkgs.pg_bigm           postgresql_11.pkgs.pg_similarity\npostgresql_11.pkgs.pg_cron           postgresql_11.pkgs.pg_topn\npostgresql_11.pkgs.pg_hll            postgresql_11.pkgs.pgjwt\npostgresql_11.pkgs.pg_partman        postgresql_11.pkgs.pgroonga\n...\n\n\n   To add plugins via NixOS configuration, set services.postgresql.extraPlugins:\n\nservices.postgresql.package = pkgs.postgresql_11;\nservices.postgresql.extraPlugins = with pkgs.postgresql_11.pkgs; [\n  pg_repack\n  postgis\n];\n\n\n   You can build custom PostgreSQL-with-plugins (to be used outside of NixOS) using function .withPackages. For example, creating a custom PostgreSQL package in an overlay can look like:\n\nself: super: {\n  postgresql_custom = self.postgresql_11.withPackages (ps: [\n    ps.pg_repack\n    ps.postgis\n  ]);\n}\n\n\n   Here's a recipe on how to override a particular plugin through an overlay:\n\nself: super: {\n  postgresql_11 = super.postgresql_11.override { this = self.postgresql_11; } // {\n    pkgs = super.postgresql_11.pkgs // {\n      pg_repack = super.postgresql_11.pkgs.pg_repack.overrideAttrs (_: {\n        name = \"pg_repack-v20181024\";\n        src = self.fetchzip {\n          url = \"https://github.com/reorg/pg_repack/archive/923fa2f3c709a506e111cc963034bf2fd127aa00.tar.gz\";\n          sha256 = \"17k6hq9xaax87yz79j773qyigm4fwk8z4zh5cyp6z0sxnwfqxxw5\";\n        };\n      });\n    };\n  };\n}\n\nChapter 26. FoundationDBTable of Contents26.1. Configuring and basic setup26.2. Scaling processes and backup agents26.3. Clustering26.4. Client connectivity26.5. Client authorization and TLS26.6. Backups and Disaster Recovery26.7. Known limitations26.8. Options26.9. Full documentation\nSource:\nmodules/services/databases/foundationdb.nix\n\nUpstream documentation:\nhttps://apple.github.io/foundationdb/\n\nMaintainer: Austin Seipp\n \nAvailable version(s): 5.1.x, 5.2.x, 6.0.x\n \n  FoundationDB (or \"FDB\") is an open source, distributed, transactional\n  key-value store.\n 26.1. Configuring and basic setup\n   To enable FoundationDB, add the following to your\n   configuration.nix:\n\nservices.foundationdb.enable = true;\nservices.foundationdb.package = pkgs.foundationdb52; # FoundationDB 5.2.x\n\n\n   The services.foundationdb.package option is required, and\n   must always be specified. Due to the fact FoundationDB network protocols and\n   on-disk storage formats may change between (major) versions, and upgrades\n   must be explicitly handled by the user, you must always manually specify\n   this yourself so that the NixOS module will use the proper version. Note\n   that minor, bugfix releases are always compatible.\n  \n   After running nixos-rebuild, you can verify whether\n   FoundationDB is running by executing fdbcli (which is\n   added to environment.systemPackages):\n\n$ sudo -u foundationdb fdbcli\nUsing cluster file `/etc/foundationdb/fdb.cluster'.\n\nThe database is available.\n\nWelcome to the fdbcli. For help, type `help'.\nfdb> status\n\nUsing cluster file `/etc/foundationdb/fdb.cluster'.\n\nConfiguration:\n  Redundancy mode        - single\n  Storage engine         - memory\n  Coordinators           - 1\n\nCluster:\n  FoundationDB processes - 1\n  Machines               - 1\n  Memory availability    - 5.4 GB per process on machine with least available\n  Fault Tolerance        - 0 machines\n  Server time            - 04/20/18 15:21:14\n\n...\n\nfdb>\n\n\n   You can also write programs using the available client libraries. For\n   example, the following Python program can be run in order to grab the\n   cluster status, as a quick example. (This example uses\n   nix-shell shebang support to automatically supply the\n   necessary Python modules).\n\na@link> cat fdb-status.py\n#! /usr/bin/env nix-shell\n#! nix-shell -i python -p python pythonPackages.foundationdb52\n\nimport fdb\nimport json\n\ndef main():\n    fdb.api_version(520)\n    db = fdb.open()\n\n    @fdb.transactional\n    def get_status(tr):\n        return str(tr['\\xff\\xff/status/json'])\n\n    obj = json.loads(get_status(db))\n    print('FoundationDB available: %s' % obj['client']['database_status']['available'])\n\nif __name__ == \"__main__\":\n    main()\na@link> chmod +x fdb-status.py\na@link> ./fdb-status.py\nFoundationDB available: True\na@link>\n\n\n   FoundationDB is run under the foundationdb user and group\n   by default, but this may be changed in the NixOS configuration. The systemd\n   unit foundationdb.service controls the\n   fdbmonitor process.\n  \n   By default, the NixOS module for FoundationDB creates a single SSD-storage\n   based database for development and basic usage. This storage engine is\n   designed for SSDs and will perform poorly on HDDs; however it can handle far\n   more data than the alternative \"memory\" engine and is a better default\n   choice for most deployments. (Note that you can change the storage backend\n   on-the-fly for a given FoundationDB cluster using\n   fdbcli.)\n  \n   Furthermore, only 1 server process and 1 backup agent are started in the\n   default configuration. See below for more on scaling to increase this.\n  \n   FoundationDB stores all data for all server processes under\n   /var/lib/foundationdb. You can override this using\n   services.foundationdb.dataDir, e.g.\n\nservices.foundationdb.dataDir = \"/data/fdb\";\n\n\n   Similarly, logs are stored under /var/log/foundationdb\n   by default, and there is a corresponding\n   services.foundationdb.logDir as well.\n  26.2. Scaling processes and backup agents\n   Scaling the number of server processes is quite easy; simply specify\n   services.foundationdb.serverProcesses to be the number of\n   FoundationDB worker processes that should be started on the machine.\n  \n   FoundationDB worker processes typically require 4GB of RAM per-process at\n   minimum for good performance, so this option is set to 1 by default since\n   the maximum amount of RAM is unknown. You're advised to abide by this\n   restriction, so pick a number of processes so that each has 4GB or more.\n  \n   A similar option exists in order to scale backup agent processes,\n   services.foundationdb.backupProcesses. Backup agents are\n   not as performance/RAM sensitive, so feel free to experiment with the number\n   of available backup processes.\n  26.3. Clustering\n   FoundationDB on NixOS works similarly to other Linux systems, so this\n   section will be brief. Please refer to the full FoundationDB documentation\n   for more on clustering.\n  \n   FoundationDB organizes clusters using a set of\n   coordinators, which are just specially-designated\n   worker processes. By default, every installation of FoundationDB on NixOS\n   will start as its own individual cluster, with a single coordinator: the\n   first worker process on localhost.\n  \n   Coordinators are specified globally using the\n   /etc/foundationdb/fdb.cluster file, which all servers and\n   client applications will use to find and join coordinators. Note that this\n   file can not be managed by NixOS so easily:\n   FoundationDB is designed so that it will rewrite the file at runtime for all\n   clients and nodes when cluster coordinators change, with clients\n   transparently handling this without intervention. It is fundamentally a\n   mutable file, and you should not try to manage it in any way in NixOS.\n  \n   When dealing with a cluster, there are two main things you want to do:\n  \n     Add a node to the cluster for storage/compute.\n    \n     Promote an ordinary worker to a coordinator.\n    \n   A node must already be a member of the cluster in order to properly be\n   promoted to a coordinator, so you must always add it first if you wish to\n   promote it.\n  \n   To add a machine to a FoundationDB cluster:\n  \n     Choose one of the servers to start as the initial coordinator.\n    \n     Copy the /etc/foundationdb/fdb.cluster file from this\n     server to all the other servers. Restart FoundationDB on all of these\n     other servers, so they join the cluster.\n    \n     All of these servers are now connected and working together in the\n     cluster, under the chosen coordinator.\n    \n   At this point, you can add as many nodes as you want by just repeating the\n   above steps. By default there will still be a single coordinator: you can\n   use fdbcli to change this and add new coordinators.\n  \n   As a convenience, FoundationDB can automatically assign coordinators based\n   on the redundancy mode you wish to achieve for the cluster. Once all the\n   nodes have been joined, simply set the replication policy, and then issue\n   the coordinators auto command\n  \n   For example, assuming we have 3 nodes available, we can enable double\n   redundancy mode, then auto-select coordinators. For double redundancy, 3\n   coordinators is ideal: therefore FoundationDB will make\n   every node a coordinator automatically:\n  \nfdbcli> configure double ssd\nfdbcli> coordinators auto\n\n   This will transparently update all the servers within seconds, and\n   appropriately rewrite the fdb.cluster file, as well as\n   informing all client processes to do the same.\n  26.4. Client connectivity\n   By default, all clients must use the current fdb.cluster\n   file to access a given FoundationDB cluster. This file is located by default\n   in /etc/foundationdb/fdb.cluster on all machines with the\n   FoundationDB service enabled, so you may copy the active one from your\n   cluster to a new node in order to connect, if it is not part of the cluster.\n  26.5. Client authorization and TLS\n   By default, any user who can connect to a FoundationDB process with the\n   correct cluster configuration can access anything. FoundationDB uses a\n   pluggable design to transport security, and out of the box it supports a\n   LibreSSL-based plugin for TLS support. This plugin not only does in-flight\n   encryption, but also performs client authorization based on the given\n   endpoint's certificate chain. For example, a FoundationDB server may be\n   configured to only accept client connections over TLS, where the client TLS\n   certificate is from organization Acme Co in the\n   Research and Development unit.\n  \n   Configuring TLS with FoundationDB is done using the\n   services.foundationdb.tls options in order to control the\n   peer verification string, as well as the certificate and its private key.\n  \n   Note that the certificate and its private key must be accessible to the\n   FoundationDB user account that the server runs under. These files are also\n   NOT managed by NixOS, as putting them into the store may reveal private\n   information.\n  \n   After you have a key and certificate file in place, it is not enough to\n   simply set the NixOS module options -- you must also configure the\n   fdb.cluster file to specify that a given set of\n   coordinators use TLS. This is as simple as adding the suffix\n   :tls to your cluster coordinator configuration, after the\n   port number. For example, assuming you have a coordinator on localhost with\n   the default configuration, simply specifying:\n  \nXXXXXX:XXXXXX@127.0.0.1:4500:tls\n\n   will configure all clients and server processes to use TLS from now on.\n  26.6. Backups and Disaster Recovery\n   The usual rules for doing FoundationDB backups apply on NixOS as written in\n   the FoundationDB manual. However, one important difference is the security\n   profile for NixOS: by default, the foundationdb systemd\n   unit uses Linux namespaces to restrict write access to\n   the system, except for the log directory, data directory, and the\n   /etc/foundationdb/ directory. This is enforced by default\n   and cannot be disabled.\n  \n   However, a side effect of this is that the fdbbackup\n   command doesn't work properly for local filesystem backups: FoundationDB\n   uses a server process alongside the database processes to perform backups\n   and copy the backups to the filesystem. As a result, this process is put\n   under the restricted namespaces above: the backup process can only write to\n   a limited number of paths.\n  \n   In order to allow flexible backup locations on local disks, the FoundationDB\n   NixOS module supports a\n   services.foundationdb.extraReadWritePaths option. This\n   option takes a list of paths, and adds them to the systemd unit, allowing\n   the processes inside the service to write (and read) the specified\n   directories.\n  \n   For example, to create backups in /opt/fdb-backups, first\n   set up the paths in the module options:\n  \nservices.foundationdb.extraReadWritePaths = [ \"/opt/fdb-backups\" ];\n\n   Restart the FoundationDB service, and it will now be able to write to this\n   directory (even if it does not yet exist.) Note: this path\n   must exist before restarting the unit. Otherwise,\n   systemd will not include it in the private FoundationDB namespace (and it\n   will not add it dynamically at runtime).\n  \n   You can now perform a backup:\n  \n$ sudo -u foundationdb fdbbackup start  -t default -d file:///opt/fdb-backups\n$ sudo -u foundationdb fdbbackup status -t default\n26.7. Known limitations\n   The FoundationDB setup for NixOS should currently be considered beta.\n   FoundationDB is not new software, but the NixOS compilation and integration\n   has only undergone fairly basic testing of all the available functionality.\n  \n     There is no way to specify individual parameters for individual\n     fdbserver processes. Currently, all server processes\n     inherit all the global fdbmonitor settings.\n    \n     Ruby bindings are not currently installed.\n    \n     Go bindings are not currently installed.\n    26.8. Options\n   NixOS's FoundationDB module allows you to configure all of the most relevant\n   configuration options for fdbmonitor, matching it quite\n   closely. A complete list of options for the FoundationDB module may be found\n   here. You should\n   also read the FoundationDB documentation as well.\n  26.9. Full documentation\n   FoundationDB is a complex piece of software, and requires careful\n   administration to properly use. Full documentation for administration can be\n   found here: https://apple.github.io/foundationdb/.\n  Chapter 27. Hiding process information\n  Setting\n\nsecurity.hideProcessInformation = true;\n\n  ensures that access to process information is restricted to the owning user.\n  This implies, among other things, that command-line arguments remain private.\n  Unless your deployment relies on unprivileged users being able to inspect the\n  process information of other users, this option should be safe to enable.\n \n  Members of the proc group are exempt from process\n  information hiding.\n \n  To allow a service foo to run without process\n  information hiding, set\n\nsystemd.services.foo.serviceConfig.SupplementaryGroups = [ \"proc\" ];\n\nChapter 28. SSL/TLS Certificates with ACMETable of Contents28.1. Prerequisites28.2. Using ACME certificates in Nginx28.3. Using ACME certificates in Apache/httpd28.4. Manual configuration of HTTP-01 validation28.5. Configuring ACME for DNS validation\n  NixOS supports automatic domain validation & certificate retrieval and\n  renewal using the ACME protocol. Any provider can be used, but by default\n  NixOS uses Let's Encrypt. The alternative ACME client lego\n  is used under the hood.\n \n  Automatic cert validation and configuration for Apache and Nginx virtual\n  hosts is included in NixOS, however if you would like to generate a wildcard\n  cert or you are not using a web server you will have to configure DNS\n  based validation.\n 28.1. Prerequisites\n   To use the ACME module, you must accept the provider's terms of service\n   by setting security.acme.acceptTerms\n   to true. The Let's Encrypt ToS can be found\n   here.\n  \n   You must also set an email address to be used when creating accounts with\n   Let's Encrypt. You can set this for all certs with\n   security.acme.email\n   and/or on a per-cert basis with\n   security.acme.certs.<name>.email.\n   This address is only used for registration and renewal reminders,\n   and cannot be used to administer the certificates in any way.\n  \n   Alternatively, you can use a different ACME server by changing the\n   security.acme.server option\n   to a provider of your choosing, or just change the server for one cert with\n   security.acme.certs.<name>.server.\n  \n   You will need an HTTP server or DNS server for verification. For HTTP,\n   the server must have a webroot defined that can serve\n   .well-known/acme-challenge. This directory must be\n   writeable by the user that will run the ACME client. For DNS, you must\n   set up credentials with your provider/server for use with lego.\n  28.2. Using ACME certificates in Nginx\n   NixOS supports fetching ACME certificates for you by setting\n   enableACME\n   = true; in a virtualHost config. We first create self-signed\n   placeholder certificates in place of the real ACME certs. The placeholder\n   certs are overwritten when the ACME certs arrive. For\n   foo.example.com the config would look like.\n  \nsecurity.acme.acceptTerms = true;\nsecurity.acme.email = \"admin+acme@example.com\";\nservices.nginx = {\n  enable = true;\n  virtualHosts = {\n    \"foo.example.com\" = {\n      forceSSL = true;\n      enableACME = true;\n      # All serverAliases will be added as extra domains on the certificate.\n      serverAliases = [ \"bar.example.com\" ];\n      locations.\"/\" = {\n        root = \"/var/www\";\n      };\n    };\n\n    # We can also add a different vhost and reuse the same certificate\n    # but we have to append extraDomains manually.\n    security.acme.certs.\"foo.example.com\".extraDomains.\"baz.example.com\" = null;\n    \"baz.example.com\" = {\n      forceSSL = true;\n      useACMEHost = \"foo.example.com\";\n      locations.\"/\" = {\n        root = \"/var/www\";\n      };\n    };\n  };\n}\n28.3. Using ACME certificates in Apache/httpd\n   Using ACME certificates with Apache virtual hosts is identical\n   to using them with Nginx. The attribute names are all the same, just replace\n   \"nginx\" with \"httpd\" where appropriate.\n  28.4. Manual configuration of HTTP-01 validation\n   First off you will need to set up a virtual host to serve the challenges.\n   This example uses a vhost called certs.example.com, with\n   the intent that you will generate certs for all your vhosts and redirect\n   everyone to HTTPS.\n  \nsecurity.acme.acceptTerms = true;\nsecurity.acme.email = \"admin+acme@example.com\";\nservices.nginx = {\n  enable = true;\n  virtualHosts = {\n    \"acmechallenge.example.com\" = {\n      # Catchall vhost, will redirect users to HTTPS for all vhosts\n      serverAliases = [ \"*.example.com\" ];\n      # /var/lib/acme/.challenges must be writable by the ACME user\n      # and readable by the Nginx user.\n      # By default, this is the case.\n      locations.\"/.well-known/acme-challenge\" = {\n        root = \"/var/lib/acme/.challenges\";\n      };\n      locations.\"/\" = {\n        return = \"301 https://$host$request_uri\";\n      };\n    };\n  };\n}\n# Alternative config for Apache\nservices.httpd = {\n  enable = true;\n  virtualHosts = {\n    \"acmechallenge.example.com\" = {\n      # Catchall vhost, will redirect users to HTTPS for all vhosts\n      serverAliases = [ \"*.example.com\" ];\n      # /var/lib/acme/.challenges must be writable by the ACME user and readable by the Apache user.\n      # By default, this is the case.\n      documentRoot = \"/var/lib/acme/.challenges\";\n      extraConfig = ''\n        RewriteEngine On\n        RewriteCond %{HTTPS} off\n        RewriteCond %{REQUEST_URI} !^/\\.well-known/acme-challenge [NC]\n        RewriteRule (.*) https://%{HTTP_HOST}%{REQUEST_URI} [R=301]\n      '';\n    };\n  };\n}\n\n   Now you need to configure ACME to generate a certificate.\n  \nsecurity.acme.certs.\"foo.example.com\" = {\n  webroot = \"/var/lib/acme/.challenges\";\n  email = \"foo@example.com\";\n  # Since we have a wildcard vhost to handle port 80,\n  # we can generate certs for anything!\n  # Just make sure your DNS resolves them.\n  extraDomains = [ \"mail.example.com\" ];\n};\n\n   The private key key.pem and certificate\n   fullchain.pem will be put into\n   /var/lib/acme/foo.example.com.\n  \n   Refer to Appendix A, Configuration Options for all available configuration\n   options for the security.acme\n   module.\n  28.5. Configuring ACME for DNS validation\n   This is useful if you want to generate a wildcard certificate, since\n   ACME servers will only hand out wildcard certs over DNS validation.\n   There a number of supported DNS providers and servers you can utilise,\n   see the lego docs\n   for provider/server specific configuration values. For the sake of these\n   docs, we will provide a fully self-hosted example using bind.\n  \nservices.bind = {\n  enable = true;\n  extraConfig = ''\n    include \"/var/lib/secrets/dnskeys.conf\";\n  '';\n  zones = [\n    rec {\n      name = \"example.com\";\n      file = \"/var/db/bind/${name}\";\n      master = true;\n      extraConfig = \"allow-update { key rfc2136key.example.com.; };\";\n    }\n  ];\n}\n\n# Now we can configure ACME\nsecurity.acme.acceptTerms = true;\nsecurity.acme.email = \"admin+acme@example.com\";\nsecurity.acme.certs.\"example.com\" = {\n  domain = \"*.example.com\";\n  dnsProvider = \"rfc2136\";\n  credentialsFile = \"/var/lib/secrets/certs.secret\";\n  # We don't need to wait for propagation since this is a local DNS server\n  dnsPropagationCheck = false;\n};\n\n   The dnskeys.conf and certs.secret\n   must be kept secure and thus you should not keep their contents in your\n   Nix config. Instead, generate them one time with these commands:\n  \nmkdir -p /var/lib/secrets\ntsig-keygen rfc2136key.example.com > /var/lib/secrets/dnskeys.conf\nchown named:root /var/lib/secrets/dnskeys.conf\nchmod 400 /var/lib/secrets/dnskeys.conf\n\n# Copy the secret value from the dnskeys.conf, and put it in\n# RFC2136_TSIG_SECRET below\n\ncat > /var/lib/secrets/certs.secret << EOF\nRFC2136_NAMESERVER='127.0.0.1:53'\nRFC2136_TSIG_ALGORITHM='hmac-sha256.'\nRFC2136_TSIG_KEY='rfc2136key.example.com'\nRFC2136_TSIG_SECRET='your secret key'\nEOF\nchmod 400 /var/lib/secrets/certs.secret\n\n   Now you're all set to generate certs! You should monitor the first invokation\n   by running systemctl start acme-example.com.service &\n   journalctl -fu acme-example.com.service and watching its log output.\n  Chapter 29. Oh my ZSHTable of Contents29.1. Basic usage29.2. Custom additions29.3. Custom environments29.4. Package your own customizations\noh-my-zsh is a\n  framework to manage your ZSH\n  configuration including completion scripts for several CLI tools or custom\n  prompt themes.\n 29.1. Basic usage\n   The module uses the oh-my-zsh package with all available\n   features. The initial setup using Nix expressions is fairly similar to the\n   configuration format of oh-my-zsh.\n\n{\n  programs.zsh.ohMyZsh = {\n    enable = true;\n    plugins = [ \"git\" \"python\" \"man\" ];\n    theme = \"agnoster\";\n  };\n}\n\n   For a detailed explanation of these arguments please refer to the\n   oh-my-zsh\n   docs.\n  \n   The expression generates the needed configuration and writes it into your\n   /etc/zshrc.\n  29.2. Custom additions\n   Sometimes third-party or custom scripts such as a modified theme may be\n   needed. oh-my-zsh provides the\n   ZSH_CUSTOM\n   environment variable for this which points to a directory with additional\n   scripts.\n  \n   The module can do this as well:\n\n{\n  programs.zsh.ohMyZsh.custom = \"~/path/to/custom/scripts\";\n}\n\n29.3. Custom environments\n   There are several extensions for oh-my-zsh packaged in\n   nixpkgs. One of them is\n   nix-zsh-completions\n   which bundles completion scripts and a plugin for\n   oh-my-zsh.\n  \n   Rather than using a single mutable path for ZSH_CUSTOM,\n   it's also possible to generate this path from a list of Nix packages:\n\n{ pkgs, ... }:\n{\n  programs.zsh.ohMyZsh.customPkgs = with pkgs; [\n    pkgs.nix-zsh-completions\n    # and even more...\n  ];\n}\n\n   Internally a single store path will be created using\n   buildEnv. Please refer to the docs of\n   buildEnv\n   for further reference.\n  \nPlease keep in mind that this is not compatible with\n   programs.zsh.ohMyZsh.custom as it requires an immutable\n   store path while custom shall remain mutable! An\n   evaluation failure will be thrown if both custom and\n   customPkgs are set.\n29.4. Package your own customizations\n   If third-party customizations (e.g. new themes) are supposed to be added to\n   oh-my-zsh there are several pitfalls to keep in mind:\n  \n     To comply with the default structure of ZSH the entire\n     output needs to be written to $out/share/zsh.\n\n     Completion scripts are supposed to be stored at\n     $out/share/zsh/site-functions. This directory is part\n     of the\n     fpath\n     and the package should be compatible with pure ZSH\n     setups. The module will automatically link the contents of\n     site-functions to completions directory in the proper\n     store path.\n    \n     The plugins directory needs the structure\n     pluginname/pluginname.plugin.zsh as structured in the\n     upstream\n     repo.\n\n   A derivation for oh-my-zsh may look like this:\n\n{ stdenv, fetchFromGitHub }:\n\nstdenv.mkDerivation rec {\n  name = \"exemplary-zsh-customization-${version}\";\n  version = \"1.0.0\";\n  src = fetchFromGitHub {\n    # path to the upstream repository\n  };\n\n  dontBuild = true;\n  installPhase = ''\n    mkdir -p $out/share/zsh/site-functions\n    cp {themes,plugins} $out/share/zsh\n    cp completions $out/share/zsh/site-functions\n  '';\n}\n\nChapter 30. Plotinus\nSource:\nmodules/programs/plotinus.nix\n\nUpstream documentation:\nhttps://github.com/p-e-w/plotinus\n\n  Plotinus is a searchable command palette in every modern GTK application.\n \n  When in a GTK 3 application and Plotinus is enabled, you can press\n  Ctrl+Shift+P to open the command palette. The command\n  palette provides a searchable list of of all menu items in the application.\n \n  To enable Plotinus, add the following to your\n  configuration.nix:\n\nprograms.plotinus.enable = true;\n\nChapter 31. Digital BitboxTable of Contents31.1. Package31.2. Hardware\n  Digital Bitbox is a hardware wallet and second-factor authenticator.\n \n  The digitalbitbox programs module may be installed by\n  setting programs.digitalbitbox to true\n  in a manner similar to\n\nprograms.digitalbitbox.enable = true;\n\n  and bundles the digitalbitbox package (see\n  Section 31.1, “Package”), which contains the\n  dbb-app and dbb-cli binaries, along\n  with the hardware module (see\n  Section 31.2, “Hardware”) which sets up the\n  necessary udev rules to access the device.\n \n  Enabling the digitalbitbox module is pretty much the easiest way to get a\n  Digital Bitbox device working on your system.\n \n  For more information, see\n  https://digitalbitbox.com/start_linux.\n 31.1. Package\n   The binaries, dbb-app (a GUI tool) and\n   dbb-cli (a CLI tool), are available through the\n   digitalbitbox package which could be installed as\n   follows:\n\nenvironment.systemPackages = [\n  pkgs.digitalbitbox\n];\n\n31.2. Hardware\n   The digitalbitbox hardware package enables the udev rules for Digital Bitbox\n   devices and may be installed as follows:\n\nhardware.digitalbitbox.enable = true;\n\n\n   In order to alter the udev rules, one may provide different values for the\n   udevRule51 and udevRule52 attributes\n   by means of overriding as follows:\n\nprograms.digitalbitbox = {\n  enable = true;\n  package = pkgs.digitalbitbox.override {\n    udevRule51 = \"something else\";\n  };\n};\n\nChapter 32. Input MethodsTable of Contents32.1. IBus32.2. Fcitx32.3. Nabi32.4. Uim\n  Input methods are an operating system component that allows any data, such as\n  keyboard strokes or mouse movements, to be received as input. In this way\n  users can enter characters and symbols not found on their input devices.\n  Using an input method is obligatory for any language that has more graphemes\n  than there are keys on the keyboard.\n \n  The following input methods are available in NixOS:\n \n    IBus: The intelligent input bus.\n   \n    Fcitx: A customizable lightweight input method.\n   \n    Nabi: A Korean input method based on XIM.\n   \n    Uim: The universal input method, is a library with a XIM bridge.\n   32.1. IBus\n   IBus is an Intelligent Input Bus. It provides full featured and user\n   friendly input method user interface.\n  \n   The following snippet can be used to configure IBus:\n  \ni18n.inputMethod = {\n  enabled = \"ibus\";\n  ibus.engines = with pkgs.ibus-engines; [ anthy hangul mozc ];\n};\n\ni18n.inputMethod.ibus.engines is optional and can be used\n   to add extra IBus engines.\n  \n   Available extra IBus engines are:\n  \n     Anthy (ibus-engines.anthy): Anthy is a system for\n     Japanese input method. It converts Hiragana text to Kana Kanji mixed text.\n    \n     Hangul (ibus-engines.hangul): Korean input method.\n    \n     m17n (ibus-engines.m17n): m17n is an input method that\n     uses input methods and corresponding icons in the m17n database.\n    \n     mozc (ibus-engines.mozc): A Japanese input method from\n     Google.\n    \n     Table (ibus-engines.table): An input method that load\n     tables of input methods.\n    \n     table-others (ibus-engines.table-others): Various\n     table-based input methods. To use this, and any other table-based input\n     methods, it must appear in the list of engines along with\n     table. For example:\n\nibus.engines = with pkgs.ibus-engines; [ table table-others ];\n\n\n   To use any input method, the package must be added in the configuration, as\n   shown above, and also (after running nixos-rebuild) the\n   input method must be added from IBus' preference dialog.\n  Troubleshooting\n    If IBus works in some applications but not others, a likely cause of this\n    is that IBus is depending on a different version of glib\n    to what the applications are depending on. This can be checked by running\n    nix-store -q --requisites <path> | grep glib,\n    where <path> is the path of either IBus or an\n    application in the Nix store. The glib packages must\n    match exactly. If they do not, uninstalling and reinstalling the\n    application is a likely fix.\n   32.2. Fcitx\n   Fcitx is an input method framework with extension support. It has three\n   built-in Input Method Engine, Pinyin, QuWei and Table-based input methods.\n  \n   The following snippet can be used to configure Fcitx:\n  \ni18n.inputMethod = {\n  enabled = \"fcitx\";\n  fcitx.engines = with pkgs.fcitx-engines; [ mozc hangul m17n ];\n};\n\ni18n.inputMethod.fcitx.engines is optional and can be\n   used to add extra Fcitx engines.\n  \n   Available extra Fcitx engines are:\n  \n     Anthy (fcitx-engines.anthy): Anthy is a system for\n     Japanese input method. It converts Hiragana text to Kana Kanji mixed text.\n    \n     Chewing (fcitx-engines.chewing): Chewing is an\n     intelligent Zhuyin input method. It is one of the most popular input\n     methods among Traditional Chinese Unix users.\n    \n     Hangul (fcitx-engines.hangul): Korean input method.\n    \n     Unikey (fcitx-engines.unikey): Vietnamese input method.\n    \n     m17n (fcitx-engines.m17n): m17n is an input method that\n     uses input methods and corresponding icons in the m17n database.\n    \n     mozc (fcitx-engines.mozc): A Japanese input method from\n     Google.\n    \n     table-others (fcitx-engines.table-others): Various\n     table-based input methods.\n    32.3. Nabi\n   Nabi is an easy to use Korean X input method. It allows you to enter\n   phonetic Korean characters (hangul) and pictographic Korean characters\n   (hanja).\n  \n   The following snippet can be used to configure Nabi:\n  \ni18n.inputMethod = {\n  enabled = \"nabi\";\n};\n32.4. Uim\n   Uim (short for \"universal input method\") is a multilingual input method\n   framework. Applications can use it through so-called bridges.\n  \n   The following snippet can be used to configure uim:\n  \ni18n.inputMethod = {\n  enabled = \"uim\";\n};\n\n   Note: The i18n.inputMethod.uim.toolbar option can be\n   used to choose uim toolbar.\n  Chapter 33. ProfilesTable of Contents33.1. All Hardware33.2. Base33.3. Clone Config33.4. Demo33.5. Docker Container33.6. Graphical33.7. Hardened33.8. Headless33.9. Installation Device33.10. Minimal33.11. QEMU Guest\n  In some cases, it may be desirable to take advantage of commonly-used,\n  predefined configurations provided by nixpkgs, but different from those that\n  come as default. This is a role fulfilled by NixOS's Profiles, which come as\n  files living in <nixpkgs/nixos/modules/profiles>.\n  That is to say, expected usage is to add them to the imports list of your\n  /etc/configuration.nix as such:\n \n  imports = [\n   <nixpkgs/nixos/modules/profiles/profile-name.nix>\n  ];\n\n  Even if some of these profiles seem only useful in the context of install\n  media, many are actually intended to be used in real installs.\n \n  What follows is a brief explanation on the purpose and use-case for each\n  profile. Detailing each option configured by each one is out of scope.\n 33.1. All Hardware\n  Enables all hardware supported by NixOS: i.e., all firmware is included, and\n  all devices from which one may boot are enabled in the initrd. Its primary\n  use is in the NixOS installation CDs.\n \n  The enabled kernel modules include support for SATA and PATA, SCSI\n  (partially), USB, Firewire (untested), Virtio (QEMU, KVM, etc.), VMware, and\n  Hyper-V. Additionally, hardware.enableAllFirmware is\n  enabled, and the firmware for the ZyDAS ZD1211 chipset is specifically\n  installed.\n 33.2. Base\n  Defines the software packages included in the \"minimal\" installation CD. It\n  installs several utilities useful in a simple recovery or install media, such\n  as a text-mode web browser, and tools for manipulating block devices,\n  networking, hardware diagnostics, and filesystems (with their respective\n  kernel modules).\n 33.3. Clone Config\n  This profile is used in installer images. It provides an editable\n  configuration.nix that imports all the modules that were also used when\n  creating the image in the first place. As a result it allows users to edit\n  and rebuild the live-system.\n \n  On images where the installation media also becomes an installation target,\n  copying over configuration.nix should be disabled by\n  setting installer.cloneConfig to false.\n  For example, this is done in sd-image-aarch64.nix.\n 33.4. Demo\n  This profile just enables a demo\n  user, with password demo, uid 1000,\n  wheel group and\n   autologin\n  in the SDDM display manager.\n 33.5. Docker Container\n  This is the profile from which the Docker images are generated. It prepares a\n  working system by importing the\n  Minimal and\n  Clone Config profiles, and\n  setting appropriate configuration options that are useful inside a container\n  context, like boot.isContainer.\n 33.6. Graphical\n  Defines a NixOS configuration with the Plasma 5 desktop. It's used by the\n  graphical installation CD.\n \n  It sets services.xserver.enable,\n  services.xserver.displayManager.sddm.enable,\n  services.xserver.desktopManager.plasma5.enable, and\n  services.xserver.libinput.enable to true. It also\n  includes glxinfo and firefox in the system packages list.\n 33.7. Hardened\n  A profile with most (vanilla) hardening options enabled by default,\n  potentially at the cost of features and performance.\n \n  This includes a hardened kernel, and limiting the system information\n  available to processes through the /sys and\n  /proc filesystems. It also disables the User Namespaces\n  feature of the kernel, which stops Nix from being able to build anything\n  (this particular setting can be overriden via\n  security.allowUserNamespaces). See the\n  \n  profile source for further detail on which settings are altered.\n 33.8. Headless\n  Common configuration for headless machines (e.g., Amazon EC2 instances).\n \n  Disables sound,\n  vesa, serial consoles,\n  emergency mode,\n  grub splash images\n  and configures the kernel to reboot automatically on panic.\n 33.9. Installation Device\n  Provides a basic configuration for installation devices like CDs.\n  This enables redistributable firmware, includes the\n  Clone Config profile\n  and a copy of the Nixpkgs channel, so nixos-install\n  works out of the box.\n \n  Documentation for Nixpkgs\n  and NixOS are\n  forcefully enabled (to override the\n  Minimal profile preference); the\n  NixOS manual is shown automatically on TTY 8, udisks is disabled.\n  Autologin is enabled as nixos user, while passwordless\n  login as both root and nixos is possible.\n  Passwordless sudo is enabled too.\n  wpa_supplicant is\n  enabled, but configured to not autostart.\n \n  It is explained how to login, start the ssh server, and if available,\n  how to start the display manager.\n \n  Several settings are tweaked so that the installer has a better chance of\n  succeeding under low-memory environments.\n 33.10. Minimal\n  This profile defines a small NixOS configuration. It does not contain any\n  graphical stuff. It's a very short file that enables\n  noXlibs, sets\n  i18n.supportedLocales to\n  only support the user-selected locale,\n  disables packages' documentation\n  , and disables sound.\n 33.11. QEMU Guest\n  This profile contains common configuration for virtual machines running under\n  QEMU (using virtio).\n \n  It makes virtio modules available on the initrd, sets the system time from\n  the hardware clock to work around a bug in qemu-kvm, and\n  enables rngd.\n Chapter 34. Kubernetes\n  The NixOS Kubernetes module is a collective term for a handful of individual\n  submodules implementing the Kubernetes cluster components.\n \n  There are generally two ways of enabling Kubernetes on NixOS. One way is to\n  enable and configure cluster components appropriately by hand:\n\nservices.kubernetes = {\n  apiserver.enable = true;\n  controllerManager.enable = true;\n  scheduler.enable = true;\n  addonManager.enable = true;\n  proxy.enable = true;\n  flannel.enable = true;\n};\n\n  Another way is to assign cluster roles (\"master\" and/or \"node\") to the host.\n  This enables apiserver, controllerManager, scheduler, addonManager,\n  kube-proxy and etcd:\n\nservices.kubernetes.roles = [ \"master\" ];\n\n  While this will enable the kubelet and kube-proxy only:\n\nservices.kubernetes.roles = [ \"node\" ];\n\n  Assigning both the master and node roles is usable if you want a single node\n  Kubernetes cluster for dev or testing purposes:\n\nservices.kubernetes.roles = [ \"master\" \"node\" ];\n\n  Note: Assigning either role will also default both\n  services.kubernetes.flannel.enable and\n  services.kubernetes.easyCerts to true. This sets up\n  flannel as CNI and activates automatic PKI bootstrapping.\n \n  As of kubernetes 1.10.X it has been deprecated to open non-tls-enabled ports\n  on kubernetes components. Thus, from NixOS 19.03 all plain HTTP ports have\n  been disabled by default. While opening insecure ports is still possible, it\n  is recommended not to bind these to other interfaces than loopback. To\n  re-enable the insecure port on the apiserver, see options:\n  services.kubernetes.apiserver.insecurePort and\n  services.kubernetes.apiserver.insecureBindAddress\nNote: \n   As of NixOS 19.03, it is mandatory to configure:\n   services.kubernetes.masterAddress. The masterAddress\n   must be resolveable and routeable by all cluster nodes. In single node\n   clusters, this can be set to localhost.\n  \n  Role-based access control (RBAC) authorization mode is enabled by default.\n  This means that anonymous requests to the apiserver secure port will\n  expectedly cause a permission denied error. All cluster components must\n  therefore be configured with x509 certificates for two-way tls communication.\n  The x509 certificate subject section determines the roles and permissions\n  granted by the apiserver to perform clusterwide or namespaced operations. See\n  also:\n  \n  Using RBAC Authorization.\n \n  The NixOS kubernetes module provides an option for automatic certificate\n  bootstrapping and configuration,\n  services.kubernetes.easyCerts. The PKI bootstrapping\n  process involves setting up a certificate authority (CA) daemon (cfssl) on\n  the kubernetes master node. cfssl generates a CA-cert for the cluster, and\n  uses the CA-cert for signing subordinate certs issued to each of the cluster\n  components. Subsequently, the certmgr daemon monitors active certificates and\n  renews them when needed. For single node Kubernetes clusters, setting\n  services.kubernetes.easyCerts = true is sufficient and\n  no further action is required. For joining extra node machines to an existing\n  cluster on the other hand, establishing initial trust is mandatory.\n \n  To add new nodes to the cluster: On any (non-master) cluster node where\n  services.kubernetes.easyCerts is enabled, the helper\n  script nixos-kubernetes-node-join is available on PATH.\n  Given a token on stdin, it will copy the token to the kubernetes secrets\n  directory and restart the certmgr service. As requested certificates are\n  issued, the script will restart kubernetes cluster components as needed for\n  them to pick up new keypairs.\n Note: \n   Multi-master (HA) clusters are not supported by the easyCerts module.\n  \n  In order to interact with an RBAC-enabled cluster as an administrator, one\n  needs to have cluster-admin privileges. By default, when easyCerts is\n  enabled, a cluster-admin kubeconfig file is generated and linked into\n  /etc/kubernetes/cluster-admin.kubeconfig as determined by\n  services.kubernetes.pki.etcClusterAdminKubeconfig.\n  export KUBECONFIG=/etc/kubernetes/cluster-admin.kubeconfig\n  will make kubectl use this kubeconfig to access and authenticate the cluster.\n  The cluster-admin kubeconfig references an auto-generated keypair owned by\n  root. Thus, only root on the kubernetes master may obtain cluster-admin\n  rights by means of this file.\n Part III. Administration\n   This chapter describes various aspects of managing a running NixOS system,\n   such as how to use the systemd service manager.\n  Table of Contents35. Service Management36. Rebooting and Shutting Down37. User Sessions38. Control Groups39. Logging40. Cleaning the Nix Store41. Container Management42. TroubleshootingChapter 35. Service Management\n  In NixOS, all system services are started and monitored using the systemd\n  program. Systemd is the “init” process of the system (i.e. PID 1), the\n  parent of all other processes. It manages a set of so-called “units”,\n  which can be things like system services (programs), but also mount points,\n  swap files, devices, targets (groups of units) and more. Units can have\n  complex dependencies; for instance, one unit can require that another unit\n  must be successfully started before the first unit can be started. When the\n  system boots, it starts a unit named default.target; the\n  dependencies of this unit cause all system services to be started, file\n  systems to be mounted, swap files to be activated, and so on.\n \n  The command systemctl is the main way to interact with\n  systemd. Without any arguments, it shows the status of\n  active units:\n\n$ systemctl\n-.mount          loaded active mounted   /\nswapfile.swap    loaded active active    /swapfile\nsshd.service     loaded active running   SSH Daemon\ngraphical.target loaded active active    Graphical Interface\n...\n\n\n  You can ask for detailed status information about a unit, for instance, the\n  PostgreSQL database service:\n\n$ systemctl status postgresql.service\npostgresql.service - PostgreSQL Server\n          Loaded: loaded (/nix/store/pn3q73mvh75gsrl8w7fdlfk3fq5qm5mw-unit/postgresql.service)\n          Active: active (running) since Mon, 2013-01-07 15:55:57 CET; 9h ago\n        Main PID: 2390 (postgres)\n          CGroup: name=systemd:/system/postgresql.service\n                  ├─2390 postgres\n                  ├─2418 postgres: writer process\n                  ├─2419 postgres: wal writer process\n                  ├─2420 postgres: autovacuum launcher process\n                  ├─2421 postgres: stats collector process\n                  └─2498 postgres: zabbix zabbix [local] idle\n\nJan 07 15:55:55 hagbard postgres[2394]: [1-1] LOG:  database system was shut down at 2013-01-07 15:55:05 CET\nJan 07 15:55:57 hagbard postgres[2390]: [1-1] LOG:  database system is ready to accept connections\nJan 07 15:55:57 hagbard postgres[2420]: [1-1] LOG:  autovacuum launcher started\nJan 07 15:55:57 hagbard systemd[1]: Started PostgreSQL Server.\n\n  Note that this shows the status of the unit (active and running), all the\n  processes belonging to the service, as well as the most recent log messages\n  from the service.\n \n  Units can be stopped, started or restarted:\n\n# systemctl stop postgresql.service\n# systemctl start postgresql.service\n# systemctl restart postgresql.service\n\n  These operations are synchronous: they wait until the service has finished\n  starting or stopping (or has failed). Starting a unit will cause the\n  dependencies of that unit to be started as well (if necessary).\n Chapter 36. Rebooting and Shutting Down\n  The system can be shut down (and automatically powered off) by doing:\n\n# shutdown\n\n  This is equivalent to running systemctl poweroff.\n \n  To reboot the system, run\n\n# reboot\n\n  which is equivalent to systemctl reboot. Alternatively,\n  you can quickly reboot the system using kexec, which\n  bypasses the BIOS by directly loading the new kernel into memory:\n\n# systemctl kexec\n\n\n  The machine can be suspended to RAM (if supported) using systemctl\n  suspend, and suspended to disk using systemctl\n  hibernate.\n \n  These commands can be run by any user who is logged in locally, i.e. on a\n  virtual console or in X11; otherwise, the user is asked for authentication.\n Chapter 37. User Sessions\n  Systemd keeps track of all users who are logged into the system (e.g. on a\n  virtual console or remotely via SSH). The command loginctl\n  allows querying and manipulating user sessions. For instance, to list all\n  user sessions:\n\n$ loginctl\n   SESSION        UID USER             SEAT\n        c1        500 eelco            seat0\n        c3          0 root             seat0\n        c4        500 alice\n\n  This shows that two users are logged in locally, while another is logged in\n  remotely. (“Seats” are essentially the combinations of displays and input\n  devices attached to the system; usually, there is only one seat.) To get\n  information about a session:\n\n$ loginctl session-status c3\nc3 - root (0)\n           Since: Tue, 2013-01-08 01:17:56 CET; 4min 42s ago\n          Leader: 2536 (login)\n            Seat: seat0; vc3\n             TTY: /dev/tty3\n         Service: login; type tty; class user\n           State: online\n          CGroup: name=systemd:/user/root/c3\n                  ├─ 2536 /nix/store/10mn4xip9n7y9bxqwnsx7xwx2v2g34xn-shadow-4.1.5.1/bin/login --\n                  ├─10339 -bash\n                  └─10355 w3m nixos.org\n\n  This shows that the user is logged in on virtual console 3. It also lists the\n  processes belonging to this session. Since systemd keeps track of this, you\n  can terminate a session in a way that ensures that all the session’s\n  processes are gone:\n\n# loginctl terminate-session c3\n\nChapter 38. Control Groups\n  To keep track of the processes in a running system, systemd uses\n  control groups (cgroups). A control group is a set of\n  processes used to allocate resources such as CPU, memory or I/O bandwidth.\n  There can be multiple control group hierarchies, allowing each kind of\n  resource to be managed independently.\n \n  The command systemd-cgls lists all control groups in the\n  systemd hierarchy, which is what systemd uses to keep\n  track of the processes belonging to each service or user session:\n\n$ systemd-cgls\n├─user\n│ └─eelco\n│   └─c1\n│     ├─ 2567 -:0\n│     ├─ 2682 kdeinit4: kdeinit4 Running...\n│     ├─ ...\n│     └─10851 sh -c less -R\n└─system\n  ├─httpd.service\n  │ ├─2444 httpd -f /nix/store/3pyacby5cpr55a03qwbnndizpciwq161-httpd.conf -DNO_DETACH\n  │ └─...\n  ├─dhcpcd.service\n  │ └─2376 dhcpcd --config /nix/store/f8dif8dsi2yaa70n03xir8r653776ka6-dhcpcd.conf\n  └─ ...\n\n  Similarly, systemd-cgls cpu shows the cgroups in the CPU\n  hierarchy, which allows per-cgroup CPU scheduling priorities. By default,\n  every systemd service gets its own CPU cgroup, while all user sessions are in\n  the top-level CPU cgroup. This ensures, for instance, that a thousand\n  run-away processes in the httpd.service cgroup cannot\n  starve the CPU for one process in the postgresql.service\n  cgroup. (By contrast, it they were in the same cgroup, then the PostgreSQL\n  process would get 1/1001 of the cgroup’s CPU time.) You can limit a\n  service’s CPU share in configuration.nix:\n\nsystemd.services.httpd.serviceConfig.CPUShares = 512;\n\n  By default, every cgroup has 1024 CPU shares, so this will halve the CPU\n  allocation of the httpd.service cgroup.\n \n  There also is a memory hierarchy that controls memory\n  allocation limits; by default, all processes are in the top-level cgroup, so\n  any service or session can exhaust all available memory. Per-cgroup memory\n  limits can be specified in configuration.nix; for\n  instance, to limit httpd.service to 512 MiB of RAM\n  (excluding swap):\n\nsystemd.services.httpd.serviceConfig.MemoryLimit = \"512M\";\n\n\n  The command systemd-cgtop shows a continuously updated\n  list of all cgroups with their CPU and memory usage.\n Chapter 39. Logging\n  System-wide logging is provided by systemd’s journal,\n  which subsumes traditional logging daemons such as syslogd and klogd. Log\n  entries are kept in binary files in /var/log/journal/.\n  The command journalctl allows you to see the contents of\n  the journal. For example,\n\n$ journalctl -b\n\n  shows all journal entries since the last reboot. (The output of\n  journalctl is piped into less by\n  default.) You can use various options and match operators to restrict output\n  to messages of interest. For instance, to get all messages from PostgreSQL:\n\n$ journalctl -u postgresql.service\n-- Logs begin at Mon, 2013-01-07 13:28:01 CET, end at Tue, 2013-01-08 01:09:57 CET. --\n...\nJan 07 15:44:14 hagbard postgres[2681]: [2-1] LOG:  database system is shut down\n-- Reboot --\nJan 07 15:45:10 hagbard postgres[2532]: [1-1] LOG:  database system was shut down at 2013-01-07 15:44:14 CET\nJan 07 15:45:13 hagbard postgres[2500]: [1-1] LOG:  database system is ready to accept connections\n\n  Or to get all messages since the last reboot that have at least a\n  “critical” severity level:\n\n$ journalctl -b -p crit\nDec 17 21:08:06 mandark sudo[3673]: pam_unix(sudo:auth): auth could not identify password for [alice]\nDec 29 01:30:22 mandark kernel[6131]: [1053513.909444] CPU6: Core temperature above threshold, cpu clock throttled (total events = 1)\n\n\n  The system journal is readable by root and by users in the\n  wheel and systemd-journal groups. All\n  users have a private journal that can be read using\n  journalctl.\n Chapter 40. Cleaning the Nix StoreTable of Contents40.1. NixOS Boot Entries\n  Nix has a purely functional model, meaning that packages are never upgraded\n  in place. Instead new versions of packages end up in a different location in\n  the Nix store (/nix/store). You should periodically run\n  Nix’s garbage collector to remove old, unreferenced\n  packages. This is easy:\n\n$ nix-collect-garbage\n\n  Alternatively, you can use a systemd unit that does the same in the\n  background:\n\n# systemctl start nix-gc.service\n\n  You can tell NixOS in configuration.nix to run this unit\n  automatically at certain points in time, for instance, every night at 03:15:\n\nnix.gc.automatic = true;\nnix.gc.dates = \"03:15\";\n\n\n  The commands above do not remove garbage collector roots, such as old system\n  configurations. Thus they do not remove the ability to roll back to previous\n  configurations. The following command deletes old roots, removing the ability\n  to roll back to them:\n\n$ nix-collect-garbage -d\n\n  You can also do this for specific profiles, e.g.\n\n$ nix-env -p /nix/var/nix/profiles/per-user/eelco/profile --delete-generations old\n\n  Note that NixOS system configurations are stored in the profile\n  /nix/var/nix/profiles/system.\n \n  Another way to reclaim disk space (often as much as 40% of the size of the\n  Nix store) is to run Nix’s store optimiser, which seeks out identical files\n  in the store and replaces them with hard links to a single copy.\n\n$ nix-store --optimise\n\n  Since this command needs to read the entire Nix store, it can take quite a\n  while to finish.\n 40.1. NixOS Boot Entries\n   If your /boot partition runs out of space, after\n   clearing old profiles you must rebuild your system with\n   nixos-rebuild to update the /boot\n   partition and clear space.\n  Chapter 41. Container ManagementTable of Contents41.1. Imperative Container Management41.2. Declarative Container Specification41.3. Container Networking\n  NixOS allows you to easily run other NixOS instances as\n  containers. Containers are a light-weight approach to\n  virtualisation that runs software in the container at the same speed as in\n  the host system. NixOS containers share the Nix store of the host, making\n  container creation very efficient.\n Warning: \n   Currently, NixOS containers are not perfectly isolated from the host system.\n   This means that a user with root access to the container can do things that\n   affect the host. So you should not give container root access to untrusted\n   users.\n  \n  NixOS containers can be created in two ways: imperatively, using the command\n  nixos-container, and declaratively, by specifying them in\n  your configuration.nix. The declarative approach implies\n  that containers get upgraded along with your host system when you run\n  nixos-rebuild, which is often not what you want. By\n  contrast, in the imperative approach, containers are configured and updated\n  independently from the host system.\n 41.1. Imperative Container Management\n  We’ll cover imperative container management using\n  nixos-container first. Be aware that container management\n  is currently only possible as root.\n \n  You create a container with identifier foo as follows:\n\n# nixos-container create foo\n\n  This creates the container’s root directory in\n  /var/lib/containers/foo and a small configuration file\n  in /etc/containers/foo.conf. It also builds the\n  container’s initial system configuration and stores it in\n  /nix/var/nix/profiles/per-container/foo/system. You can\n  modify the initial configuration of the container on the command line. For\n  instance, to create a container that has sshd running,\n  with the given public key for root:\n\n# nixos-container create foo --config '\n  services.openssh.enable = true;\n  users.users.root.openssh.authorizedKeys.keys = [\"ssh-dss AAAAB3N…\"];\n'\n\n  By default the next free address in the 10.233.0.0/16 subnet will be chosen\n  as container IP. This behavior can be altered by setting --host-address and\n  --local-address:\n\n# nixos-container create test --config-file test-container.nix \\\n    --local-address 10.235.1.2 --host-address 10.235.1.1\n\n\n  Creating a container does not start it. To start the container, run:\n\n# nixos-container start foo\n\n  This command will return as soon as the container has booted and has reached\n  multi-user.target. On the host, the container runs within\n  a systemd unit called\n  container@container-name.service.\n  Thus, if something went wrong, you can get status info using\n  systemctl:\n\n# systemctl status container@foo\n\n\n  If the container has started successfully, you can log in as root using the\n  root-login operation:\n\n# nixos-container root-login foo\n[root@foo:~]#\n\n  Note that only root on the host can do this (since there is no\n  authentication). You can also get a regular login prompt using the\n  login operation, which is available to all users on the\n  host:\n\n# nixos-container login foo\nfoo login: alice\nPassword: ***\n\n  With nixos-container run, you can execute arbitrary\n  commands in the container:\n\n# nixos-container run foo -- uname -a\nLinux foo 3.4.82 #1-NixOS SMP Thu Mar 20 14:44:05 UTC 2014 x86_64 GNU/Linux\n\n\n  There are several ways to change the configuration of the container. First,\n  on the host, you can edit\n  /var/lib/container/name/etc/nixos/configuration.nix,\n  and run\n\n# nixos-container update foo\n\n  This will build and activate the new configuration. You can also specify a\n  new configuration on the command line:\n\n# nixos-container update foo --config '\n  services.httpd.enable = true;\n  services.httpd.adminAddr = \"foo@example.org\";\n  networking.firewall.allowedTCPPorts = [ 80 ];\n'\n\n# curl http://$(nixos-container show-ip foo)/\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">…\n\n  However, note that this will overwrite the container’s\n  /etc/nixos/configuration.nix.\n \n  Alternatively, you can change the configuration from within the container\n  itself by running nixos-rebuild switch inside the\n  container. Note that the container by default does not have a copy of the\n  NixOS channel, so you should run nix-channel --update\n  first.\n \n  Containers can be stopped and started using nixos-container\n  stop and nixos-container start, respectively, or\n  by using systemctl on the container’s service unit. To\n  destroy a container, including its file system, do\n\n# nixos-container destroy foo\n\n41.2. Declarative Container Specification\n  You can also specify containers and their configuration in the host’s\n  configuration.nix. For example, the following specifies\n  that there shall be a container named database running\n  PostgreSQL:\n\ncontainers.database =\n  { config =\n      { config, pkgs, ... }:\n      { services.postgresql.enable = true;\n      services.postgresql.package = pkgs.postgresql_9_6;\n      };\n  };\n\n  If you run nixos-rebuild switch, the container will be\n  built. If the container was already running, it will be updated in place,\n  without rebooting. The container can be configured to start automatically by\n  setting containers.database.autoStart = true in its\n  configuration.\n \n  By default, declarative containers share the network namespace of the host,\n  meaning that they can listen on (privileged) ports. However, they cannot\n  change the network configuration. You can give a container its own network as\n  follows:\n\ncontainers.database = {\n  privateNetwork = true;\n  hostAddress = \"192.168.100.10\";\n  localAddress = \"192.168.100.11\";\n};\n\n  This gives the container a private virtual Ethernet interface with IP address\n  192.168.100.11, which is hooked up to a virtual Ethernet\n  interface on the host with IP address 192.168.100.10. (See\n  the next section for details on container networking.)\n \n  To disable the container, just remove it from\n  configuration.nix and run nixos-rebuild\n  switch. Note that this will not delete the root directory of the\n  container in /var/lib/containers. Containers can be\n  destroyed using the imperative method: nixos-container destroy\n  foo.\n \n  Declarative containers can be started and stopped using the corresponding\n  systemd service, e.g. systemctl start container@database.\n 41.3. Container Networking\n  When you create a container using nixos-container create,\n  it gets it own private IPv4 address in the range\n  10.233.0.0/16. You can get the container’s IPv4 address\n  as follows:\n\n# nixos-container show-ip foo\n10.233.4.2\n\n$ ping -c1 10.233.4.2\n64 bytes from 10.233.4.2: icmp_seq=1 ttl=64 time=0.106 ms\n\n\n  Networking is implemented using a pair of virtual Ethernet devices. The\n  network interface in the container is called eth0, while\n  the matching interface in the host is called\n  ve-container-name (e.g.,\n  ve-foo). The container has its own network namespace and\n  the CAP_NET_ADMIN capability, so it can perform arbitrary\n  network configuration such as setting up firewall rules, without affecting or\n  having access to the host’s network.\n \n  By default, containers cannot talk to the outside network. If you want that,\n  you should set up Network Address Translation (NAT) rules on the host to\n  rewrite container traffic to use your external IP address. This can be\n  accomplished using the following configuration on the host:\n\nnetworking.nat.enable = true;\nnetworking.nat.internalInterfaces = [\"ve-+\"];\nnetworking.nat.externalInterface = \"eth0\";\n\n  where eth0 should be replaced with the desired external\n  interface. Note that ve-+ is a wildcard that matches all\n  container interfaces.\n \n  If you are using Network Manager, you need to explicitly prevent it from\n  managing container interfaces:\n\nnetworking.networkmanager.unmanaged = [ \"interface-name:ve-*\" ];\n\n\n  You may need to restart your system for the changes to take effect.\n Chapter 42. TroubleshootingTable of Contents42.1. Boot Problems42.2. Maintenance Mode42.3. Rolling Back Configuration Changes42.4. Nix Store Corruption42.5. Network Problems\n  This chapter describes solutions to common problems you might encounter when\n  you manage your NixOS system.\n 42.1. Boot Problems\n  If NixOS fails to boot, there are a number of kernel command line parameters\n  that may help you to identify or fix the issue. You can add these parameters\n  in the GRUB boot menu by pressing “e” to modify the selected boot entry\n  and editing the line starting with linux. The following\n  are some useful kernel command line parameters that are recognised by the\n  NixOS boot scripts or by systemd:\n  \nboot.shell_on_fail\n\n      Start a root shell if something goes wrong in stage 1 of the boot process\n      (the initial ramdisk). This is disabled by default because there is no\n      authentication for the root shell.\n     \nboot.debug1\n\n      Start an interactive shell in stage 1 before anything useful has been\n      done. That is, no modules have been loaded and no file systems have been\n      mounted, except for /proc and\n      /sys.\n     \nboot.trace\n\n      Print every shell command executed by the stage 1 and 2 boot scripts.\n     \nsingle\n\n      Boot into rescue mode (a.k.a. single user mode). This will cause systemd\n      to start nothing but the unit rescue.target, which\n      runs sulogin to prompt for the root password and start\n      a root login shell. Exiting the shell causes the system to continue with\n      the normal boot process.\n     \nsystemd.log_level=debug systemd.log_target=console\n\n      Make systemd very verbose and send log messages to the console instead of\n      the journal.\n     \n  For more parameters recognised by systemd, see systemd(1).\n \n  If no login prompts or X11 login screens appear (e.g. due to hanging\n  dependencies), you can press Alt+ArrowUp. If you’re lucky, this will start\n  rescue mode (described above). (Also note that since most units have a\n  90-second timeout before systemd gives up on them, the\n  agetty login prompts should appear eventually unless\n  something is very wrong.)\n 42.2. Maintenance Mode\n  You can enter rescue mode by running:\n\n# systemctl rescue\n  This will eventually give you a single-user root shell. Systemd will stop\n  (almost) all system services. To get out of maintenance mode, just exit from\n  the rescue shell.\n 42.3. Rolling Back Configuration Changes\n  After running nixos-rebuild to switch to a new\n  configuration, you may find that the new configuration doesn’t work very\n  well. In that case, there are several ways to return to a previous\n  configuration.\n \n  First, the GRUB boot manager allows you to boot into any previous\n  configuration that hasn’t been garbage-collected. These configurations can\n  be found under the GRUB submenu “NixOS - All configurations”. This is\n  especially useful if the new configuration fails to boot. After the system\n  has booted, you can make the selected configuration the default for\n  subsequent boots:\n\n# /run/current-system/bin/switch-to-configuration boot\n\n  Second, you can switch to the previous configuration in a running system:\n\n# nixos-rebuild switch --rollback\n  This is equivalent to running:\n\n# /nix/var/nix/profiles/system-N-link/bin/switch-to-configuration switch\n  where N is the number of the NixOS system\n  configuration. To get a list of the available configurations, do:\n\n$ ls -l /nix/var/nix/profiles/system-*-link\n...\nlrwxrwxrwx 1 root root 78 Aug 12 13:54 /nix/var/nix/profiles/system-268-link -> /nix/store/202b...-nixos-13.07pre4932_5a676e4-4be1055\n\n42.4. Nix Store Corruption\n  After a system crash, it’s possible for files in the Nix store to become\n  corrupted. (For instance, the Ext4 file system has the tendency to replace\n  un-synced files with zero bytes.) NixOS tries hard to prevent this from\n  happening: it performs a sync before switching to a new\n  configuration, and Nix’s database is fully transactional. If corruption\n  still occurs, you may be able to fix it automatically.\n \n  If the corruption is in a path in the closure of the NixOS system\n  configuration, you can fix it by doing\n\n# nixos-rebuild switch --repair\n\n  This will cause Nix to check every path in the closure, and if its\n  cryptographic hash differs from the hash recorded in Nix’s database, the\n  path is rebuilt or redownloaded.\n \n  You can also scan the entire Nix store for corrupt paths:\n\n# nix-store --verify --check-contents --repair\n\n  Any corrupt paths will be redownloaded if they’re available in a binary\n  cache; otherwise, they cannot be repaired.\n 42.5. Network Problems\n  Nix uses a so-called binary cache to optimise building a\n  package from source into downloading it as a pre-built binary. That is,\n  whenever a command like nixos-rebuild needs a path in the\n  Nix store, Nix will try to download that path from the Internet rather than\n  build it from source. The default binary cache is\n  https://cache.nixos.org/. If this cache is unreachable, Nix\n  operations may take a long time due to HTTP connection timeouts. You can\n  disable the use of the binary cache by adding --option\n  use-binary-caches false, e.g.\n\n# nixos-rebuild switch --option use-binary-caches false\n\n  If you have an alternative binary cache at your disposal, you can use it\n  instead:\n\n# nixos-rebuild switch --option binary-caches http://my-cache.example.org/\n\nPart IV. Development\n   This chapter describes how you can modify and extend NixOS.\n  Table of Contents43. Getting the Sources44. Writing NixOS Modules45. Building Specific Parts of NixOS46. Writing NixOS Documentation47. Building Your Own NixOS CD48. NixOS Tests49. Testing the Installer50. ReleasesChapter 43. Getting the Sources\n  By default, NixOS’s nixos-rebuild command uses the NixOS\n  and Nixpkgs sources provided by the nixos channel (kept in\n  /nix/var/nix/profiles/per-user/root/channels/nixos). To\n  modify NixOS, however, you should check out the latest sources from Git. This\n  is as follows:\n\n$ git clone https://github.com/NixOS/nixpkgs\n$ cd nixpkgs\n$ git remote update origin\n\n  This will check out the latest Nixpkgs sources to\n  ./nixpkgs the NixOS sources to\n  ./nixpkgs/nixos. (The NixOS source tree lives in a\n  subdirectory of the Nixpkgs repository.) The\n  nixpkgs repository has branches that correspond\n  to each Nixpkgs/NixOS channel (see Chapter 4, Upgrading NixOS for more\n  information about channels). Thus, the Git branch\n  origin/nixos-17.03 will contain the latest built and\n  tested version available in the nixos-17.03 channel.\n \n  It’s often inconvenient to develop directly on the master branch, since if\n  somebody has just committed (say) a change to GCC, then the binary cache may\n  not have caught up yet and you’ll have to rebuild everything from source.\n  So you may want to create a local branch based on your current NixOS version:\n\n$ nixos-version\n17.09pre104379.6e0b727 (Hummingbird)\n\n$ git checkout -b local 6e0b727\n\n  Or, to base your local branch on the latest version available in a NixOS\n  channel:\n\n$ git remote update origin\n$ git checkout -b local origin/nixos-17.03\n\n  (Replace nixos-17.03 with the name of the channel you want\n  to use.) You can use git merge or git\n  rebase to keep your local branch in sync with the channel, e.g.\n\n$ git remote update origin\n$ git merge origin/nixos-17.03\n\n  You can use git cherry-pick to copy commits from your\n  local branch to the upstream branch.\n \n  If you want to rebuild your system using your (modified) sources, you need to\n  tell nixos-rebuild about them using the\n  -I flag:\n\n# nixos-rebuild switch -I nixpkgs=/my/sources/nixpkgs\n\n\n  If you want nix-env to use the expressions in\n  /my/sources, use nix-env -f\n  /my/sources/nixpkgs, or change the\n  default by adding a symlink in ~/.nix-defexpr:\n\n$ ln -s /my/sources/nixpkgs ~/.nix-defexpr/nixpkgs\n\n  You may want to delete the symlink\n  ~/.nix-defexpr/channels_root to prevent root’s NixOS\n  channel from clashing with your own tree (this may break the\n  command-not-found utility though). If you want to go back to the default\n  state, you may just remove the ~/.nix-defexpr directory\n  completely, log out and log in again and it should have been recreated with a\n  link to the root channels.\n Chapter 44. Writing NixOS ModulesTable of Contents44.1. Option Declarations44.2. Options Types44.3. Option Definitions44.4. Warnings and Assertions44.5. Meta Attributes44.6. Importing Modules44.7. Replace Modules\n  NixOS has a modular system for declarative configuration. This system\n  combines multiple modules to produce the full system\n  configuration. One of the modules that constitute the configuration is\n  /etc/nixos/configuration.nix. Most of the others live in\n  the\n  nixos/modules\n  subdirectory of the Nixpkgs tree.\n \n  Each NixOS module is a file that handles one logical aspect of the\n  configuration, such as a specific kind of hardware, a service, or network\n  settings. A module configuration does not have to handle everything from\n  scratch; it can use the functionality provided by other modules for its\n  implementation. Thus a module can declare options that\n  can be used by other modules, and conversely can define\n  options provided by other modules in its own implementation. For example, the\n  module\n  pam.nix\n  declares the option security.pam.services that allows other\n  modules (e.g.\n  sshd.nix)\n  to define PAM services; and it defines the option\n  environment.etc (declared by\n  etc.nix)\n  to cause files to be created in /etc/pam.d.\n \n  In Chapter 5, Configuration Syntax, we saw the following structure\n  of NixOS modules:\n\n{ config, pkgs, ... }:\n\n{ option definitions\n}\n\n  This is actually an abbreviated form of module that only\n  defines options, but does not declare any. The structure of full NixOS\n  modules is shown in Example 44.1, “Structure of NixOS Modules”.\n Example 44.1. Structure of NixOS Modules\n{ config, pkgs, ... }: \n\n{\n  imports =\n    [ paths of other modules \n    ];\n\n  options = {\n    option declarations \n  };\n\n  config = {\n    option definitions \n  };\n}\n  The meaning of each part is as follows.\n   \n     This line makes the current Nix expression a function. The variable\n     pkgs contains Nixpkgs, while config\n     contains the full system configuration. This line can be omitted if there\n     is no reference to pkgs and config\n     inside the module.\n     \n     This list enumerates the paths to other NixOS modules that should be\n     included in the evaluation of the system configuration. A default set of\n     modules is defined in the file\n     modules/module-list.nix. These don't need to be added\n     in the import list.\n     \n     The attribute options is a nested set of\n     option declarations (described below).\n     \n     The attribute config is a nested set of\n     option definitions (also described below).\n    \n\nExample 44.2, “NixOS Module for the “locate” Service” shows a module that handles the regular\n  update of the “locate” database, an index of all files in the file\n  system. This module declares two options that can be defined by other modules\n  (typically the user’s configuration.nix):\n  services.locate.enable (whether the database should be\n  updated) and services.locate.interval (when the update\n  should be done). It implements its functionality by defining two options\n  declared by other modules: systemd.services (the set of all\n  systemd services) and systemd.timers (the list of commands\n  to be executed periodically by systemd).\n Example 44.2. NixOS Module for the “locate” Service\n{ config, lib, pkgs, ... }:\n\nwith lib;\n\nlet\n  cfg = config.services.locate;\nin {\n  options.services.locate = {\n    enable = mkOption {\n      type = types.bool;\n      default = false;\n      description = ''\n        If enabled, NixOS will periodically update the database of\n        files used by the locate command.\n      '';\n    };\n\n    interval = mkOption {\n      type = types.str;\n      default = \"02:15\";\n      example = \"hourly\";\n      description = ''\n        Update the locate database at this interval. Updates by\n        default at 2:15 AM every day.\n\n        The format is described in\n        systemd.time(7).\n      '';\n    };\n\n    # Other options omitted for documentation\n  };\n\n  config = {\n    systemd.services.update-locatedb =\n      { description = \"Update Locate Database\";\n        path  = [ pkgs.su ];\n        script =\n          ''\n            mkdir -m 0755 -p $(dirname ${toString cfg.output})\n            exec updatedb \\\n              --localuser=${cfg.localuser} \\\n              ${optionalString (!cfg.includeStore) \"--prunepaths='/nix/store'\"} \\\n              --output=${toString cfg.output} ${concatStringsSep \" \" cfg.extraFlags}\n          '';\n      };\n\n    systemd.timers.update-locatedb = mkIf cfg.enable\n      { description = \"Update timer for locate database\";\n        partOf      = [ \"update-locatedb.service\" ];\n        wantedBy    = [ \"timers.target\" ];\n        timerConfig.OnCalendar = cfg.interval;\n      };\n  };\n}\n44.1. Option Declarations\n  An option declaration specifies the name, type and description of a NixOS\n  configuration option. It is invalid to define an option that hasn’t been\n  declared in any module. An option declaration generally looks like this:\n\noptions = {\n  name = mkOption {\n    type = type specification;\n    default = default value;\n    example = example value;\n    description = \"Description for use in the NixOS manual.\";\n  };\n};\n\n  The attribute names within the name attribute path\n  must be camel cased in general but should, as an exception, match the\n  \n  package attribute name when referencing a Nixpkgs package. For\n  example, the option services.nix-serve.bindAddress\n  references the nix-serve Nixpkgs package.\n \n  The function mkOption accepts the following arguments.\n  \ntype\n\n      The type of the option (see Section 44.2, “Options Types”). It may\n      be omitted, but that’s not advisable since it may lead to errors that\n      are hard to diagnose.\n     \ndefault\n\n      The default value used if no value is defined by any module. A default is\n      not required; but if a default is not given, then users of the module\n      will have to define the value of the option, otherwise an error will be\n      thrown.\n     \nexample\n\n      An example value that will be shown in the NixOS manual.\n     \ndescription\n\n      A textual description of the option, in DocBook format, that will be\n      included in the NixOS manual.\n     \n44.1.1. Extensible Option Types\n   Extensible option types is a feature that allow to extend certain types\n   declaration through multiple module files. This feature only work with a\n   restricted set of types, namely enum and\n   submodules and any composed forms of them.\n  \n   Extensible option types can be used for enum options that\n   affects multiple modules, or as an alternative to related\n   enable options.\n  \n   As an example, we will take the case of display managers. There is a central\n   display manager module for generic display manager options and a module file\n   per display manager backend (sddm, gdm ...).\n  \n   There are two approach to this module structure:\n   \n      Managing the display managers independently by adding an enable option to\n      every display manager module backend. (NixOS)\n     \n      Managing the display managers in the central module by adding an option\n      to select which display manager backend to use.\n     \n\n   Both approaches have problems.\n  \n   Making backends independent can quickly become hard to manage. For display\n   managers, there can be only one enabled at a time, but the type system can\n   not enforce this restriction as there is no relation between each backend\n   enable option. As a result, this restriction has to be\n   done explicitely by adding assertions in each display manager backend\n   module.\n  \n   On the other hand, managing the display managers backends in the central\n   module will require to change the central module option every time a new\n   backend is added or removed.\n  \n   By using extensible option types, it is possible to create a placeholder\n   option in the central module\n   (Example 44.3, “Extensible type placeholder in the service module”), and to extend\n   it in each backend module\n   (Example 44.4, “Extending services.xserver.displayManager.enable in the gdm module”,\n   Example 44.5, “Extending services.xserver.displayManager.enable in the sddm module”).\n  \n   As a result, displayManager.enable option values can be\n   added without changing the main service module file and the type system\n   automatically enforce that there can only be a single display manager\n   enabled.\n  Example 44.3. Extensible type placeholder in the service module\nservices.xserver.displayManager.enable = mkOption {\n  description = \"Display manager to use\";\n  type = with types; nullOr (enum [ ]);\n};Example 44.4. Extending services.xserver.displayManager.enable in the gdm module\nservices.xserver.displayManager.enable = mkOption {\n  type = with types; nullOr (enum [ \"gdm\" ]);\n};Example 44.5. Extending services.xserver.displayManager.enable in the sddm module\nservices.xserver.displayManager.enable = mkOption {\n  type = with types; nullOr (enum [ \"sddm\" ]);\n};\n   The placeholder declaration is a standard mkOption\n   declaration, but it is important that extensible option declarations only\n   use the type argument.\n  \n   Extensible option types work with any of the composed variants of\n   enum such as with types; nullOr (enum [ \"foo\"\n   \"bar\" ]) or with types; listOf (enum [ \"foo\" \"bar\"\n   ]).\n  44.2. Options Types\n  Option types are a way to put constraints on the values a module option can\n  take. Types are also responsible of how values are merged in case of multiple\n  value definitions.\n 44.2.1. Basic Types\n   Basic types are the simplest available types in the module system. Basic\n   types include multiple string types that mainly differ in how definition\n   merging is handled.\n  \ntypes.attrs\n\n      A free-form attribute set.\n     \ntypes.bool\n\n      A boolean, its values can be true or\n      false.\n     \ntypes.path\n\n      A filesystem path, defined as anything that when coerced to a string\n      starts with a slash. Even if derivations can be considered as path, the\n      more specific types.package should be preferred.\n     \ntypes.package\n\n      A derivation or a store path.\n     \n   Integer-related types:\n  \ntypes.int\n\n      A signed integer.\n     \ntypes.ints.{s8, s16, s32}\n\n      Signed integers with a fixed length (8, 16 or 32 bits). They go from\n      −2n/2 to 2n/2−1 respectively (e.g. −128 to\n      127 for 8 bits).\n     \ntypes.ints.unsigned\n\n      An unsigned integer (that is >= 0).\n     \ntypes.ints.{u8, u16, u32}\n\n      Unsigned integers with a fixed length (8, 16 or 32 bits). They go from\n      0 to\n      2n−1 respectively (e.g. 0 to\n      255 for 8 bits).\n     \ntypes.ints.positive\n\n      A positive integer (that is > 0).\n     \ntypes.port\n\n      A port number. This type is an alias to\n      types.ints.u16.\n     \n   String-related types:\n  \ntypes.str\n\n      A string. Multiple definitions cannot be merged.\n     \ntypes.lines\n\n      A string. Multiple definitions are concatenated with a new line\n      \"\\n\".\n     \ntypes.commas\n\n      A string. Multiple definitions are concatenated with a comma\n      \",\".\n     \ntypes.envVar\n\n      A string. Multiple definitions are concatenated with a collon\n      \":\".\n     \ntypes.strMatching\n\n      A string matching a specific regular expression. Multiple definitions\n      cannot be merged. The regular expression is processed using\n      builtins.match.\n     44.2.2. Value Types\n   Value types are types that take a value parameter.\n  \ntypes.enum l\n\n      One element of the list l, e.g.\n      types.enum [ \"left\" \"right\" ]. Multiple definitions\n      cannot be merged.\n     \ntypes.separatedString sep\n\n      A string with a custom separator sep, e.g.\n      types.separatedString \"|\".\n     \ntypes.ints.between lowest highest\n\n      An integer between lowest and\n      highest (both inclusive). Useful for creating\n      types like types.port.\n     \ntypes.submodule o\n\n      A set of sub options o.\n      o can be an attribute set, a function\n      returning an attribute set, or a path to a file containing such a value. Submodules are used in\n      composed types to create modular options. This is equivalent to\n      types.submoduleWith { modules = toList o; shorthandOnlyDefinesConfig = true; }.\n      Submodules are detailed in\n      Section 44.2.4, “Submodule”.\n     \ntypes.submoduleWith {\n        modules,\n        specialArgs ? {},\n        shorthandOnlyDefinesConfig ? false }\n     \n         Like types.submodule, but more flexible and with better defaults.\n         It has parameters\n         \nmodules\n             A list of modules to use by default for this submodule type. This gets combined\n             with all option definitions to build the final list of modules that will be included.\n             Note: \n               Only options defined with this argument are included in rendered documentation.\n             \n\nspecialArgs\n             An attribute set of extra arguments to be passed to the module functions.\n             The option _module.args should be used instead\n             for most arguments since it allows overriding. specialArgs should only be\n             used for arguments that can't go through the module fixed-point, because of\n             infinite recursion or other problems. An example is overriding the\n             lib argument, because lib itself is used\n             to define _module.args, which makes using\n             _module.args to define it impossible.\n           \nshorthandOnlyDefinesConfig\n             Whether definitions of this type should default to the config\n             section of a module (see Example 44.1, “Structure of NixOS Modules”) if it is an attribute\n             set. Enabling this only has a benefit when the submodule defines an option named\n             config or options. In such a case it would\n             allow the option to be set with the-submodule.config = \"value\"\n             instead of requiring the-submodule.config.config = \"value\".\n             This is because only when modules don't set the\n             config or options keys, all keys are interpreted\n             as option definitions in the config section. Enabling this option\n             implicitly puts all attributes in the config section.\n           \n             With this option enabled, defining a non-config section requires\n             using a function: the-submodule = { ... }: { options = { ... }; }.\n           \n44.2.3. Composed Types\n   Composed types are types that take a type as parameter. listOf\n   int and either int str are examples of composed\n   types.\n  \ntypes.listOf t\n\n      A list of t type, e.g. types.listOf\n      int. Multiple definitions are merged with list concatenation.\n     \ntypes.attrsOf t\n\n      An attribute set of where all the values are of\n      t type. Multiple definitions result in the\n      joined attribute set.\n      Note: \n       This type is strict in its values, which in turn\n       means attributes cannot depend on other attributes. See \n       types.lazyAttrsOf for a lazy version.\n      \n\ntypes.lazyAttrsOf t\n\n      An attribute set of where all the values are of\n      t type. Multiple definitions result in the\n      joined attribute set. This is the lazy version of types.attrsOf\n      , allowing attributes to depend on each other.\n      Warning: \n       This version does not fully support conditional definitions! With an\n       option foo of this type and a definition\n       foo.attr = lib.mkIf false 10, evaluating\n       foo ? attr will return true\n       even though it should be false. Accessing the value will then throw\n       an error. For types t that have an\n       emptyValue defined, that value will be returned\n       instead of throwing an error. So if the type of foo.attr\n       was lazyAttrsOf (nullOr int), null\n       would be returned instead for the same mkIf false definition.\n      \n\ntypes.loaOf t\n\n      An attribute set or a list of t type. Multiple\n      definitions are merged according to the value.\n     \ntypes.nullOr t\n\nnull or type t. Multiple\n      definitions are merged according to type t.\n     \ntypes.uniq t\n\n      Ensures that type t cannot be merged. It is\n      used to ensure option definitions are declared only once.\n     \ntypes.either t1 t2\n\n      Type t1 or type t2,\n      e.g. with types; either int str. Multiple definitions\n      cannot be merged.\n     \ntypes.oneOf [ t1 t2 ... ]\n    \n      Type t1 or type t2 and so forth,\n      e.g. with types; oneOf [ int str bool ]. Multiple definitions\n      cannot be merged.\n     \ntypes.coercedTo from f to\n\n      Type to or type\n      from which will be coerced to type\n      to using function f\n      which takes an argument of type from and\n      return a value of type to. Can be used to\n      preserve backwards compatibility of an option if its type was changed.\n     44.2.4. Submodule\nsubmodule is a very powerful type that defines a set of\n   sub-options that are handled like a separate module.\n  \n   It takes a parameter o, that should be a set, or\n   a function returning a set with an options key defining\n   the sub-options. Submodule option definitions are type-checked accordingly\n   to the options declarations. Of course, you can nest\n   submodule option definitons for even higher modularity.\n  \n   The option set can be defined directly\n   (Example 44.6, “Directly defined submodule”) or as reference\n   (Example 44.7, “Submodule defined as a reference”).\n  Example 44.6. Directly defined submodule\noptions.mod = mkOption {\n  description = \"submodule example\";\n  type = with types; submodule {\n    options = {\n      foo = mkOption {\n        type = int;\n      };\n      bar = mkOption {\n        type = str;\n      };\n    };\n  };\n};Example 44.7. Submodule defined as a reference\nlet\n  modOptions = {\n    options = {\n      foo = mkOption {\n        type = int;\n      };\n      bar = mkOption {\n        type = int;\n      };\n    };\n  };\nin\noptions.mod = mkOption {\n  description = \"submodule example\";\n  type = with types; submodule modOptions;\n};\n   The submodule type is especially interesting when used\n   with composed types like attrsOf or\n   listOf. When composed with listOf\n   (Example 44.8, “Declaration of a list of submodules”),\n   submodule allows multiple definitions of the submodule\n   option set (Example 44.9, “Definition of a list of submodules”).\n  Example 44.8. Declaration of a list of submodules\noptions.mod = mkOption {\n  description = \"submodule example\";\n  type = with types; listOf (submodule {\n    options = {\n      foo = mkOption {\n        type = int;\n      };\n      bar = mkOption {\n        type = str;\n      };\n    };\n  });\n};Example 44.9. Definition of a list of submodules\nconfig.mod = [\n  { foo = 1; bar = \"one\"; }\n  { foo = 2; bar = \"two\"; }\n];\n   When composed with attrsOf\n   (Example 44.10, “Declaration of attribute sets of submodules”),\n   submodule allows multiple named definitions of the\n   submodule option set (Example 44.11, “Declaration of attribute sets of submodules”).\n  Example 44.10. Declaration of attribute sets of submodules\noptions.mod = mkOption {\n  description = \"submodule example\";\n  type = with types; attrsOf (submodule {\n    options = {\n      foo = mkOption {\n        type = int;\n      };\n      bar = mkOption {\n        type = str;\n      };\n    };\n  });\n};Example 44.11. Declaration of attribute sets of submodules\nconfig.mod.one = { foo = 1; bar = \"one\"; };\nconfig.mod.two = { foo = 2; bar = \"two\"; };44.2.5. Extending types\n   Types are mainly characterized by their check and\n   merge functions.\n  \ncheck\n\n      The function to type check the value. Takes a value as parameter and\n      return a boolean. It is possible to extend a type check with the\n      addCheck function\n      (Example 44.12, “Adding a type check”), or to fully\n      override the check function\n      (Example 44.13, “Overriding a type check”).\n     Example 44.12. Adding a type check\nbyte = mkOption {\n  description = \"An integer between 0 and 255.\";\n  type = types.addCheck types.int (x: x >= 0 && x <= 255);\n};Example 44.13. Overriding a type check\nnixThings = mkOption {\n  description = \"words that start with 'nix'\";\n  type = types.str // {\n    check = (x: lib.hasPrefix \"nix\" x)\n  };\n};\nmerge\n\n      Function to merge the options values when multiple values are set. The\n      function takes two parameters, loc the option path as\n      a list of strings, and defs the list of defined values\n      as a list. It is possible to override a type merge function for custom\n      needs.\n     44.2.6. Custom Types\n   Custom types can be created with the mkOptionType\n   function. As type creation includes some more complex topics such as\n   submodule handling, it is recommended to get familiar with\n   types.nix\n   code before creating a new type.\n  \n   The only required parameter is name.\n  \nname\n\n      A string representation of the type function name.\n     \ndefinition\n\n      Description of the type used in documentation. Give information of the\n      type and any of its arguments.\n     \ncheck\n\n      A function to type check the definition value. Takes the definition value\n      as a parameter and returns a boolean indicating the type check result,\n      true for success and false for\n      failure.\n     \nmerge\n\n      A function to merge multiple definitions values. Takes two parameters:\n     \nloc\n\n         The option path as a list of strings, e.g. [\"boot\" \"loader\n         \"grub\" \"enable\"].\n        \ndefs\n\n         The list of sets of defined value and\n         file where the value was defined, e.g. [ {\n         file = \"/foo.nix\"; value = 1; } { file = \"/bar.nix\"; value = 2 }\n         ]. The merge function should return the\n         merged value or throw an error in case the values are impossible or\n         not meant to be merged.\n        \ngetSubOptions\n\n      For composed types that can take a submodule as type parameter, this\n      function generate sub-options documentation. It takes the current option\n      prefix as a list and return the set of sub-options. Usually defined in a\n      recursive manner by adding a term to the prefix, e.g. prefix:\n      elemType.getSubOptions (prefix ++\n      [\"prefix\"]) where\n      \"prefix\" is the newly added prefix.\n     \ngetSubModules\n\n      For composed types that can take a submodule as type parameter, this\n      function should return the type parameters submodules. If the type\n      parameter is called elemType, the function should just\n      recursively look into submodules by returning\n      elemType.getSubModules;.\n     \nsubstSubModules\n\n      For composed types that can take a submodule as type parameter, this\n      function can be used to substitute the parameter of a submodule type. It\n      takes a module as parameter and return the type with the submodule\n      options substituted. It is usually defined as a type function call with a\n      recursive call to substSubModules, e.g for a type\n      composedType that take an elemtype\n      type parameter, this function should be defined as m:\n      composedType (elemType.substSubModules m).\n     \ntypeMerge\n\n      A function to merge multiple type declarations. Takes the type to merge\n      functor as parameter. A null return\n      value means that type cannot be merged.\n     \nf\n\n         The type to merge functor.\n        \n      Note: There is a generic defaultTypeMerge that work\n      with most of value and composed types.\n     \nfunctor\n\n      An attribute set representing the type. It is used for type operations\n      and has the following keys:\n     \ntype\n\n         The type function.\n        \nwrapped\n\n         Holds the type parameter for composed types.\n        \npayload\n\n         Holds the value parameter for value types. The types that have a\n         payload are the enum,\n         separatedString and submodule\n         types.\n        \nbinOp\n\n         A binary operation that can merge the payloads of two same types.\n         Defined as a function that take two payloads as parameters and return\n         the payloads merged.\n        44.3. Option Definitions\n  Option definitions are generally straight-forward bindings of values to\n  option names, like\n\nconfig = {\n  services.httpd.enable = true;\n};\n\n  However, sometimes you need to wrap an option definition or set of option\n  definitions in a property to achieve certain effects:\n Delaying Conditionals\n   If a set of option definitions is conditional on the value of another\n   option, you may need to use mkIf. Consider, for instance:\n\nconfig = if config.services.httpd.enable then {\n  environment.systemPackages = [ ... ];\n  ...\n} else {};\n\n   This definition will cause Nix to fail with an “infinite recursion”\n   error. Why? Because the value of\n   config.services.httpd.enable depends on the value being\n   constructed here. After all, you could also write the clearly circular and\n   contradictory:\n\nconfig = if config.services.httpd.enable then {\n  services.httpd.enable = false;\n} else {\n  services.httpd.enable = true;\n};\n\n   The solution is to write:\n\nconfig = mkIf config.services.httpd.enable {\n  environment.systemPackages = [ ... ];\n  ...\n};\n\n   The special function mkIf causes the evaluation of the\n   conditional to be “pushed down” into the individual definitions, as if\n   you had written:\n\nconfig = {\n  environment.systemPackages = if config.services.httpd.enable then [ ... ] else [];\n  ...\n};\n\nSetting Priorities\n   A module can override the definitions of an option in other modules by\n   setting a priority. All option definitions that do not\n   have the lowest priority value are discarded. By default, option definitions\n   have priority 1000. You can specify an explicit priority by using\n   mkOverride, e.g.\n\nservices.openssh.enable = mkOverride 10 false;\n\n   This definition causes all other definitions with priorities above 10 to be\n   discarded. The function mkForce is equal to\n   mkOverride 50.\n  Merging Configurations\n   In conjunction with mkIf, it is sometimes useful for a\n   module to return multiple sets of option definitions, to be merged together\n   as if they were declared in separate modules. This can be done using\n   mkMerge:\n\nconfig = mkMerge\n  [ # Unconditional stuff.\n    { environment.systemPackages = [ ... ];\n    }\n    # Conditional stuff.\n    (mkIf config.services.bla.enable {\n      environment.systemPackages = [ ... ];\n    })\n  ];\n\n44.4. Warnings and Assertions\n  When configuration problems are detectable in a module, it is a good idea to\n  write an assertion or warning. Doing so provides clear feedback to the user\n  and prevents errors after the build.\n \n  Although Nix has the abort and\n  builtins.trace\nfunctions\n  to perform such tasks, they are not ideally suited for NixOS modules. Instead\n  of these functions, you can declare your warnings and assertions using the\n  NixOS module system.\n 44.4.1. Warnings\n   This is an example of using warnings.\n  \n\n{ config, lib, ... }:\n{\n  config = lib.mkIf config.services.foo.enable {\n    warnings =\n      if config.services.foo.bar\n      then [ ''You have enabled the bar feature of the foo service.\n               This is known to cause some specific problems in certain situations.\n               '' ]\n      else [];\n  }\n}\n\n44.4.2. Assertions\n   This example, extracted from the\n   \nsyslogd module  shows how to use\n   assertions. Since there can only be one active syslog\n   daemon at a time, an assertion is useful to prevent such a broken system\n   from being built.\n  \n\n{ config, lib, ... }:\n{\n  config = lib.mkIf config.services.syslogd.enable {\n    assertions =\n      [ { assertion = !config.services.rsyslogd.enable;\n          message = \"rsyslogd conflicts with syslogd\";\n        }\n      ];\n  }\n}\n\n44.5. Meta Attributes\n  Like Nix packages, NixOS modules can declare meta-attributes to provide extra\n  information. Module meta attributes are defined in the\n  meta.nix\n  special module.\n \nmeta is a top level attribute like\n  options and config. Available\n  meta-attributes are maintainers and\n  doc.\n \n  Each of the meta-attributes must be defined at most once per module file.\n \n{ config, lib, pkgs, ... }:\n{\n  options = {\n    ...\n  };\n\n  config = {\n    ...\n  };\n\n  meta = {\n    maintainers = with lib.maintainers; [ ericsagnes ]; \n    doc = ./default.xml; \n  };\n}\n \nmaintainers contains a list of the module maintainers.\n    \ndoc points to a valid DocBook file containing the module\n    documentation. Its contents is automatically added to\n    Part II, “Configuration”. Changes to a module documentation\n    have to be checked to not break building the NixOS manual:\n   $ nix-build nixos/release.nix -A manual44.6. Importing Modules\n  Sometimes NixOS modules need to be used in configuration but exist outside of\n  Nixpkgs. These modules can be imported:\n \n{ config, lib, pkgs, ... }:\n\n{\n  imports =\n    [ # Use a locally-available module definition in\n      # ./example-module/default.nix\n        ./example-module\n    ];\n\n  services.exampleModule.enable = true;\n}\n\n  The environment variable NIXOS_EXTRA_MODULE_PATH is an\n  absolute path to a NixOS module that is included alongside the Nixpkgs NixOS\n  modules. Like any NixOS module, this module can import additional modules:\n \n# ./module-list/default.nix\n[\n  ./example-module1\n  ./example-module2\n]\n\n# ./extra-module/default.nix\n{ imports = import ./module-list.nix; }\n\n# NIXOS_EXTRA_MODULE_PATH=/absolute/path/to/extra-module\n{ config, lib, pkgs, ... }:\n\n{\n  # No `imports` needed\n\n  services.exampleModule1.enable = true;\n}\n44.7. Replace Modules\n  Modules that are imported can also be disabled. The option declarations,\n  config implementation and the imports of a disabled module will be ignored, allowing another\n  to take it's place. This can be used to import a set of modules from another\n  channel while keeping the rest of the system on a stable release.\n \ndisabledModules is a top level attribute like\n  imports, options and\n  config. It contains a list of modules that will be\n  disabled. This can either be the full path to the module or a string with the\n  filename relative to the modules path (eg. <nixpkgs/nixos/modules> for\n  nixos).\n \n  This example will replace the existing postgresql module with the version\n  defined in the nixos-unstable channel while keeping the rest of the modules\n  and packages from the original nixos channel. This only overrides the module\n  definition, this won't use postgresql from nixos-unstable unless explicitly\n  configured to do so.\n \n{ config, lib, pkgs, ... }:\n\n{\n  disabledModules = [ \"services/databases/postgresql.nix\" ];\n\n  imports =\n    [ # Use postgresql service from nixos-unstable channel.\n      # sudo nix-channel --add https://nixos.org/channels/nixos-unstable nixos-unstable\n      <nixos-unstable/nixos/modules/services/databases/postgresql.nix>\n    ];\n\n  services.postgresql.enable = true;\n}\n\n  This example shows how to define a custom module as a replacement for an\n  existing module. Importing this module will disable the original module\n  without having to know it's implementation details.\n \n{ config, lib, pkgs, ... }:\n\nwith lib;\n\nlet\n  cfg = config.programs.man;\nin\n\n{\n  disabledModules = [ \"services/programs/man.nix\" ];\n\n  options = {\n    programs.man.enable = mkOption {\n      type = types.bool;\n      default = true;\n      description = \"Whether to enable manual pages.\";\n    };\n  };\n\n  config = mkIf cfg.enabled {\n    warnings = [ \"disabled manpages for production deployments.\" ];\n  };\n}\nChapter 45. Building Specific Parts of NixOS\n  With the command nix-build, you can build specific parts\n  of your NixOS configuration. This is done as follows:\n\n$ cd /path/to/nixpkgs/nixos\n$ nix-build -A config.option\n  where option is a NixOS option with type\n  “derivation” (i.e. something that can be built). Attributes of interest\n  include:\n  \nsystem.build.toplevel\n\n      The top-level option that builds the entire NixOS system. Everything else\n      in your configuration is indirectly pulled in by this option. This is\n      what nixos-rebuild builds and what\n      /run/current-system points to afterwards.\n     \n      A shortcut to build this is:\n\n$ nix-build -A system\n\nsystem.build.manual.manualHTML\n\n      The NixOS manual.\n     \nsystem.build.etc\n\n      A tree of symlinks that form the static parts of\n      /etc.\n     \nsystem.build.initialRamdisk\n    , \nsystem.build.kernel\n\n      The initial ramdisk and kernel of the system. This allows a quick way to\n      test whether the kernel and the initial ramdisk boot correctly, by using\n      QEMU’s -kernel and -initrd options:\n\n$ nix-build -A config.system.build.initialRamdisk -o initrd\n$ nix-build -A config.system.build.kernel -o kernel\n$ qemu-system-x86_64 -kernel ./kernel/bzImage -initrd ./initrd/initrd -hda /dev/null\n\n\nsystem.build.nixos-rebuild\n    , \nsystem.build.nixos-install\n    , \nsystem.build.nixos-generate-config\n\n      These build the corresponding NixOS commands.\n     \nsystemd.units.unit-name.unit\n\n      This builds the unit with the specified name. Note that since unit names\n      contain dots (e.g. httpd.service), you need to put\n      them between quotes, like this:\n\n$ nix-build -A 'config.systemd.units.\"httpd.service\".unit'\n\n      You can also test individual units, without rebuilding the whole system,\n      by putting them in /run/systemd/system:\n\n$ cp $(nix-build -A 'config.systemd.units.\"httpd.service\".unit')/httpd.service \\\n    /run/systemd/system/tmp-httpd.service\n# systemctl daemon-reload\n# systemctl start tmp-httpd.service\n\n      Note that the unit must not have the same name as any unit in\n      /etc/systemd/system since those take precedence over\n      /run/systemd/system. That’s why the unit is\n      installed as tmp-httpd.service here.\n     \nChapter 46. Writing NixOS DocumentationTable of Contents46.1. Building the Manual46.2. Editing DocBook XML46.3. Creating a Topic46.4. Adding a Topic to the Book\n  As NixOS grows, so too does the need for a catalogue and explanation of its\n  extensive functionality. Collecting pertinent information from disparate\n  sources and presenting it in an accessible style would be a worthy\n  contribution to the project.\n 46.1. Building the Manual\n   The DocBook sources of the NixOS Manual are in the\n   nixos/doc/manual\n   subdirectory of the Nixpkgs repository.\n  \n   You can quickly validate your edits with make:\n  \n  $ cd /path/to/nixpkgs/nixos/doc/manual\n  $ make\n\n   Once you are done making modifications to the manual, it's important to\n   build it before committing. You can do that as follows:\n  nix-build nixos/release.nix -A manual.x86_64-linux\n   When this command successfully finishes, it will tell you where the manual\n   got generated. The HTML will be accessible through the\n   result symlink at\n   ./result/share/doc/nixos/index.html.\n  46.2. Editing DocBook XML\n   For general information on how to write in DocBook, see\n    DocBook\n   5: The Definitive Guide.\n  \n   Emacs nXML Mode is very helpful for editing DocBook XML because it validates\n   the document as you write, and precisely locates errors. To use it, see\n   Section 23.3.3, “Editing DocBook 5 XML Documents”.\n  \nPandoc can generate DocBook XML\n   from a multitude of formats, which makes a good starting point.\n   Example 46.1. Pandoc invocation to convert GitHub-Flavoured MarkDown to DocBook 5 XMLpandoc -f markdown_github -t docbook5 docs.md -o my-section.md\n   Pandoc can also quickly convert a single section.xml to\n   HTML, which is helpful when drafting.\n  \n   Sometimes writing valid DocBook is simply too difficult. In this case,\n   submit your documentation updates in a\n   GitHub\n   Issue and someone will handle the conversion to XML for you.\n  46.3. Creating a Topic\n   You can use an existing topic as a basis for the new topic or create a topic\n   from scratch.\n  \n   Keep the following guidelines in mind when you create and add a topic:\n   \n      The NixOS\n      book\n      element is in nixos/doc/manual/manual.xml. It\n      includes several\n      parts\n      which are in subdirectories.\n     \n      Store the topic file in the same directory as the part to\n      which it belongs. If your topic is about configuring a NixOS module, then\n      the XML file can be stored alongside the module definition\n      nix file.\n     \n      If you include multiple words in the file name, separate the words with a\n      dash. For example: ipv6-config.xml.\n     \n      Make sure that the xml:id value is unique. You can use\n      abbreviations if the ID is too long. For example:\n      nixos-config.\n     \n      Determine whether your topic is a chapter or a section. If you are\n      unsure, open an existing topic file and check whether the main element is\n      chapter or section.\n     \n46.4. Adding a Topic to the Book\n   Open the parent XML file and add an xi:include element to\n   the list of chapters with the file name of the topic that you created. If\n   you created a section, you add the file to the chapter\n   file. If you created a chapter, you add the file to the\n   part file.\n  \n   If the topic is about configuring a NixOS module, it can be automatically\n   included in the manual by using the meta.doc attribute.\n   See Section 44.5, “Meta Attributes” for an explanation.\n  Chapter 47. Building Your Own NixOS CD\n  Building a NixOS CD is as easy as configuring your own computer. The idea is\n  to use another module which will replace your\n  configuration.nix to configure the system that would be\n  installed on the CD.\n \n  Default CD/DVD configurations are available inside\n  nixos/modules/installer/cd-dvd.\n\n$ git clone https://github.com/NixOS/nixpkgs.git\n$ cd nixpkgs/nixos\n$ nix-build -A config.system.build.isoImage -I nixos-config=modules/installer/cd-dvd/installation-cd-minimal.nix default.nix\n\n  Before burning your CD/DVD, you can check the content of the image by\n  mounting anywhere like suggested by the following command:\n\n# mount -o loop -t iso9660 ./result/iso/cd.iso /mnt/iso\nChapter 48. NixOS TestsTable of Contents48.1. Writing Tests48.2. Running Tests48.3. Running Tests interactively\n  When you add some feature to NixOS, you should write a test for it. NixOS\n  tests are kept in the directory\n  nixos/tests,\n  and are executed (using Nix) by a testing framework that automatically starts\n  one or more virtual machines containing the NixOS system(s) required for the\n  test.\n 48.1. Writing Tests\n  A NixOS test is a Nix expression that has the following structure:\n\nimport ./make-test-python.nix {\n\n  # Either the configuration of a single machine:\n  machine =\n    { config, pkgs, ... }:\n    { configuration…\n    };\n\n  # Or a set of machines:\n  nodes =\n    { machine1 =\n        { config, pkgs, ... }: { … };\n      machine2 =\n        { config, pkgs, ... }: { … };\n      …\n    };\n\n  testScript =\n    ''\n      Python code…\n    '';\n}\n\n  The attribute testScript is a bit of Python code that\n  executes the test (described below). During the test, it will start one or\n  more virtual machines, the configuration of which is described by the\n  attribute machine (if you need only one machine in your\n  test) or by the attribute nodes (if you need multiple\n  machines). For instance,\n  login.nix\n  only needs a single machine to test whether users can log in on the virtual\n  console, whether device ownership is correctly maintained when switching\n  between consoles, and so on. On the other hand,\n  nfs.nix,\n  which tests NFS client and server functionality in the Linux kernel\n  (including whether locks are maintained across server crashes), requires\n  three machines: a server and two clients.\n \n  There are a few special NixOS configuration options for test VMs:\n\n  \nvirtualisation.memorySize\n\n      The memory of the VM in megabytes.\n     \nvirtualisation.vlans\n\n      The virtual networks to which the VM is connected. See\n      nat.nix\n      for an example.\n     \nvirtualisation.writableStore\n\n      By default, the Nix store in the VM is not writable. If you enable this\n      option, a writable union file system is mounted on top of the Nix store\n      to make it appear writable. This is necessary for tests that run Nix\n      operations that modify the store.\n     \n  For more options, see the module\n  qemu-vm.nix.\n \n  The test script is a sequence of Python statements that perform various\n  actions, such as starting VMs, executing commands in the VMs, and so on. Each\n  virtual machine is represented as an object stored in the variable\n  name if this is also the\n  identifier of the machine in the declarative config.\n  If you didn't specify multiple machines using the nodes\n  attribute, it is just machine.\n  The following example starts the machine, waits until it has finished booting,\n  then executes a command and checks that the output is more-or-less correct:\n\nmachine.start()\nmachine.wait_for_unit(\"default.target\")\nif not \"Linux\" in machine.succeed(\"uname\"):\n  raise Exception(\"Wrong OS\")\n\n  The first line is actually unnecessary; machines are implicitly started when\n  you first execute an action on them (such as wait_for_unit\n  or succeed). If you have multiple machines, you can speed\n  up the test by starting them in parallel:\n\nstart_all()\n\n\n  The following methods are available on machine objects:\n  \nstart\n\n      Start the virtual machine. This method is asynchronous — it does not\n      wait for the machine to finish booting.\n     \nshutdown\n\n      Shut down the machine, waiting for the VM to exit.\n     \ncrash\n\n      Simulate a sudden power failure, by telling the VM to exit immediately.\n     \nblock\n\n      Simulate unplugging the Ethernet cable that connects the machine to the\n      other machines.\n     \nunblock\n\n      Undo the effect of block.\n     \nscreenshot\n\n      Take a picture of the display of the virtual machine, in PNG format. The\n      screenshot is linked from the HTML log.\n     \nget_screen_text\n\n      Return a textual representation of what is currently visible on the\n      machine's screen using optical character recognition.\n     Note: \n       This requires passing enableOCR to the test attribute\n       set.\n      \nsend_monitor_command\n\n      Send a command to the QEMU monitor. This is rarely used, but allows doing\n      stuff such as attaching virtual USB disks to a running machine.\n     \nsend_keys\n\n      Simulate pressing keys on the virtual keyboard, e.g.,\n      send_keys(\"ctrl-alt-delete\").\n     \nsend_chars\n\n      Simulate typing a sequence of characters on the virtual keyboard, e.g.,\n      send_keys(\"foobar\\n\") will type the string\n      foobar followed by the Enter key.\n     \nexecute\n\n      Execute a shell command, returning a list\n      (status,\n      stdout).\n     \nsucceed\n\n      Execute a shell command, raising an exception if the exit status is not\n      zero, otherwise returning the standard output.\n     \nfail\n\n      Like succeed, but raising an exception if the\n      command returns a zero status.\n     \nwait_until_succeeds\n\n      Repeat a shell command with 1-second intervals until it succeeds.\n     \nwait_until_fails\n\n      Repeat a shell command with 1-second intervals until it fails.\n     \nwait_for_unit\n\n      Wait until the specified systemd unit has reached the “active” state.\n     \nwait_for_file\n\n      Wait until the specified file exists.\n     \nwait_for_open_port\n\n      Wait until a process is listening on the given TCP port (on\n      localhost, at least).\n     \nwait_for_closed_port\n\n      Wait until nobody is listening on the given TCP port.\n     \nwait_for_x\n\n      Wait until the X11 server is accepting connections.\n     \nwait_for_text\n\n      Wait until the supplied regular expressions matches the textual contents\n      of the screen by using optical character recognition (see\n      get_screen_text).\n     Note: \n       This requires passing enableOCR to the test attribute\n       set.\n      \nwait_for_window\n\n      Wait until an X11 window has appeared whose name matches the given\n      regular expression, e.g., wait_for_window(\"Terminal\").\n     \ncopy_file_from_host\n\n      Copies a file from host to machine, e.g.,\n      copy_file_from_host(\"myfile\", \"/etc/my/important/file\").\n     \n      The first argument is the file on the host. The file needs to be\n      accessible while building the nix derivation. The second argument is the\n      location of the file on the machine.\n     \nsystemctl\n\n      Runs systemctl commands with optional support for\n      systemctl --user\n\n\nmachine.systemctl(\"list-jobs --no-pager\") # runs `systemctl list-jobs --no-pager`\nmachine.systemctl(\"list-jobs --no-pager\", \"any-user\") # spawns a shell for `any-user` and runs `systemctl --user list-jobs --no-pager`\n\n\n\n  To test user units declared by systemd.user.services the\n  optional user argument can be used:\n\nmachine.start()\nmachine.wait_for_x()\nmachine.wait_for_unit(\"xautolock.service\", \"x-session-user\")\n\n  This applies to systemctl, get_unit_info,\n  wait_for_unit, start_job and\n  stop_job.\n \n  For faster dev cycles it's also possible to disable the code-linters (this shouldn't\n  be commited though):\n\nimport ./make-test-python.nix {\n  skipLint = true;\n  machine =\n    { config, pkgs, ... }:\n    { configuration…\n    };\n\n  testScript =\n    ''\n      Python code…\n    '';\n}\n\n48.2. Running Tests\n  You can run tests using nix-build. For example, to run the\n  test\n  login.nix,\n  you just do:\n\n$ nix-build '<nixpkgs/nixos/tests/login.nix>'\n\n  or, if you don’t want to rely on NIX_PATH:\n\n$ cd /my/nixpkgs/nixos/tests\n$ nix-build login.nix\n…\nrunning the VM test script\nmachine: QEMU running (pid 8841)\n…\n6 out of 6 tests succeeded\n\n  After building/downloading all required dependencies, this will perform a\n  build that starts a QEMU/KVM virtual machine containing a NixOS system. The\n  virtual machine mounts the Nix store of the host; this makes VM creation very\n  fast, as no disk image needs to be created. Afterwards, you can view a\n  pretty-printed log of the test:\n\n$ firefox result/log.html\n\n48.3. Running Tests interactively\n  The test itself can be run interactively. This is particularly useful when\n  developing or debugging a test:\n\n$ nix-build nixos/tests/login.nix -A driver\n$ ./result/bin/nixos-test-driver\nstarting VDE switch for network 1\n>\n\n  You can then take any Python statement, e.g.\n\n> start_all()\n> test_script()\n> machine.succeed(\"touch /tmp/foo\")\n> print(machine.succeed(\"pwd\")) # Show stdout of command\n\n  The function test_script executes the entire test script\n  and drops you back into the test driver command line upon its completion.\n  This allows you to inspect the state of the VMs after the test (e.g. to debug\n  the test script).\n \n  To just start and experiment with the VMs, run:\n\n$ nix-build nixos/tests/login.nix -A driver\n$ ./result/bin/nixos-run-vms\n\n  The script nixos-run-vms starts the virtual machines\n  defined by test.\n \n  The machine state is kept across VM restarts in\n  /tmp/vm-state-machinename.\n Chapter 49. Testing the Installer\n  Building, burning, and booting from an installation CD is rather tedious, so\n  here is a quick way to see if the installer works properly:\n\n# mount -t tmpfs none /mnt\n# nixos-generate-config --root /mnt\n$ nix-build '<nixpkgs/nixos>' -A config.system.build.nixos-install\n# ./result/bin/nixos-install\n  To start a login shell in the new NixOS installation in\n  /mnt:\n\n$ nix-build '<nixpkgs/nixos>' -A config.system.build.nixos-enter\n# ./result/bin/nixos-enter\n\nChapter 50. ReleasesTable of Contents50.1. Release process50.2. Release Management Team50.3. Release schedule50.1. Release process\n   Going through an example of releasing NixOS 17.09:\n  50.1.1. One month before the beta\n      Send an email to the nix-devel mailinglist as a warning about upcoming\n      beta \"feature freeze\" in a month.\n     \n      Discuss with Eelco Dolstra and the community (via IRC, ML) about what\n      will reach the deadline. Any issue or Pull Request targeting the release\n      should be included in the release milestone.\n     50.1.2. At beta release time\nCreate\n      an issue for tracking Zero Hydra Failures progress. ZHF is an effort to\n      get build failures down to zero.\n\ngit tag -a -s -m \"Release 17.09-beta\" 17.09-beta\n      && git push origin 17.09-beta\n\n      From the master branch run git checkout -b\n      release-17.09.\n     \n\n      Make sure a channel is created at https://nixos.org/channels/. \n\n\n      Bump the system.defaultChannel attribute in\n      nixos/modules/misc/version.nix \n\n\n      Update versionSuffix in\n      nixos/release.nix, use git log\n      --format=%an|wc -l to get the commit count\n     \necho -n \"18.03\" > .version on master.\n     \n\n      Pick a new name for the unstable branch. \n\n      Create a new release notes file for the upcoming release + 1, in this\n      case rl-1803.xml.\n     \n      Create two Hydra jobsets: release-17.09 and release-17.09-small with\n      stableBranch set to false.\n     \n      Remove attributes that we know we will not be able to support,\n      especially if there is a stable alternative. E.g. Check that our\n      Linux kernels'\n      \n      projected end-of-life are after our release projected\n      end-of-life\n     \n      Edit changelog at\n      nixos/doc/manual/release-notes/rl-1709.xml (double\n      check desktop versions are noted)\n     \n        Get all new NixOS modules git diff\n        release-17.03..release-17.09 nixos/modules/module-list.nix|grep\n        ^+\n\n        Note systemd, kernel, glibc and Nix upgrades.\n       50.1.3. During Beta\n      Monitor the master branch for bugfixes and minor updates and cherry-pick\n      them to the release branch.\n     50.1.4. Before the final release\n      Re-check that the release notes are complete.\n     \n      Release Nix (currently only Eelco Dolstra can do that).\n      \n      Make sure fallback is updated. \n\n\n      Update README.md with new stable NixOS version information. \n\n      Change stableBranch to true in Hydra and wait for\n      the channel to update.\n     50.1.5. At final release time\ngit tag -s -a -m \"Release 15.09\" 15.09\n\n      Update \"Chapter 4. Upgrading NixOS\" section of the manual to match\n      new stable release version.\n     \n      Update the\n      NIXOS_SERIES\n      in the\n      nixos-homepage\n      repository.\n     \n      Get number of commits for the release: git log\n      release-14.04..release-14.12 --format=%an|wc -l\n\n      Commits by contributor: git log release-14.04..release-14.12\n      --format=%an|sort|uniq -c|sort -rn\n\n      Create a new topic on the\n      Discourse instance to announce the release with the above information.\n      Best to check how previous email was formulated to see what needs to be\n      included.\n     50.2. Release Management Team\n   For each release there are two release managers. After each release the\n   release manager having managed two releases steps down and the release\n   management team of the last release appoints a new release manager.\n  \n   This makes sure a release management team always consists of one release\n   manager who already has managed one release and one release manager being\n   introduced to their role, making it easier to pass on knowledge and\n   experience.\n  \n   Release managers for the current NixOS release are tracked by GitHub team\n   @NixOS/nixos-release-managers.\n  \n   A release manager's role and responsibilities are:\n  manage the release processstart discussions about features and changes for a given releasecreate a roadmaprelease in cooperation with Eelco Dolstradecide which bug fixes, features, etc... get backported after a release50.3. Release schedule\n            Date\n          \n            Event\n          \n            2016-07-25\n          \n            Send email to nix-dev about upcoming branch-off\n          \n            2016-09-01\n          release-16.09 branch and corresponding jobsets are created,\n            change freeze\n          \n            2016-09-30\n          \n            NixOS 16.09 released\n          Appendix A. Configuration Options →\n\n\n\n\n\nThe project\n\nChannel Status\nPackages search\nOptions search\nSecurity\n\n\n\nGet in Touch\n\nForum\nChat\nCommercial support\n\n\n\nContribute\n\nContributing Guide\nDonate\n\n\n\nStay up to date\n\nAnnouncements\nNewsletter\n\n\n\n\n\n\nNixOS\n\n\n            Copyright © 2020 NixOS\n          \n\n\n              CC-BY-SA-4.0\n            \n\n\n\n\nConnect with us\n\nTwitter\nYoutube\nGitHub\n\n\n\n\n \n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# nixos-rebuild\n\n> Reconfigure a NixOS machine.\n> More information: <https://nixos.org/nixos/manual/#sec-changing-config>.\n\n- Build and switch to the new configuration, making it the boot default:\n\n`sudo nixos-rebuild switch`\n\n- Build and switch to the new configuration, making it the boot default and naming the boot entry:\n\n`sudo nixos-rebuild switch -p {{name}}`\n\n- Build and switch to the new configuration, making it the boot default and installing updates:\n\n`sudo nixos-rebuild switch --upgrade`\n\n- Rollback changes to the configuration, switching to the previous generation:\n\n`sudo nixos-rebuild switch --rollback`\n\n- Build the new configuration and make it the boot default without switching to it:\n\n`sudo nixos-rebuild boot`\n\n- Build and activate the new configuration, but don't make a boot entry (for testing purposes):\n\n`sudo nixos-rebuild test`\n\n- Build the configuration and open it in a virtual machine:\n\n`sudo nixos-rebuild build-vm`\n"
 },
 {
   "command": "acpi",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# acpi\n\n> Shows battery status or thermal information.\n\n- Show battery information:\n\n`acpi`\n\n- Show thermal information:\n\n`acpi -t`\n\n- Show cooling device information:\n\n`acpi -c`\n\n- Show thermal information in Fahrenheit:\n\n`acpi -tf`\n\n- Show all information:\n\n`acpi -V`\n"
 },
 {
   "command": "whiptail",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# whiptail\n\n> Display text-based dialog boxes from shell scripts.\n\n- Display a simple message:\n\n`whiptail --title \"{{title}}\" --msgbox \"{{message}}\" {{height_in_chars}} {{width_in_chars}}`\n\n- Display a boolean choice, returning the result through the exit code:\n\n`whiptail --title \"{{title}}\" --yesno \"{{message}}\" {{height_in_chars}} {{width_in_chars}}`\n\n- Customise the text on the yes / no buttons:\n\n`whiptail --title \"{{title}}\" --yes-button \"{{text}}\" --no-button \"{{text}}\" --yesno \"{{message}}\" {{height_in_chars}} {{width_in_chars}}`\n\n- Display a text input box:\n\n`{{result_variable_name}}=\"$(whiptail --title \"{{title}}\" --inputbox \"{{message}}\" {{height_in_chars}} {{width_in_chars}} {{default_text}} 3>&1 1>&2 2>&3)\"`\n\n- Display a password input box:\n\n`{{result_variable_name}}=\"$(whiptail --title \"{{title}}\" --passwordbox \"{{message}}\" {{height_in_chars}} {{width_in_chars}} 3>&1 1>&2 2>&3)\"`\n\n- Display a multiple-choice menu:\n\n`{{result_variable_name}}=$(whiptail --title \"{{title}}\" --menu \"{{message}}\" {{height_in_chars}} {{width_in_chars}} {{menu_display_height}} \"{{value_1}}\" \"{{display_text_1}}\" \"{{value_n}}\" \"{{display_text_n}}\" ..... 3>&1 1>&2 2>&3)`\n"
 },
 {
   "command": "runcon",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# runcon\n\n> Run a program in a different SELinux security context.\n> With neither context nor command, print the current security context.\n\n- Determine the current domain:\n\n`runcon`\n\n- Specify the domain to run a command in:\n\n`runcon -t {{domain}}_t {{command}}`\n\n- Specify the context role to run a command with:\n\n`runcon -r {{role}}_r {{command}}`\n\n- Specify the full context to run a command with:\n\n`runcon {{user}}_u:{{role}}_r:{{domain}}_t {{command}}`\n"
 },
 {
   "command": "systemd-analyze",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# systemd-analyze\n\n> Show timing details about the boot process of units (services, mount points, devices, sockets).\n\n- List time of each unit to start up:\n\n`systemd-analyze blame`\n\n- Print a tree of the time critical chain of units:\n\n`systemd-analyze critical-chain`\n"
 },
 {
   "command": "gedit",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# gedit\n\n> Text editor of the GNOME Desktop project.\n\n- Open a text file:\n\n`gedit {{path/to/file}}`\n\n- Open multiple text files:\n\n`gedit {{file1 file2 ...}}`\n\n- Open a text file with a specific encoding:\n\n`gedit --encoding={{UTF-8}} {{path/to/file}}`\n\n- Display a list of supported encodings:\n\n`gedit --list-encodings`\n"
 },
 {
   "command": "zramctl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# zramctl\n\n> Setup and control zram devices.\n> Use `mkfs` or `mkswap` to format zram devices to partitions.\n\n- Check if zram is enabled:\n\n`lsmod | grep -i zram`\n\n- Enable zram with a dynamic number of devices (use `zramctl` to configure devices further):\n\n`sudo modprobe zram`\n\n- Enable zram with exactly 2 devices:\n\n`sudo modprobe zram num_devices={{2}}`\n\n- Find and initialise the next free zram device to a 2GB virtual drive using LZ4 compression:\n\n`sudo zramctl --find --size {{2GB}} --algorithm {{lz4}}`\n\n- List currently initialised devices:\n\n`zramctl`\n"
 },
 {
   "command": "repquota",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nREPQUOTA(8)\t\t  BSD System Manager's Manual\t\t   REPQUOTA(8)\n\nNAME\n     repquota -- summarize quotas for a file system\n\nSYNOPSIS\n     repquota [-g] [-u] [-v] filesystem ...\n     repquota [-g] [-u] [-v] -a\n\nDESCRIPTION\n     Repquota prints a summary of the disk usage and quotas for the specified\n     file systems.\n\n     Available options:\n\n     -a      Print the quotas of all the filesystems configured with a quota\n\t     mount option file at its root.\n\n     -g      Print only group quotas (the default is to print both group and\n\t     user quotas if they exist).\n\n     -u      Print only user quotas (the default is to print both group and\n\t     user quotas if they exist).\n\n     -v      Print a header line before printing each filesystem quotas.\n\n     For each user or group, the current number of files and amount of space\n     (in kilobytes) is printed, along with any quotas created with edquota(8).\n\n     Only members of the operator group or the super-user may use this com-\n     mand.\n\nFILES\n     Each of the following quota files is located at the root of the mounted\n     filesystem.  The mount option files are empty files whose existence indi-\n     cates that quotas are to be enabled for that filesystem.\n\n     .quota.user       data file containing user quotas\n     .quota.group      data file containing group quotas\n     .quota.ops.user   mount option file used to enable user quotas\n     .quota.ops.group  mount option file used to enable group quotas\n\nSEE ALSO\n     quota(1), quotactl(2), edquota(8), quotacheck(8), quotaon(8)\n\nDIAGNOSTICS\n     Various messages about inaccessible files; self-explanatory.\n\nHISTORY\n     The repquota command appeared in 4.2BSD.\n\n4.2 Berkeley Distribution\tMarch 28, 2002\t     4.2 Berkeley Distribution\n",
   "tldr_summary": "# repquota\n\n> Display a summary of existing file quotas for a filesystem.\n\n- Report stats for all quotas in use:\n\n`sudo repquota -all`\n\n- Report quota stats for all users, even those who aren't using any of their quota:\n\n`sudo repquota -v {{filesystem}}`\n\n- Report on quotas for users only:\n\n`repquota --user {{filesystem}}`\n\n- Report on quotas for groups only:\n\n`sudo repquota --group {{filesystem}}`\n\n- Report on used quota and limits in a human-readable format:\n\n`sudo repquota --human-readable {{filesystem}}`\n\n- Report on all quotas for users and groups in a human-readable format:\n\n`sudo repquota -augs`\n"
 },
 {
   "command": "aspell",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# aspell\n\n> Interactive spell checker.\n\n- Spell check a single file:\n\n`aspell check {{path/to/file}}`\n\n- List misspelled words from standard input:\n\n`cat {{file}} | aspell list`\n\n- Show available dictionary languages:\n\n`aspell dicts`\n\n- Run aspell with different language (takes two letter ISO 639 language code):\n\n`aspell --lang={{cs}}`\n\n- List misspelled words from standard input and ignore words from personal word list:\n\n`cat {{file}} | aspell --personal={{personal-word-list.pws}} {{list}}`\n"
 },
 {
   "command": "xfce4-screenshooter",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xfce4-screenshooter\n\n> The XFCE4 screenshot tool.\n\n- Launch the screenshooter GUI:\n\n`xfce4-screenshooter`\n\n- Take a screenshot of the entire screen and launch the GUI to ask how to proceed:\n\n`xfce4-screenshooter --fullscreen`\n\n- Take a screenshot of the entire screen and save it in the specified directory:\n\n`xfce4-screenshooter --fullscreen --save {{path/to/directory}}`\n\n- Wait some time before taking the screenshot:\n\n`xfce4-screenshooter --delay {{seconds}}`\n\n- Take a screenshot of a region of the screen (select using the mouse):\n\n`xfce4-screenshooter --region`\n\n- Take a screenshot of the active window, and copy it to the clipboard:\n\n`xfce4-screenshooter --window --clipboard`\n\n- Take a screenshot of the active window, and open it with a chosen program:\n\n`xfce4-screenshooter --window --open {{gimp}}`\n"
 },
 {
   "command": "groupadd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# groupadd\n\n> Add user groups to the system.\n\n- Create a new Linux group:\n\n`groupadd {{group_name}}`\n\n- Create new group with a specific groupid:\n\n`groupadd {{group_name}} -g {{group_id}}`\n"
 },
 {
   "command": "lrunzip",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lrunzip\n\n> A large file decompression program.\n> See also `lrzip`, `lrztar`, `lrzuntar`.\n\n- Decompress a file:\n\n`lrunzip {{filename.lrz}}`\n\n- Decompress a file using a specific number of processor threads:\n\n`lrunzip -p {{8}} {{filename.lrz}}`\n\n- Decompress a file and silently overwrite files if they exist:\n\n`lrunzip -f {{filename.lrz}}`\n\n- Keep broken or damaged files instead of deleting them when decompressing:\n\n`lrunzip -K {{filename.lrz}}`\n\n- Specify output file name and/or path:\n\n`lrunzip -o {{outfilename}} {{filename.lrz}}`\n"
 },
 {
   "command": "pivpn",
   "doc_url": "http://www.pivpn.io/",
   "doc_text": "\n\nPIVPN: Simplest way to setup a VPN\n\n\n\n\n\n\n\n\n\n\n\nThe PiVPN Project\n\n\t\t\t\t\t\tSecure connectivity for the masses.\n\t\t\t\t\t\tLow cost, high security.\n\t\t\t\t\t\n\n\n\nInstall\nAbout\nTechnical Information\nContribute!\n\n\n\n\n\n\nGithub\n\n\n\n\nReddit\n\n\n\n\n\n\n\n\n\n\n\n\n\nPiVPN\n\n\t\t\t\t\t\t\t\tThe simplest way to setup and manage a VPN,\n\t\t\t\t\t\t\t\tdesigned for Raspberry Pi.\n\t\t\t\t\t\t\t\n\n\n\n::: INSTALLATION :::\n\ncurl -L https://install.pivpn.io | bash\n\n::: Test (unstable) Branch :::\n\ncurl -L https://test.pivpn.io | TESTING= bash\n\n\n\nSIMPLE ::: Yes, that's it!  It is *almost* that simple.\n\t\t\t\t\t\t\tTo elaborate a little more, you will want to\n\t\t\t\t\t\t\tinstall Raspbian\n\t\t\t\t\t\t\ton a Raspberry pi, we strongly recommend using the latest\n\t\t\t\t\t\t\tRaspbian Lite\n\t\t\t\t\t\t\timage but the normal Raspbian image will work as well,\n\t\t\t\t\t\t\tpreferably enable ssh access and then begin.\n\t\t\t\t\t\t\tAfter install, you may need to open a port on your router.\n\t\t\t\t\t\t\tThere is a (now slightly outdated) guided walkthrough of the install available\n\t\t\t\t\t\t\there.\n\t\t\t\t\t\t\tMore information is also available on the PiVPN GitHub\n\n\nFLEXIBLE ::: \n\t\t\t\t\t\t\tThink if you can figure out how to do this yourself you'll have\n\t\t\t\t\t\t\tmore options?\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tThis installer is no slouch! It'll allow you to customize your\n\t\t\t\t\t\t\tVPN port, key encryption strength, client DNS server, and more!\n\t\t\t\t\t\t\tEven if you are an expert, the options presented within are a\n\t\t\t\t\t\t\tperfect foundation for any openvpn server installation.\n\t\t\t\t\t\t\tAlthough this is geared toward running on a $35 Raspberry Pi,\n\t\t\t\t\t\t\tthe installer will work just as well on an Ubuntu or Debian server.\n\t\t\t\t\t\t\n\nMANAGEABLE ::: \n\t\t\t\t\t\t\tInstallation is finished, now what do you do? No worries,\n\t\t\t\t\t\t\twe've got you covered!\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tProvided free of charge on your server is a new 'pivpn' command.\n\t\t\t\t\t\t\tSimply run pivpn and you are presented with all of the available options.\n\t\t\t\t\t\t\tEasily add client profiles (OVPN), revoke them, list the ones you created, etc.\n\t\t\t\t\t\t\tThere is also an option to completely remove everything\n\t\t\t\t\t\t\tthe installer did with the 'pivpn uninstall' command.\n\t\t\t\t\t\t\tSo you can experiment with pivpn with no fear of irreversible\n\t\t\t\t\t\t\tchanges to your server.\n\t\t\t\t\t\t\n\nSECURE ::: \n\t\t\t\t\t\tEven though this installer makes everything so trivial,\n\t\t\t\t\t\tit doesn't mean it gives you trivial security settings.\n\t\t\t\t\t\t\n\t\t\t\t\t\tEverything has been upgraded right out of the box beyond the default\n\t\t\t\t\t\tsettings to harden the security of the server and client.\n\t\t\t\t\t\tStarting with offering you the ability to enable unattended-upgrades\n\t\t\t\t\t\twhich will automatically patch your server with security updates.\n\t\t\t\t\t\tNext, the server configuration will only use the latest TLS protocol.\n\t\t\t\t\t\tBoth the data and control channels use upgraded AES and SHA256 encryption and hash algorithms.\n\t\t\t\t\t\tOptions are pre-configured to verify your server certificate to battle MITM attack vectors.\n\t\t\t\t\t\tAll this and more are configured out of the box by the pivpn installer.\n\t\t\t\t\t\tThis is a detailed level of hardening you'll have a difficult time finding elsewhere.\n\t\t\t\t\t\t\n\n\n\n\n\nAbout\nOrigin\n\n\t\t\t\t\t\t\tThere are quite a few various scripts that in some way install openvpn for you.\n\t\t\t\t\t\t\tThis project, in particular, was started by 0-kaladin and began\n\t\t\t\t\t\t\tfrom the code by StarshipEngineer\n\t\t\t\t\t\t\tto help to install OpenVPN on a raspberry pi as simple as it can be.\n\t\t\t\t\t\t\tThis is still the striving goal today (see Why This Is Important just below) however,\n\t\t\t\t\t\t\teven with the solid foundation provided by StarshipEngineer,\n\t\t\t\t\t\t\t0-kaladin came across the Pi-Hole\n\t\t\t\t\t\t\tproject and saw just how easy the installation can be! He took the\n\t\t\t\t\t\t\tscripts from StarshipEngineer, the framework, and functions from\n\t\t\t\t\t\t\tthe pi-hole project, and merged them into what you now see as PiVPN.\n\t\t\t\t\t\t\tThen added a ton of functionality, failsafe checks, hardened security, etc...\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tCurrently, community-maintained this should be bar none, the simplest\n\t\t\t\t\t\t\tand fastest way to set up an OpenVPN server on your raspberry pi\n\t\t\t\t\t\t\tthat leaves you with an extremely secure configuration.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tWe've made a few additions and tweaks as well to help make managing\n\t\t\t\t\t\t\tthe OpenVPN server even easier after install.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tEverything can be managed by using a new 'pivpn' command on your system,\n\t\t\t\t\t\t\tthis includes adding new client certs, revoking them,\n\t\t\t\t\t\t\tand completely uninstalling the pivpn.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tThere is a lot more that can be added and we hope the suggestions\n\t\t\t\t\t\t\tand improvements can be contributed by the community at large.\n\t\t\t\t\t\t\nWhy This Is Important\n\n\t\t\t\t\t\t\tThere are a few driving factors that make this very important to us,\n\t\t\t\t\t\t\tand we believe, the community at large. In this post-Snowden era\n\t\t\t\t\t\t\twhere our privacy and security are infringed upon,\n\t\t\t\t\t\t\tnot only by bad actors but potentially by those whom we thought\n\t\t\t\t\t\t\tshould be protecting these very ideals, normal citizens must take\n\t\t\t\t\t\t\tmatters into their own hands. The trouble with this, many times,\n\t\t\t\t\t\t\tis that if you are not very technical you may not know how to begin.\n\t\t\t\t\t\t\tI believe the EFF has helped lower a barrier of encrypted sites with their\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tLet's Encrypt\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tinitiative.\n\t\t\t\t\t\t\tAllowing many to now have their sites on encrypted channels.\n\t\t\t\t\t\t\tTo us, the next logical step here is also ensuring the pipe you are\n\t\t\t\t\t\t\tusing is as secure as possible. This not only could include unknown\n\t\t\t\t\t\t\tnetworks at airports, Starbucks, generic public hot-spots;\n\t\t\t\t\t\t\tbut also your ISP. To that end, We'd like to make sure these\n\t\t\t\t\t\t\tscripts also work on a Debian image from an Amazon free tier server.\n\t\t\t\t\t\t\tIt is important that more and more people, have access to protecting\n\t\t\t\t\t\t\ttheir traffic online. Its clear others won't hand you this protection.\n\t\t\t\t\t\t\tPiVPN tries to make it easier for you to grab.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tEnjoy!\n\t\t\t\t\t\t\n\n\n\n\n\nTechnical Information & Features\n\nSupports OpenVPN 2.4\nSupports WireGuard\nElliptic curve encryption keys up to 512 bit\nIntegrates with Bitwarden\niOS keychain support\nSupports multiple DNS providers\nSupports Custom DNS Servers\nCustom Search Domains (OpenVPN Only)\nRuns with Pi-Hole®\nDoesn't need to be a raspberry pi, It runs on any Debian VPS Server\nSupports unattended installation for automated deployments\n\n\t\t\t\t\t\tFor more information on PiVPN be sure to check the\n\t\t\t\t\t\tPiVPN Wiki\n\n\t\t\t\t\t\tIt could also be helpful to browse closed Issues with the\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tInformation\n\t\t\t\t\t\t\n\t\t\t\t\t\tor\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tQuestion\n\t\t\t\t\t\t\n\t\t\t\t\t\ttag.\n\t\t\t\t\t\t\n\n\nBlogs / Video's About PiVPN\n\n\t\t\t\t\t\t\t\tThe links below showcase some good write-ups and tutorials that use PiVPN.\n\t\t\t\t\t\t\t\tSome other decent information may also be contained regarding VPNs and security in general.\n\t\t\t\t\t\t\t\tIf you find you have more questions on this area then read and/or watch some of them below!\n\t\t\t\t\t\t\t\nArticles / Blogs\n\n\n\n\t\t\t\t\t\t\t\t\t\tMaintainer post about where to properly place a VPN\n\t\t\t\t\t\t\t\t\t\n\n\n\t\t\t\t\t\t\t\t\t\tCreate your own VPN server with the Raspberry Pi\n\t\t\t\t\t\t\t\t\t\n\n\n\n\t\t\t\t\t\t\t\t\t\tPiVPN - Create your own VPN for your home network\n\t\t\t\t\t\t\t\t\t\n\n\n\n\t\t\t\t\t\t\t\t\t\tPiVPN, Easiest & Quickest Setup of OpenVPN\n\t\t\t\t\t\t\t\t\t\n\n\nVideo Guides\n\n\n\n\t\t\t\t\t\t\t\t\t\tHow to Setup PiVPN on the Raspberry Pi Tutorial\n\t\t\t\t\t\t\t\t\t\n\n\n\n\t\t\t\t\t\t\t\t\t\tRaspberry Pi - OpenVPN Setup via PiVPN\n\t\t\t\t\t\t\t\t\t\n\n\nFAQs & Support\n\n\t\t\t\t\t\t\t\t\tThere are\n\t\t\t\t\t\t\t\t\tFAQs\n\t\t\t\t\t\t\t\t\tand a Wiki\n\t\t\t\t\t\t\t\t\tavailable on the Github page.\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tMake sure you check the\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tPiVPN Issues\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tsection and especially the closed ones as your question may\n\t\t\t\t\t\t\t\t\talready be answered!\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tWe also have our subreddit for support and discussion at\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\tr/PiVPN\n\t\t\t\t\t\t\t\t\t\n\n\n\n\n\n\n\nContribute!\n\n\t\t\t\t\t\t\tContributions are Welcome and Encouraged!\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tThe PiVPN installation code is available on\n\t\t\t\t\t\t\tgithub.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tPlase Make sure you read the\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tContributors Guide\n\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tAfter reading the\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tContributors Guide\n\t\t\t\t\t\t\t,\n\t\t\t\t\t\t\tcheckout for any issues\n\t\t\t\t\t\t\tespecially with the 'help wanted' label.\n\t\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n© The PiVPN Project. All rights reserved.\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# pivpn\n\n> Easy security-hardened OpenVPN setup and manager.\n> Originally designed for the Raspberry Pi, but works on other Linux devices too.\n> More information: <http://www.pivpn.io/>.\n\n- Add a new client device:\n\n`sudo pivpn add`\n\n- List all client devices:\n\n`sudo pivpn list`\n\n- List currently connected devices and their statistics:\n\n`sudo pivpn clients`\n\n- Revoke a previously authenticated device:\n\n`sudo pivpn revoke`\n\n- Uninstall PiVPN:\n\n`sudo pivpn uninstall`\n"
 },
 {
   "command": "sa",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nSA(8)\t\t\t  BSD System Manager's Manual\t\t\t SA(8)\n\nNAME\n     sa -- print system accounting statistics\n\nSYNOPSIS\n     sa [-abcdDfijkKlmnqrstu] [-P file] [-U file] [-v cutoff] [file ...]\n\nDESCRIPTION\n     The sa utility reports on, cleans up, and generally maintains system\n     accounting files.\n\n     The sa utility is able to condense the information in /var/account/acct\n     into the summary files /var/account/savacct and /var/account/usracct,\n     which contain system statistics according to command name and login id,\n     respectively.  This condensation is desirable because on a large system,\n     /var/account/acct can grow by hundreds of blocks per day.\tThe summary\n     files are normally read before the accounting file, so that reports\n     include all available information.\n\n     If file names are supplied, they are read instead of /var/account/acct.\n     After each file is read, if the summary files are being updated, an\n     updated summary will be saved to disk.  Only one report is printed, after\n     the last file is processed.\n\n     The labels used in the output indicate the following, except where other-\n     wise specified by individual options:\n\n     avio   Average number of I/O operations per execution\n\n     cp     Sum of user and system time, in minutes\n\n     cpu    Same as cp\n\n     k\t    CPU-time averaged core usage, in 1k units\n\n     k*sec  CPU storage integral, in 1k-core seconds\n\n     re     Real time, in minutes\n\n     s\t    System time, in minutes\n\n     tio    Total number of I/O operations\n\n     u\t    User time, in minutes\n\n     The options to sa are:\n\n     -a      List all command names, including those containing unprintable\n\t     characters and those used only once.  By default, sa places all\n\t     names containing unprintable characters and those used only once\n\t     under the name ``***other''.\n\n     -b      If printing command statistics, sort output by the sum of user\n\t     and system time divided by number of calls.\n\n     -c      In addition to the number of calls and the user, system and real\n\t     times for each command, print their percentage of the total over\n\t     all commands.\n\n     -d      If printing command statistics, sort by the average number of\n\t     disk I/O operations.  If printing user statistics, print the\n\t     average number of disk I/O operations per user.\n\n     -D      If printing command statistics, sort and print by the total num-\n\t     ber of disk I/O operations.\n\n     -f      Force no interactive threshold comparison with the -v option.\n\n     -i      Do not read in the summary files.\n\n     -j      Instead of the total minutes per category, give seconds per call.\n\n     -k      If printing command statistics, sort by the cpu-time average mem-\n\t     ory usage.  If printing user statistics, print the cpu-time aver-\n\t     age memory usage.\n\n     -K      If printing command statistics, print and sort by the cpu-storage\n\t     integral.\n\n     -l      Separate system and user time; normally they are combined.\n\n     -m      Print per-user statistics rather than per-command statistics.\n\n     -n      Sort by number of calls.\n\n     -P file\n\t     Use the specified file for accessing the per-command accounting\n\t     summary database, instead of the default /var/account/savacct.\n\n     -q      Create no output other than error messages.\n\n     -r      Reverse order of sort.\n\n     -s      Truncate the accounting files when done and merge their data into\n\t     the summary files.\n\n     -t      For each command, report the ratio of real time to the sum of\n\t     user and system cpu times.  If the cpu time is too small to\n\t     report, ``*ignore*'' appears in this field.\n\n     -U file\n\t     Use the specified file for accessing the per-user accounting sum-\n\t     mary database, instead of the default /var/account/usracct.\n\n     -u      Superseding all other flags, for each entry in the accounting\n\t     file, print the user ID, total seconds of cpu usage, total memory\n\t     usage, number of I/O operations performed, and command name.\n\n     -v cutoff\n\t     For each command used cutoff times or fewer, print the command\n\t     name and await a reply from the terminal.\tIf the reply begins\n\t     with ``y'', add the command to the category ``**junk**''.\tThis\n\t     flag is used to strip garbage from the report.\n\n     By default, per-command statistics will be printed.  The number of calls,\n     the total elapsed time in minutes, total cpu and user time in minutes,\n     average number of I/O operations, and CPU-time averaged core usage will\n     be printed.  If the -m option is specified, per-user statistics will be\n     printed, including the user name, the number of commands invoked, total\n     cpu time used (in minutes), total number of I/O operations, and CPU stor-\n     age integral for each user.  If the -u option is specified, the uid, user\n     and system time (in seconds), CPU storage integral, I/O usage, and com-\n     mand name will be printed for each entry in the accounting data file.\n\n     If the -u flag is specified, all flags other than -q are ignored.\tIf the\n     -m flag is specified, only the -b, -d, -i, -k, -q, and -s flags are hon-\n     ored.\n\nFILES\n     /var/account/acct\t   raw accounting data file\n     /var/account/savacct  per-command accounting summary database\n     /var/account/usracct  per-user accounting summary database\n\nEXIT STATUS\n     The sa utility exits 0 on success, and >0 if an error occurs.\n\nSEE ALSO\n     lastcomm(1), acct(5), ac(8), accton(8)\n\nCAVEATS\n     While the behavior of the options in this version of sa was modeled after\n     the original version, there are some intentional differences and undoubt-\n     edly some unintentional ones as well.  In particular, the -q option has\n     been added, and the -m option now understands more options than it used\n     to.\n\n     The formats of the summary files created by this version of sa are very\n     different from the those used by the original version.  This is not con-\n     sidered a problem, however, because the accounting record format has\n     changed as well (since user ids are now 32 bits).\n\nAUTHORS\n     Chris G. Demetriou <cgd@postgres.berkeley.edu>\n\nBUGS\n     The number of options to this program is absurd, especially considering\n     that there is not much logic behind their lettering.\n\n     The field labels should be more consistent.\n\n     The VM system does not record the CPU storage integral.\n\nBSD\t\t\t\t May 18, 2007\t\t\t\t   BSD\n",
   "tldr_summary": "# sa\n\n> Summarizes accounting information. Part of the acct package.\n> Shows commands called by users, including basic info on CPU time spent processing and I/O rates.\n\n- Display executable invocations per user (username not displayed):\n\n`sudo sa`\n\n- Display executable invocations per user, showing responsible usernames:\n\n`sudo sa --print-users`\n\n- List resources used recently per user:\n\n`sudo sa --user-summary`\n"
 },
 {
   "command": "hostname",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nHOSTNAME(1)\t\t  BSD General Commands Manual\t\t   HOSTNAME(1)\n\nNAME\n     hostname -- set or print name of current host system\n\nSYNOPSIS\n     hostname [-fs] [name-of-host]\n\nDESCRIPTION\n     The hostname utility prints the name of the current host.\tThe super-user\n     can set the hostname by supplying an argument.  To keep the hostname\n     between reboots, run `scutil --set HostName name-of-host'.\n\n     Options:\n\n     -f    Include domain information in the printed name.  This is the\n\t   default behavior.\n\n     -s    Trim off any domain information from the printed name.\n\nSEE ALSO\n     gethostname(3), scutil(8)\n\nHISTORY\n     The hostname command appeared in 4.2BSD.\n\nBSD\t\t\t       December 7, 2006 \t\t\t   BSD\n",
   "tldr_summary": "# hostname\n\n> Show or set the system's host name.\n\n- Show current host name:\n\n`hostname`\n\n- Show the network address of the host name:\n\n`hostname -i`\n\n- Show all network addresses of the host:\n\n`hostname -I`\n\n- Show the FQDN (Fully Qualified Domain Name):\n\n`hostname --fqdn`\n\n- Set current host name:\n\n`hostname {{new_hostname}}`\n"
 },
 {
   "command": "apache2ctl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apache2ctl\n\n> The CLI tool to administrate HTTP web server Apache.\n> This commmand comes with Debian based OSes, for RHEL based ones see `httpd`.\n\n- Start the Apache daemon. Throw a message if it is already running:\n\n`sudo apache2ctl start`\n\n- Stop the Apache daemon:\n\n`sudo apache2ctl stop`\n\n- Restart the Apache daemon:\n\n`sudo apache2ctl restart`\n\n- Test syntax of the configuration file:\n\n`sudo apache2ctl -t`\n\n- List loaded modules:\n\n`sudo apache2ctl -M`\n"
 },
 {
   "command": "ctrlaltdel",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ctrlaltdel\n\n> Utility to control what happens when CTRL+ALT+DEL is pressed.\n\n- Get current setting:\n\n`ctrlaltdel`\n\n- Set CRTL+ALT+DEL to reboot immediately, without any preparation:\n\n`sudo ctrlaltdel hard`\n\n- Set CTRL+ALT+DEL to reboot \"normally\", giving processes a chance to exit first (send SIGINT to PID1):\n\n`sudo ctrlaltdel soft`\n"
 },
 {
   "command": "prt-get",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# prt-get\n\n> The CRUX package manager.\n\n- Install a package:\n\n`prt-get install {{package_name}}`\n\n- Install a package with dependency handling:\n\n`prt-get depinst {{package_name}}`\n\n- Update a package manually:\n\n`prt-get upgrade {{package_name}}`\n\n- Remove a package:\n\n`prt-get remove {{package_name}}`\n\n- Upgrade the system from the local ports tree:\n\n`prt-get sysup`\n\n- Search the ports tree:\n\n`prt-get search {{package_name}}`\n\n- Search for a file in a package:\n\n`prt-get fsearch {{file}}`\n"
 },
 {
   "command": "toilet",
   "doc_url": "http://caca.zoy.org/wiki/toilet",
   "doc_text": "\n\n\n      toilet – Caca Labs\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n         \n      \n\n\n\n\n\n\nSearch:\n\n\n\n\n\n\nLoginHelp/GuideAbout TracPreferences\n\n\n\n\n\nHomeForumsDocTimelineBug ReportsBrowse SourceSearch\n\n\n\n\nwiki:toilet\nTweet\n\nContext Navigation\n\nStart PageIndexHistory\n\n\n\n\n\n\n\n\nTOIlet\n\nThe TOIlet project attempts to create a free replacement for the ​FIGlet utility. TOIlet stands for “The Other Implementation’s letters”, coined after FIGlet’s “Frank, Ian and Glen’s letters”.\n\n\nTOIlet is in its very early development phase. It uses the powerful libcaca library to achieve various text-based effects. TOIlet implements or plans to implement the following features:\n\nThe ability to load FIGlet fonts\nSupport for Unicode input and output\nSupport for colour fonts\nSupport for colour output\nSupport for various output formats: HTML, IRC, ANSI...\n\nTOIlet also aims for full FIGlet compatibility. It is currently able to load FIGlet fonts and perform horizontal smushing.\n\nLive test\n\nThe live test is currently disabled.\n\nDownload\n\nThe latest TOIlet version is toilet-0.3.tar.gz (6 Apr 2012).\n\nScreenshot\n\n\n\nDevelopment\n\nDevelopment happens in a centralised Subversion repository:\n\n​svn://svn.zoy.org/caca/toilet/trunk\nassociated web interface\n\nThere is also a Git repository that mirrors the central one:\n\nusing the Git protocol: ​git://git.zoy.org/toilet.git\nusing HTTP: http://caca.zoy.org/git/toilet.git\n\nIf you want to discuss toilet or report bugs, you can write to me at ​sam@hocevar.net or join #libcaca on irc.freenode.net.\n\n\n\nLast modified 8 years ago\nLast modified on Apr 6, 2012, 11:05:20 PM\n\n\n\nAttachments (3)\n\n\n\ntoilet-0.1.tar.gz​ (419.4 KB) - added by Sam Hocevar 12 years ago.\n            \ntoilet-0.2.tar.gz​ (842.3 KB) - added by Sam Hocevar 11 years ago.\n            \ntoilet-0.3.tar.gz​ (844.6 KB) - added by Sam Hocevar 8 years ago.\n            \n\n\n\n\n\nDownload in other formats:\n\n\nPlain Text\n\n\n\n\n\n\nPowered by Trac 1.2.2\n        By Edgewall Software.\nVisit the Caca Labs athttp://caca.zoy.org/\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# toilet\n\n> A tool to display ASCII-art fonts.\n> More information: <http://caca.zoy.org/wiki/toilet>.\n\n- Generate ASCII art for a given text:\n\n`toilet {{input_text}}`\n\n- Generate ASCII art using a custom font file:\n\n`toilet {{input_text}} -f {{font_filename}}`\n\n- Generate ASCII art using a filter:\n\n`toilet {{input_text}} --filter {{filter_name}}`\n\n- Show available toilet filters:\n\n`toilet --filter list `\n"
 },
 {
   "command": "lftp",
   "doc_url": "https://linux.die.net/man/1/lftp",
   "doc_text": "\n\nlftp(1): Sophisticated file transfer program - Linux man page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlftp(1) - Linux man page\nName\nlftp - Sophisticated file transfer program\nSyntax\nlftp [-d] [-e cmd] [-p port] [-u user[,pass]] [site]\nlftp -f script_file\nlftp -c commands\nlftp --version\nlftp --help\nVersion\nThis man page documents lftp version 4.0.9.\nDescription\n\n\n\n\n\nlftp is a file transfer program that allows sophisticated ftp, http and other connections to other hosts. If site is specified then lftp will\nconnect to that site otherwise a connection has to be established with the open command.\nlftp can handle several file access methods - ftp, ftps, http, https, hftp, fish, sftp and file (https and ftps are only available when lftp is\ncompiled with GNU TLS or OpenSSL library). You can specify the method to use in 'open URL' command, e.g. 'open http://www.us.kernel.org/pub/linux'. hftp is\nftp-over-http-proxy protocol. It can be used automatically instead of ftp if ftp:proxy is set to 'http://proxy[:port]'. Fish is a protocol working over an ssh\nconnection to a unix account. SFtp is a protocol implemented in ssh2 as sftp subsystem.\nBesides FTP-like protocols, lftp has support for BitTorrent protocol as 'torrent' command. Seeding is also supported.\nEvery operation in lftp is reliable, that is any not fatal error is ignored and the operation is repeated. So if downloading breaks, it will be\nrestarted from the point automatically. Even if ftp server does not support REST command, lftp will try to retrieve the file from the very beginning\nuntil the file is transferred completely.\nlftp has shell-like command syntax allowing you to launch several commands in parallel in background (&). It is also possible to group commands\nwithin () and execute them in background. All background jobs are executed in the same single process. You can bring a foreground job to background with ^Z\n(c-z) and back with command 'wait' (or 'fg' which is alias to 'wait'). To list running jobs, use command 'jobs'. Some commands allow redirecting their output\n(cat, ls, ...) to file or via pipe to external command. Commands can be executed conditionally based on termination status of previous command (&&,\n||).\nIf you exit lftp when some jobs are not finished yet, lftp will move itself to nohup mode in background. The same happens when you have a real\nmodem hangup or when you close an xterm.\nlftp has builtin mirror which can download or update a whole directory tree. There is also reverse mirror (mirror -R) which uploads or updates a\ndirectory tree on server. Mirror can also synchronize directories between two remote servers, using FXP if available.\nThere is command 'at' to launch a job at specified time in current context, command 'queue' to queue commands for sequential execution for current server,\nand much more.\nOn startup, lftp executes /etc/lftp.conf and then ~/.lftprc and ~/.lftp/rc. You can place aliases and 'set' commands there. Some\npeople prefer to see full protocol debug, use 'debug' to turn the debug on. Use 'debug 3' to see only greeting messages and error messages.\nlftp has a number of settable variables. You can use 'set -a' to see all variables and their values or 'set -d' to see list of defaults. Variable\nnames can be abbreviated and prefix can be omitted unless the rest becomes ambiguous.\nIf lftp was compiled with OpenSSL (configure --with-openssl), then it includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit.\n(http://www.openssl.org/)\n\nCommands\n\n! shell command\nLaunch shell or shell command.\n\n!ls\nTo do a directory listing of the local host.\nalias [name [value]]\nDefine or undefine alias name. If value is omitted, the alias is undefined, else it takes the value value. If no argument is given the\ncurrent aliases are listed.\n\nalias dir ls -lF\nalias less zmore\nanon\nSets the user to anonymous. This is the default.\nat time [ -- command ]\nWait until the given time and execute given (optional) command. See also at(1).\nbookmark [subcommand]\nThe bookmark command controls bookmarks.\nadd <name> [<loc>]\n\nadd current place or given location\n\nto bookmarks and bind to given name\n\ndel <name>\n\nremove bookmark with name\n\nedit\n\nstart editor on bookmarks file\n\nimport <type>\n\nimport foreign bookmarks\n\nlist\n\nlist bookmarks (default)\ncache [subcommand]\nThe cache command controls local memory cache. The following subcommands are recognized:\nstat\n\nprint cache status (default)\n\non|off\n\nturn on/off caching\n\nflush\n\nflush cache\n\nsize lim\nset memory limit, -1 means unlimited\n\nexpire Nx\nset cache expiration time to N seconds (x=s)\n\nminutes (x=m) hours (x=h) or days (x=d)\ncat files\ncat outputs the remote file(s) to stdout. (See also more, zcat and zmore)\ncd rdir\nChange current remote directory. The previous remote directory is stored as '-'. You can do 'cd -' to change the directory back. The previous directory for\neach site is also stored on disk, so you can do 'open site; cd -' even after lftp restart.\nchmod mode files\nChange permission mask on remote files. The mode must be an octal number.\nclose [-a]\nClose idle connections. By default only with the current server, use -a to close all idle connections.\ncls [OPTS] files...\n'cls' tries to retrieve information about specified files or directories and outputs the information according to format options. The difference between\n'ls' and 'cls' is that 'ls' requests the server to format file listing, and 'cls' formats it itself, after retrieving all the needed information. See 'help\ncls' for options.\ncommand cmd args...\nexecute given command ignoring aliases.\ndebug [-o file] level|off\nSwitch debugging to level or turn it off. Use -o to redirect the debug output to a file.\necho [-n] string\nguess what it does.\neval [-f format ] args...\nwithout -f it just executes given arguments as a command. With -f, arguments are transformed into a new command. The format can contain plain text and\nplaceholders $0...$9 and $@, corresponding to the arguments.\nexit [bg] [top] [kill] [code]\nexit will exit from lftp or move to background if there are active jobs. If no job is active, code is passed to operating system as lftp's\ntermination status. If code is omitted, the exit code of last command is used.\n'exit bg' forces moving to background when cmd:move-background is false. 'exit top' makes top level 'shell' (internal lftp command executor) terminate.\n'exit kill' kills all numbered jobs before exiting. The options can be combined, e.g. 'at 08:00 -- exit top kill &' kills all jobs and makes lftp exit at\nspecified time.\nfg\nAlias for 'wait'.\nfind [directory]\nList files in the directory (current directory by default) recursively. This can help with servers lacking ls -R support. You can redirect output of this\ncommand.\nftpcopy\nObsolete. Use one of the following instead:\n\nget ftp://... -o ftp://...\nget -O ftp://... file1 file2...\nput ftp://...\nmput ftp://.../*\nmget -O ftp://... ftp://.../*\nor other combinations to get FXP transfer (directly between two ftp servers). lftp would fallback to plain copy (via client) if FXP transfer cannot be\ninitiated or ftp:use-fxp is false.\nget [-E] [-a] [-c] [-O base] rfile [-o lfile] ...\nRetrieve the remote file rfile and store it as the local file lfile. If -o is omitted, the file is stored to local file named as base name of\nrfile. You can get multiple files by specifying multiple instances of rfile (and -o lfile). Does not expand wildcards, use mget for\nthat.\n-c\n\ncontinue, reget\n\n-E\n\ndelete source files after successful transfer\n\n-a\n\nuse ascii mode (binary is the default)\n\n-O <base>\n\nspecifies base directory or URL where files should be placed\nExamples:\n\nget README\nget README -o debian.README\nget README README.mirrors\nget README -o debian.README README.mirrors -o debian.mirrors\nget README -o ftp://some.host.org/debian.README\nget README -o ftp://some.host.org/debian-dir/ (end slash is important)\nget1 [OPTS] rfile\nTransfer a single file. Options:\n-o <lfile>\n\ndestination file name (default - basename of rfile)\n\n-c\n\ncontinue, reget\n\n-E\n\ndelete source files after successful transfer\n\n-a\n\nuse ascii mode (binary is the default)\n--source-region=<from-to>\ntransfer specified region of source file\n--target-position=<pos>\nposition in target file to write data at\nglob [-d] [-a] [-f] command patterns\nGlob given patterns containing metacharacters and pass result to given command. E.g. ''glob echo *''.\n-f\n\nplain files (default)\n\n-d\n\ndirectories\n\n-a\n\nall types\nhelp [cmd]\nPrint help for cmd or if no cmd was specified print a list of available commands.\njobs [-v]\nList running jobs. -v means verbose, several -v can be specified.\nkill all|job_no\nDelete specified job with job_no or all jobs. (For job_no see jobs)\nlcd ldir\nChange current local directory ldir. The previous local directory is stored as '-'. You can do 'lcd -' to change the directory back.\n\nlpwd\nPrint current working directory on local machine.\nls params\nList remote files. You can redirect output of this command to file or via pipe to external command. By default, ls output is cached, to see new listing use\nrels or cache flush.\nmget [-c] [-d] [-a] [-E] [-O base] files\nGets selected files with expanded wildcards.\n-c\n\ncontinue, reget.\n\n-d\n\ncreate directories the same as file names and get\n\nthe files into them instead of current directory.\n\n-E\n\ndelete source files after successful transfer\n\n-a\n\nuse ascii mode (binary is the default)\n\n-O <base>\n\nspecifies base directory or URL where files should be placed\nmirror [OPTS] [source [target]]\nMirror specified source directory to local target directory. If target directory ends with a slash, the source base name is appended to target directory\nname. Source and/or target can be URLs pointing to directories.\n-c, --continue\n\ncontinue a mirror job if possible\n\n-e, --delete\n\ndelete files not present at remote site\n\n--delete-first\n\ndelete old files before transferring new ones\n\n--depth-first\n\ndescend into subdirectories before transferring files\n\n-s, --allow-suid\n\nset suid/sgid bits according to remote site\n\n--allow-chown\n\ntry to set owner and group on files\n\n--ascii\n\nuse ascii mode transfers (implies --ignore-size)\n\n--ignore-time\n\nignore time when deciding whether to download\n\n--ignore-size\n\nignore size when deciding whether to download\n\n--only-missing\n\ndownload only missing files\n\n--only-existing\n\ndownload only files already existing at target\n\n-n, --only-newer\n\ndownload only newer files (-c won't work)\n\n--no-empty-dirs\n\ndon't create empty directories (implies --depth-first)\n\n-r, --no-recursion\n\ndon't go to subdirectories\n\n--no-symlinks\n\ndon't create symbolic links\n\n-p, --no-perms\n\ndon't set file permissions\n\n--no-umask\n\ndon't apply umask to file modes\n\n-R, --reverse\n\nreverse mirror (put files)\n\n-L, --dereference\n\ndownload symbolic links as files\n\n-N, --newer-than=SPEC\n\ndownload only files newer than specified time\n\n--on-change=CMD\n\nexecute the command if anything has been changed\n\n--older-than=SPEC\n\ndownload only files older than specified time\n\n--size-range=RANGE\n\ndownload only files with size in specified range\n\n-P, --parallel[=N]\n\ndownload N files in parallel\n\n--use-pget[-n=N]\n\nuse pget to transfer every single file\n\n--loop\n\nloop until no changes found\n\n-i RX, --include RX\ninclude matching files\n\n-x RX, --exclude RX\nexclude matching files\n\n-I GP, --include-glob GP\ninclude matching files\n\n-X GP, --exclude-glob GP\nexclude matching files\n\n-v, --verbose[=level]\n\nverbose operation\n\n--log=FILE\n\nwrite lftp commands being executed to FILE\n\n--script=FILE\n\nwrite lftp commands to FILE, but don't execute them\n\n--just-print, --dry-run\n\nsame as --script=-\n\n--use-cache\n\nuse cached directory listings\n\n--Remove-source-files\n\nremove files after transfer (use with caution)\n\n-a\n\nsame as --allow-chown --allow-suid --no-umask\nWhen using -R, the first directory is local and the second is remote. If the second directory is omitted, base name of first directory is used. If both\ndirectories are omitted, current local and remote directories are used. If target directory ends with a slash (except root directory) then base name of source\ndirectory is appended.\nRX is an extended regular expression, just like in egrep(1).\nGP is a glob pattern, e.g. '*.zip'.\nInclude and exclude options can be specified multiple times. It means that a file or directory would be mirrored if it matches an include and does not match\nto excludes after the include, or does not match anything and the first check is exclude. Directories are matched with a slash appended.\nNote that symbolic links are not created when uploading to remote server, because ftp protocol cannot do it. To upload files the links refer to, use 'mirror\n-RL' command (treat symbolic links as files).\nFor option --newer-than you can either specify a file or time specification like that used by at(1) command, e.g. 'now-7days' or 'week ago'. If you\nspecify a file, then modification time of that file will be used.\nVerbosity level can be selected using --verbose=level option or by several -v options, e.g. -vvv. Levels are:\n\n0 - no output (default)\n1 - print actions\n2 - +print not deleted file names (when -e is not specified)\n3 - +print directory names which are mirrored\n--only-newer turns off file size comparison and uploads/downloads only newer files even if size is different. By default older files are transferred and\nreplace newer ones.\nYou can mirror between two servers if you specify URLs instead of directories. FXP is used automatically for transfers between ftp servers, if possible.\n\nSome ftp servers hide dot-files by default (e.g. .htaccess), and show them only when LIST command is used with -a option. In such case try to use\n'set ftp:list-options -a'.\nmkdir [-p] dir(s)\nMake remote directories. If -p is used, make all components of paths.\nmodule module [ args ]\nLoad given module using dlopen(3) function. If module name does not contain a slash, it is searched in directories specified by module:path variable.\nArguments are passed to module_init function. See README.modules for technical details.\nmore files\nSame as 'cat files | more'. if PAGER is set, it is used as filter. (See also cat, zcat and zmore)\nmput [-c] [-d] [-a] [-E] [-O base] files\nUpload files with wildcard expansion. By default it uses the base name of local name as remote one. This can be changed by '-d' option.\n-c\n\ncontinue, reput\n\n-d\n\ncreate directories the same as in file names and put the\n\nfiles into them instead of current directory\n\n-E\n\ndelete source files after successful transfer (dangerous)\n\n-a\n\nuse ascii mode (binary is the default)\n\n-O <base>\n\nspecifies base directory or URL where files should be placed\nmrm file(s)\nSame as 'glob rm'. Removes specified file(s) with wildcard expansion.\nmv file1 file2\nRename file1 to file2.\nnlist [args]\nList remote file names\nopen [-e cmd] [-u user[,pass]] [-p port] host|url\nSelect an ftp server.\npget [OPTS] rfile [-o lfile]\nGets the specified file using several connections. This can speed up transfer, but loads the net and server heavily impacting other users. Use only if you\nreally have to transfer the file ASAP. Options:\n-c\n\ncontinue transfer. Requires lfile.lftp-pget-status file.\n\n-n maxconn\nset maximum number of connections (default is taken from pget:default-n setting)\nput [-E] [-a] [-c] [-O base] lfile [-o rfile]\nUpload lfile with remote name rfile. If -o omitted, the base name of lfile is used as remote name. Does not expand wildcards, use\nmput for that.\n-o <rfile>\n\nspecifies remote file name (default - basename of lfile)\n\n-c\n\ncontinue, reput\n\nit requires permission to overwrite remote files\n\n-E\n\ndelete source files after successful transfer (dangerous)\n\n-a\n\nuse ascii mode (binary is the default)\n\n-O <base>\n\nspecifies base directory or URL where files should be placed\npwd [-p]\nPrint current remote URL. Use '-p' option to show password in the URL.\nqueue [-n num ] cmd\nAdd the given command to queue for sequential execution. Each site has its own queue. '-n' adds the command before the given item in the queue. Don't try to\nqueue 'cd' or 'lcd' commands, it may confuse lftp. Instead do the cd/lcd before 'queue' command, and it will remember the place in which the command is to be\ndone. It is possible to queue up an already running job by 'queue wait <jobno>', but the job will continue execution even if it is not the first in\nqueue.\n'queue stop' will stop the queue, it will not execute any new commands, but already running jobs will continue to run. You can use 'queue stop' to create an\nempty stopped queue. 'queue start' will resume queue execution. When you exit lftp, it will start all stopped queues automatically.\n'queue' with no arguments will either create a stopped queue or print queue status.\nqueue --delete|-d [index or wildcard expression]\nDelete one or more items from the queue. If no argument is given, the last entry in the queue is deleted.\nqueue --move|-m <index or wildcard expression> [index]\nMove the given items before the given queue index, or to the end if no destination is given.\n-q\n\nBe quiet.\n\n-v\n\nBe verbose.\n\n-Q\n\nOutput in a format that can be used to re-queue.\n\nUseful with --delete.\n\n> get file &\n[1] get file\n> queue wait 1\n> queue get another_file\n> cd a_directory\n> queue get yet_another_file\nqueue -d 3\n\nDelete the third item in the queue.\n\nqueue -m 6 4\n\nMove the sixth item in the queue before the fourth.\n\nqueue -m \"get*zip\" 1\n\nMove all commands matching \"get*zip\" to the beginning\n\nof the queue. (The order of the items is preserved.)\n\nqueue -d \"get*zip\"\n\nDelete all commands matching \"get*zip\".\nquote cmd\nFor FTP - send the command uninterpreted. Use with caution - it can lead to unknown remote state and thus will cause reconnect. You cannot be sure that any\nchange of remote state because of quoted command is solid - it can be reset by reconnect at any time.\nFor HTTP - specific to HTTP action. Syntax: ''quote <command> [<args>]''. Command may be ''set-cookie'' or ''post''.\n\nopen http://www.site.net\nquote set-cookie \"variable=value; othervar=othervalue\"\nset http:post-content-type application/x-www-form-urlencoded\nquote post /cgi-bin/script.cgi \"var=value&othervar=othervalue\" > local_file\nFor FISH - send the command uninterpreted. This can be used to execute arbitrary commands on server. The command must not take input or print ### at new\nline beginning. If it does, the protocol will become out of sync.\n\nopen fish://server\nquote find -name \\*.zip\nreget rfile [-o lfile]\nSame as 'get -c'.\nrels [args]\nSame as 'ls', but ignores the cache.\nrenlist [args]\nSame as 'nlist', but ignores the cache.\nrepeat [OPTS] [[-d] delay] [command]\nRepeat specified command with a delay between iterations. Default delay is one second, default command is empty.\n-c <count>\n\nmaximum number of iterations\n\n-d <delay>\n\ndelay between iterations\n\n--while-ok\n\nstop when command exits with non-zero code\n\n--until-ok\n\nstop when command exits with zero code\n\n--weak\n\nstop when lftp moves to background.\nExamples:\n\nrepeat at tomorrow -- mirror\nrepeat 1d mirror\nreput lfile [-o rfile]\nSame as 'put -c'.\nrm [-r] [-f] files\nRemove remote files. Does not expand wildcards, use mrm for that. -r is for recursive directory remove. Be careful, if something goes wrong you can\nlose files. -f suppress error messages.\nrmdir dir(s)\nRemove remote directories.\nscache [session]\nList cached sessions or switch to specified session.\nset [var [val]]\nSet variable to given value. If the value is omitted, unset the variable. Variable name has format ''name/closure'', where closure can specify exact\napplication of the setting. See below for details. If set is called with no variable then only altered settings are listed. It can be changed by\noptions:\n-a\n\nlist all settings, including default values\n\n-d\n\nlist only default values, not necessary current ones\nsite site_cmd\nExecute site command site_cmd and output the result. You can redirect its output.\nsleep interval\nSleep given time interval and exit. Interval is in seconds by default, but can be suffixed with 'm', 'h', 'd' for minutes, hours and days respectively. See\nalso at.\nslot [name]\nSelect specified slot or list all slots allocated. A slot is a connection to a server, somewhat like a virtual console. You can create multiple slots\nconnected to different servers and switch between them. You can also use slot:name as a pseudo-URL evaluating to that slot location.\nDefault readline binding allows quick switching between slots named 0-9 using Meta-0 - Meta-9 keys (often you can use Alt instead of Meta).\n\nsource file\nsource -e command\nExecute commands recorded in file file or returned by specified external command.\n\nsource ~/.lftp/rc\nsource -e echo help\nsuspend\nStop lftp process. Note that transfers will be also stopped until you continue the process with shell's fg or bg commands.\ntorrent torrent-file [-O directory]\nStart BitTorrent process for the given torrent-file, which can be a local file or URL. Existing files are first validated. Missing pieces are\ndownloaded. Files are stored in specified directory or current working directory by default. Seeding continues until ratio reachs\ntorrent:stop-on-ratio setting or time of torrent:seed-max-time outs.\nuser user [pass]\nuser URL [pass]\nUse specified info for remote login. If you specify an URL with user name, the entered password will be cached so that future URL references can use it.\n\nversion\nPrint lftp version.\nwait [jobno]\nwait all\nWait for specified job to terminate. If jobno is omitted, wait for last backgrounded job.\n'wait all' waits for all jobs termination.\nzcat files\nSame as cat, but filter each file through zcat. (See also cat, more and zmore)\nzmore files\nSame as more, but filter each file through zcat. (See also cat, zcat and more)\n\nSettings\n\nOn startup, lftp executes ~/.lftprc and ~/.lftp/rc. You can place aliases and 'set' commands there. Some people prefer to see full protocol\ndebug, use 'debug' to turn the debug on.\nThere is also a system-wide startup file in /etc/lftp.conf. It can be in different directory, see FILES section.\nlftp has the following settable variables (you can also use 'set -a' to see all variables and their values):\nbmk:save-passwords (boolean)\nsave plain text passwords in ~/.lftp/bookmarks on 'bookmark add' command. Off by default.\ncmd:at-exit (string)\nthe commands in string are executed before lftp exits.\ncmd:csh-history (boolean)\nenables csh-like history expansion.\ncmd:default-protocol (string)\nThe value is used when 'open' is used with just host name without protocol. Default is 'ftp'.\ncmd:fail-exit (boolean)\nif true, exit when an unconditional (without || and && at begin) command fails.\ncmd:long-running (seconds)\ntime of command execution, which is considered as 'long' and a beep is done before next prompt. 0 means off.\ncmd:ls-default (string)\ndefault ls argument\ncmd:move-background (boolean)\nwhen false, lftp refuses to go to background when exiting. To force it, use 'exit bg'.\ncmd:move-background-detach (boolean)\nwhen true (default), lftp detaches itself from the control terminal when moving to background, it is not possible to attach back; when false, lftp tricks\nthe shell to move lftp to background process group and continues to run, then fg shell command brings lftp back to foreground unless it has done all jobs and\nterminated.\ncmd:prompt (string)\nThe prompt. lftp recognizes the following backslash-escaped special characters that are decoded as follows:\n\\@\ninsert @ if current user is not default\n\n\\a\nan ASCII bell character (07)\n\n\\e\nan ASCII escape character (033)\n\n\\h\nthe hostname you are connected to\n\n\\n\nnewline\n\n\\s\nthe name of the client (lftp)\n\n\\S\ncurrent slot name\n\n\\u\nthe username of the user you are logged in as\n\n\\U\nthe URL of the remote site (e.g., ftp://g437.ub.gu.se/home/james/src/lftp)\n\n\\v\nthe version of lftp (e.g., 2.0.3)\n\n\\w\nthe current working directory at the remote site\n\n\\W\nthe base name of the current working directory at the remote site\n\n\\nnn\nthe character corresponding to the octal number nnn\n\\\\\na backslash\n\n\\?\nskips next character if previous substitution was empty.\n\n\\[\nbegin a sequence of non-printing characters, which could be used to embed a terminal control sequence into the prompt\n\n\\]\nend a sequence of non-printing characters\ncmd:parallel (number)\nNumber of jobs run in parallel in non-interactive mode. For example, this may be useful for scripts with multiple 'get' commands. Note that setting this to\na value greater than 1 changes conditional execution behaviour, basically makes it inconsistent.\ncmd:queue-parallel (number)\nNumber of jobs run in parallel in a queue.\ncmd:time-style (string)\nThis setting is the default value for cls --time-style option.\ncmd:trace (boolean)\nwhen true, lftp prints the commands it executes (like sh -x).\ncache:cache-empty-listings (boolean)\nWhen false, empty listings are not cached.\ncache:enable (boolean)\nWhen false, cache is disabled.\ncache:expire (time interval)\nPositive cache entries expire in this time interval.\ncache:expire-negative (time interval)\nNegative cache entries expire in this time interval.\ncache:size (number)\nMaximum cache size. When exceeded, oldest cache entries will be removed from cache.\ncmd:remote-completion (boolean)\na boolean to control whether or not lftp uses remote completion.\ncmd:verify-host (boolean)\nif true, lftp resolves host name immediately in 'open' command. It is also possible to skip the check for a single 'open' command if '&' is given, or if\n^Z is pressed during the check.\ncmd:verify-path (boolean)\nif true, lftp checks the path given in 'cd' command. It is also possible to skip the check for a single 'cd' command if '&' is given, or if ^Z is\npressed during the check. Examples:\n\nset cmd:verify-path/hftp://* false\ncd directory &\ncmd:verify-path-cached (boolean)\nWhen false, 'cd' to a directory known from cache as existent will succeed immediately. Otherwise the verification will depend on cmd:verify-path\nsetting.\ncolor:use-color (boolean)\nwhen true, cls command and completion output colored file listings according to color:dir-colors setting.\ncolor:dir-colors (string)\nfile listing color description. By default the value of LS_COLORS environment variable is used. See dircolors(1).\ndns:SRV-query (boolean)\nquery for SRV records and use them before gethostbyname. The SRV records are only used if port is not explicitly specified. See RFC2052 for details.\ndns:cache-enable (boolean)\nenable DNS cache. If it is off, lftp resolves host name each time it reconnects.\ndns:cache-expire (time interval)\ntime to live for DNS cache entries. It has format <number><unit>+, e.g. 1d12h30m5s or just 36h. To disable expiration, set it to 'inf' or\n'never'.\ndns:cache-size (number)\nmaximum number of DNS cache entries.\ndns:fatal-timeout (time interval)\nlimit the time for DNS queries. If DNS server is unavailable too long, lftp will fail to resolve a given host name. Set to 'never' to disable.\ndns:order (list of protocol names)\nsets the order of DNS queries. Default is ''inet6 inet'' which means first look up address in inet6 family, then inet and use them in that order. To disable\ninet6 (AAAA) lookup, set this variable to ''inet''.\ndns:use-fork (boolean)\nif true, lftp will fork before resolving host address. Default is true.\ndns:max-retries (number)\nIf zero, there is no limit on the number of times lftp will try to lookup an address. If > 0, lftp will try only this number of times to look up an\naddress of each address family in dns:order.\nfile:charset (string)\nlocal character set. It is set from current locale initially.\nfish:charset (string)\nthe character set used by fish server in requests, replies and file listings. Default is empty which means the same as local.\nfish:connect-program (string)\nthe program to use for connecting to remote server. It should support '-l' option for user name, '-p' for port number. Default is 'ssh -a -x'. You can set\nit to 'rsh', for example.\nfish:shell (string)\nuse specified shell on server side. Default is /bin/sh. On some systems, /bin/sh exits when doing cd to a non-existent directory. lftp can handle that but\nit has to reconnect. Set it to /bin/bash for such systems if bash is installed.\nftp:acct (string)\nSend this string in ACCT command after login. The result is ignored. The closure for this setting has format user@host.\nftp:anon-pass (string)\nsets the password used for anonymous ftp access authentication. Default is \"-name@\", where name is the username of the user running the program.\nftp:anon-user (string)\nsets the user name used for anonymous ftp access authentication. Default is \"anonymous\".\nftp:auto-sync-mode (regex)\nif first server message matches this regex, turn on sync mode for that host.\nftp:charset (string)\nthe character set used by ftp server in requests, replies and file listings. Default is empty which means the same as local. This setting is only used when\nthe server does not support UTF8.\nftp:client (string)\nthe name of ftp client to send with CLNT command, if supported by server. If it is empty, then no CLNT command will be sent.\nftp:bind-data-socket (boolean)\nbind data socket to the interface of control connection (in passive mode). Default is true, exception is the loopback interface.\nftp:fix-pasv-address (boolean)\nif true, lftp will try to correct address returned by server for PASV command in case when server address is in public network and PASV returns an address\nfrom a private network. In this case lftp would substitute server address instead of the one returned by PASV command, port number would not be changed.\nDefault is true.\nftp:fxp-passive-source (boolean)\nif true, lftp will try to set up source ftp server in passive mode first, otherwise destination one. If first attempt fails, lftp tries to set them up the\nother way. If the other disposition fails too, lftp falls back to plain copy. See also ftp:use-fxp.\nftp:home (string)\nInitial directory. Default is empty string which means auto. Set this to '/' if you don't like the look of %2F in ftp URLs. The closure for this setting has\nformat user@host.\nftp:ignore-pasv-address (boolean)\nIf true, lftp uses control connection address instead of the one returned in PASV reply for data connection. This can be useful for broken NATs. Default is\nfalse.\nftp:list-empty-ok (boolean)\nif set to false, empty lists from LIST command will be treated as incorrect, and another method (NLST) will be used.\nftp:list-options (string)\nsets options which are always appended to LIST command. It can be useful to set this to '-a' if server does not show dot (hidden) files by default. Default\nis empty.\nftp:nop-interval (seconds)\ndelay between NOOP commands when downloading tail of a file. This is useful for ftp servers which send \"Transfer complete\" message before flushing data\ntransfer. In such cases NOOP commands can prevent connection timeout.\nftp:passive-mode (boolean)\nsets passive ftp mode. This can be useful if you are behind a firewall or a dumb masquerading router. In passive mode lftp uses PASV command, not the PORT\ncommand which is used in active mode. In passive mode lftp itself makes the data connection to the server; in active mode the server connects to lftp for data\ntransfer. Passive mode is the default.\nftp:port-ipv4 (ipv4 address)\nspecifies an IPv4 address to send with PORT command. Default is empty which means to send the address of local end of control connection.\nftp:port-range (from-to)\nallowed port range for active mode. Format is min-max, or 'full' or 'any' to indicate any port. Default is 'full'.\nftp:prefer-epsv (boolean)\nuse EPSV as preferred passive mode. Default is 'false'.\nftp:proxy (URL)\nspecifies ftp proxy to use. To disable proxy set this to empty string. Note that it is an ftp proxy which uses ftp protocol, not ftp over http. Default\nvalue is taken from environment variable ftp_proxy if it starts with ''ftp://''. If your ftp proxy requires authentication, specify user name and\npassword in the URL. If ftp:proxy starts with http:// then hftp protocol (ftp over http proxy) is used instead of ftp automatically.\nftp:proxy-auth-type (string)\nWhen set to ''joined'', lftp sends ''user@proxy_user@ftp.example.org'' as user name to proxy, and ''password@proxy_password'' as password.\nWhen set to ''joined-acct'', lftp sends ''user@ftp.example.org proxy_user'' (with space) as user name to proxy. The site password is sent as usual and the\nproxy password is expected in the following ACCT command.\nWhen set to ''open'', lftp first sends proxy user and proxy password and then ''OPEN ftp.example.org'' followed by ''USER user''. The site password is then\nsent as usual.\nWhen set to ''user'' (default), lftp first sends proxy user and proxy password and then ''user@ftp.example.org'' as user name. The site password is then\nsent as usual.\nWhen set to ''proxy-user@host'', lftp first sends ''USER proxy_user@ftp.example.org'', then proxy password. The site user and password are then sent as\nusual.\nftp:rest-list (boolean)\nallow usage of REST command before LIST command. This might be useful for large directories, but some ftp servers silently ignore REST before LIST.\nftp:rest-stor (boolean)\nif false, lftp will not try to use REST before STOR. This can be useful for some buggy servers which corrupt (fill with zeros) the file if REST followed by\nSTOR is used.\nftp:retry-530 (regex)\nRetry on server reply 530 for PASS command if text matches this regular expression. This setting should be useful to distinguish between overloaded server\n(temporary condition) and incorrect password (permanent condition).\nftp:retry-530-anonymous (regex)\nAdditional regular expression for anonymous login, like ftp:retry-530.\nftp:site-group (string)\nSend this string in SITE GROUP command after login. The result is ignored. The closure for this setting has format user@host.\nftp:skey-allow (boolean)\nallow sending skey/opie reply if server appears to support it. On by default.\nftp:skey-force (boolean)\ndo not send plain text password over the network, use skey/opie instead. If skey/opie is not available, assume failed login. Off by default.\nftp:ssl-allow (boolean)\nif true, try to negotiate SSL connection with ftp server for non-anonymous access. Default is true. This and other ssl settings are only available if lftp\nwas compiled with an ssl/tls library.\nftp:ssl-data-use-keys (boolean)\nif true, lftp loads ssl:key-file for protected data connection too. When false, it does not, and the server can match data and control connections by\nsession ID. Default is true.\nftp:ssl-force (boolean)\nif true, refuse to send password in clear when server does not support SSL. Default is false.\nftp:ssl-protect-data (boolean)\nif true, request ssl connection for data transfers. This is cpu-intensive but provides privacy. Default is false.\nftp:ssl-protect-fxp (boolean)\nif true, request ssl connection for data transfer between two ftp servers in FXP mode. CPSV or SSCN command will be used in that case. If ssl connection\nfails for some reason, lftp would try unprotected FXP transfer unless ftp:ssl-force is set for any of the two servers. Default is false.\nftp:ssl-protect-list (boolean)\nif true, request ssl connection for file list transfers. Default is true.\nftp:ssl-use-ccc (boolean)\nif true, lftp would issue CCC command after logon, thus disable ssl protection layer on control connection.\nftp:stat-interval (time interval)\ninterval between STAT commands. Default is 1 second.\nftp:sync-mode (boolean)\nif true, lftp will send one command at a time and wait for response. This might be useful if you are using a buggy ftp server or router. When it is off,\nlftp sends a pack of commands and waits for responses - it speeds up operation when round trip time is significant. Unfortunately it does not work with all ftp\nservers and some routers have troubles with it, so it is on by default.\nftp:timezone (string)\nAssume this timezone for time in listings returned by LIST command. This setting can be GMT offset [+|-]HH[:MM[:SS]] or any valid TZ value (e.g.\nEurope/Moscow or MSK-3MSD,M3.5.0,M10.5.0/3). The default is GMT. Set it to an empty value to assume local timezone specified by environment variable\nTZ.\nftp:trust-feat (string)\nWhen true, assume that FEAT returned data are correct and don't use common protocol extensions like SIZE, MDTM, REST if they are not listed. Default is\nfalse.\nftp:use-abor (boolean)\nif false, lftp does not send ABOR command but closes data connection immediately.\nftp:use-allo (boolean)\nwhen true (default), lftp sends ALLO command before uploading a file.\nftp:use-feat (boolean)\nwhen true (default), lftp uses FEAT command to determine extended features of ftp server.\nftp:use-fxp (boolean)\nif true, lftp will try to set up direct connection between two ftp servers.\nftp:use-hftp (boolean)\nwhen ftp:proxy points to an http proxy, this setting selects hftp method (GET, HEAD) when true, and CONNECT method when false. Default is true.\nftp:lang (boolean)\nthe language selected with LANG command, if supported as indicated by FEAT response. Default is empty which means server default.\nftp:use-mdtm (boolean)\nwhen true (default), lftp uses MDTM command to determine file modification time.\nftp:use-mdtm-overloaded (boolean)\nwhen true, lftp uses two argument MDTM command to set file modification time on uploaded files. Default is false.\nftp:use-site-idle (boolean)\nwhen true, lftp sends 'SITE IDLE' command with net:idle argument. Default is false.\nftp:use-site-utime (boolean)\nwhen true, lftp sends 5-argument 'SITE UTIME' command to set file modification time on uploaded files. Default is true.\nftp:use-site-utime2 (boolean)\nwhen true, lftp sends 2-argument 'SITE UTIME' command to set file modification time on uploaded files. Default is true. If 5-argument 'SITE UTIME' is also\nenabled, 2-argument command is tried first.\nftp:use-size (boolean)\nwhen true (default), lftp uses SIZE command to determine file size.\nftp:use-stat (boolean)\nif true, lftp sends STAT command in FXP mode transfer to know how much data has been transferred. See also ftp:stat-interval. Default is true.\nftp:use-stat-for-list (boolean)\nwhen true, lftp uses STAT instead of LIST command. By default '.' is used as STAT argument. Using STAT, lftp avoids creating data connection for directory\nlisting. Some servers require special options for STAT, use ftp:list-options to specify them (e.g. -la).\nftp:use-telnet-iac (boolean)\nwhen true (default), lftp uses TELNET IAC command and follows TELNET protocol as specified in RFC959. When false, it does not follow TELNET protocol and\nthus does not double 255 (0xFF, 0377) character and does not prefix ABOR and STAT commands with TELNET IP+SYNCH signal.\nftp:use-quit (boolean)\nif true, lftp sends QUIT before disconnecting from ftp server. Default is true.\nftp:verify-address (boolean)\nverify that data connection comes from the network address of control connection peer. This can possibly prevent data connection spoofing which can lead to\ndata corruption. Unfortunately, this can fail for certain ftp servers with several network interfaces, when they do not set outgoing address on data socket, so\nit is disabled by default.\nftp:verify-port (boolean)\nverify that data connection has port 20 (ftp-data) on its remote end. This can possibly prevent data connection spoofing by users of remote host.\nUnfortunately, too many windows and even unix ftp servers forget to set proper port on data connection, thus this check is off by default.\nftp:web-mode (boolean)\ndisconnect after closing data connection. This can be useful for totally broken ftp servers. Default is false.\nftps:initial-prot (string)\nspecifies initial PROT setting for FTPS connections. Should be one of: C, S, E, P, or empty. Default is empty which means unknown, so that lftp will use\nPROT command unconditionally. If PROT command turns out to be unsupported, then Clear mode would be assumed.\nhftp:cache (boolean)\nallow server/proxy side caching for ftp-over-http protocol.\nhftp:cache-control (string)\nspecify corresponding HTTP request header.\nhftp:proxy (URL)\nspecifies http proxy for ftp-over-http protocol (hftp). The protocol hftp cannot work without a http proxy, obviously. Default value is taken from\nenvironment variable ftp_proxy if it starts with ''http://'', otherwise from environment variable http_proxy. If your ftp proxy requires\nauthentication, specify user name and password in the URL.\nhftp:use-authorization (boolean)\nif set to off, lftp will send password as part of URL to the proxy. This may be required for some proxies (e.g. M-soft). Default is on, and lftp will send\npassword as part of Authorization header.\nhftp:use-head (boolean)\nif set to off, lftp will try to use 'GET' instead of 'HEAD' for hftp protocol. While this is slower, it may allow lftp to work with some proxies which don't\nunderstand or mishandle ''HEAD ftp://'' requests.\nhftp:use-mkcol (boolean)\nif set to off, lftp will try to use 'PUT' instead of 'MKCOL' to create directories with hftp protocol. Default is off.\nhftp:use-propfind (boolean)\nif set to off, lftp will not try to use 'PROPFIND' to get directory contents with hftp protocol and use 'GET' instead. Default is off.\nhftp:use-type (boolean)\nIf set to off, lftp won't try to append ';type=' to URLs passed to proxy. Some broken proxies don't handle it correctly. Default is on.\nhttp:accept, http:accept-charset, http:accept-language (string)\nspecify corresponding HTTP request headers.\nhttp:authorization (string)\nthe authorization to use by default, when no user is specified. The format is ''user:password''. Default is empty which means no authorization.\nhttp:cache (boolean)\nallow server/proxy side caching.\nhttp:cache-control (string)\nspecify corresponding HTTP request header.\nhttp:cookie (string)\nsend this cookie to server. A closure is useful here: set cookie/www.somehost.com \"param=value\"\nhttp:post-content-type (string)\nspecifies value of Content-Type http request header for POST method. Default is ''application/x-www-form-urlencoded''.\nhttp:proxy (URL)\nspecifies http proxy. It is used when lftp works over http protocol. Default value is taken from environment variable http_proxy. If your proxy\nrequires authentication, specify user name and password in the URL.\nhttp:put-method (PUT or POST)\nspecifies which http method to use on put.\nhttp:put-content-type (string)\nspecifies value of Content-Type http request header for PUT method.\nhttp:referer (string)\nspecifies value for Referer http request header. Single dot '.' expands to current directory URL. Default is '.'. Set to empty string to disable Referer\nheader.\nhttp:set-cookies (boolean)\nif true, lftp modifies http:cookie variables when Set-Cookie header is received.\nhttp:use-mkcol (boolean)\nif set to off, lftp will try to use 'PUT' instead of 'MKCOL' to create directories with http protocol. Default is on.\nhttp:use-propfind (boolean)\nif set to off, lftp will not try to use 'PROPFIND' to get directory contents with http protocol and use 'GET' instead. Default is on.\nhttp:user-agent (string)\nthe string lftp sends in User-Agent header of HTTP request.\nhttps:proxy (string)\nspecifies https proxy. Default value is taken from environment variable https_proxy.\nmirror:dereference (boolean)\nwhen true, mirror will dereference symbolic links by default. You can override it by --no-dereference option. Default if false.\nmirror:exclude-regex (regex)\nspecifies default exclusion pattern. You can override it by --include option.\nmirror:include-regex (regex)\nspecifies default inclusion pattern. It is used just after mirror:exclude-regex is applied. It is never used if mirror:exclude-regex is empty.\nmirror:order (list of patterns)\nspecifies order of file transfers. E.g. setting this to \"*.sfv *.sum\" makes mirror to transfer files matching *.sfv first, then ones matching *.sum and then\nall other files. To process directories after other files, add \"*/\" to end of pattern list.\nmirror:parallel-directories (boolean)\nif true, mirror will start processing of several directories in parallel when it is in parallel mode. Otherwise, it will transfer files from a single\ndirectory before moving to other directories.\nmirror:parallel-transfer-count (number)\nspecifies number of parallel transfers mirror is allowed to start. Default is 1. You can override it with --parallel option.\nmirror:set-permissions (boolean)\nWhen set to off, mirror won't try to copy file and directory permissions. You can override it by --perms option. Default is on.\nmirror:use-pget-n (number)\nspecifies -n option for pget command used to transfer every single file under mirror. Default is 1 which disables pget.\nmodule:path (string)\ncolon separated list of directories to look for modules. Can be initialized by environment variable LFTP_MODULE_PATH. Default is\n'PKGLIBDIR/VERSION:PKGLIBDIR'.\nnet:connection-limit (number)\nmaximum number of concurrent connections to the same site. 0 means unlimited.\nnet:connection-takeover (boolean)\nif true, foreground connections have priority over background ones and can interrupt background transfers to complete a foreground operation.\nnet:idle (time interval)\ndisconnect from server after this idle time. Default is 3 minutes.\nnet:limit-rate (bytes per second)\nlimit transfer rate on data connection. 0 means unlimited. You can specify two numbers separated by colon to limit download and upload rate\nseparately.\nnet:limit-max (bytes)\nlimit accumulating of unused limit-rate. 0 means twice of limit-rate.\nnet:limit-total-rate (bytes per second)\nlimit transfer rate of all connections in sum. 0 means unlimited. You can specify two numbers separated by colon to limit download and upload rate\nseparately. Note that sockets have receive buffers on them, this can lead to network link load higher than this rate limit just after transfer beginning. You\ncan try to set net:socket-buffer to relatively small value to avoid this.\nnet:limit-total-max (bytes)\nlimit accumulating of unused limit-total-rate. 0 means twice of limit-total-rate.\nnet:max-retries (number)\nthe maximum number of sequential retries of an operation without success. 0 means unlimited.\nnet:no-proxy (string)\ncontains comma separated list of domains for which proxy should not be used. Default is taken from environment variable no_proxy.\nnet:persist-retries (number)\nignore this number of hard errors. Useful to login to buggy ftp servers which reply 5xx when there is too many users.\nnet:reconnect-interval-base (seconds)\nsets the base minimal time between reconnects. Actual interval depends on net:reconnect-interval-multiplier and number of attempts to perform an\noperation.\nnet:reconnect-interval-max (seconds)\nsets maximum reconnect interval. When current interval after multiplication by net:reconnect-interval-multiplier reachs this value (or exceeds it), it is\nreset back to net:reconnect-interval-base.\nnet:reconnect-interval-multiplier (real number)\nsets multiplier by which base interval is multiplied each time new attempt to perform an operation fails. When the interval reachs maximum, it is reset to\nbase value. See net:reconnect-interval-base and net:reconnect-interval-max.\nnet:socket-bind-ipv4 (ipv4 address)\nbind all IPv4 sockets to specified address. This can be useful to select a specific network interface to use. Default is empty which means not to bind IPv4\nsockets, operating system will choose an address automatically using routing table.\nnet:socket-bind-ipv6 (ipv6 address)\nthe same for IPv6 sockets.\nnet:socket-buffer (bytes)\nuse given size for SO_SNDBUF and SO_RCVBUF socket options. 0 means system default.\nnet:socket-maxseg (bytes)\nuse given size for TCP_MAXSEG socket option. Not all operating systems support this option, but linux does.\nnet:timeout (time interval)\nsets the network protocol timeout.\npget:default-n (number)\ndefault number of chunks to split the file to in pget.\npget:save-status (time interval)\nsave pget transfer status this often. Set to 'never' to disable saving of the status file. The status is saved to a file with suffix\n.lftp-pget-status.\nsftp:charset (string)\nthe character set used by sftp server in file names and file listings. Default is empty which means the same as local. This setting is only used for sftp\nprotocol version prior to 4. Version 4 and later always use UTF-8.\nsftp:connect-program (string)\nthe program to use for connecting to remote server. It should support '-l' option for user name, '-p' for port number. Default is 'ssh -a -x'. You can set\nit to 'rsh', for example.\nsftp:max-packets-in-flight (number)\nThe maximum number of unreplied packets in flight. If round trip time is significant, you should increase this and size-read/size-write. Default is\n16.\nsftp:protocol-version (number)\nThe protocol number to negotiate. Default is 4. The actual protocol version used depends on server.\nsftp:server-program (string)\nThe server program implementing SFTP protocol. If it does not contain a slash '/', it is considered a ssh2 subsystem and -s option is used when starting\nconnect-program. Default is 'sftp'. You can use rsh as transport level protocol like this:\n\nset sftp:connect-program rsh\nset sftp:server-program /usr/libexec/openssh/sftp-server\nSimilarly you can run sftp over ssh1.\nsftp:size-read (number)\nBlock size for reading. Default is 0x8000.\nsftp:size-write (number)\nBlock size for writing. Default is 0x8000.\nssl:ca-file (path to file)\nuse specified file as Certificate Authority certificate.\nssl:ca-path (path to directory)\nuse specified directory as Certificate Authority certificate repository (OpenSSL only).\nssl:check-hostname (boolean)\nwhen true, lftp checks if the host name used to connect to the server corresponds to the host name in its certificate.\nssl:crl-file (path to file)\nuse specified file as Certificate Revocation List certificate.\nssl:crl-path (path to directory)\nuse specified directory as Certificate Revocation List certificate repository (OpenSSL only).\nssl:key-file (path to file)\nuse specified file as your private key.\nssl:cert-file (path to file)\nuse specified file as your certificate.\nssl:verify-certificate (boolean)\nif set to yes, then verify server's certificate to be signed by a known Certificate Authority and not be on Certificate Revocation List.\ntorrent:ip (ipv4 address)\nIP address for the tracker. Specify it if you are using an http proxy.\ntorrent:max-peers (number)\nmaximum number of peers for a torrent. Least used peers are removed to maintain this limit.\ntorrent:port-range (from-to)\nport range to accept connections on. A single port is selected when a torrent starts.\ntorrent:seed-max-time (time interval)\nmaximum seed time. After this period of time a complete torrent shuts down independently of ratio. It can be set to infinity if needed.\ntorrent:seed-min-peers (number)\nminimum number of peers when the torrent is complete. If there are less, new peers are actively searched for.\ntorrent:stop-on-ratio (real number)\ntorrent stops when it's complete and ratio reached this number.\nxfer:clobber (boolean)\nif this setting is off, get commands will not overwrite existing files and generate an error instead.\nxfer:destination-directory (path or URL to directory)\nThis setting is used as default -O option for get and mget commands. Default is empty, which means current directory (no -O option).\nxfer:full-disk-fatal (boolean)\nwhen true, lftp aborts a thansfer if it cannot write target file because of full disk or quota; when false, lftp waits for disk space to be freed.\nxfer:eta-period (seconds)\nthe period over which weighted average rate is calculated to produce ETA.\nxfer:eta-terse (boolean)\nshow terse ETA (only high order parts). Default is true.\nxfer:log (boolean)\nwhen true, lftp logs transfers to ~/.lftp/transfer_log.\nxfer:max-redirections (number)\nmaximum number of redirections. This can be useful for downloading over HTTP. 0 prohibits redirections.\nxfer:rate-period (seconds)\nthe period over which weighted average rate is calculated to be shown.\nThe name of a variable can be abbreviated unless it becomes ambiguous. The prefix before ':' can be omitted too. You can set one variable several times for\ndifferent closures, and thus you can get a particular settings for particular state. The closure is to be specified after variable name separated with slash\n'/'.\nThe closure for 'dns:', 'net:', 'ftp:', 'http:', 'hftp:' domain variables is currently just the host name as you specify it in the 'open' command (with some\nexceptions where closure is meaningless, e.g. dns:cache-size). For some 'cmd:' domain variables the closure is current URL without path. For other variables it\nis not currently used. See examples in the sample lftp.conf.\nCertain commands and settings take a time interval parameter. It has the format Nx[Nx...], where N is time amount (floating point) and x is time unit: d -\ndays, h - hours, m - minutes, s - seconds. Default unit is second. E.g. 5h30m or 5.5h. Also the interval can be 'infinity', 'inf', 'never', 'forever' - it\nmeans infinite interval. E.g. 'sleep forever' or 'set dns:cache-expire never'.\nBoolean settings can be one of (true, on, yes, 1, +) for a True value or one of (false, off, no, 0, -) for a False value.\nInteger settings can have a suffix: k - kibi, m - mebi, g - gigi, etc. They can also have a prefix: 0 - octal, 0x - hexadecimal.\n\nFTP asynchronous mode (pipelining)\n\nLftp can speed up ftp operations by sending several commands at once and then checking all the responses. See ftp:sync-mode variable. Sometimes this\ndoes not work, thus synchronous mode is the default. You can try to turn synchronous mode off and see if it works for you. It is known that some network\nsoftware dealing with address translation works incorrectly in the case of several FTP commands in one network packet.\nRFC959 says: ''The user-process sending another command before the completion reply would be in violation of protocol; but server-FTP processes should queue\nany commands that arrive while a preceding command is in progress''. Also, RFC1123 says: ''Implementors MUST NOT assume any correspondence between READ\nboundaries on the control connection and the Telnet EOL sequences (CR LF).'' and ''a single READ from the control connection may include more than one FTP\ncommand''.\nSo it must be safe to send several commands at once, which speeds up operation a lot and seems to work with all Unix and VMS based ftp servers.\nUnfortunately, windows based servers often cannot handle several commands in one packet, and so cannot some broken routers.\n\nOptions\n\n-d\nSwitch on debugging mode\n-e commands\nExecute given commands and don't exit.\n-p port\nUse the given port to connect\n-u user[,pass]\nUse the given username and password to connect\n-f script_file\nExecute commands in the file and exit\n-c commands\nExecute the given commands and exit. Commands can be separated with a semicolon, '&&' or '||'.\n\nEnvironment Variables\nThe following environment variables are processed by lftp:\n\nHOME\nUsed for (local) tilde ('~') expansion\n\nSHELL\nUsed by the ! command to determine the shell to run.\n\nPAGER\nThis should be the name of the pager to use. It's used by the more and zmore commands.\nhttp_proxy, https_proxy\nUsed to set initial http:proxy, hftp:proxy and https:proxy variables.\nftp_proxy\nUsed to set initial ftp:proxy or hftp:proxy variables, depending on URL protocol used in this environment variable.\nno_proxy\nUsed to set initial net:no-proxy variable.\nLFTP_MODULE_PATH\nUsed to set initial module:path variable.\nLFTP_HOME\nUsed to locate the directory that stores user-specific configuration files. If unset, ~/.lftp will be used.\nLS_COLORS\nused to set initial color:dir-colors variable.\n\nFiles\n/etc/lftp.conf\n\nsystem-wide startup file. Actual location depends on --sysconfdir configure option. It is /etc when prefix is /usr, /usr/local/etc by\ndefault.\n~/.lftp/rc, ~/.lftprc\nThese files are executed on lftp startup after /etc/lftp.conf.\n~/.lftp/log\nThe file things are logged to when lftp moves into the background in nohup mode.\n~/.lftp/transfer_log\nThe file transfers are logged to when xfer:log setting is set to 'yes'.\n~/.lftp/bookmarks\nThe file is used to store lftp's bookmarks. See the bookmark command.\n~/.lftp/cwd_history\nThe file is used to store last working directories for each site visited.\n~/.netrc\nThe file is consulted to get default login and password to ftp server. Passwords are also searched here if an URL with user name but with no password is\nused.\n\nSee Also\nftpd(8), ftp(1)\nRFC854 (telnet), RFC959 (ftp), RFC1123, RFC1945 (http/1.0), RFC2052 (SRV RR), RFC2228 (ftp security extensions), RFC2389 (ftp FEAT), RFC2428 (ftp/ipv6),\nRFC2518 (WebDAV), RFC2616 (http/1.1), RFC2617 (http/1.1 authentication), RFC2640 (ftp i18n), RFC4217 (ftp over ssl).\nhttp://www.ietf.org/internet-drafts/draft-ietf-ftpext-mlst-16.txt (ftp extensions over RFC959),\nhttp://www.ietf.org/internet-drafts/draft-ietf-secsh-filexfer-10.txt (sftp).\nhttp://wiki.theory.org/BitTorrentSpecification\nAuthor\nAlexander V. Lukyanov\nlav@yars.free.net\nAcknowledgments\nThis manual page was originally written by Christoph Lameter <clameter@debian.org>, for the Debian GNU/Linux system. The page was improved and updated\nlater by Nicolas Lichtmaier <nick@Feedback.com.ar>, James Troup <J.J.Troup@comp.brad.ac.uk> and Alexander V. Lukyanov\n<lav@yars.free.net>.\n\n\nReferenced By\nlftp.conf(5),\nlftpget(1)\n\n\n\n\n\n\n\n\nSite Search\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nlinux docs\nlinux man pages\npage load time\n\n\nToys\nworld sunlight\nmoon phase\ntrace explorer\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# lftp\n\n> Sophisticated file transfer program.\n> More information: <https://linux.die.net/man/1/lftp>.\n\n- Connect to an FTP server:\n\n`lftp {{ftp.example.com}}`\n\n- Download multiple files (glob expression):\n\n`mget {{path/to/*.png}}`\n\n- Upload multiple files (glob expression):\n\n`mput {{path/to/*.zip}}`\n\n- Delete multiple files on the remote server:\n\n`mrm {{path/to/*.txt}}`\n\n- Rename a file on the remote server:\n\n`mv {{original_filename}} {{new_filename}}`\n\n- Download or update an entire directory:\n\n`mirror {{path/to/remote_dir}} {{path/to/local_output_dir}}`\n\n- Upload or update an entire directory:\n\n`mirror -R {{path/to/local_dir}} {{path/to/remote_output_dir}}`\n"
 },
 {
   "command": "brew",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "BREW(1) \t\t\t     brew\t\t\t       BREW(1)\n\n\n\nNAME\n       brew - The Missing Package Manager for macOS\n\nSYNOPSIS\n       brew --version\n       brew command [--verbose|-v] [options] [formula] ...\n\nDESCRIPTION\n       Homebrew is the easiest and most flexible way to install the UNIX tools\n       Apple didn't include with macOS.\n\nESSENTIAL COMMANDS\n       For the full command list, see the COMMANDS section.\n\n       With --verbose or --debug, many commands print extra debugging informa-\n       tion. Note that these options should only appear after a command.\n\n   install formula:\n       Install formula.\n\n       formula is usually the name of the formula to install, but it has other\n       syntaxes which are listed in the SPECIFYING FORMULAE section.\n\n   uninstall formula:\n       Uninstall formula.\n\n   list:\n       List all installed formulae.\n\n   search (text|/text/):\n       Perform a substring search of cask tokens and formula names  for  text.\n       If  text  is flanked by slashes, it is interpreted as a regular expres-\n       sion. The search for text is extended online to homebrew/core and home-\n       brew/cask.  If no search term is provided, all locally available formu-\n       lae are listed.\n\nCOMMANDS\n   analytics [subcommand]\n       Control Homebrew's anonymous aggregate user behaviour  analytics.  Read\n       more at https://docs.brew.sh/Analytics.\n\n       brew analytics [state]\n\t   Display the current state of Homebrew's analytics.\n\n       brew analytics [on|off]\n\t   Turn Homebrew's analytics on or off respectively.\n\n       brew analytics regenerate-uuid\n\t   Regenerate the UUID used for Homebrew's analytics.\n\n   cask command [options] [cask]\n       Homebrew  Cask  provides a friendly CLI workflow for the administration\n       of macOS applications distributed as binaries.\n\n       Commands:\n\n       o   --cache\n\t   Display the file used to cache a cask\n\n       o   audit\n\t   Check cask for Homebrew coding style violations\n\n       o   cat\n\t   Dump raw source of a cask to the standard output\n\n       o   create\n\t   Creates the given cask and opens it in an editor\n\n       o   doctor\n\t   Checks for configuration issues\n\n       o   edit\n\t   Open the given cask for editing\n\n       o   fetch\n\t   Downloads remote application files to local cache\n\n       o   help\n\t   Print help for cask commands\n\n       o   home\n\t   Opens the homepage of the given cask\n\n       o   info\n\t   Displays information about the given cask\n\n       o   install\n\t   Installs the given cask\n\n       o   list\n\t   Lists installed casks or the casks provided in the arguments\n\n       o   outdated\n\t   List the outdated installed casks\n\n       o   reinstall\n\t   Reinstalls the given cask\n\n       o   style\n\t   Checks style of the given cask using RuboCop\n\n       o   uninstall\n\t   Uninstalls the given cask\n\n       o   upgrade\n\t   Upgrades all outdated casks or the specified casks\n\n       o   zap\n\t   Zaps all files associated with the given cask\n\n\n\n       See also: man brew\n\n       --appdir\n\t      Target location for Applications. Default: /Applications\n\n       --colorpickerdir\n\t      Target location for Color Pickers. Default: ~/Library/ColorPick-\n\t      ers\n\n       --prefpanedir\n\t      Target location for Preference Panes. Default: ~/Library/Prefer-\n\t      encePanes\n\n       --qlplugindir\n\t      Target location for QuickLook Plugins. Default: ~/Library/Quick-\n\t      Look\n\n       --mdimporterdir\n\t      Target  location for Spotlight Plugins. Default: ~/Library/Spot-\n\t      light\n\n       --dictionarydir\n\t      Target location for Dictionaries. Default:  ~/Library/Dictionar-\n\t      ies\n\n       --fontdir\n\t      Target location for Fonts. Default: ~/Library/Fonts\n\n       --servicedir\n\t      Target location for Services. Default: ~/Library/Services\n\n       --input_methoddir\n\t      Target  location\tfor  Input  Methods.  Default: ~/Library/Input\n\t      Methods\n\n       --internet_plugindir\n\t      Target location for Internet Plugins. Default:  ~/Library/Inter-\n\t      net Plug-Ins\n\n       --audio_unit_plugindir\n\t      Target\tlocation    for    Audio    Unit   Plugins.   Default:\n\t      ~/Library/Audio/Plug-Ins/Components\n\n       --vst_plugindir\n\t      Target\t location     for      VST\tPlugins.      Default:\n\t      ~/Library/Audio/Plug-Ins/VST\n\n       --vst3_plugindir\n\t      Target\t  location\tfor\tVST3\t Plugins.     Default:\n\t      ~/Library/Audio/Plug-Ins/VST3\n\n       --screen_saverdir\n\t      Target location for  Screen  Savers.  Default:  ~/Library/Screen\n\t      Savers\n\n       --language\n\t      Set language of the Cask to install. The first matching language\n\t      is used, otherwise the default language on the Cask. The default\n\t      value is the language of your system\n\n   cleanup [options] [formula|cask]\n       Remove  stale  lock  files  and outdated downloads for all formulae and\n       casks, and remove old versions of installed formulae. If arguments  are\n       specified,  only  do this for the given formulae and casks. Removes all\n       downloads more than 120 days old.  This\tcan  be  adjusted  with  HOME-\n       BREW_CLEANUP_MAX_AGE_DAYS.\n\n       --prune\n\t      Remove all cache files older than specified days.\n\n       -n, --dry-run\n\t      Show what would be removed, but do not actually remove anything.\n\n       -s     Scrub the cache, including downloads for even  the  latest  ver-\n\t      sions.  Note  downloads for any installed formulae or casks will\n\t      still not be deleted. If you want to delete those  too:  rm  -rf\n\t      \"$(brew --cache)\"\n\n       --prune-prefix\n\t      Only  prune  the\tsymlinks  and  directories from the prefix and\n\t      remove no other files.\n\n   commands [options]\n       Show lists of built-in and external commands.\n\n       -q, --quiet\n\t      List only the names of commands without category headers.\n\n       --include-aliases\n\t      Include aliases of internal commands.\n\n   config\n       Show Homebrew and system configuration info useful  for\tdebugging.  If\n       you  file  a  bug report, you will be required to provide this informa-\n       tion.\n\n   deps [options] [formula]\n       Show dependencies for formula. Additional options specific  to  formula\n       may  be appended to the command. When given multiple formula arguments,\n       show the intersection of dependencies for each formula.\n\n       -n     Sort dependencies in topological order.\n\n       --1    Only show dependencies one level down, instead of recursing.\n\n       --union\n\t      Show the union of dependencies for multiple formula, instead  of\n\t      the intersection.\n\n       --full-name\n\t      List dependencies by their full name.\n\n       --include-build\n\t      Include :build dependencies for formula.\n\n       --include-optional\n\t      Include :optional dependencies for formula.\n\n       --include-test\n\t      Include :test dependencies for formula (non-recursive).\n\n       --skip-recommended\n\t      Skip :recommended dependencies for formula.\n\n       --include-requirements\n\t      Include requirements in addition to dependencies for formula.\n\n       --tree Show  dependencies  as a tree. When given multiple formula argu-\n\t      ments, show individual trees for each formula.\n\n       --annotate\n\t      Mark any build, test, optional, or recommended  dependencies  as\n\t      such in the output.\n\n       --installed\n\t      List  dependencies for formulae that are currently installed. If\n\t      formula is specified, list only its dependencies that  are  cur-\n\t      rently installed.\n\n       --all  List dependencies for all available formulae.\n\n       --for-each\n\t      Switch  into  the  mode  used by the --all option, but only list\n\t      dependencies for each provided formula, one  formula  per  line.\n\t      This is used for debugging the --installed/--all display mode.\n\n   desc [options] (text|/text/|formula)\n       Display\tformula's  name and one-line description. Formula descriptions\n       are cached; the cache is created  on  the  first  search,  making  that\n       search slower than subsequent ones.\n\n       -s, --search\n\t      Search  both names and descriptions for text. If text is flanked\n\t      by slashes, it is interpreted as a regular expression.\n\n       -n, --name\n\t      Search just names for text. If text is flanked by slashes, it is\n\t      interpreted as a regular expression.\n\n       -d, --description\n\t      Search  just  descriptions  for  text.  If  text\tis  flanked by\n\t      slashes, it is interpreted as a regular expression.\n\n   doctor [options]\n       Check your system for potential problems. Will  exit  with  a  non-zero\n       status  if  any\tpotential  problems  are found. Please note that these\n       warnings are just used to help the Homebrew maintainers with  debugging\n       if  you\tfile  an  issue. If everything you use Homebrew for is working\n       fine: please don't worry or file an issue; just ignore this.\n\n       --list-checks\n\t      List all audit methods, which can be run\tindividually  if  pro-\n\t      vided as arguments.\n\n       -D, --audit-debug\n\t      Enable debugging and profiling of audit methods.\n\n   fetch [options] formula\n       Download  a  bottle  (if available) or source packages for formula. For\n       tarballs, also print SHA-256 checksums.\n\n       --HEAD Fetch HEAD version instead of stable version.\n\n       --devel\n\t      Fetch development version instead of stable version.\n\n       -f, --force\n\t      Remove a previously cached version and re-fetch.\n\n       -v, --verbose\n\t      Do a verbose VCS checkout, if the URL represents a VCS. This  is\n\t      useful for seeing if an existing VCS cache has been updated.\n\n       --retry\n\t      Retry  if  downloading fails or re-download if the checksum of a\n\t      previously cached version no longer matches.\n\n       --deps Also download dependencies for any listed formula.\n\n       -s, --build-from-source\n\t      Download source packages rather than a bottle.\n\n       --build-bottle\n\t      Download source packages (for eventual bottling) rather  than  a\n\t      bottle.\n\n       --force-bottle\n\t      Download a bottle if it exists for the current or newest version\n\t      of macOS, even if it would not be used during installation.\n\n   gist-logs [options] formula\n       Upload logs for a failed build of formula to a new  Gist.  Presents  an\n       error message if no logs are found.\n\n       --with-hostname\n\t      Include the hostname in the Gist.\n\n       -n, --new-issue\n\t      Automatically  create  a\tnew  issue  in\tthe appropriate GitHub\n\t      repository after creating the Gist.\n\n       -p, --private\n\t      The Gist will be marked private and will not appear in  listings\n\t      but will be accessible with its link.\n\n   home [formula]\n       Open  formula's\thomepage in a browser, or open Homebrew's own homepage\n       if no formula is provided.\n\n   info [options] [formula]\n       Display brief statistics for your Homebrew installation.\n\n       If formula is provided, show summary of information about formula.\n\n       --analytics\n\t      List global Homebrew analytics data or, if specified,  installa-\n\t      tion  and  build\terror data for formula (provided neither HOME-\n\t      BREW_NO_ANALYTICS nor HOMEBREW_NO_GITHUB_API are set).\n\n       --days How many days of analytics data to retrieve. The value for  days\n\t      must be 30, 90 or 365. The default is 30.\n\n       --category\n\t      Which type of analytics data to retrieve. The value for category\n\t      must be install, install-on-request or build-error; cask-install\n\t      or os-version may be specified if formula is not. The default is\n\t      install.\n\n       --github\n\t      Open the GitHub source page for formula in a  browser.  To  view\n\t      formula history locally: brew log -p formula\n\n       --json Print  a\tJSON  representation of formula. Currently the default\n\t      and only accepted value for version is  v1.  See\tthe  docs  for\n\t      examples\tof  using the JSON output: https://docs.brew.sh/Query-\n\t      ing-Brew\n\n       --installed\n\t      Print JSON of formulae that are currently installed.\n\n       --all  Print JSON of all available formulae.\n\n       -v, --verbose\n\t      Show more verbose analytics data for formula.\n\n   install [options] formula\n       Install formula. Additional options specific to formula may be appended\n       to the command.\n\n       Unless  HOMEBREW_NO_INSTALL_CLEANUP  is\tset, brew cleanup will then be\n       run for the installed formulae or, every 30 days, for all formulae.\n\n       -d, --debug\n\t      If brewing fails, open an  interactive  debugging  session  with\n\t      access to IRB or a shell inside the temporary build directory.\n\n       --env  If  std is passed, use the standard build environment instead of\n\t      superenv. If super is passed, use superenv even if  the  formula\n\t      specifies the standard build environment.\n\n       --ignore-dependencies\n\t      An  unsupported Homebrew development flag to skip installing any\n\t      dependencies of any kind. If the dependencies  are  not  already\n\t      present,\tthe formula will have issues. If you're not developing\n\t      Homebrew, consider adjusting your PATH rather  than  using  this\n\t      flag.\n\n       --only-dependencies\n\t      Install  the  dependencies  with\tspecified  options  but do not\n\t      install the formula itself.\n\n       --cc   Attempt to compile using the specified compiler, which should be\n\t      the  name of the compiler's executable, e.g. gcc-7 for GCC 7. In\n\t      order to use  LLVM's  clang,  specify  llvm_clang.  To  use  the\n\t      Apple-provided  clang,  specify  clang.  This  option  will only\n\t      accept compilers that are provided by Homebrew or  bundled  with\n\t      macOS.  Please  do not file issues if you encounter errors while\n\t      using this option.\n\n       -s, --build-from-source\n\t      Compile formula from source even if a bottle is provided. Depen-\n\t      dencies  will still be installed from bottles if they are avail-\n\t      able.\n\n       --force-bottle\n\t      Install from a bottle if it exists for  the  current  or\tnewest\n\t      version  of  macOS,  even  if  it would not normally be used for\n\t      installation.\n\n       --include-test\n\t      Install testing dependencies required to run brew test  formula.\n\n       --HEAD If  formula  defines  it, install the HEAD version, aka. master,\n\t      trunk, unstable.\n\n       --fetch-HEAD\n\t      Fetch the upstream repository to detect if the HEAD installation\n\t      of  the  formula\tis  outdated. Otherwise, the repository's HEAD\n\t      will only be checked for updates when a new stable  or  develop-\n\t      ment version has been released.\n\n       --keep-tmp\n\t      Retain the temporary files created during installation.\n\n       --build-bottle\n\t      Prepare  the  formula for eventual bottling during installation,\n\t      skipping any post-install steps.\n\n       --bottle-arch\n\t      Optimise bottles for the specified architecture rather than  the\n\t      oldest  architecture  supported by the version of macOS the bot-\n\t      tles are built on.\n\n       -f, --force\n\t      Install without checking for previously  installed  keg-only  or\n\t      non-migrated versions.\n\n       -v, --verbose\n\t      Print the verification and postinstall steps.\n\n       --display-times\n\t      Print install times for each formula at the end of the run.\n\n       -i, --interactive\n\t      Download\tand  patch formula, then open a shell. This allows the\n\t      user to run ./configure --help and otherwise  determine  how  to\n\t      turn the software package into a Homebrew package.\n\n       -g, --git\n\t      Create  a  Git  repository,  useful  for creating patches to the\n\t      software.\n\n   leaves\n       List installed formulae that are not dependencies of another  installed\n       formula.\n\n   link, ln [options] formula\n       Symlink\tall  of formula's installed files into Homebrew's prefix. This\n       is done automatically when you install formulae but can be  useful  for\n       DIY installations.\n\n       --overwrite\n\t      Delete files that already exist in the prefix while linking.\n\n       -n, --dry-run\n\t      List files which would be linked or deleted by brew link --over-\n\t      write without actually linking or deleting any files.\n\n       -f, --force\n\t      Allow keg-only formulae to be linked.\n\n   list, ls [options] [formula|cask]\n       List all installed formulae or casks\n\n       If formula is provided, summarise the paths within its current keg.\n\n       --full-name\n\t      Print formulae with fully-qualified names. If --full-name is not\n\t      passed,  other  options  (i.e.  -1, -l, -r and -t) are passed to\n\t      ls(1) which produces the actual output.\n\n       --unbrewed\n\t      List files in Homebrew's prefix not installed by Homebrew.\n\n       --versions\n\t      Show the version number for  installed  formulae,  or  only  the\n\t      specified formulae if formula are provided.\n\n       --multiple\n\t      Only show formulae with multiple versions installed.\n\n       --pinned\n\t      Show  the  versions  of  pinned  formulae, or only the specified\n\t      (pinned) formulae if formula are provided. See also pin,\tunpin.\n\n       --formula\n\t      List only formulae.\n\n       --cask List only casks.\n\n       -1     Force  output to be one entry per line. This is the default when\n\t      output is not to a terminal.\n\n       -l     List in long format. If the output is to a terminal, a total sum\n\t      for all the file sizes is printed before the long listing.\n\n       -r     Reverse  the order of the sort to list the oldest entries first.\n\n       -t     Sort by time modified, listing most recently modified first.\n\n   log [options] [formula]\n       Show the git log for formula, or show the log for the Homebrew  reposi-\n       tory if no formula is provided.\n\n       -p, --patch\n\t      Also print patch from commit.\n\n       --stat Also print diffstat from commit.\n\n       --oneline\n\t      Print only one line per commit.\n\n       -1     Print only one commit.\n\n       -n, --max-count\n\t      Print only a specified number of commits.\n\n   migrate [options] formula\n       Migrate\trenamed  packages to new names, where formula are old names of\n       packages.\n\n       -f, --force\n\t      Treat installed formula and provided formula as if they are from\n\t      the same taps and migrate them anyway.\n\n   missing [options] [formula]\n       Check  the  given  formula kegs for missing dependencies. If no formula\n       are provided, check all kegs. Will exit with a non-zero status  if  any\n       kegs are found to be missing dependencies.\n\n       --hide Act  as  if  none  of the specified hidden are installed. hidden\n\t      should be a comma-separated list of formulae.\n\n   options [options] [formula]\n       Show install options specific to formula.\n\n       --compact\n\t      Show all options on a single line separated by spaces.\n\n       --installed\n\t      Show options for formulae that are currently installed.\n\n       --all  Show options for all available formulae.\n\n       --command\n\t      Show options for the specified command.\n\n   outdated [options] [formula|cask]\n       List installed casks and formulae that have an updated  version\tavail-\n       able.  By  default,  version  information  is  displayed in interactive\n       shells, and suppressed otherwise.\n\n       -q, --quiet\n\t      List only the names of  outdated\tkegs  (takes  precedence  over\n\t      --verbose).\n\n       -v, --verbose\n\t      Include detailed version information.\n\n       --formula\n\t      Only output outdated formulae.\n\n       --cask Only output outdated casks.\n\n       --json Print  output in JSON format. There are two versions: v1 and v2.\n\t      v1 is deprecated and is currently the default if no  version  is\n\t      specified. v2 prints outdated formulae and casks.\n\n       --fetch-HEAD\n\t      Fetch the upstream repository to detect if the HEAD installation\n\t      of the formula is outdated.  Otherwise,  the  repository's  HEAD\n\t      will  only  be checked for updates when a new stable or develop-\n\t      ment version has been released.\n\n       --greedy\n\t      Print outdated casks with auto_updates or version :latest.\n\n   pin formula\n       Pin the specified formula, preventing them  from  being\tupgraded  when\n       issuing the brew upgrade formula command. See also unpin.\n\n   postinstall formula\n       Rerun the post-install steps for formula.\n\n   readall [options] [tap]\n       Import  all items from the specified tap, or from all installed taps if\n       none is provided. This can be useful for debugging  issues  across  all\n       items  when  making significant changes to formula.rb, testing the per-\n       formance of loading all items or checking if any current formulae/casks\n       have Ruby issues.\n\n       --aliases\n\t      Verify any alias symlinks in each tap.\n\n       --syntax\n\t      Syntax-check  all  of  Homebrew's  Ruby  files  (if  no <tap> is\n\t      passed).\n\n   reinstall [options] formula\n       Uninstall and then install formula using the same options it was origi-\n       nally installed with, plus any appended brew formula options.\n\n       Unless  HOMEBREW_NO_INSTALL_CLEANUP  is\tset, brew cleanup will then be\n       run for the reinstalled formulae or, every 30 days, for all formulae.\n\n       -d, --debug\n\t      If brewing fails, open an  interactive  debugging  session  with\n\t      access to IRB or a shell inside the temporary build directory.\n\n       -s, --build-from-source\n\t      Compile formula from source even if a bottle is available.\n\n       -i, --interactive\n\t      Download\tand  patch formula, then open a shell. This allows the\n\t      user to run ./configure --help and otherwise  determine  how  to\n\t      turn the software package into a Homebrew package.\n\n       --force-bottle\n\t      Install  from  a\tbottle\tif it exists for the current or newest\n\t      version of macOS, even if it would  not  normally  be  used  for\n\t      installation.\n\n       --keep-tmp\n\t      Retain the temporary files created during installation.\n\n       -f, --force\n\t      Install  without\tchecking  for previously installed keg-only or\n\t      non-migrated versions.\n\n       -v, --verbose\n\t      Print the verification and postinstall steps.\n\n       --display-times\n\t      Print install times for each formula at the end of the run.\n\n   search [options] [text|/text/]\n       Perform a substring search of cask tokens and formula names  for  text.\n       If  text  is flanked by slashes, it is interpreted as a regular expres-\n       sion. The search for text is extended online to homebrew/core and home-\n       brew/cask.\n\n       If  no text is provided, list all locally available formulae (including\n       tapped ones). No online search is performed.\n\n       --formula\n\t      Without text, list all locally  available  formulae  (no\tonline\n\t      search  is  performed). With text, search online and locally for\n\t      formulae.\n\n       --cask Without text, list all locally available casks (including tapped\n\t      ones,  no  online search is performed). With text, search online\n\t      and locally for casks.\n\n       --desc Search for formulae with a description matching text  and  casks\n\t      with a name matching text.\n\n       --macports\n\t      Search for text in the given package manager's list.\n\n       --fink Search for text in the given package manager's list.\n\n       --opensuse\n\t      Search for text in the given package manager's list.\n\n       --fedora\n\t      Search for text in the given package manager's list.\n\n       --debian\n\t      Search for text in the given package manager's list.\n\n       --ubuntu\n\t      Search for text in the given package manager's list.\n\n   shellenv\n       Print  export  statements.  When  run  in a shell, this installation of\n       Homebrew will be added to your PATH, MANPATH, and INFOPATH.\n\n       The variables HOMEBREW_PREFIX, HOMEBREW_CELLAR and  HOMEBREW_REPOSITORY\n       are  also  exported  to\tavoid  querying  them multiple times. Consider\n       adding evaluation of this  command's  output  to  your  dotfiles  (e.g.\n       ~/.profile,  ~/.bash_profile,  or  ~/.zprofile) with: eval $(brew shel-\n       lenv)\n\n   switch formula version\n       Symlink all of the specified version  of  formula's  installation  into\n       Homebrew's prefix.\n\n   tap [options] [user/repo] [URL]\n       Tap a formula repository.\n\n       If no arguments are provided, list all installed taps.\n\n       With URL unspecified, tap a formula repository from GitHub using HTTPS.\n       Since so many taps are hosted on GitHub, this command is a shortcut for\n       brew tap user/repo https://github.com/user/homebrew-repo.\n\n       With  URL  specified, tap a formula repository from anywhere, using any\n       transport protocol that git(1) handles. The one-argument  form  of  tap\n       simplifies  but also limits. This two-argument command makes no assump-\n       tions, so taps can be cloned from places other than  GitHub  and  using\n       protocols other than HTTPS, e.g. SSH, git, HTTP, FTP(S), rsync.\n\n       --full Convert  a shallow clone to a full clone without untapping. Taps\n\t      are only cloned as shallow clones on continuous integration,  or\n\t      if --shallow was originally passed.\n\n       --shallow\n\t      Fetch  tap  as  a shallow clone rather than a full clone. Useful\n\t      for continuous integration.\n\n       --force-auto-update\n\t      Auto-update tap even if it is not hosted on GitHub. By  default,\n\t      only  taps  hosted  on  GitHub are auto-updated (for performance\n\t      reasons).\n\n       --repair\n\t      Migrate tapped formulae from  symlink-based  to  directory-based\n\t      structure.\n\n       --list-pinned\n\t      List all pinned taps.\n\n   tap-info [options] [tap]\n       Show detailed information about one or more taps.\n\n       If  no  tap  names  are\tprovided,  display  brief  statistics  for all\n       installed taps.\n\n       --installed\n\t      Show information on each installed tap.\n\n       --json Print a JSON representation of tap. Currently  the  default  and\n\t      only accepted value for version is v1. See the docs for examples\n\t      of using the JSON output: https://docs.brew.sh/Querying-Brew\n\n   uninstall, rm, remove [options] formula\n       Uninstall formula.\n\n       -f, --force\n\t      Delete all installed versions of formula.\n\n       --ignore-dependencies\n\t      Don't fail uninstall, even if formula is\ta  dependency  of  any\n\t      installed formulae.\n\n   unlink [options] formula\n       Remove  symlinks for formula from Homebrew's prefix. This can be useful\n       for temporarily disabling a formula: brew unlink formula && commands &&\n       brew link formula\n\n       -n, --dry-run\n\t      List files which would be unlinked without actually unlinking or\n\t      deleting any files.\n\n   unpin formula\n       Unpin formula, allowing them to be upgraded by  brew  upgrade  formula.\n       See also pin.\n\n   untap tap\n       Remove a tapped formula repository.\n\n   update [options]\n       Fetch the newest version of Homebrew and all formulae from GitHub using\n       git(1) and perform any necessary migrations.\n\n       --merge\n\t      Use git merge to apply updates (rather than git rebase).\n\n       --preinstall\n\t      Run on auto-updates  (e.g.  before  brew\tinstall).  Skips  some\n\t      slower steps.\n\n       -f, --force\n\t      Always do a slower, full update check (even if unnecessary).\n\n   update-reset [repository]\n       Fetch  and  reset  Homebrew  and all tap repositories (or any specified\n       repository) using git(1) to their latest origin/master.\n\n       Note: this will destroy all your uncommitted or committed changes.\n\n   upgrade [options] [formula|cask]\n       Upgrade outdated casks and outdated, unpinned formulae using  the  same\n       options\tthey  were  originally\tinstalled with, plus any appended brew\n       formula options. If cask or formula are\tspecified,  upgrade  only  the\n       given cask or formula kegs (unless they are pinned; see pin, unpin).\n\n       Unless  HOMEBREW_NO_INSTALL_CLEANUP  is\tset, brew cleanup will then be\n       run for the upgraded formulae or, every 30 days, for all formulae.\n\n       -d, --debug\n\t      If brewing fails, open an  interactive  debugging  session  with\n\t      access to IRB or a shell inside the temporary build directory.\n\n       --formula\n\t      Only upgrade outdated formulae.\n\n       --cask Only upgrade outdated casks.\n\n       -s, --build-from-source\n\t      Compile formula from source even if a bottle is available.\n\n       -i, --interactive\n\t      Download\tand  patch formula, then open a shell. This allows the\n\t      user to run ./configure --help and otherwise  determine  how  to\n\t      turn the software package into a Homebrew package.\n\n       --force-bottle\n\t      Install  from  a\tbottle\tif it exists for the current or newest\n\t      version of macOS, even if it would  not  normally  be  used  for\n\t      installation.\n\n       --fetch-HEAD\n\t      Fetch the upstream repository to detect if the HEAD installation\n\t      of the formula is outdated.  Otherwise,  the  repository's  HEAD\n\t      will  only  be checked for updates when a new stable or develop-\n\t      ment version has been released.\n\n       --ignore-pinned\n\t      Set a successful exit status even if  pinned  formulae  are  not\n\t      upgraded.\n\n       --keep-tmp\n\t      Retain the temporary files created during installation.\n\n       -f, --force\n\t      Install  without\tchecking  for previously installed keg-only or\n\t      non-migrated versions.\n\n       -v, --verbose\n\t      Print the verification and postinstall steps.\n\n       --display-times\n\t      Print install times for each formula at the end of the run.\n\n       -n, --dry-run\n\t      Show what would be upgraded, but do not  actually  upgrade  any-\n\t      thing.\n\n       --greedy\n\t      Upgrade casks with auto_updates or version :latest\n\n   uses [options] formula\n       Show  formulae  that  specify formula as a dependency (i.e. show depen-\n       dents of formula). When given  multiple\tformula  arguments,  show  the\n       intersection  of  formulae that use formula. By default, uses shows all\n       formulae that specify formula as a required or  recommended  dependency\n       for their stable builds.\n\n       --recursive\n\t      Resolve more than one level of dependencies.\n\n       --installed\n\t      Only list formulae that are currently installed.\n\n       --include-build\n\t      Include  all formulae that specify formula as :build type depen-\n\t      dency.\n\n       --include-test\n\t      Include all formulae that specify formula as :test  type\tdepen-\n\t      dency.\n\n       --include-optional\n\t      Include  all  formulae  that  specify  formula as :optional type\n\t      dependency.\n\n       --skip-recommended\n\t      Skip all formulae that  specify  formula\tas  :recommended  type\n\t      dependency.\n\n   --cache [options] [formula|cask]\n       Display Homebrew's download cache. See also HOMEBREW_CACHE.\n\n       If  formula  is\tprovided,  display the file or directory used to cache\n       formula.\n\n       -s, --build-from-source\n\t      Show the cache file used when building from source.\n\n       --force-bottle\n\t      Show the cache file used when pouring a bottle.\n\n       --formula\n\t      Only show cache files for formulae.\n\n       --cask Only show cache files for casks.\n\n   --caskroom [cask]\n       Display Homebrew's Caskroom path.\n\n       If cask is provided, display the location in the  Caskroom  where  cask\n       would be installed, without any sort of versioned directory as the last\n       path.\n\n   --cellar [formula]\n       Display Homebrew's Cellar path. Default: $(brew --prefix)/Cellar, or if\n       that directory doesn't exist, $(brew --repository)/Cellar.\n\n       If  formula  is provided, display the location in the Cellar where for-\n       mula would be installed, without any sort of versioned directory as the\n       last path.\n\n   --env [options] [formula]\n       Summarise Homebrew's build environment as a plain list.\n\n       If  the\tcommand's output is sent through a pipe and no shell is speci-\n       fied, the list is formatted for export to  bash(1)  unless  --plain  is\n       passed.\n\n       --shell\n\t      Generate\ta  list  of  environment  variables  for the specified\n\t      shell, or --shell=auto to detect the current shell.\n\n       --plain\n\t      Generate plain output even when piped.\n\n   --prefix [formula]\n       Display Homebrew's install  path.  Default:  /usr/local\ton  macOS  and\n       /home/linuxbrew/.linuxbrew on Linux.\n\n       If  formula  is provided, display the location in the Cellar where for-\n       mula is or would be installed.\n\n   --repository, --repo [user/repo]\n       Display where Homebrew's .git directory is located.\n\n       If user/repo are provided, display where tap user/repo's  directory  is\n       located.\n\n   --version\n       Print the version numbers of Homebrew, Homebrew/homebrew-core and Home-\n       brew/homebrew-cask (if tapped) to standard output.\n\nDEVELOPER COMMANDS\n   audit [options] [formula]\n       Check formula for Homebrew coding style violations. This should be  run\n       before  submitting a new formula. If no formula are provided, check all\n       locally available formulae and skip style  checks.  Will  exit  with  a\n       non-zero status if any errors are found.\n\n       --strict\n\t      Run additional, stricter style checks.\n\n       --git  Run additional, slower style checks that navigate the Git repos-\n\t      itory.\n\n       --online\n\t      Run additional, slower style checks that require a network  con-\n\t      nection.\n\n       --new-formula\n\t      Run  various  additional style checks to determine if a new for-\n\t      mula is eligible for Homebrew. This should be used when creating\n\t      new formula and implies --strict and --online.\n\n       --tap  Check the formulae within the given tap, specified as user/repo.\n\n       --fix  Fix style violations automatically using RuboCop's  auto-correct\n\t      feature.\n\n       --display-cop-names\n\t      Include the RuboCop cop name for each violation in the output.\n\n       --display-filename\n\t      Prefix  every line of output with the file or formula name being\n\t      audited, to make output easy to grep.\n\n       --skip-style\n\t      Skip running non-RuboCop style checks. Useful  if  you  plan  on\n\t      running brew style separately. Default unless a formula is spec-\n\t      ified by name\n\n       -D, --audit-debug\n\t      Enable debugging and profiling of audit methods.\n\n       --only Specify a comma-separated method list to only  run  the  methods\n\t      named audit_method.\n\n       --except\n\t      Specify  a comma-separated method list to skip running the meth-\n\t      ods named audit_method.\n\n       --only-cops\n\t      Specify a comma-separated cops list to check for\tviolations  of\n\t      only the listed RuboCop cops.\n\n       --except-cops\n\t      Specify  a comma-separated cops list to skip checking for viola-\n\t      tions of the listed RuboCop cops.\n\n   bottle [options] formula\n       Generate a bottle (binary package) from a formula  that\twas  installed\n       with  --build-bottle.  If  the  formula specifies a rebuild version, it\n       will be incremented in  the  generated  DSL.  Passing  --keep-old  will\n       attempt\tto  keep  it  at  its  original value, while --no-rebuild will\n       remove it.\n\n       --skip-relocation\n\t      Do not check if the bottle can be marked as relocatable.\n\n       --force-core-tap\n\t      Build a bottle even if formula is not in\thomebrew/core  or  any\n\t      installed taps.\n\n       --no-rebuild\n\t      If  the  formula specifies a rebuild version, remove it from the\n\t      generated DSL.\n\n       --keep-old\n\t      If the formula specifies a rebuild version, attempt to  preserve\n\t      its value in the generated DSL.\n\n       --json Write  bottle  information  to a JSON file, which can be used as\n\t      the value for --merge.\n\n       --merge\n\t      Generate an updated bottle block for a  formula  and  optionally\n\t      merge  it  into  the  formula  file.  Instead of a formula name,\n\t      requires the path to a JSON  file  generated  with  brew\tbottle\n\t      --json formula.\n\n       --write\n\t      Write  changes  to the formula file. A new commit will be gener-\n\t      ated unless --no-commit is passed.\n\n       --no-commit\n\t      When passed with --write, a new commit will not generated  after\n\t      writing changes to the formula file.\n\n       --root-url\n\t      Use the specified URL as the root of the bottle's URL instead of\n\t      Homebrew's default.\n\n   bump [options] [formula]\n       Display out-of-date brew formulae and  the  latest  version  available.\n       Also displays whether a pull request has been opened with the URL.\n\n       --limit\n\t      Limit number of package results returned.\n\n   bump-cask-pr [options] [cask]\n       Create a pull request to update cask with a new version.\n\n       A best effort to determine the SHA-256 will be made if the value is not\n       supplied by the user.\n\n       -n, --dry-run\n\t      Print what would be done rather than doing it.\n\n       --write\n\t      Make the expected file  modifications  without  taking  any  Git\n\t      actions.\n\n       --commit\n\t      When  passed  with  --write, generate a new commit after writing\n\t      changes to the cask file.\n\n       --no-audit\n\t      Don't run brew cask audit before opening the PR.\n\n       --no-style\n\t      Don't run brew cask style --fix before opening the PR.\n\n       --no-browse\n\t      Print the pull request URL instead of opening in a browser.\n\n       --no-fork\n\t      Don't try to fork the repository.\n\n       --version\n\t      Specify the new version for the cask.\n\n       --message\n\t      Append message to the default pull request message.\n\n       --url  Specify the URL for the new download.\n\n       --sha256\n\t      Specify the SHA-256 checksum of the new download.\n\n       -f, --force\n\t      Ignore duplicate open PRs.\n\n   bump-formula-pr [options] [formula]\n       Create a pull request to update formula with a new URL or a new tag.\n\n       If a URL is specified, the SHA-256 checksum of the new download\tshould\n       also  be  specified. A best effort to determine the SHA-256 and formula\n       name will be made if either or both values  are\tnot  supplied  by  the\n       user.\n\n       If  a  tag  is specified, the Git commit revision corresponding to that\n       tag should also be specified. A best effort to determine  the  revision\n       will be made if the value is not supplied by the user.\n\n       If  a  version  is  specified,  a  best effort to determine the URL and\n       SHA-256 or the tag and revision will be made if\tboth  values  are  not\n       supplied by the user.\n\n       Note:  this  command  cannot  be  used  to  transition a formula from a\n       URL-and-SHA-256 style specification into a tag-and-revision style spec-\n       ification,  nor\tvice  versa. It must use whichever style specification\n       the formula already uses.\n\n       -n, --dry-run\n\t      Print what would be done rather than doing it.\n\n       --write\n\t      Make the expected file  modifications  without  taking  any  Git\n\t      actions.\n\n       --commit\n\t      When  passed  with  --write, generate a new commit after writing\n\t      changes to the formula file.\n\n       --no-audit\n\t      Don't run brew audit before opening the PR.\n\n       --strict\n\t      Run brew audit --strict before opening the PR.\n\n       --no-browse\n\t      Print the pull request URL instead of opening in a browser.\n\n       --no-fork\n\t      Don't try to fork the repository.\n\n       --mirror\n\t      Use the specified URL as a mirror URL. If URL is\ta  comma-sepa-\n\t      rated list of URLs, multiple mirrors will be added.\n\n       --version\n\t      Use  the specified version to override the value parsed from the\n\t      URL or tag. Note that --version=0  can  be  used\tto  delete  an\n\t      existing version override from a formula if it has become redun-\n\t      dant.\n\n       --message\n\t      Append message to the default pull request message.\n\n       --url  Specify the URL for the new download. If a URL is specified, the\n\t      SHA-256 checksum of the new download should also be specified.\n\n       --sha256\n\t      Specify the SHA-256 checksum of the new download.\n\n       --tag  Specify the new git commit tag for the formula.\n\n       --revision\n\t      Specify  the new git commit revision corresponding to the speci-\n\t      fied tag.\n\n       -f, --force\n\t      Ignore duplicate open PRs. Remove all mirrors if\t--mirror=  was\n\t      not specified.\n\n   bump-revision [options] formula [formula ...]\n       Create a commit to increment the revision of formula. If no revision is\n       present, \"revision 1\" will be added.\n\n       -n, --dry-run\n\t      Print what would be done rather than doing it.\n\n       --message\n\t      Append message to the default commit message.\n\n   cat formula\n       Display the source of formula.\n\n   command cmd\n       Display the path to the file being used when invoking brew cmd.\n\n   create [options] URL\n       Generate a formula for the downloadable file at URL and open it in  the\n       editor.\tHomebrew will attempt to automatically derive the formula name\n       and version, but if it fails, you'll have to make  your\town  template.\n       The wget formula serves as a simple example. For the complete API, see:\n       https://rubydoc.brew.sh/Formula\n\n       --autotools\n\t      Create a basic template for an Autotools-style build.\n\n       --cmake\n\t      Create a basic template for a CMake-style build.\n\n       --crystal\n\t      Create a basic template for a Crystal build.\n\n       --go   Create a basic template for a Go build.\n\n       --meson\n\t      Create a basic template for a Meson-style build.\n\n       --node Create a basic template for a Node build.\n\n       --perl Create a basic template for a Perl build.\n\n       --python\n\t      Create a basic template for a Python build.\n\n       --ruby Create a basic template for a Ruby build.\n\n       --rust Create a basic template for a Rust build.\n\n       --no-fetch\n\t      Homebrew will not download URL to the cache and  will  thus  not\n\t      add  its\tSHA-256  to the formula for you, nor will it check the\n\t      GitHub API for GitHub projects (to fill out its description  and\n\t      homepage).\n\n       --HEAD Indicate that URL points to the package's repository rather than\n\t      a file.\n\n       --set-name\n\t      Explicitly set the name of the new formula.\n\n       --set-version\n\t      Explicitly set the version of the new formula.\n\n       --set-license\n\t      Explicitly set the license of the new formula.\n\n       --tap  Generate the new formula within  the  given  tap,  specified  as\n\t      user/repo.\n\n       -f, --force\n\t      Ignore errors for disallowed formula names and named that shadow\n\t      aliases.\n\n   diy [options]\n       Automatically determine the installation prefix for non-Homebrew  soft-\n       ware.  Using  the  output  from\tthis command, you can install your own\n       software into the Cellar and then link it into Homebrew's  prefix  with\n       brew link.\n\n       --name Explicitly set the name of the package being installed.\n\n       --version\n\t      Explicitly set the version of the package being installed.\n\n   edit [formula]\n       Open  formula  in  the editor set by EDITOR or HOMEBREW_EDITOR, or open\n       the Homebrew repository for editing if no formula is provided.\n\n   extract [options] formula tap\n       Look through repository history to find the most recent version of for-\n       mula and create a copy in tap/Formula/formula@version.rb. If the tap is\n       not installed yet, attempt to install/clone the tap before  continuing.\n       To  extract  a  formula\tfrom  a  tap that is not homebrew/core use its\n       fully-qualified form of user/repo/formula.\n\n       --version\n\t      Extract the specified version of formula\tinstead  of  the  most\n\t      recent.\n\n       -f, --force\n\t      Overwrite the destination formula if it already exists.\n\n   formula formula\n       Display the path where formula is located.\n\n   install-bundler-gems\n       Install Homebrew's Bundler gems.\n\n   irb [options]\n       Enter the interactive Homebrew Ruby shell.\n\n       --examples\n\t      Show several examples.\n\n       --pry  Use Pry instead of IRB. Implied if HOMEBREW_PRY is set.\n\n   linkage [options] [formula]\n       Check  the library links from the given formula kegs. If no formula are\n       provided, check all kegs. Raises an error if run on uninstalled\tformu-\n       lae.\n\n       --test Show  only  missing libraries and exit with a non-zero status if\n\t      any missing libraries are found.\n\n       --reverse\n\t      For every library that a keg references, print  its  dylib  path\n\t      followed by the binaries that link to it.\n\n       --cached\n\t      Print the cached linkage values stored in HOMEBREW_CACHE, set by\n\t      a previous brew linkage run.\n\n   livecheck [formulae]\n       Check for newer versions of formulae from upstream.\n\n       If no formula argument is passed, the list  of  formulae  to  check  is\n       taken from HOMEBREW_LIVECHECK_WATCHLIST or ~/.brew_livecheck_watchlist.\n\n       --full-name\n\t      Print formulae with fully-qualified names.\n\n       --tap  Check the formulae within the given tap, specified as user/repo.\n\n       --installed\n\t      Check formulae that are currently installed.\n\n       --json Output informations in JSON format.\n\n       --all  Check all available formulae.\n\n       --newer-only\n\t      Show the latest version only if it's newer than the formula.\n\n   man [options]\n       Generate Homebrew's manpages.\n\n       --fail-if-changed\n\t      Return a failing status code if changes are detected in the man-\n\t      page outputs. This can be used to notify CI  when  the  manpages\n\t      are  out\tof  date.  Additionally, the date used in new manpages\n\t      will match those in the existing manpages (to  allow  comparison\n\t      without factoring in the date).\n\n       --link This is now done automatically by brew update.\n\n   pr-automerge [options]\n       Find  pull requests that can be automatically merged using brew pr-pub-\n       lish.\n\n       --tap  Target tap repository (default: homebrew/core).\n\n       --with-label\n\t      Pull requests must have this label.\n\n       --without-labels\n\t      Pull requests must not have these labels (default: do not merge,\n\t      new formula).\n\n       --without-approval\n\t      Pull requests do not require approval to be merged.\n\n       --publish\n\t      Run brew pr-publish on matching pull requests.\n\n       --ignore-failures\n\t      Include pull requests that have failing status checks.\n\n   pr-publish [options] pull_request [pull_request ...]\n       Publish\tbottles for a pull request with GitHub Actions. Requires write\n       access to the repository.\n\n       --tap  Target tap repository (default: homebrew/core).\n\n       --workflow\n\t      Target workflow filename (default:  publish-commit-bottles.yml).\n\n   pr-pull [options] pull_request [pull_request ...]\n       Download  and  publish bottles, and apply the bottle commit from a pull\n       request with artifacts generated  by  GitHub  Actions.  Requires  write\n       access to the repository.\n\n       --no-publish\n\t      Download\tthe  bottles,  apply  the bottle commit and upload the\n\t      bottles to Bintray, but don't publish them.\n\n       --no-upload\n\t      Download the bottles and apply  the  bottle  commit,  but  don't\n\t      upload to Bintray.\n\n       -n, --dry-run\n\t      Print what would be done rather than doing it.\n\n       --clean\n\t      Do not amend the commits from pull requests.\n\n       --keep-old\n\t      If  the formula specifies a rebuild version, attempt to preserve\n\t      its value in the generated DSL.\n\n       --branch-okay\n\t      Do not warn if pulling to a branch besides  master  (useful  for\n\t      testing).\n\n       --resolve\n\t      When a patch fails to apply, leave in progress and allow user to\n\t      resolve, instead of aborting.\n\n       --warn-on-upload-failure\n\t      Warn instead of raising an error if  the\tbottle\tupload\tfails.\n\t      Useful for repairing bottle uploads that previously failed.\n\n       --workflow\n\t      Retrieve\t artifacts   from  the\tspecified  workflow  (default:\n\t      tests.yml).\n\n       --artifact\n\t      Download artifacts with the specified name (default: bottles).\n\n       --bintray-org\n\t      Upload to the specified  Bintray\torganisation  (default:  home-\n\t      brew).\n\n       --tap  Target tap repository (default: homebrew/core).\n\n       --root-url\n\t      Use the specified URL as the root of the bottle's URL instead of\n\t      Homebrew's default.\n\n       --bintray-mirror\n\t      Use the specified Bintray  repository  to  automatically\tmirror\n\t      stable URLs defined in the formulae (default: mirror).\n\n   pr-upload [options]\n       Apply the bottle commit and publish bottles to Bintray.\n\n       --no-publish\n\t      Apply  the  bottle commit and upload the bottles, but don't pub-\n\t      lish them.\n\n       --keep-old\n\t      If the formula specifies a rebuild version, attempt to  preserve\n\t      its value in the generated DSL.\n\n       -n, --dry-run\n\t      Print what would be done rather than doing it.\n\n       --warn-on-upload-failure\n\t      Warn  instead  of  raising  an error if the bottle upload fails.\n\t      Useful for repairing bottle uploads that previously failed.\n\n       --bintray-org\n\t      Upload to the specified  Bintray\torganisation  (default:  home-\n\t      brew).\n\n       --root-url\n\t      Use the specified URL as the root of the bottle's URL instead of\n\t      Homebrew's default.\n\n   prof [command]\n       Run Homebrew with a Ruby profiler, e.g. brew prof readall.\n\n       --stackprof\n\t      Use stackprof instead of ruby-prof (the default).\n\n   release-notes [options] [previous_tag] [end_ref]\n       Print the merged pull requests on Homebrew/brew between two  Git  refs.\n       If  no  previous_tag  is  provided it defaults to the latest tag. If no\n       end_ref is provided it defaults to origin/master.\n\n       --markdown\n\t      Print as a Markdown list.\n\n   ruby (-e text|file)\n       Run a Ruby instance with Homebrew's libraries loaded, e.g. brew ruby -e\n       \"puts :gcc.f.deps\" or brew ruby script.rb.\n\n       -r     Load a library using require.\n\n       -e     Execute the given text string as a script.\n\n   sh [options] [file]\n       Homebrew  build environment that uses years-battle-hardened build logic\n       to help your ./configure && make && make  install  and  even  your  gem\n       install\tsucceed. Especially handy if you run Homebrew in an Xcode-only\n       configuration since it adds tools like make to your  PATH  which  build\n       systems would not find otherwise.\n\n       --env  Use  the standard PATH instead of superenv's when std is passed.\n\n       -c, --cmd\n\t      Execute commands in a non-interactive shell.\n\n   sponsors\n       Print a Markdown summary of Homebrew's GitHub  Sponsors,  suitable  for\n       pasting into a README.\n\n   style [options] [file|tap|formula]\n       Check formulae or files for conformance to Homebrew style guidelines.\n\n       Lists  of  file,  tap and formula may not be combined. If none are pro-\n       vided, style will run style  checks  on\tthe  whole  Homebrew  library,\n       including core code and all formulae.\n\n       --fix  Fix  style violations automatically using RuboCop's auto-correct\n\t      feature.\n\n       --display-cop-names\n\t      Include the RuboCop cop name for each violation in the output.\n\n       --only-cops\n\t      Specify a comma-separated cops list to check for\tviolations  of\n\t      only the listed RuboCop cops.\n\n       --except-cops\n\t      Specify  a comma-separated cops list to skip checking for viola-\n\t      tions of the listed RuboCop cops.\n\n   tap-new user/repo\n       Generate the template files for a new tap.\n\n   test [options] formula\n       Run the test method provided by an installed formula. There is no stan-\n       dard  output or return code, but generally it should notify the user if\n       something is wrong with the installed formula.\n\n       Example: brew install jruby && brew test jruby\n\n       --devel\n\t      Test the development version of a formula.\n\n       --HEAD Test the head version of a formula.\n\n       --keep-tmp\n\t      Retain the temporary files created for the test.\n\n       --retry\n\t      Retry if a testing fails.\n\n   tests [options]\n       Run Homebrew's unit and integration tests.\n\n       --coverage\n\t      Generate code coverage reports.\n\n       --generic\n\t      Run only OS-agnostic tests.\n\n       --no-compat\n\t      Do not load the compatibility layer when running tests.\n\n       --online\n\t      Include tests that use the GitHub API and tests that use any  of\n\t      the taps for official external commands.\n\n       --byebug\n\t      Enable debugging using byebug.\n\n       --only Run  only test_script_spec.rb. Appending :line_number will start\n\t      at a specific line.\n\n       --seed Randomise tests with the specified value\tinstead  of  a\trandom\n\t      seed.\n\n   typecheck\n       Check for typechecking errors using Sorbet.\n\n       -q, --quiet\n\t      Silence all non-critical errors.\n\n       --update-definitions\n\t      Update Tapioca gem definitions of recently bumped gems\n\n       --fail-if-not-changed\n\t      Return  a failing status code if all gems are up to date and gem\n\t      definitions do not need a tapioca update\n\n       --dir  Typecheck all files in a specific directory.\n\n       --file Typecheck a single file.\n\n       --ignore\n\t      Ignores input files that contain the given string in their paths\n\t      (relative to the input path passed to Sorbet).\n\n   unpack [options] formula\n       Unpack  the source files for formula into subdirectories of the current\n       working directory.\n\n       --destdir\n\t      Create subdirectories in the directory named by path instead.\n\n       --patch\n\t      Patches for formula will be applied to the unpacked source.\n\n       -g, --git\n\t      Initialise a Git repository in the unpacked source. This is use-\n\t      ful for creating patches for the software.\n\n       -f, --force\n\t      Overwrite the destination directory if it already exists.\n\n   update-license-data [options]\n       Update SPDX license data in the Homebrew repository.\n\n       --fail-if-not-changed\n\t      Return  a  failing status code if current license data's version\n\t      is the same as the upstream. This can be used to notify CI  when\n\t      the SPDX license data is out of date.\n\n   update-python-resources [options] formula\n       Update versions for PyPI resource blocks in formula.\n\n       -p, --print-only\n\t      Print the updated resource blocks instead of changing formula.\n\n       -s, --silent\n\t      Suppress any output.\n\n       --ignore-non-pypi-packages\n\t      Don't fail if formula is not a PyPI package.\n\n       --version\n\t      Use the specified version when finding resources for formula. If\n\t      no version is specified, the current version for formula will be\n\t      used.\n\n   update-test [options]\n       Run  a  test  of brew update with a new repository clone. If no options\n       are passed, use origin/master as the start commit.\n\n       --to-tag\n\t      Set HOMEBREW_UPDATE_TO_TAG to test updating between tags.\n\n       --keep-tmp\n\t      Retain the temporary directory  containing  the  new  repository\n\t      clone.\n\n       --commit\n\t      Use the specified commit as the start commit.\n\n       --before\n\t      Use the commit at the specified date as the start commit.\n\n   vendor-gems\n       Install and commit Homebrew's vendored gems.\n\nGLOBAL OPTIONS\n       These options are applicable across multiple subcommands.\n\n       -d, --debug\n\t      Display any debugging information.\n\n       -q, --quiet\n\t      Suppress any warnings.\n\n       -v, --verbose\n\t      Make some output more verbose.\n\n       -h, --help\n\t      Show this message.\n\nOFFICIAL EXTERNAL COMMANDS\n   bundle [subcommand]\n       Bundler for non-Ruby dependencies from Homebrew, Homebrew Cask, Mac App\n       Store and Whalebrew.\n\n       brew bundle [install]\n\t   Install and upgrade (by default) all dependencies  from  the  Brew-\n       file.\n\n       You can skip the installation of dependencies by adding space-separated\n       values to one or more of the  following\tenvironment  variables:  HOME-\n       BREW_BUNDLE_BREW_SKIP,\t  HOMEBREW_BUNDLE_CASK_SKIP,\t HOMEBREW_BUN-\n       DLE_MAS_SKIP, HOMEBREW_BUNDLE_WHALEBREW_SKIP, HOMEBREW_BUNDLE_TAP_SKIP\n\n       brew bundle will output a Brewfile.lock.json in the same  directory  as\n       the  Brewfile if all dependencies are installed successfully. This con-\n       tains dependency and system status information which can be  useful  in\n       debugging  brew\tbundle\tfailures  and  replicating  a \"last known good\n       build\" state. You can opt-out of this behaviour by  setting  the  HOME-\n       BREW_BUNDLE_NO_LOCK  environment  variable  or  passing\tthe  --no-lock\n       option. You may wish to check this file into the same  version  control\n       system  as your Brewfile (or ensure your version control system ignores\n       it if you'd prefer to  rely  on\tdebugging  information\tfrom  a  local\n       machine).\n\n       brew bundle dump\n\t   Write all installed casks/formulae/images/taps into a Brewfile.\n\n       brew bundle cleanup\n\t   Uninstall all dependencies not listed from the Brewfile.\n\n       This  workflow  is  useful  for\tmaintainers  or  testers who regularly\n       install lots of formulae.\n\n       brew bundle check\n\t   Check if all dependencies are installed from the Brewfile .\n\n       This provides a successful exit code if everything is up-to-date,  mak-\n       ing it useful for scripting.\n\n       brew bundle list\n\t   List all dependencies present in a Brewfile.\n\n       By default, only Homebrew dependencies are listed.\n\n       brew bundle exec command\n\t   Run\tan  external command in an isolated build environment based on\n       the Brewfile dependencies.\n\n       This sanitized  build  environment  ignores  unrequested  dependencies,\n       which  makes sure that things you didn't specify in your Brewfile won't\n       get picked up by commands like bundle install,  npm  install,  etc.  It\n       will also add compiler flags which will help find keg-only dependencies\n       like openssl, icu4c, etc.\n\n       --file Read the Brewfile from this location. Use --file=-  to  pipe  to\n\t      stdin/stdout.\n\n       --global\n\t      Read the Brewfile from ~/.Brewfile.\n\n       -v, --verbose\n\t      install prints output from commands as they are run. check lists\n\t      all missing dependencies.\n\n       --no-upgrade\n\t      install won't run brew upgrade on  outdated  dependencies.  Note\n\t      they may still be upgraded by brew install if needed.\n\n       -f, --force\n\t      dump  overwrites an existing Brewfile. cleanup actually performs\n\t      its cleanup operations.\n\n       --no-lock\n\t      install won't output a Brewfile.lock.json.\n\n       --all  list all dependencies.\n\n       --formula\n\t      list Homebrew dependencies.\n\n       --cask list Homebrew Cask dependencies.\n\n       --tap  list tap dependencies.\n\n       --mas  list Mac App Store dependencies.\n\n       --whalebrew\n\t      list Whalebrew dependencies.\n\n       --describe\n\t      dump adds a description comment  above  each  line,  unless  the\n\t      dependency does not have a description.\n\n       --no-restart\n\t      dump does not add restart_service to formula lines.\n\n       --zap  cleanup casks using the zap command instead of uninstall.\n\n   services [subcommand]\n       Manage background services with macOS' launchctl(1) daemon manager.\n\n       If sudo is passed, operate on /Library/LaunchDaemons (started at boot).\n       Otherwise, operate on ~/Library/LaunchAgents (started at login).\n\n       [sudo] brew services [list]\n\t   List all managed services for the current user (or root).\n\n       [sudo] brew services run (formula|--all)\n\t   Run the service formula without registering to launch at login  (or\n       boot).\n\n       [sudo] brew services start (formula|--all)\n\t   Start  the service formula immediately and register it to launch at\n       login (or boot).\n\n       [sudo] brew services stop (formula|--all)\n\t   Stop the service formula immediately and unregister it from launch-\n       ing at login (or boot).\n\n       [sudo] brew services restart (formula|--all)\n\t   Stop  (if  necessary) and start the service formula immediately and\n       register it to launch at login (or boot).\n\n       [sudo] brew services cleanup\n\t   Remove all unused services.\n\n       --all  Run subcommand on all services.\n\n   test-bot [options] [formula]:\n       Tests the full lifecycle of a Homebrew change to  a  tap  (Git  reposi-\n       tory).  For  example,  for a GitHub Actions pull request that changes a\n       formula brew test-bot will ensure the system is cleaned\tand  setup  to\n       test  the formula, install the formula, run various tests and checks on\n       it, bottle (package) the binaries and test formulae that depend\ton  it\n       to ensure they aren't broken by these changes.\n\n       Only supports GitHub Actions as a CI provider. This is because Homebrew\n       uses GitHub Actions and it's freely available for  public  and  private\n       use with macOS and Linux workers.\n\n       --dry-run\n\t      print what would be done rather than doing it.\n\n       --cleanup\n\t      clean all state from the Homebrew directory. Use with care!\n\n       --skip-setup\n\t      don't check if the local system is set up correctly.\n\n       --keep-old\n\t      run  brew  bottle  --keep-old  to build new bottles for a single\n\t      platform.\n\n       --skip-relocation\n\t      run brew bottle --skip-relocation  to  build  new  bottles  that\n\t      don't require relocation.\n\n       --local\n\t      ask  Homebrew  to write verbose logs under ./logs/ and set $HOME\n\t      to ./home/\n\n       --tap  use the git repository of the given tap. Defaults  to  the  core\n\t      tap for syntax checking.\n\n       --fail-fast\n\t      immediately exit on a failing step.\n\n       -v, --verbose\n\t      print  test  step  output  in  real time. Has the side effect of\n\t      passing output as raw bytes instead of re-encoding in UTF-8.\n\n       --test-default-formula\n\t      use a default testing formula when not building  a  tap  and  no\n\t      other formulae are specified.\n\n       --bintray-org\n\t      upload to the given Bintray organisation.\n\n       --root-url\n\t      use the specified URL as the root of the bottle's URL instead of\n\t      Homebrew's default.\n\n       --git-name\n\t      set the Git author/committer names to the given name.\n\n       --git-email\n\t      set the Git author/committer email to the given email.\n\n       --ci-upload\n\t      use the Homebrew CI bottle upload options.\n\n       --publish\n\t      publish the uploaded bottles.\n\n       --skip-recursive-dependents\n\t      only test the direct dependents.\n\n       --only-cleanup-before\n\t      Only run the pre-cleanup step. Needs --cleanup.\n\n       --only-setup\n\t      Only run the local system setup check step.\n\n       --only-tap-syntax\n\t      Only run the tap syntax check step.\n\n       --only-formulae\n\t      Only run the formulae steps.\n\n       --only-cleanup-after\n\t      Only run the post-cleanup step. Needs --cleanup.\n\nCUSTOM EXTERNAL COMMANDS\n       Homebrew, like git(1), supports external commands. These are executable\n       scripts\tthat  reside  somewhere  in  the  PATH,  named brew-cmdname or\n       brew-cmdname.rb, which can be invoked like brew\tcmdname.  This\tallows\n       you to create your own commands without modifying Homebrew's internals.\n\n       Instructions for creating your own commands can be found in  the  docs:\n       https://docs.brew.sh/External-Commands\n\nSPECIFYING FORMULAE\n       Many  Homebrew  commands  accept  one  or more formula arguments. These\n       arguments can take several different forms:\n\n       The name of a formula\n\t      e.g. git, node, wget.\n\n       The fully-qualified name of a tapped formula\n\t      Sometimes a formula from a tapped repository may\tconflict  with\n\t      one  in  homebrew/core.  You  can still access these formulae by\n\t      using a special syntax, e.g. homebrew/dupes/vim or homebrew/ver-\n\t      sions/node4.\n\n       An arbitrary file\n\t      Homebrew can install formulae from a local path. It can point to\n\t      either a formula file or a bottle.\n\nSPECIFYING CASKS\n       Many Homebrew Cask commands accept one or more  cask  arguments.  These\n       can  be\tspecified  the\tsame way as the formula arguments described in\n       SPECIFYING FORMULAE above.\n\nENVIRONMENT\n       Note that environment variables must have a value set to  be  detected.\n       For  example,  run  export  HOMEBREW_NO_INSECURE_REDIRECT=1 rather than\n       just export HOMEBREW_NO_INSECURE_REDIRECT.\n\n       HOMEBREW_ARCH\n\t      Linux only: Pass the set value to a type name  representing  the\n\t      compiler's -march option.\n\n\t      Default: native.\n\n       HOMEBREW_ARTIFACT_DOMAIN\n\t      Prefix all download URLs, including those for bottles, with this\n\t      variable.  For  example,\tHOMEBREW_ARTIFACT_DOMAIN=http://local-\n\t      host:8080  will  cause  a  formula  with\tthe  URL https://exam-\n\t      ple.com/foo.tar.gz  to  instead  download   from\t http://local-\n\t      host:8080/example.com/foo.tar.gz.\n\n       HOMEBREW_AUTO_UPDATE_SECS\n\t      Automatically  check for updates once per this seconds interval.\n\n\t      Default: 300.\n\n       HOMEBREW_BAT\n\t      If set, use bat for the brew cat command.\n\n       HOMEBREW_BAT_CONFIG_PATH\n\t      Use   the   bat\tconfiguration\tfile.\tFor   example,\t HOME-\n\t      BREW_BAT=$HOME/.bat/config.\n\n\t      Default: $HOME/.bat/config\n\n       HOMEBREW_BINTRAY_KEY\n\t      Use  this  API key when accessing the Bintray API (where bottles\n\t      are stored).\n\n       HOMEBREW_BINTRAY_USER\n\t      Use this username when accessing the Bintray API (where  bottles\n\t      are stored).\n\n       HOMEBREW_BOTTLE_DOMAIN\n\t      Use  the\tspecified  URL as the download mirror for bottles. For\n\t      example, HOMEBREW_BOTTLE_DOMAIN=http://localhost:8080 will cause\n\t      all  bottles to download from the prefix http://localhost:8080/.\n\n\t      Default:\t  macOS:     https://homebrew.bintray.com/,\tLinux:\n\t      https://linuxbrew.bintray.com/.\n\n       HOMEBREW_BREW_GIT_REMOTE\n\t      Use the specified URL as the Homebrew/brew git(1) remote.\n\n\t      Default: https://github.com/Homebrew/brew.\n\n       HOMEBREW_BROWSER\n\t      Use this as the browser when opening project homepages.\n\n\t      Default: $BROWSER or the OS's default browser.\n\n       HOMEBREW_CACHE\n\t      Use the specified directory as the download cache.\n\n\t      Default:\t   macOS:     $HOME/Library/Caches/Homebrew,\tLinux:\n\t      $XDG_CACHE_HOME/Homebrew or $HOME/.cache/Homebrew.\n\n       HOMEBREW_CASK_OPTS\n\t      Options which should be used for all cask commands.  All\t--*dir\n\t      options,\t  --language,\t--require-sha,\t --no-quarantine   and\n\t      --no-binaries are supported. For example, you  might  add  some-\n\t      thing like the following to your ~/.profile, ~/.bash_profile, or\n\t      ~/.zshenv:\n\n       export\t    HOMEBREW_CASK_OPTS='--appdir=~/Applications        --font-\n       dir=/Library/Fonts'\n\n       HOMEBREW_CLEANUP_MAX_AGE_DAYS\n\t      Cleanup all cached files older than this many days.\n\n\t      Default: 120.\n\n       HOMEBREW_COLOR\n\t      If set, force colour output on non-TTY outputs.\n\n       HOMEBREW_CORE_GIT_REMOTE\n\t      Use  the\tspecified  URL\tas  the  Homebrew/homebrew-core git(1)\n\t      remote.\n\n\t      Default:\t  macOS:    https://github.com/Homebrew/homebrew-core,\n\t      Linux: https://github.com/Homebrew/linuxbrew-core.\n\n       HOMEBREW_CURLRC\n\t      If  set, do not pass --disable when invoking curl(1), which dis-\n\t      ables the use of curlrc.\n\n       HOMEBREW_CURL_RETRIES\n\t      Pass the given retry count to --retry when invoking curl(1).\n\n\t      Default: 3.\n\n       HOMEBREW_CURL_VERBOSE\n\t      If set, pass --verbose when invoking curl(1).\n\n       HOMEBREW_DEVELOPER\n\t      If set, tweak behaviour to be more relevant for Homebrew\tdevel-\n\t      opers  (active or budding) by e.g. turning warnings into errors.\n\n       HOMEBREW_DISABLE_LOAD_FORMULA\n\t      If set, refuse to load formulae. This is\tuseful\twhen  formulae\n\t      are not trusted (such as in pull requests).\n\n       HOMEBREW_DISPLAY\n\t      Use this X11 display when opening a page in a browser, for exam-\n\t      ple with brew home. Primarily useful on Linux.\n\n\t      Default: $DISPLAY.\n\n       HOMEBREW_DISPLAY_INSTALL_TIMES\n\t      If set, print install times for each formula at the end  of  the\n\t      run.\n\n       HOMEBREW_EDITOR\n\t      Use this editor when editing a single formula, or several formu-\n\t      lae in the same directory.\n\n\t      Note: brew edit will open all of Homebrew as discontinuous files\n\t      and directories. Visual Studio Code can handle this correctly in\n\t      project mode, but many editors will do strange  things  in  this\n\t      case.\n\n\t      Default: $EDITOR or $VISUAL.\n\n       HOMEBREW_FAIL_LOG_LINES\n\t      Output this many lines of output on formula system failures.\n\n\t      Default: 15.\n\n       HOMEBREW_FORBIDDEN_LICENSES\n\t      A  space-separated  list\tof  licenses.  Homebrew will refuse to\n\t      install a formula if that formula or any of its dependencies has\n\t      a license on this list.\n\n       HOMEBREW_FORCE_BREWED_CURL\n\t      If  set, always use a Homebrew-installed curl(1) rather than the\n\t      system version. Automatically set if the system version of  curl\n\t      is too old.\n\n       HOMEBREW_FORCE_BREWED_GIT\n\t      If  set,\talways use a Homebrew-installed git(1) rather than the\n\t      system version. Automatically set if the system version  of  git\n\t      is too old.\n\n       HOMEBREW_FORCE_HOMEBREW_ON_LINUX\n\t      If  set, running Homebrew on Linux will use URLs for macOS. This\n\t      is useful when merging pull requests for macOS while on Linux.\n\n       HOMEBREW_FORCE_VENDOR_RUBY\n\t      If set, always use Homebrew's vendored, relocatable Ruby version\n\t      even if the system version of Ruby is new enough.\n\n       HOMEBREW_GITHUB_API_PASSWORD\n\t      Use  this  password  for authentication with the GitHub API, for\n\t      features such as brew search. We strongly recommend using  HOME-\n\t      BREW_GITHUB_API_TOKEN instead.\n\n       HOMEBREW_GITHUB_API_TOKEN\n\t      Use  this personal access token for the GitHub API, for features\n\t      such   as   brew\t  search.    You    can    create    one    at\n\t      https://github.com/settings/tokens.  If  set,  GitHub will allow\n\t      you a greater number of API requests. For more information, see:\n\t      https://docs.github.com/en/rest/over-\n\t      view/resources-in-the-rest-api#rate-limiting.\n\n\t      Note: Homebrew  doesn't  require\tpermissions  for  any  of  the\n\t      scopes,  but some developer commands may require additional per-\n\t      missions.\n\n       HOMEBREW_GITHUB_API_USERNAME\n\t      Use this username for authentication with the  GitHub  API,  for\n\t      features\tsuch as brew search. We strongly recommend using HOME-\n\t      BREW_GITHUB_API_TOKEN instead.\n\n       HOMEBREW_GIT_EMAIL\n\t      Set the Git author and committer name to this value.\n\n       HOMEBREW_GIT_NAME\n\t      Set the Git author and committer email to this value.\n\n       HOMEBREW_INSTALL_BADGE\n\t      Print this text before the installation summary of each success-\n\t      ful build.\n\n\t      Default: The \"Beer Mug\" emoji.\n\n       HOMEBREW_LIVECHECK_WATCHLIST\n\t      Use  this file to get the list of default Formulae to check when\n\t      no Formula argument is passed to brew livecheck\n\n\t      Default: $HOME/.brew_livecheck_watchlist.\n\n       HOMEBREW_LOGS\n\t      Use the specified directory to store log files.\n\n\t      Default:\t   macOS:     $HOME/Library/Logs/Homebrew,\tLinux:\n\t      $XDG_CACHE_HOME/Homebrew/Logs or $HOME/.cache/Homebrew/Logs.\n\n       HOMEBREW_MAKE_JOBS\n\t      Use this value as the number of parallel jobs to run when build-\n\t      ing with make(1).\n\n\t      Default: The number of available CPU cores.\n\n       HOMEBREW_NO_ANALYTICS\n\t      If set, do not send analytics. See: https://docs.brew.sh/Analyt-\n\t      ics.\n\n       HOMEBREW_NO_AUTO_UPDATE\n\t      If set, do not automatically update before running brew install,\n\t      brew upgrade or brew tap.\n\n       HOMEBREW_NO_BOTTLE_SOURCE_FALLBACK\n\t      If set, fail on the failure of installation from a bottle rather\n\t      than falling back to building from source.\n\n       HOMEBREW_NO_COLOR\n\t      If set, do not print text with colour added.\n\n\t      Default: $NO_COLOR.\n\n       HOMEBREW_NO_COMPAT\n\t      If set, disable all use of legacy compatibility code.\n\n       HOMEBREW_NO_EMOJI\n\t      If  set,\tdo  not  print\tHOMEBREW_INSTALL_BADGE on a successful\n\t      build.\n\n\t      Note: Only tries to print emoji on OS X Lion or newer.\n\n       HOMEBREW_NO_GITHUB_API\n\t      If set, do not use the GitHub API, e.g. for searches or fetching\n\t      relevant issues on a failed install.\n\n       HOMEBREW_NO_INSECURE_REDIRECT\n\t      If set, forbid redirects from secure HTTPS to insecure HTTP.\n\n\t      Note:  While  ensuring  your downloads are fully secure, this is\n\t      likely to cause from-source SourceForge, some GNU & GNOME  based\n\t      formulae to fail to download.\n\n       HOMEBREW_NO_INSTALL_CLEANUP\n\t      If set, brew install, brew upgrade and brew reinstall will never\n\t      automatically cleanup installed/upgraded/reinstalled formulae or\n\t      all formulae every 30 days.\n\n       HOMEBREW_PRY\n\t      If set, use Pry for the brew irb command.\n\n       HOMEBREW_SKIP_OR_LATER_BOTTLES\n\t      If  set  with  HOMEBREW_DEVELOPER, do not use bottles from older\n\t      versions of macOS. This is useful in development\ton  new  macOS\n\t      versions.\n\n       HOMEBREW_SVN\n\t      Use this as the svn(1) binary.\n\n\t      Default: A Homebrew-built Subversion (if installed), or the sys-\n\t      tem-provided binary.\n\n       HOMEBREW_TEMP\n\t      Use this path as the temporary directory for building  packages.\n\t      Changing\tthis  may be needed if your system temporary directory\n\t      and Homebrew prefix are on different volumes, as macOS has trou-\n\t      ble  moving symlinks across volumes when the target does not yet\n\t      exist. This issue typically occurs when using FileVault or  cus-\n\t      tom SSD configurations.\n\n\t      Default: macOS: /private/tmp, Linux: /tmp.\n\n       HOMEBREW_UPDATE_REPORT_ONLY_INSTALLED\n\t      If  set, brew update only outputs updates to installed software.\n\n       HOMEBREW_UPDATE_TO_TAG\n\t      If set, always use the latest stable tag (even if developer com-\n\t      mands have been run).\n\n       HOMEBREW_VERBOSE\n\t      If set, always assume --verbose when running commands.\n\n       HOMEBREW_DEBUG\n\t      If set, always assume --debug when running commands.\n\n       HOMEBREW_VERBOSE_USING_DOTS\n\t      If  set,\tverbose  output  will  print  a  . no more than once a\n\t      minute. This can be useful to avoid long-running\tHomebrew  com-\n\t      mands being killed due to no output.\n\n       all_proxy\n\t      Use  this SOCKS5 proxy for curl(1), git(1) and svn(1) when down-\n\t      loading through Homebrew.\n\n       ftp_proxy\n\t      Use this FTP proxy for curl(1), git(1) and svn(1) when download-\n\t      ing through Homebrew.\n\n       http_proxy\n\t      Use  this  HTTP  proxy for curl(1), git(1) and svn(1) when down-\n\t      loading through Homebrew.\n\n       https_proxy\n\t      Use this HTTPS proxy for curl(1), git(1) and svn(1)  when  down-\n\t      loading through Homebrew.\n\n       no_proxy\n\t      A  comma-separated  list\tof hostnames and domain names excluded\n\t      from proxying by curl(1), git(1)\tand  svn(1)  when  downloading\n\t      through Homebrew.\n\n       SUDO_ASKPASS\n\t      When  this variable is set, the -A option is passed when calling\n\t      sudo(8)\n\nUSING HOMEBREW BEHIND A PROXY\n       Set the http_proxy, https_proxy, all_proxy, ftp_proxy  and/or  no_proxy\n       environment variables documented above.\n\n       For example, to use an unauthenticated HTTP or SOCKS5 proxy:\n\n\n\n\t   export http_proxy=http://$HOST:$PORT\n\n\t   export all_proxy=socks5://$HOST:$PORT\n\n\n\n       And for an authenticated HTTP proxy:\n\n\n\n\t   export http_proxy=http://$USER:$PASSWORD@$HOST:$PORT\n\n\n\nSEE ALSO\n       Homebrew Documentation: https://docs.brew.sh\n\n       Homebrew API: https://rubydoc.brew.sh\n\n       git(1), git-log(1)\n\nAUTHORS\n       Homebrew's Project Leader is Mike McQuaid.\n\n       Homebrew's Project Leadership Committee is Misty De Meo, Shaun Jackman,\n       Jonathan Chang, Sean Molenaar and Markus Reiter.\n\n       Homebrew's Technical Steering Committee is Michka Popoff,  FX  Coudert,\n       Markus Reiter, Misty De Meo and Mike McQuaid.\n\n       Homebrew/brew's\tLinux  maintainers  are  Michka Popoff, Shaun Jackman,\n       Dawid Dziurla, Issy Long and Maxim Belkin.\n\n       Homebrew's other  current  maintainers  are  Claudia  Pellegrino,  Zach\n       Auten,  Rui  Chen, Vitor Galvao, Caleb Xu, Gautham Goli, Steven Peters,\n       Bo  Anderson,  William  Woodruff,  Igor\tKapkov,  Sam  Ford,  Alexander\n       Bayandin,  Izaak  Beekman, Eric Knibbe, Viktor Szakats, Thierry Moisan,\n       Steven Peters, Tom Schoonjans, Issy Long, CoreCode, Randall, Rylan Pol-\n       ster, SeekingMeaning, William Ma and Dustin Rodrigues.\n\n       Former maintainers with significant contributions include Jan Viljanen,\n       JCount, commitay, Dominyk Tiller,  Tim  Smith,  Baptiste  Fontaine,  Xu\n       Cheng,  Martin Afanasjew, Brett Koonce, Charlie Sharpsteen, Jack Nagel,\n       Adam Vandenberg,  Andrew  Janke,  Alex  Dunn,  neutric,\tTomasz\tPajor,\n       Uladzislau  Shablinski,\tAlyssa\tRoss,  ilovezfs, Chongyu Zhu and Home-\n       brew's creator: Max Howell.\n\nBUGS\n       See our issues on GitHub:\n\n       Homebrew/brew\n\t      https://github.com/Homebrew/brew/issues\n\n       Homebrew/homebrew-core\n\t      https://github.com/Homebrew/homebrew-core/issues\n\n       Homebrew/homebrew-cask\n\t      https://github.com/Homebrew/homebrew-cask/issues\n\n\n\n\nHomebrew\t\t\tSeptember 2020\t\t\t       BREW(1)\n",
   "tldr_summary": "# brew\n\n> The Homebrew package manager for Linux.\n\n- Search for available formulas:\n\n`brew search {{text}}`\n\n- Install the latest stable version of a formula (use `--devel` for development versions):\n\n`brew install {{formula}}`\n\n- List all installed formulae:\n\n`brew list`\n\n- Upgrade an installed formula (if no formula name is given, all installed formulae are upgraded):\n\n`brew upgrade {{formula}}`\n\n- Fetch the newest version of Linuxbrew and of all formulae from GitHub:\n\n`brew update`\n\n- Show formulae that have a more recent version available:\n\n`brew outdated`\n\n- Display information about a formula (version, installation path, dependencies, etc.):\n\n`brew info {{formula}}`\n\n- Check the local Linuxbrew installation for potential problems:\n\n`brew doctor`\n"
 },
 {
   "command": "lvcreate",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lvcreate\n\n> Creates a logical volume in an existing volume group.\n> A volume group is a collection of logical and physical volumes.\n\n- Create a logical volume of 10 gigabytes in the volume group vg1:\n\n`lvcreate -L {{10G}} {{vg1}}`\n\n- Create a 1500 megabyte linear logical volume named mylv in the volume group vg1:\n\n`lvcreate -L {{1500}} -n {{mylv}} {{vg1}}`\n\n- Create a logical volume called mylv that uses 60% of the total space in volume group vg1:\n\n`lvcreate -l {{60%VG}} -n {{mylv}} {{vg1}}`\n\n- Create a logical volume called mylv that uses all of the unallocated space in the volume group vg1:\n\n`lvcreate -l {{100%FREE}} -n {{mylv}} {{vg1}}`\n"
 },
 {
   "command": "mac2unix",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mac2unix\n\n> Change macOS-style line endings to Unix-style.\n> Replaces LF with CR.\n\n- Change the line endings of a file:\n\n`mac2unix {{filename}}`\n\n- Create a copy with Unix-style line endings:\n\n`mac2unix -n {{filename}} {{new_filename}}`\n"
 },
 {
   "command": "hwclock",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# hwclock\n\n> Used for reading or changing the hardware clock. Usually requires root.\n\n- Display the current time as reported by the hardware clock:\n\n`hwclock`\n\n- Write the current software clock time to the hardware clock (sometimes used during system setup):\n\n`hwclock --systohc`\n\n- Write the current hardware clock time to the software clock:\n\n`hwclock --hctosys`\n"
 },
 {
   "command": "pacman4console",
   "doc_url": "https://github.com/YoctoForBeaglebone/pacman4console",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - YoctoForBeaglebone/pacman4console: Console based PacMan Game\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYoctoForBeaglebone\n\n/\n\npacman4console\n\n\n\n\n\n\n\n    Watch\n \n      4\n    \n\n\n\n\n      Star\n\n\n      35\n    \n\n\n\n\n          Fork\n\n\n        7\n      \n\n\n\n\n\n        Console based PacMan Game\n      \n\n\n\n            GPL-2.0 License\n        \n\n\n\n\n35\n        stars\n \n\n7\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n0\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n0\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n \n \nGit stats\n\n\n\n\n\n18\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\nLevels\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING\n\n\n \n\n\n \n\n\n\n\n\n\n\nChangeLog\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\npacman.c\n\n\n \n\n\n \n\n\n\n\n\n\n\npacman.h\n\n\n \n\n\n \n\n\n\n\n\n\n\npacmanedit.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nscreenshot.png\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\nPacman For Console\nOkay, so basically, I got tired of enabling flash on my browser so that I could\nplay Pacman.  That, and I was extremely bored one night.  So I decided to make\nmy own Pacman... for Console.\nLicensing Information\nSee COPYING for details on the GNU/GPL version 2.\nCompile/Install/Run\nTo make... gee... let's see... type make.\nTo install... type make install.\nTo run... type pacman [level_#]          where # is 1-9, for a premade level,\nor      type pacmac [level_file_name]  for a custom level you made.\nTo uninstall... type make uninstall.\ni.e.:\n\nmake && su -c \"make install\"\npacman 3                                           # Start @ level 3\npacman /usr/local/share/pacman/Levels/level07.dat  # Play only level 7\necho \":-( I don't like it.\" && make uninstall      # Uninstall :-(\n\n\nThe ASCII art\n\nC\t-\tPacman - That's you.\n&\t-\tGhosts - Boo.\n.\t-\tPellet - Yummy. Collect all of them to pass to the next level.\n*\t-\tPower pellet - Makes you invincible for a short while.\nWall - No one can walk through it.\nBlocker - A.K.A. Ghost wall. Only the Ghosts can walk through this.\n\n\n13 Basic Playing Rules\nIn case you don't know the rules of Pacman (rules I programmed in), here are\nmost of them:\n\nPacman must collect all the pellets of food in the maze. 1 point per pellet.\nBig pellets make Pacman invincible for a short amount of time.\nIf Pacman touches a ghost without being invincible, you die and lose 1 life.\nIf Pacman touches a ghost while invincible, the ghost is sent back to his\nstarting point.\nPoints are awarded for each ghost eaten in a row while invincible: 20, 40,\n80, 160 (10*2^x).\nPacman cannot go through the Ghost Walls (Blockers).\nGhosts, cannot turn completely around unless there is no other option.\nWhile Pacman is invincible, Ghosts will be a bit slower and tend to stay\naway from him.\nWhile Pacman is NOT invincible, Ghosts will tend to come toward him.\nPacman starts with 3 extra lives, once all three are gone, the game is\nover.\nExtra lives are awarded at 1000 points, 2000, 4000, 8000... (500*2^[x]).\nIf any character reaches a border of the maze, he will be transported to\nthe opposite side.\nEach character can only go in one X or Y direction at a time.\n\nThe keys used are UP, DOWN, LEFT, RIGHT or W, S, A, D.\nTo make your own levels, see Levels/README.\nContact Information\nSend comments and levels you have made to doctormike@gmail.com.\nThere is a homepage.\n\n\n\n\n\n\n\n\nAbout\n\n      Console based PacMan Game\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-2.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\nNo releases published\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\nC\n91.1%\n\n\n\n\n\nMakefile\n4.4%\n\n\n\n\n\nPerl\n2.7%\n\n\n\n\n\nC++\n1.8%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# pacman4console\n\n> A text-based console game inspired by the original Pacman.\n> More information: <https://github.com/YoctoForBeaglebone/pacman4console>.\n\n- Start a game at Level 1:\n\n`pacman4console`\n\n- Start a game on a certain level (there are nine official levels):\n\n`pacman4console --level={{level_number}}`\n\n- Start the pacman4console level editor, saving to a specified text file:\n\n`pacman4consoleedit {{path/to/level_file}}`\n\n- Play a custom level:\n\n`pacman4console --level={{path/to/level_file}}`\n"
 },
 {
   "command": "compgen",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# compgen\n\n> A built-in command for auto-completion in bash, which is called on pressing TAB key twice.\n\n- List all commands that you could run:\n\n`compgen -c`\n\n- List all aliases:\n\n`compgen -a`\n\n- List all functions that you could run:\n\n`compgen -A function`\n\n- Show shell reserved key words:\n\n`compgen -k`\n\n- See all available commands/aliases starting with 'ls':\n\n`compgen -ac {{ls}}`\n"
 },
 {
   "command": "eval",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# eval\n\n> Execute arguments as a single command in the current shell and return its result.\n\n- Call `echo` with the \"foo\" argument:\n\n`eval \"{{echo foo}}\"`\n\n- Set a variable in the current shell:\n\n`eval \"{{foo=bar}}\"`\n"
 },
 {
   "command": "apt-key",
   "doc_url": "https://host.tld/filename.key",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apt-key\n\n> Key management utility for the APT Package Manager on Debian and Ubuntu.\n\n- List trusted keys:\n\n`apt-key list`\n\n- Add a key to the trusted keystore:\n\n`apt-key add {{public_key_file.asc}}`\n\n- Delete a key from the trusted keystore:\n\n`apt-key del {{key_id}}`\n\n- Add a remote key to the trusted keystore:\n\n`wget -qO - {{https://host.tld/filename.key}} | apt-key add -`\n\n- Add a key from keyserver with only key id:\n\n`apt-key adv --keyserver {{pgp.mit.edu}} --recv {{KEYID}}`\n"
 },
 {
   "command": "progress",
   "doc_url": "https://github.com/Xfennec/progress",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - Xfennec/progress: Linux tool to show progress for cp, mv, dd, ... (formerly known as cv)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXfennec\n\n/\n\nprogress\n\n\n\n\n\n\n\n    Watch\n \n      128\n    \n\n\n\n\n      Star\n\n\n      5.1k\n    \n\n\n\n\n          Fork\n\n\n        262\n      \n\n\n\n\n\n        Linux tool to show progress for cp, mv, dd, ... (formerly known as cv)\n      \n\n\n\n            GPL-3.0 License\n        \n\n\n\n\n5.1k\n        stars\n \n\n262\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n31\n \n\n\n\nPull requests\n13\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n18\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nXfennec\n\nbump version to 0.15\n\n\n\n…\n\n\n\nb56ae2b\n\nJun 8, 2020\n\n\n\n\n\nbump version to 0.15\n\n\nb56ae2b\n\n\n\nGit stats\n\n\n\n\n\n151\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\n.travis.yml\n\n\n \n\n\n \n\n\n\n\n\n\n\nLICENSE\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\ncapture.png\n\n\n \n\n\n \n\n\n\n\n\n\n\nhlist.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nhlist.h\n\n\n \n\n\n \n\n\n\n\n\n\n\nprogress.1\n\n\n \n\n\n \n\n\n\n\n\n\n\nprogress.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nprogress.h\n\n\n \n\n\n \n\n\n\n\n\n\n\nsizes.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nsizes.h\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\nprogress - Coreutils Progress Viewer \nWhat is it?\nThis tool can be described as a Tiny, Dirty, Linux-and-OSX-Only C command\nthat looks for coreutils basic commands (cp, mv, dd, tar, gzip/gunzip,\ncat, etc.) currently running on your system and displays the\npercentage of copied data. It can also show estimated time and throughput,\nand provides a \"top-like\" mode (monitoring).\n\n(After many requests: the colors in the shell come from powerline-shell. Try it, it's cool.)\nFormerly known as cv (Coreutils Viewer).\nHow do you install it?\nOn deb-based systems (Debian, Ubuntu, Mint, etc.) run:\napt install progress\n\nOn rpm-based systems (Red Hat, CentOS, SUSE, etc.), run:\nyum install progress\n\nOn macOS, with homebrew, run:\nbrew install progress\n\nOn macOS, with MacPorts, run:\nport install progress\n\nHow do you build it from source?\nmake && make install\n\nIt depends on library ncurses, you may have to install corresponding packages (may be something like 'libncurses5-dev' or 'ncurses-devel').\nHow do you run it?\nJust launch the binary, progress.\nWhat can I do with it?\nA few examples. You can:\n\n\nmonitor all current and upcoming instances of coreutils commands in\na simple window:\n  watch progress -q\n\n\n\nsee how your download is progressing:\n  watch progress -wc firefox\n\n\n\nlook at your Web server activity:\n  progress -c httpd\n\n\n\nlaunch and monitor any heavy command using $!:\n  cp bigfile newfile & progress -mp $!\n\n\n\nand much more.\nHow does it work?\nIt simply scans /proc for interesting commands, and then looks at\ndirectories fd and fdinfo to find opened files and seek positions,\nand reports status for the largest file.\nIt's very light, and compatible with virtually any command.\n\n\n\n\n\n\n\n\nAbout\n\n      Linux tool to show progress for cp, mv, dd, ... (formerly known as cv)\n    \nTopics\n\n\n\n  monitoring\n\n\n  linux\n\n\n  coreutils\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-3.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\n\n\n18\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 21\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 10 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\nC\n89.0%\n\n\n\n\n\nRoff\n7.8%\n\n\n\n\n\nMakefile\n3.2%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# progress\n\n> Display/Monitor the progress of running coreutils.\n> More information: <https://github.com/Xfennec/progress>.\n\n- Show the progress of running coreutils:\n\n`progress`\n\n- Show the progress of running coreutils in quiet mode:\n\n`progress -q`\n\n- Launch and monitor a single long-running command:\n\n`{{command}} & progress -mp $!`\n"
 },
 {
   "command": "groupdel",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# groupdel\n\n> Delete existing user groups from the system.\n\n- Delete an existing group:\n\n`groupdel {{group_name}}`\n"
 },
 {
   "command": "pidof",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pidof\n\n> Gets the ID of a process using its name.\n\n- List all process IDs with given name:\n\n`pidof {{bash}}`\n\n- List a single process ID with given name:\n\n`pidof -s {{bash}}`\n\n- List process IDs including scripts with given name:\n\n`pidof -x {{script.py}}`\n\n- Kill all processes with given name:\n\n`kill \"$(pidof {{name}})\" `\n"
 },
 {
   "command": "mke2fs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mke2fs\n\n> Creates a Linux filesystem inside a partition.\n\n- Create an ext2 filesystem in partition 1 of device b (`sdb1`):\n\n`mkfs.ext2 {{/dev/sdb1}}`\n\n- Create an ext3 filesystem in partition 1 of device b (`sdb1`):\n\n`mkfs.ext3 {{/dev/sdb1}}`\n\n- Create an ext3 filesystem in partition 1 of device b (`sdb1`):\n\n`mkfs.ext3 {{/dev/sdb1}}`\n"
 },
 {
   "command": "lrztar",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lrztar\n\n> A wrapper for `lrzip` to simplify compression of directories.\n> See also: `tar`, `lrzuntar`, `lrunzip`.\n\n- Archive a directory with `tar`, then compress:\n\n`lrztar {{path/to/directory}}`\n\n- Same as above, with ZPAQ - extreme compression, but very slow:\n\n`lrztar -z {{path/to/directory}}`\n\n- Specify the output file:\n\n`lrztar -o {{path/to/file}} {{path/to/directory}}`\n\n- Override the number of processor threads to use:\n\n`lrztar -p {{8}} {{path/to/directory}}`\n\n- Force overwriting of existing files:\n\n`lrztar -f {{path/to/directory}}`\n"
 },
 {
   "command": "fsck",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nFSCK(8) \t\t  BSD System Manager's Manual\t\t       FSCK(8)\n\nNAME\n     fsck -- filesystem consistency check and interactive repair\n\nSYNOPSIS\n     fsck -p [-f]\n     fsck [-l maxparallel] [-q] [-y] [-n] [-d]\n\nDESCRIPTION\n     The first form of fsck preens a standard set of filesystems or the speci-\n     fied filesystems.\tIt is normally used in the script /etc/rc during auto-\n     matic reboot.  Here fsck reads the filesystem descriptor table (using\n     getfsent(3)) to determine which filesystems to check.  Only partitions\n     that have ``rw,'' ``rq'' or ``ro'' as options, and that have non-zero\n     pass number are checked.  Filesystems with pass number 1 (normally just\n     the root filesystem) are checked one at a time.  When pass 1 completes,\n     all remaining filesystems are checked, running one process per disk\n     drive.  The disk drive containing each filesystem is inferred from the\n     shortest prefix of the device name that ends in one or more digits; the\n     remaining characters are assumed to be the partition designator.  In\n     preening mode, filesystems that are marked clean are skipped.  Filesys-\n     tems are marked clean when they are unmounted, when they have been\n     mounted read-only, or when fsck runs on them successfully.\n\n     It should be noted that fsck is now essentially a wrapper that invokes\n     other fsck_XXX utilities as needed.  Currently, fsck can invoke fsck_hfs,\n     fsck_apfs, fsck_msdos, fsck_exfat, and fsck_udf.  If this underlying\n     process that fsck invokes encounters serious inconsistencies or the\n     filesystem type is not one of the above, it exits with an abnormal return\n     status and an automatic reboot will then fail.  For each corrected incon-\n     sistency one or more lines will be printed identifying the filesystem on\n     which the correction will take place, and the nature of the correction.\n\n     If sent a QUIT signal, fsck will finish the filesystem checks, then exit\n     with an abnormal return status that causes an automatic reboot to fail.\n     This is useful when you want to finish the filesystem checks during an\n     automatic reboot, but do not want the machine to come up multiuser after\n     the checks complete.\n\n     Without the -p option, fsck audits and interactively repairs inconsistent\n     conditions for filesystems.  It should be noted that some of the correc-\n     tive actions which are not correctable under the -p option will result in\n     some loss of data.  The amount and severity of data lost may be deter-\n     mined from the diagnostic output.\tIf the operator does not have write\n     permission on the filesystem fsck will default to a -n action.\n\n     The following flags are interpreted by fsck and passed along to the\n     underlying tool that it spawns.\n\n     -f \t Force fsck to check `clean' filesystems when preening.\n\n     -l \t Limit the number of parallel checks to the number specified\n\t\t in the following argument.  By default, the limit is the num-\n\t\t ber of disks, running one process per disk.  If a smaller\n\t\t limit is given, the disks are checked round-robin, one\n\t\t filesystem at a time.\n\n     -R \t Specify a particular passno number for which fsck is to\n\t\t check.  You may only specify 1 or 2.  Only those filesystems\n\t\t matching that particular passno entry (if using fstab) will\n\t\t be checked.  For more information on the passno field, see\n\t\t fstab(5).\n\n     -p \t \"Preen\" mode, described above.\n\n     -q \t Do a quick check to determine if the filesystem was unmounted\n\t\t cleanly.\n\n     -y \t Assume a yes response to all questions asked by fsck; this\n\t\t should be used with great caution as this is a free license\n\t\t to continue after essentially unlimited trouble has been\n\t\t encountered.\n\n     -n \t Assume a no response to all questions asked by fsck except\n\t\t for `CONTINUE?', which is assumed to be affirmative; do not\n\t\t open the filesystem for writing.\n\n     If no filesystems are given to fsck then a default list of filesystems is\n     read using getfsent(3).\n\n     Because of inconsistencies between the block device and the buffer cache,\n     the raw device should always be used.\n\nSEE ALSO\n     fs(5), fsck_hfs(8), fsck_apfs(8), fsck_msdos(8), getfsent(3), fstab(5,)\n     reboot(8)\n\n4th Berkeley Distribution\t May 18, 2010\t     4th Berkeley Distribution\n",
   "tldr_summary": "# fsck\n\n> Check the integrity of a filesystem or repair it. The filesystem should be unmounted at the time the command is run.\n\n- Check filesystem /dev/sda, reporting any damaged blocks:\n\n`fsck {{/dev/sda}}`\n\n- Check filesystem /dev/sda, reporting any damaged blocks and interactively letting the user choose to repair each one:\n\n`fsck -r {{/dev/sda}}`\n\n- Check filesystem /dev/sda, reporting any damaged blocks and automatically repairing them:\n\n`fsck -a {{/dev/sda}}`\n"
 },
 {
   "command": "rpcinfo",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nRPCINFO(8)\t\t  BSD System Manager's Manual\t\t    RPCINFO(8)\n\nNAME\n     rpcinfo -- report RPC information\n\nSYNOPSIS\n     rpcinfo [--rpcbvers version] [-m | -s] [host]\n     rpcinfo [--rpcbvers version] -T netid host program [version]\n     rpcinfo [--rpcbvers version] -a server address -T netid program [version]\n     rpcinfo [--rpcbvers version] -b [-T netid] program version\n     rpcinfo [--rpcbvers version] -d [-T netid] program version\n     rpcinfo -l [-T netid] [host] program version\n     rpcinfo [--rpcbvers version] --getaddr [-T netid] [host] program version\n     rpcinfo --getversaddr [-T netid] [host] program version\n     rpcinfo --indirect [-T netid] [host] program version\n     rpcinfo [--rpcbvers version] --time [-T netid] [host]\n     rpcinfo {--help | -h}\n     rpcinfo -p [host]\n     rpcinfo [-n portnum] -u host program [version]\n     rpcinfo [-n portnum] -t host program [version]\n\nDESCRIPTION\n     rpcinfo makes an RPC call to an RPC server and reports what it finds.\n     Unless otherwise specified or noted below the default rpcbind protocol\n     version is 3.  With no or only generic options, call the rpcbind dump\n     procedure on the specified host or ``localhost'' if host is not specified\n     and display the results.  For versions 3 and 4 display the program num-\n     ber, the version, the ``netid'', the universal address that the services\n     is listening on, symbolic name of the program if known, and then the\n     owner that registered the <program, version, netid, address> tuple.  For\n     version 2 of the protocol list the program, version, protocol, port, and\n     symbolic program name.  See the --summary option below for a typically\n     more useful output. rpcbind defaults the netid to ``tcp'' for the dump\n     procedure.\n\n     The program argument can be either a name or a number.\n\n     If a version is specified, rpcinfo attempts to call that version of the\n     specified program.  Otherwise, if the version is optional rpcinfo\n     attempts to find all the registered version numbers for the specified\n     program by calling version 0 (which is presumed not to exist; if it does\n     exist, rpcinfo attempts to obtain this information by calling an\n     extremely high version number instead) and attempts to call each regis-\n     tered version.\n\n     A required transport option is needed for the second and third lines of\n     the synopsis which is used to ping, i.e., call the null procedure of the\n     specified program and version. The results will be displayed on stdout.\n     If version is not specified each valid version found as described above\n     will be called.  The third synopsis will use the supplied universal\n     address over the transport specified by netid to call the null procedure\n     of the specified program in the same manner as above. In addition the\n     last two lines of the synopsis can ``ping'' the server as described in\n     the Legacy Options section below.\n\nGENERIC OPTIONS\n     --rpcbvers version\n\t     Attempt to use the supplied rpcbind version. Note some options\n\t     below are version specific and this option may be ignored. If\n\t     specifying version 2 (portmapper), netid below must be one of\n\t     ``udp'' or ``tcp''.\n\n     -T netid\n\t     Specify the netid to use. Supported netids are ``udp'', ``tcp'',\n\t     ``udp6'', and ``tcp6''.\n\n     --timeout seconds\n\t     Timeout used in creating client handles and the client calls to\n\t     rpcbind. Current default is 12 seconds.\n\n     Generic options may be supplied with any of the rpcinfo options below,\n     though some options will override their values.\n\nLEGACY OPTIONS\n     The options below imply version 2 (portmapper) rpcbind calls. They are\n     compatible with older versions of rpcinfo.\n\n     {-p | --portmap} [-T netid] [host]\n\t     Probe the portmapper on host, and print a list of all registered\n\t     RPC programs.  If host is not specified, it defaults to the value\n\t     ``localhost''.\n\n     {-u | --udpping} host program [version]\n\t     Make an RPC call to the NULL procedure of program on the speci-\n\t     fied host using UDP, and report whether a response was received.\n\n     {-t | --tcpping} host program [version]\n\t     Make an RPC call to the NULL procedure of program on the speci-\n\t     fied host using TCP, and report whether a response was received.\n\n     {-n | --portnum} portnum\n\t     Use portnum as the port number for the -t and -u options instead\n\t     of the port number given by the portmapper.\n\nOPTIONS\n     {-b | --broadcast} program version\n\t     Make an RPC multicast over INET6 to the RPCB_MULTICAST_ADDR,\n\t     ``FF02::202'', and broadcast over INET using UDP to procedure 0\n\t     of the specified program and version and report all hosts that\n\t     respond.  rpcifno will first use RPCBIND version 3 and then call\n\t     the broadcast procedure of the portmapper protocol to collect\n\t     older hosts. There is a reply cache kept so duplicates will not\n\t     be returned unless the cache fills.\n\n\t     Note that the -b option by its self is compatible with the older\n\t     portmapper.  However, specifying --rpcbvers 2 will short circuit\n\t     the rpcbind version 3 calls and only call the portmapper.\n\n     {-d | --delete} [-T netid] program version\n\t     Delete registration for the RPC service of the specified program\n\t     and version.  If the netid is specified, only unregister the\n\t     program and version over that transport.  This option can be\n\t     exercised only by the super-user or the user who registered the\n\t     the RPC service.\n\n     --getaddr [-T netid] [host] program version\n\t     Get the universal address that the client can use to contact the\n\t     program and version from host over netid.\tIf host is not speci-\n\t     fied localhost is assumed. If netid is not specified ``udp'' is\n\t     assumed. If the specified version is not available but some other\n\t     version is, return the universal address for one of those ver-\n\t     sions of the program.\n\n     --getversaddr [-T netid] [host] program version\n\t     Get the universal address that the client can use to contact the\n\t     program and version from host over netid.\tIf host is not speci-\n\t     fied localhost is assumed. If netid is not specified ``udp'' is\n\t     assumed. If the version is not available then that will be indi-\n\t     cated. This requires the remote rpcbind support version 4.\n\n     -h      Print out the synopsis of this program.\n\n     --help  Print out the synopsis and an explanation of the options.\n\n     --indirect [-T netid] [host] program version\n\t     Send a indirect call to the null procedure of program and version\n\t     on the specified host or localhost.  This requires the remote\n\t     rpcbind to support version 4.\n\n     {-l | --list} [-T netid] [host] program version\n\t     List the transports available over the transport family specified\n\t     by the netid for the given program and version on the optional\n\t     host or localhost if not specified.  Requires the remote rpcbind\n\t     to support version 4.  The default transport family is INET.\n\n     {-m | --metrics}\n\t     Print the metrics of rpcbind daemon for the specified host or\n\t     localhost if not specified.  Requires support for rpcbind ver-\n\t     sion 4 on the remote.\n\n     {-s | --summary}\n\t     Print a summary of programs registered on host or ``localhost''\n\t     if host is not specified.\tFor each program registered list any\n\t     versions followed by any transports supported by that program.\n\t     Try to list the symbolic name of the transport and the owner that\n\t     registered the program.\n\n     --time [host]\n\t     Return rpcbind's version of time on the specified host.\n\nEXAMPLES\n     To show all of the RPC services registered on the local machine use:\n\n\t   example% rpcinfo\n\n     To show all of the RPC services registered on the machine named klaxon\n     use:\n\n\t   example% rpcinfo klaxon\n\n     More usefully to show the services registered on klaxon use:\n\n\t   example% rpcinfo -s klaxon\n\n     To show all of the RPC services from an older host only running version 2\n     of rpcbind on a host named horn use:\n\n\t   example% rpcinfo -p horn\n\n     To show all machines on the local net that are running the NFS File ser-\n     vice use:\n\n\t   example% rpcinfo -b nfs 'version'\n\n     where 'version' is one of the current nfs versions of interest.\n\n     To delete the registration for version 1 of the rquotad service use:\n\n\t   example% rpcinfo -d rquotad 1\n\nSEE ALSO\n     rpc(5), rpcbind(8)\n\n     RPC Programming Guide.\n\n     RFC 1833 Binding Protocols for ONC RPC Version 2.\n\n     RFC 5665 IANA Considerations for Remote Procedure Call (RPC) Network\n     Identifiers and Universal Address Formats.\n\nBUGS\n     In summary mode the maximum number of versions and transports is 16. The\n     first 16 versions and the first 16 transports received from the server\n     are displayed and the rest is silently ignored.\n\n     In the second synopsis line, for a host that is specified as a link-local\n     INET6 address will always return ``no route to host''.\n\n     In releases prior to SunOS 3.0, the Network File System (NFS) did not\n     register itself with the portmapper; rpcinfo cannot be used to make RPC\n     calls to the NFS server on hosts running such releases.\n\nBSD\t\t\t       November 14, 2012\t\t\t   BSD\n",
   "tldr_summary": "# rpcinfo\n\n> Makes an RPC call to an RPC server and reports what it finds.\n\n- Show full table of all RPC services registered on localhost:\n\n`rpcinfo`\n\n- Show concise table of all RPC services registered on localhost:\n\n`rpcinfo -s {{localhost}}`\n\n- Display table of statistics of rpcbind operations on localhost:\n\n`rpcinfo -m`\n\n- Display list of entries of given service name (mountd) and version number (2) on a remote nfs share:\n\n`rpcinfo -l {{remote_nfs_server_ip}} {{mountd}} {{2}}`\n\n- Delete the registration for version 1 of the mountd service for all transports:\n\n`rpcinfo -d {{mountd}} {{1}}`\n"
 },
 {
   "command": "sysctl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nSYSCTL(8)\t\t  BSD System Manager's Manual\t\t     SYSCTL(8)\n\nNAME\n     sysctl -- get or set kernel state\n\nSYNOPSIS\n     sysctl [-bdehiNnoqx] name[=value] ...\n     sysctl [-bdehNnoqx] -a\n\nDESCRIPTION\n     The sysctl utility retrieves kernel state and allows processes with\n     appropriate privilege to set kernel state.  The state to be retrieved or\n     set is described using a ``Management Information Base'' (``MIB'') style\n     name, described as a dotted set of components.\n\n     The following options are available:\n\n     -A      Equivalent to -o -a (for compatibility).\n\n     -a      List all the currently available non-opaque values.  This option\n\t     is ignored if one or more variable names are specified on the\n\t     command line.\n\n     -b      Force the value of the variable(s) to be output in raw, binary\n\t     format.  No names are printed and no terminating newlines are\n\t     output.  This is mostly useful with a single variable.\n\n     -d      Print the description of the variable instead of its value.\n\n     -e      Separate the name and the value of the variable(s) with `='.\n\t     This is useful for producing output which can be fed back to the\n\t     sysctl utility.  This option is ignored if either -N or -n is\n\t     specified, or a variable is being set.\n\n     -h      Format output for human, rather than machine, readability.\n\n     -i      Ignore unknown OIDs.  The purpose is to make use of sysctl for\n\t     collecting data from a variety of machines (not all of which are\n\t     necessarily running exactly the same software) easier.\n\n     -N      Show only variable names, not their values.  This is particularly\n\t     useful with shells that offer programmable completion.  To enable\n\t     completion of variable names in zsh(1) (ports/shells/zsh), use\n\t     the following code:\n\n\t\t   listsysctls () { set -A reply $(sysctl -AN ${1%.*}) }\n\t\t   compctl -K listsysctls sysctl\n\n\t     To enable completion of variable names in tcsh(1), use:\n\n\t\t   complete sysctl 'n/*/`sysctl -Na`/'\n\n     -n      Show only variable values, not their names.  This option is use-\n\t     ful for setting shell variables.  For instance, to save the page-\n\t     size in variable psize, use:\n\n\t\t   set psize=`sysctl -n hw.pagesize`\n\n     -o      Show opaque variables (which are normally suppressed).  The for-\n\t     mat and length are printed, as well as a hex dump of the first\n\t     sixteen bytes of the value.\n\n     -q      Suppress some warnings generated by sysctl to standard error.\n\n     -X      Equivalent to -x -a (for compatibility).\n\n     -x      As -o, but prints a hex dump of the entire value instead of just\n\t     the first few bytes.\n\n     The information available from sysctl consists of integers, strings, and\n     opaque types.  The sysctl utility only knows about a couple of opaque\n     types, and will resort to hexdumps for the rest.  The opaque information\n     is much more useful if retrieved by special purpose programs such as\n     ps(1), systat(1), and netstat(1).\n\n     The string and integer information is summarized below.  For a detailed\n     description of these variable see sysctl(3).\n\n     The changeable column indicates whether a process with appropriate privi-\n     lege can change the value.  String and integer values can be set using\n     sysctl.\n\n     Name\t\t\t\t\t Type\t       Changeable\n     hw.activecpu\t\t\t\t integer       no\n     hw.busfrequency\t\t\t\t integer       no\n     hw.busfrequency_max\t\t\t integer       no\n     hw.busfrequency_min\t\t\t integer       no\n     hw.byteorder\t\t\t\t integer       no\n     hw.cacheconfig\t\t\t\t struct        no\n     hw.cachelinesize\t\t\t\t integer       no\n     hw.cachesize\t\t\t\t struct        no\n     hw.cpu64bit_capable\t\t\t integer       no\n     hw.cpufamily\t\t\t\t integer       no\n     hw.cpufrequency\t\t\t\t integer       no\n     hw.cpufrequency_max\t\t\t integer       no\n     hw.cpufrequency_min\t\t\t integer       no\n     hw.cpusubtype\t\t\t\t integer       no\n     hw.cputhreadtype\t\t\t\t integer       no\n     hw.cputype \t\t\t\t integer       no\n     hw.l1dcachesize\t\t\t\t integer       no\n     hw.l1icachesize\t\t\t\t integer       no\n     hw.l2cachesize\t\t\t\t integer       no\n     hw.l3cachesize\t\t\t\t integer       no\n     hw.logicalcpu\t\t\t\t integer       no\n     hw.logicalcpu_max\t\t\t\t integer       no\n     hw.memsize \t\t\t\t integer       no\n     hw.ncpu\t\t\t\t\t integer       no\n     hw.packages\t\t\t\t integer       no\n     hw.pagesize\t\t\t\t integer       no\n     hw.physicalcpu\t\t\t\t integer       no\n     hw.physicalcpu_max \t\t\t integer       no\n     hw.tbfrequency\t\t\t\t integer       no\n     kern.argmax\t\t\t\t integer       no\n     kern.bootargs\t\t\t\t string        no\n     kern.boottime\t\t\t\t struct        no\n     kern.clockrate\t\t\t\t struct        no\n     kern.coredump\t\t\t\t integer       yes\n     kern.corefile\t\t\t\t string        yes\n     kern.flush_cache_on_write\t\t\t integer       yes\n     kern.hostid\t\t\t\t integer       yes\n     kern.hostname\t\t\t\t string        yes\n     kern.job_control\t\t\t\t integer       no\n     kern.maxfiles\t\t\t\t integer       yes\n     kern.maxfilesperproc\t\t\t integer       yes\n     kern.maxnbuf\t\t\t\t integer       yes\n     kern.maxproc\t\t\t\t integer       yes\n     kern.maxprocperuid \t\t\t integer       yes\n     kern.maxvnodes\t\t\t\t integer       yes\n     kern.msgbuf\t\t\t\t integer       yes\n     kern.nbuf\t\t\t\t\t integer       no\n     kern.netboot\t\t\t\t integer       no\n     kern.ngroups\t\t\t\t integer       no\n     kern.nisdomainname \t\t\t string        yes\n     kern.num_files\t\t\t\t integer       no\n     kern.num_tasks\t\t\t\t integer       no\n     kern.num_taskthreads\t\t\t integer       no\n     kern.num_threads\t\t\t\t integer       no\n     kern.num_vnodes\t\t\t\t integer       no\n     kern.nx\t\t\t\t\t integer       yes\n     kern.osrelease\t\t\t\t string        no\n     kern.osrevision\t\t\t\t integer       no\n     kern.ostype\t\t\t\t string        no\n     kern.osversion\t\t\t\t string        yes\n     kern.posix1version \t\t\t integer       no\n     kern.procname\t\t\t\t string        yes\n     kern.safeboot\t\t\t\t integer       no\n     kern.saved_ids\t\t\t\t integer       no\n     kern.secure_kernel \t\t\t integer       no\n     kern.securelevel\t\t\t\t integer       yes\n     kern.singleuser\t\t\t\t integer       no\n     kern.sleeptime\t\t\t\t struct        no\n     kern.slide \t\t\t\t integer       no\n     kern.stack_depth_max\t\t\t integer       no\n     kern.stack_size\t\t\t\t integer       no\n     kern.sugid_coredump\t\t\t integer       yes\n     kern.sugid_scripts \t\t\t integer       yes\n     kern.symfile\t\t\t\t string        no\n     kern.usrstack\t\t\t\t integer       no\n     kern.usrstack64\t\t\t\t integer       no\n     kern.uuid\t\t\t\t\t string        no\n     kern.version\t\t\t\t string        no\n     kern.waketime\t\t\t\t struct        no\n     machdep.cpu.address_bits.physical\t\t integer       no\n     machdep.cpu.address_bits.virtual\t\t integer       no\n     machdep.cpu.brand\t\t\t\t integer       no\n     machdep.cpu.brand_string\t\t\t string        no\n     machdep.cpu.cache.L2_associativity \t integer       no\n     machdep.cpu.cache.linesize \t\t integer       no\n     machdep.cpu.cache.size\t\t\t integer       no\n     machdep.cpu.core_count\t\t\t integer       no\n     machdep.cpu.cores_per_package\t\t integer       no\n     machdep.cpu.extfamily\t\t\t integer       no\n     machdep.cpu.extfeature_bits\t\t integer       no\n     machdep.cpu.extfeatures\t\t\t string        no\n     machdep.cpu.extmodel\t\t\t integer       no\n     machdep.cpu.family \t\t\t integer       no\n     machdep.cpu.feature_bits\t\t\t integer       no\n     machdep.cpu.features\t\t\t string        no\n     machdep.cpu.leaf7_feature_bits\t\t integer       no\n     machdep.cpu.leaf7_features \t\t string        no\n     machdep.cpu.logical_per_package\t\t integer       no\n     machdep.cpu.max_basic\t\t\t integer       no\n     machdep.cpu.max_ext\t\t\t integer       no\n     machdep.cpu.microcode_version\t\t integer       no\n     machdep.cpu.model\t\t\t\t integer       no\n     machdep.cpu.processor_flag \t\t integer       no\n     machdep.cpu.signature\t\t\t integer       no\n     machdep.cpu.stepping\t\t\t integer       no\n     machdep.cpu.thread_count\t\t\t integer       no\n     machdep.cpu.tlb.data.large \t\t integer       no\n     machdep.cpu.tlb.data.large_level1\t\t integer       no\n     machdep.cpu.tlb.data.small \t\t integer       no\n     machdep.cpu.tlb.data.small_level1\t\t integer       no\n     machdep.cpu.tlb.inst.large \t\t integer       no\n     machdep.cpu.tlb.inst.small \t\t integer       no\n     machdep.cpu.tlb.shared\t\t\t integer       no\n     machdep.cpu.ucupdate\t\t\t integer       yes\n     machdep.cpu.vendor \t\t\t string        no\n     machdep.cpu.xsave.extended_state\t\t integer       no\n     machdep.tsc.deep_idle_rebase\t\t integer       yes\n     machdep.tsc.frequency\t\t\t integer       no\n     machdep.tsc.nanotime.generation\t\t integer       no\n     machdep.tsc.nanotime.shift \t\t integer       no\n     net.inet.ip.forwarding\t\t\t integer       yes\n     net.inet.ip.portrange.first\t\t integer       yes\n     net.inet.ip.portrange.hifirst\t\t integer       yes\n     net.inet.ip.portrange.hilast\t\t integer       yes\n     net.inet.ip.portrange.last \t\t integer       yes\n     net.inet.ip.portrange.lowfirst\t\t integer       yes\n     net.inet.ip.portrange.lowlast\t\t integer       yes\n     net.inet.ip.redirect\t\t\t integer       yes\n     net.inet.ip.ttl\t\t\t\t integer       yes\n     net.inet.udp.checksum\t\t\t integer       yes\n     net.inet.udp.maxdgram\t\t\t integer       yes\n     vm.loadavg \t\t\t\t struct        no\n     vm.swapusage\t\t\t\t struct        no\n     user.bc_base_max\t\t\t\t integer       no\n     user.bc_dim_max\t\t\t\t integer       no\n     user.bc_scale_max\t\t\t\t integer       no\n     user.bc_string_max \t\t\t integer       no\n     user.coll_weights_max\t\t\t integer       no\n     user.cs_path\t\t\t\t string        no\n     user.expr_nest_max \t\t\t integer       no\n     user.line_max\t\t\t\t integer       no\n     user.posix2_c_bind \t\t\t integer       no\n     user.posix2_c_dev\t\t\t\t integer       no\n     user.posix2_char_term\t\t\t integer       no\n     user.posix2_fort_dev\t\t\t integer       no\n     user.posix2_fort_run\t\t\t integer       no\n     user.posix2_localedef\t\t\t integer       no\n     user.posix2_sw_dev \t\t\t integer       no\n     user.posix2_upe\t\t\t\t integer       no\n     user.posix2_version\t\t\t integer       no\n     user.re_dup_max\t\t\t\t integer       no\n     user.stream_max\t\t\t\t integer       no\n     user.tzname_max\t\t\t\t integer       no\n\nFILES\n     <sys/sysctl.h>\t   definitions for top level identifiers, second level\n\t\t\t   kernel and hardware identifiers, and user level\n\t\t\t   identifiers\n     <sys/socket.h>\t   definitions for second level network identifiers\n     <sys/gmon.h>\t   definitions for third level profiling identifiers\n     <vm/vm_param.h>\t   definitions for second level virtual memory identi-\n\t\t\t   fiers\n     <netinet/in.h>\t   definitions for third level Internet identifiers\n\t\t\t   and fourth level IP identifiers\n     <netinet/icmp_var.h>  definitions for fourth level ICMP identifiers\n     <netinet/udp_var.h>   definitions for fourth level UDP identifiers\n\nEXAMPLES\n     For example, to retrieve the maximum number of processes allowed in the\n     system, one would use the following request:\n\n\t   sysctl kern.maxproc\n\n     To set the maximum number of processes allowed per uid to 1000, one would\n     use the following request:\n\n\t   sysctl kern.maxprocperuid=1000\n\n     Information about the system clock rate may be obtained with:\n\n\t   sysctl kern.clockrate\n\n     Information about the load average history may be obtained with:\n\n\t   sysctl vm.loadavg\n\n     More variables than these exist, and the best and likely only place to\n     search for their deeper meaning is undoubtedly the source where they are\n     defined.\n\nCOMPATIBILITY\n     The -w option has been deprecated and is silently ignored.\n\nSEE ALSO\n     sysctl(3), sysctl.conf(5)\n\nHISTORY\n     A sysctl utility first appeared in 4.4BSD.\n\n     In FreeBSD 2.2, sysctl was significantly remodeled.\n\nBSD\t\t\t       January 17, 2011 \t\t\t   BSD\n",
   "tldr_summary": "# sysctl\n\n> List and change kernel runtime variables.\n\n- Show all available variables and their values:\n\n`sysctl -a`\n\n- Set a changeable kernel state variable:\n\n`sysctl -w {{section.tunable}}={{value}}`\n\n- Get currently open file handlers:\n\n`sysctl fs.file-nr`\n\n- Get limit for simultaneous open files:\n\n`sysctl fs.file-max`\n\n- Apply changes from /etc/sysctl.conf:\n\n`sysctl -p`\n"
 },
 {
   "command": "cpufreq-set",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# cpufreq-set\n\n> A tool to modify CPU frequency settings.\n> The frequency value should range between the output of command `cpufreq-info -l`.\n\n- Set the CPU frequency policy of CPU 1 to \"userspace\":\n\n`sudo cpufreq-set -c {{1}} -g {{userspace}}`\n\n- Set the current minimum CPU frequency of CPU 1:\n\n`sudo cpufreq-set -c {{1}} --min {{min_frequency}}`\n\n- Set the current maximum CPU frequency of CPU 1:\n\n`sudo cpufreq-set -c {{1}} --max {{max_frequency}}`\n\n- Set the current work frequency of CPU 1:\n\n`sudo cpufreq-set -c {{1}} -f {{work_frequency}}`\n"
 },
 {
   "command": "feh",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# feh\n\n> Lightweight image viewing utility.\n\n- View images locally or using a URL:\n\n`feh {{path/to/images}}`\n\n- View images recursively:\n\n`feh --recursive {{path/to/images}}`\n\n- View images without window borders:\n\n`feh --borderless {{path/to/images}}`\n\n- Exit after the last image:\n\n`feh --cycle-once {{path/to/images}}`\n\n- Set the slideshow cycle delay:\n\n`feh --slideshow-delay {{seconds}} {{path/to/images}}`\n\n- Set your wallpaper (centered, filled, maximized, scaled or tiled):\n\n`feh --bg-{{center|fill|max|scale|tile}} {{path/to/image}}`\n"
 },
 {
   "command": "betterlockscreen",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# betterlockscreen\n\n> Simple, minimal lock screen.\n\n- Lock the screen:\n\n`betterlockscreen --lock`\n\n- Change the lock screen background:\n\n`betterlockscreen -u {{path/to/image.png}}`\n\n- Lock the screen, showing some custom text:\n\n`betterlockscreen -l pixel -t \"{{custom lock screen text}}\"`\n\n- Lock the screen, with a custom monitor off timeout in seconds:\n\n`betterlockscreen --off {{5}} -l`\n"
 },
 {
   "command": "fc-list",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "FC-LIST(1)\t\t\t\t\t\t\t    FC-LIST(1)\n\n\n\nNAME\n       fc-list - list available fonts\n\nSYNOPSIS\n       fc-list\t[ -vVh ]  [ --verbose ]  [  [ -f format ]  [ --format format ]\n       ]  [  [ -q ]  [ --quiet ]  ]  [ --version ]  [ --help ]\n\n\t[ pattern  [ element... ]   ]\n\nDESCRIPTION\n       fc-list lists fonts and styles available on the system for applications\n       using  fontconfig.   If\tany  elements  are  specified,\tonly those are\n       printed.  Otherwise family and style are printed, unless verbose output\n       is requested.\n\nOPTIONS\n       This  program  follows  the  usual  GNU\tcommand line syntax, with long\n       options starting with  two  dashes  (`-').  A  summary  of  options  is\n       included below.\n\n       -v     Print  verbose  output of the whole font pattern for each match,\n\t      or elements if any is provided.\n\n       -f     Format output according to the format specifier format.\n\n       -q     Suppress all normal output. returns 1 as the error  code\tif  no\n\t      fonts matched.\n\n       -V     Show version of the program and exit.\n\n       -h     Show summary of options.\n\n       pattern\n\t      If  this\targument  is set, only fonts matching pattern are dis-\n\t      played.\n\n       element\n\t      If set, the element property is displayed for matching fonts.\n\nEXAMPLES\n       fc-list\n\t      Lists all font faces.\n\n       fc-list :lang=hi\n\t      Lists font faces that cover Hindi.\n\n       fc-list : family style file spacing\n\t      Lists the filename and spacing value for each font  face.  ``:''\n\t      is an empty pattern that matches all fonts.\n\nSEE ALSO\n       fc-match(1)  FcFontList(3) FcPatternFormat(3) fc-cat(1) fc-cache(1) fc-\n       pattern(1) fc-query(1) fc-scan(1)\n\n       The fontconfig user's guide, in\tHTML  format:  /usr/share/doc/fontcon-\n       fig/fontconfig-user.html.\n\nAUTHOR\n       This  manual  page was written by Keith Packard <keithp@keithp.com> and\n       Josselin Mouette <joss@debian.org>.\n\n\n\n\t\t\t\t Aug 13, 2008\t\t\t    FC-LIST(1)\n",
   "tldr_summary": "# fc-list\n\n> List available fonts installed on the system.\n\n- Return a list of installed fonts in your system:\n\n`fc-list`\n\n- Return a list of installed fonts with given name:\n\n`fc-list | grep '{{DejaVu Serif}}'`\n\n- Return the number of installed fonts in your system:\n\n`fc-list | wc -l`\n"
 },
 {
   "command": "watch",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "WATCH(1)\t\t\t User Commands\t\t\t      WATCH(1)\n\n\n\nNAME\n       watch - execute a program periodically, showing output fullscreen\n\nSYNOPSIS\n       watch [options] command\n\nDESCRIPTION\n       watch  runs  command  repeatedly, displaying its output and errors (the\n       first screenfull).  This allows you to watch the program output\tchange\n       over  time.   By default, command is run every 2 seconds and watch will\n       run until interrupted.\n\nOPTIONS\n       -d, --differences [permanent]\n\t      Highlight the differences between  successive  updates.\tOption\n\t      will  read optional argument that changes highlight to be perma-\n\t      nent, allowing to see what has changed at least once since first\n\t      iteration.\n\n       -n, --interval seconds\n\t      Specify  update  interval.   The\tcommand will not allow quicker\n\t      than 0.1 second interval, in which the smaller values  are  con-\n\t      verted. Both '.' and ',' work for any locales.\n\n       -p, --precise\n\t      Make watch attempt to run command every interval seconds. Try it\n\t      with  ntptime  and  notice  how  the  fractional\tseconds  stays\n\t      (nearly) the same, as opposed to normal mode where they continu-\n\t      ously increase.\n\n       -t, --no-title\n\t      Turn off the header showing the interval, command,  and  current\n\t      time  at\tthe top of the display, as well as the following blank\n\t      line.\n\n       -b, --beep\n\t      Beep if command has a non-zero exit.\n\n       -e, --errexit\n\t      Freeze updates on command error, and exit after a key press.\n\n       -g, --chgexit\n\t      Exit when the output of command changes.\n\n       -c, --color\n\t      Interpret ANSI color and style sequences.\n\n       -x, --exec\n\t      Pass command to exec(2) instead of sh -c which reduces the  need\n\t      to use extra quoting to get the desired effect.\n\n       -h, --help\n\t      Display help text and exit.\n\n       -v, --version\n\t      Display version information and exit.\n\nEXIT STATUS\n\t      0      Success.\n\t      1      Various failures.\n\t      2      Forking the process to watch failed.\n\t      3      Replacing\tchild  process\tstdout\twith  write  side pipe\n\t\t     failed.\n\t      4      Command execution failed.\n\t      5      Closing child process write pipe failed.\n\t      7      IPC pipe creation failed.\n\t      8      Getting  child  process  return  value  with   waitpid(2)\n\t\t     failed, or command exited up on error.\n\t      other  The  watch  will  propagate  command exit status as child\n\t\t     exit status.\nNOTES\n       POSIX option processing is used (i.e., option processing stops  at  the\n       first  non-option argument).  This means that flags after command don't\n       get interpreted by watch itself.\nBUGS\n       Upon terminal resize, the screen will not be correctly repainted  until\n       the  next  scheduled update.  All --differences highlighting is lost on\n       that update as well.\n\n       Non-printing characters are stripped from program output.  Use \"cat -v\"\n       as part of the command pipeline if you want to see them.\n\n       Combining  Characters  that are supposed to display on the character at\n       the last column on the screen may display one column early, or they may\n       not display at all.\n\n       Combining  Characters  never  count as different in --differences mode.\n       Only the base character counts.\n\n       Blank lines directly after a line which ends in the last column do  not\n       display.\n\n       --precise mode doesn't yet have advanced temporal distortion technology\n       to compensate for a command that takes more than  interval  seconds  to\n       execute.   watch also can get into a state where it rapid-fires as many\n       executions of command as it can to catch up from a previous  executions\n       running longer than interval (for example, netstat taking ages on a DNS\n       lookup).\nEXAMPLES\n       To watch for mail, you might do\n\t      watch -n 60 from\n       To watch the contents of a directory change, you could use\n\t      watch -d ls -l\n       If you're only interested in files owned by user joe, you might use\n\t      watch -d 'ls -l | fgrep joe'\n       To see the effects of quoting, try these out\n\t      watch echo $$\n\t      watch echo '$$'\n\t      watch echo \"'\"'$$'\"'\"\n       To see the effect of precision time keeping, try adding -p to\n\t      watch -n 10 sleep 1\n       You can watch for your administrator to install the latest kernel with\n\t      watch uname -r\n       (Note that -p isn't guaranteed to work across  reboots,\tespecially  in\n       the face of ntpdate or other bootup time-changing mechanisms)\n\n\n\nprocps-ng\t\t\t  2018-03-03\t\t\t      WATCH(1)\n",
   "tldr_summary": "# watch\n\n> Execute a command repeatedly, and monitor the output in full-screen mode.\n\n- Monitor files in the current directory:\n\n`watch {{ls}}`\n\n- Monitor disk space and highlight the changes:\n\n`watch -d {{df}}`\n\n- Monitor \"node\" processes, refreshing every 3 seconds:\n\n`watch -n {{3}} \"{{ps aux | grep node}}\"`\n"
 },
 {
   "command": "rpm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rpm\n\n> RPM Package Manager.\n\n- Show version of httpd package:\n\n`rpm -q {{httpd}}`\n\n- List versions of all matching packages:\n\n`rpm -qa '{{mariadb*}}'`\n\n- Forcibly install a package regardless of currently installed versions:\n\n`rpm -U {{package_name.rpm}} --force`\n\n- Identify owner of a file and show version of the package:\n\n`rpm -qf {{/etc/postfix/main.cf}}`\n\n- List package-owned files:\n\n`rpm -ql {{kernel}}`\n\n- Show scriptlets from an RPM file:\n\n`rpm -qp --scripts {{package_name.rpm}}`\n\n- Show changed, missing and/or incorrectly installed files of matching packages:\n\n`rpm -Va '{{php-*}}'`\n"
 },
 {
   "command": "feedreader",
   "doc_url": "https://jangernert.github.io/FeedReader/",
   "doc_text": "\n\n\nFeedReader - RSS desktop client\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToggle navigation\n\n\n\n\nFeedReader\n\n\n\nFeatures\nInstallation\nSupport & Getting Involved\n\n\n\n\n   \n\n\nFeedReader RSS desktop client\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            \tFeedReader is a modern desktop application designed to complement existing web-based RSS accounts.\n\n            \t\tIt combines all the advantages of web based services like synchronisation across all your devices with everything you expect from a modern desktop application.\n            \t\n\n\n\n\n\nFeatures\nFeedReader works with\n\n\n\n\nFeedbin\n\n\nA fast, simple service that delivers a great reading experience.\n\n\n\n\nfeedly\n\n\nOne of the most popular online RSS services available.\n\n\n\n\nFreshRSS\n\n\nA free, self-hostable aggregator. Probably the best, according to the develpers.\n\n\n\n\n\n\nInoReader\n\n\nPopular alternative to feedly with similar features.\n\n\n\n\nLocal RSS\n\n\nNo online account or server needed. All data on your own harddrive.\n\n\n\n\nNextcloud\n\n\nSelf hosted cloud that can do RSS and much, much more.\n\n\n\n\n\n\nThe Old Reader\n\n\nWelcome to the ultimate social RSS reader for The Open Web.\n\n\n\n\nTiny Tiny RSS\n\n\nSelf hosted powerful but lightweight RSS reader.\n\n\n\n\nPush to Read-it-later\n\n\n\n\nInstapaper\n\n\nSave Anything. Read Anywhere.\n\n\n\n\nPocket\n\n\nThe world’s leading save-for-later service.\n\n\n\n\nWallabag\n\n\nSave the web, freely.\n\n\n\nShare with others\n\n\n\n\nEmail\n\n\nShare via email right from FeedReader.\n\n\n\n\nTelegram\n\n\nShare articles to your friends and groups easly from FeedReader.\n\n\n\n\nTwitter\n\n\nTweet about articles.\n\n\n\nWhat makes FeedReader special?\n\n\n\n\nConsistent article formating\n\n\n Read the complete article nicely formated directly inside FeedReader and choose one of 4 themes.\n\n\n\n\nCustomizability\n\n\n FeedReader is more flexible than it might first seem. Just open up dconf-editor and start tweaking.\n\n\n\n\nDesktop notifications\n\n\n Always stay up to date. FeedReader will notify you whenever there are new articles for you.\n\n\n\n\n\n\nPodcasts\n\n\n Listen to podcasts right from within FeedReader.\n\n\n\n\nFast search and filters\n\n\n Remember that one article from last week you can’t find anymore? With FeedReader you can.\n\n\n\n\nHandy keyboard shortcuts\n\n\n Don’t like clicking? No problem! FeedReader has keyboard-shortcut’s for most of it’s actions.\n\n\n\n\n\n\nTagging\n\n\n Keep track of all your articles. Create tags to categorize and sort articles.\n\n\n\nAnd much more ...\n\n\n\nInstallation\n\n\n\nFlatpak\n\n\nManual Installation\n\n\n\n\nLatest stable FeedReader\nFeedReader is now availble as Flatpak and should be installable on all major Linux distributions that support the Flatpak Application Framework eg. Fedora, Debian, Ubuntu, elementaryOS, Arch, openSuSE, Mageia and many more.\nFor more information about Flatpak and how to use or install it for your distribution see the Flatpak webpage.\nYou will need the following packages installed:\n(names can differ depending on the distribution)\nxdg-desktop-portal\nxdg-desktop-portal-gtk\n\nThe Flatpak package is distributed using Flathub. The Flathub repository needs to be configured correctly in order to receive the latest updates. The Flathub website has a quick setup for each distribution.\nInstall the latest stable FeedReader with just one command.\nflatpak install flathub org.gnome.FeedReader\n\n\n\nRequired dependencies:\nThe packages names can differ depending on the distribution\nbuild-essential\nmeson\nninja-build\nvala (>=0.26)\npkg-config\nlibgirepository1.0-dev\nlibgtk-3-dev (>= 3.22)\nlibsoup2.4-dev\nlibjson-glib-dev\nlibwebkit2gtk-4.0-dev (or 3.0\nlibsqlite3-dev\nlibsecret-1-dev\nlibnotify-dev\nlibxml2-dev\nlibunity-dev (optional)\nlibrest-dev\nlibgee-0.8-dev\nlibgstreamer1.0-dev\nlibgstreamer-plugins-base1.0-dev (gstreamer-pbutils-1.0)\nlibgoa-1.0-dev (>= 3.20)\nlibcurl-dev\nlibpeas-dev\n\n1 - Navigate to the directory which contains the source and run meson to generate the required build-files:\nmeson -C builddir --prefix=/usr\n\n2 - Compile the source-code and install the binaries:\nsudo ninja -C builddir install\n\n\n\n\nNOTE: If you run FeedReader with the TinyTinyRSS-backend please install the \"api_feedreader\"-extension. Running FeedReader with the TinyTinyRSS-backend and without the extension is NOT supported.\n\n\n\nSupport & Getting Involved\n\n\nSupport\n\n\n\n\n                You can support the development of FeedReader over at Bountysource and throw in a few bucks at any bug you would like to be fixed or any\n                feature you would like to see implemented.\n            \n\n\nTranslation\n\n\n\n\n                Help us translate Feedreader to other languages at Weblate and join Feedreader translators team.\n            \n\n\n\n\nBugs and new features\n\n\n\n\n            The source code is available on GitHub.\n            The list of the open issues can be found here. \n            The team working on FeedReader can be reached on Gitter chat room\n\n\n\nGrabber Configuration\n\n\n\n\n                Have you encountered a feed that does only contain a small preview of the article? Then help us change that. \n                FeedReader uses Full-Text RSS site config files. \n                Which allows the application to grab the whole content of an article. If a only contains the preview of the article, then the website config file is missing or outdated.\n                You can either create a PR upstream or report that there. \n            \n\n\n\n   \n\n\n\nDesigned by Aleksandar Todorović & Bilal Elmoussaoui using the Readable Bootstrap theme. \n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# feedreader\n\n> A GUI desktop RSS client.\n> More information: <https://jangernert.github.io/FeedReader/>.\n\n- Print the count of unread articles:\n\n`feedreader --unreadCount`\n\n- Add a URL for a feed to follow:\n\n`feedreader --addFeed={{feed_url}}`\n\n- Grab a specific article using its URL:\n\n`feedreader --grabArticle={{article_url}}`\n\n- Download all images from a specific article:\n\n`feedreader --url={{feed_url}} --grabImages={{article_path}}`\n\n- Play media from a URL:\n\n`feedreader --playMedia={{article_url}}`\n"
 },
 {
   "command": "iptables",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# iptables\n\n> Program that allows configuration of tables, chains and rules provided by the Linux kernel firewall.\n\n- View chains, rules, and packet/byte counters for all tables:\n\n`sudo iptables -vnL`\n\n- Set chain policy rule:\n\n`sudo iptables -P {{chain}} {{rule}}`\n\n- Append rule to chain policy for IP:\n\n`sudo iptables -A {{chain}} -s {{ip}} -j {{rule}}`\n\n- Append rule to chain policy for IP considering protocol and port:\n\n`sudo iptables -A {{chain}} -s {{ip}} -p {{protocol}} --dport {{port}} -j {{rule}}`\n\n- Delete chain rule:\n\n`sudo iptables -D {{chain}} {{rule_line_number}}`\n\n- Save iptables configuration of a given table to a file:\n\n`sudo iptables-save -t {{tablename}} > {{path/to/iptables_file}}`\n\n- Restore iptables configuration from a file:\n\n`sudo iptables-restore < {{path/to/iptables_file}}`\n"
 },
 {
   "command": "hlint",
   "doc_url": "http://hackage.haskell.org/package/hlint",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n    hlint: Source code suggestions\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nHackage :: [Package]\n\n\n\nSearch \n\n\n\nBrowse\nWhat's new\nUpload\nUser accounts\n\n\n\nhlint: Source code suggestions\n\n      [ bsd3, development, library, program ]\n      [ Propose Tags  ]\n    \n\nHLint gives suggestions on how to improve your source code.\n\n    [Skip to Readme]\n    \n    \n\n\n\n\nVersions [faq]\n1.0.0.0, 1.0.0.1, 1.2, 1.4, 1.6, 1.6.1, 1.6.2, 1.6.3, 1.6.4, 1.6.5, 1.6.6, 1.6.7, 1.6.8, 1.6.9, 1.6.10, 1.6.11, 1.6.12, 1.6.13, 1.6.14, 1.6.15, 1.6.16, 1.6.17, 1.6.18, 1.6.19, 1.6.20, 1.6.21, 1.7, 1.7.1, 1.7.2, 1.7.3, 1.8, 1.8.1, 1.8.2, 1.8.3, 1.8.4, 1.8.5, 1.8.6, 1.8.7, 1.8.8, 1.8.9, 1.8.10, 1.8.11, 1.8.12, 1.8.13, 1.8.14, 1.8.15, 1.8.16, 1.8.17, 1.8.18, 1.8.19, 1.8.20, 1.8.21, 1.8.22, 1.8.23, 1.8.24, 1.8.25, 1.8.26, 1.8.27, 1.8.28, 1.8.29, 1.8.30, 1.8.31, 1.8.32, 1.8.33, 1.8.34, 1.8.35, 1.8.36, 1.8.37, 1.8.39, 1.8.40, 1.8.41, 1.8.42, 1.8.43, 1.8.44, 1.8.45, 1.8.46, 1.8.47, 1.8.48, 1.8.49, 1.8.50, 1.8.51, 1.8.52, 1.8.53, 1.8.54, 1.8.55, 1.8.56, 1.8.57, 1.8.58, 1.8.59, 1.8.60, 1.8.61, 1.9, 1.9.1, 1.9.2, 1.9.3, 1.9.4, 1.9.5, 1.9.6, 1.9.7, 1.9.8, 1.9.9, 1.9.10, 1.9.11, 1.9.12, 1.9.13, 1.9.14, 1.9.15, 1.9.16, 1.9.17, 1.9.18, 1.9.19, 1.9.20, 1.9.21, 1.9.22, 1.9.23, 1.9.24, 1.9.25, 1.9.26, 1.9.27, 1.9.28, 1.9.29, 1.9.30, 1.9.31, 1.9.32, 1.9.33, 1.9.34, 1.9.35, 1.9.36, 1.9.37, 1.9.38, 1.9.39, 1.9.40, 1.9.41, 2.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.10, 2.0.11, 2.0.12, 2.0.13, 2.0.14, 2.0.15, 2.1, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.6, 2.1.7, 2.1.8, 2.1.9, 2.1.10, 2.1.11, 2.1.12, 2.1.13, 2.1.14, 2.1.15, 2.1.16, 2.1.17, 2.1.18, 2.1.19, 2.1.20, 2.1.21, 2.1.22, 2.1.23, 2.1.24, 2.1.25, 2.1.26, 2.2, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.2.7, 2.2.8, 2.2.9, 2.2.10, 2.2.11, 3.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.1, 3.1.1, 3.1.2, 3.1.3, 3.1.4, 3.1.5, 3.1.6, 3.2 (info)\n\n\nChange log\nCHANGES.txt\n\n\nDependencies\naeson (>=1.1.2.0), ansi-terminal (>=0.8.1), base (==4.*), bytestring, cmdargs (>=0.10), containers, cpphs (>=1.20.1), data-default (>=0.3), directory, extra (>=1.7.3), file-embed, filepath, filepattern (>=0.1.1), ghc (==8.10.*), ghc-boot, ghc-boot-th, ghc-lib-parser (==8.10.*), ghc-lib-parser-ex (>=8.10.0.16 && <8.10.1), hlint, hscolour (>=1.21), process, refact (>=0.3), text, transformers, uniplate (>=1.5), unordered-containers, utf8-string, vector, yaml (>=0.5.0) [details]\n\n\nLicense\nBSD-3-Clause\n\n\nCopyright\nNeil Mitchell 2006-2020\n\n\nAuthor\nNeil Mitchell <ndmitchell@gmail.com>\n\n\nMaintainer\nNeil Mitchell <ndmitchell@gmail.com>\n\n\n\nCategory\nDevelopment\n\n\nHome page\n\n\n              https://github.com/ndmitchell/hlint#readme\n            \n\n\n\nBug tracker\n\n\n              https://github.com/ndmitchell/hlint/issues\n            \n\n\n\nSource repo\nhead: git clone https://github.com/ndmitchell/hlint.git\n\n\nUploaded\nby NeilMitchell at 2020-09-14T15:52:22Z\n\n\nDistributions\nArch:3.2, Debian:2.1.10, Fedora:3.1.6, FreeBSD:1.9.21, LTSHaskell:2.1.11, NixOS:3.1.6, Stackage:2.1.24, openSUSE:3.1.6\n\n\nExecutables\nhlint\n\n\nDownloads\n240321 total (2844 in the last 30 days)\n\n\n Rating\n2.75 (votes: 11)\n\t  [estimated by Bayesian average]\n\n\nYour Rating\n\n\nλ\nλ\nλ\n\n\n\n\nStatus\nDocs uploaded by userBuild status unknown [no reports yet]\n\n\n\n \n\nModules[Index] [Quick Jump]LanguageHaskellLanguage.Haskell.HLint\n\n\nFlagsNameDescriptionDefaultTypethreadedBuild with support for multithreaded executionEnabledManualgplUse GPL libraries, specifically hscolourEnabledManualghc-libForce dependency on ghc-lib-parser even if GHC API in the ghc package is supportedDisabledManualhsyamlUse HsYAML instead of yamlDisabledManualUse -f <flag> to enable a flag, or -f -<flag> to disable that flag. More info\n\n\nDownloadshlint-3.2.tar.gz [browse] (Cabal source package)Package description (as included in the package)\n\n\nMaintainer's Corner\nFor package maintainers and hackage trustees\n\n\n\n            edit package information\n          \n\n\n\n\n\nReadme for hlint-3.2\n      [back to package description]\n      HLint    \nHLint is a tool for suggesting possible improvements to Haskell code. These suggestions include ideas such as using alternative functions, simplifying code and spotting redundancies. This document is structured as follows:\n\nInstalling and running HLint\nFAQ\nCustomizing the hints\nHacking HLint\n\nBugs and limitations\nBugs can be reported on the bug tracker. There are some issues that I do not intend to fix:\n\nHLint operates on each module at a time in isolation, as a result HLint does not know about types or which names are in scope. This decision is deliberate, allowing HLint to parallelise and be used incrementally on code that may not type-check. If fixities are required to parse the code properly, they can be supplied.\nThe presence of seq may cause some hints (i.e. eta-reduction) to change the semantics of a program.\nSome transformed programs may require additional type signatures, particularly if the transformations trigger the monomorphism restriction or involve rank-2 types.\nSometimes HLint will change the code in a way that causes values to default to different types, which may change the behaviour.\nHLint assumes duplicate identical expressions within in a single expression are used at the same type.\nThe RebindableSyntax extension can cause HLint to suggest incorrect changes.\nHLint can be configured with knowledge of C Pre Processor flags, but it can only see one conditional set of code at a time.\nHLint turns on many language extensions so it can parse more documents, occasionally some break otherwise legal syntax - e.g. {-#INLINE foo#-} doesn't work with MagicHash, foo $bar means something different with TemplateHaskell. These extensions can be disabled with -XNoMagicHash or -XNoTemplateHaskell etc.\nHLint doesn't run any custom preprocessors, e.g. markdown-unlit or record-dot-preprocessor, so code making use of them will usually fail to parse.\n\nInstalling and running HLint\nInstallation follows the standard pattern of any Haskell library or program: type cabal update to update your local hackage database, then cabal install hlint to install HLint.\nOnce HLint is installed, run hlint source where source is either a Haskell file, or a directory containing Haskell files. A directory will be searched recursively for any files ending with .hs or .lhs. For example, running HLint over darcs would give:\n$ hlint darcs-2.1.2\n\ndarcs-2.1.2\\src\\CommandLine.lhs:94:1: Warning: Use concatMap\nFound:\n    concat $ map escapeC s\nPerhaps:\n    concatMap escapeC s\n\ndarcs-2.1.2\\src\\CommandLine.lhs:103:1: Suggestion: Use fewer brackets\nFound:\n    ftable ++ (map (\\ (c, x) -> (toUpper c, urlEncode x)) ftable)\nPerhaps:\n    ftable ++ map (\\ (c, x) -> (toUpper c, urlEncode x)) ftable\n\ndarcs-2.1.2\\src\\Darcs\\Patch\\Test.lhs:306:1: Warning: Use a more efficient monadic variant\nFound:\n    mapM (delete_line (fn2fp f) line) old\nPerhaps:\n    mapM_ (delete_line (fn2fp f) line) old\n\n... lots more hints ...\n\nEach hint says which file/line the hint relates to, how serious an issue it is, a description of the hint, what it found, and what you might want to replace it with. In the case of the first hint, it has suggested that instead of applying concat and map separately, it would be better to use the combination function concatMap.\nThe first hint is marked as an warning, because using concatMap in preference to the two separate functions is always desirable. In contrast, the removal of brackets is probably a good idea, but not always. Reasons that a hint might be a suggestion include requiring an additional import, something not everyone agrees on, and functions only available in more recent versions of the base library.\nAny configuration can be done via .hlint.yaml file.\nBug reports: The suggested replacement should be equivalent - please report all incorrect suggestions not mentioned as known limitations.\nSuggested usage\nHLint usage tends to proceed in three distinct phases:\n\nInitially, run hlint . --report to generate report.html containing a list of all issues HLint has found. Fix those you think are worth fixing and keep repeating.\nOnce you are happy, run hlint . --default > .hlint.yaml, which will generate a settings file ignoring all the hints currently outstanding. Over time you may wish to edit the list.\nFor larger projects, add custom hints or rules.\n\nMost hints are intended to be a good idea in most circumstances, but not universally - judgement is required. When contributing to someone else's project, HLint can identify pieces of code to look at, but only make changes you consider improvements - not merely to adhere to HLint rules.\nRunning with Continuous Integration\nOn CI you might wish to run hlint . (or hlint src if you only want to check the src directory). To avoid the cost of compilation you may wish to fetch the latest HLint binary release.\nFor the CI systems Travis, Appveyor and Azure Pipelines add the line:\ncurl -sSL https://raw.github.com/ndmitchell/hlint/master/misc/run.sh | sh -s .\n\nThe arguments after -s are passed to hlint, so modify the final . if you want other arguments. This command works on Windows, Mac and Linux.\nIntegrations\nHLint is integrated into lots of places:\n\nLots of editors have HLint plugins (quite a few have more than one HLint plugin).\nHLint is part of the multiple editor plugins ghc-mod and Intero.\nHLint Source Plugin makes HLint available as a GHC plugin.\nSplint is another source plugin that doesn't require reparsing the GHC source if you are on the latest GHC version.\nCode Climate is a CI for analysis which integrates HLint.\nDanger can be used to automatically comment on pull requests with HLint suggestions.\nRestyled includes an HLint Restyler to automatically run hlint --refactor on files changed in GitHub Pull Requests.\nlpaste integrates with HLint - suggestions are shown at the bottom.\nhlint-test helps you write a small test runner with HLint.\nhint-man automatically submits reviews to opened pull requests in your repositories with inline hints.\nCircleCI has a plugin to run HLint more easily.\n\nAutomatically Applying Hints\nHLint can automatically apply some suggestions using the --refactor flag. If passed, instead of printing out the hints, HLint will output the refactored file on stdout. For --refactor to work it is necessary to have the refactor executable from the apply-refact package on your $PATH. HLint uses that tool to perform the refactoring.\nWhen using --refactor you can pass additional options to the refactor binary using --refactor-options flag. Some useful flags include -i (which replaces the original file) and -s (which asks for confirmation before performing a hint). The --with-refactor flag can be used to specify an alternative location for the refactor binary. Simple bindings for Vim, Emacs and Atom are available.\nWhile the --refactor flag is useful, not all hints support refactoring. See hints.md for which hints don't support refactoring.\nReports\nHLint can generate a lot of information, making it difficult to search for particular types of errors. The --report flag will cause HLint to generate a report file in HTML, which can be viewed interactively. Reports are recommended when there are more than a handful of hints.\nLanguage Extensions\nHLint enables most Haskell extensions, disabling only those which steal too much syntax (e.g. Arrows, TransformListComp and TypeApplications). Individual extensions can be enabled or disabled with, for instance, -XArrows, or -XNoMagicHash. The flag -XHaskell2010 selects Haskell 2010 compatibility. You can also pass them via .hlint.yaml file. For example: - arguments: [-XArrows].\nEmacs Integration\nEmacs integration has been provided by Alex Ott. The integration is similar to compilation-mode, allowing navigation between errors. The script is at hs-lint.el, and a copy is installed locally in the data directory. To use, add the following code to the Emacs init file:\n(require 'hs-lint)\n(defun my-haskell-mode-hook ()\n    (local-set-key \"\\C-cl\" 'hs-lint))\n(add-hook 'haskell-mode-hook 'my-haskell-mode-hook)\n\nGHCi Integration\nGHCi integration has been provided by Gwern Branwen. The integration allows running :hlint from the GHCi prompt. The script is at hlint.ghci, and a copy is installed locally in the data directory. To use, add the contents to your GHCi startup file.\nParallel Operation\nTo run HLint on 4 processors append the flags -j4. HLint will usually perform fastest if n is equal to the number of physical processors, which can be done with -j alone.\nIf your version of GHC does not support the GHC threaded runtime then install with the command: cabal install --flags=\"-threaded\"\nC preprocessor support\nHLint runs the cpphs C preprocessor over all input files, by default using the current directory as the include path with no defined macros. These settings can be modified using the flags --cpp-include and --cpp-define. To disable the C preprocessor use the flag -XNoCPP. There are a number of limitations to the C preprocessor support:\n\nHLint will only check one branch of an #if, based on which macros have been defined.\nAny missing #include files will produce a warning on the console, but no information in the reports.\n\nFAQ\nWhy are hints not applied recursively?\nConsider:\nfoo xs = concat (map op xs)\n\nThis will suggest eta reduction to concat . map op, and then after making that change and running HLint again, will suggest use of concatMap. Many people wonder why HLint doesn't directly suggest concatMap op. There are a number of reasons:\n\nHLint aims to both improve code, and to teach the author better style. Doing modifications individually helps this process.\nSometimes the steps are reasonably complex, by automatically composing them the user may become confused.\nSometimes HLint gets transformations wrong. If suggestions are applied recursively, one error will cascade.\nSome people only make use of some of the suggestions. In the above example using concatMap is a good idea, but sometimes eta reduction isn't. By suggesting them separately, people can pick and choose.\nSometimes a transformed expression will be large, and a further hint will apply to some small part of the result, which appears confusing.\nConsider f $ (a b). There are two valid hints, either remove the $ or remove the brackets, but only one can be applied.\n\nWhy doesn't the compiler automatically apply the optimisations?\nHLint doesn't suggest optimisations, it suggests code improvements - the intention is to make the code simpler, rather than making the code perform faster. The GHC compiler automatically applies many of the rules suggested by HLint, so HLint suggestions will rarely improve performance.\nWhy doesn't HLint know the fixity for my custom !@%$ operator?\nHLint knows the fixities for all the operators in the base library, as well as operators whose fixities are declared in the module being linted, but no others. HLint works on a single file at a time, and does not resolve imports, so cannot see fixity declarations from imported modules. You can tell HLint about fixities by putting them in a hint file named .hlint.yaml with the syntax - fixity: \"infixr 5 !@%$\". You can also use --find to automatically produce a list of fixity declarations in a file.\nWhich hints are ignored?\nSome hints are off-by-default. Some are ignored by the configuration settings. To see all hints pass --show. This feature is often useful in conjunction with --report which shows the hints in an interactive web page, allowing them to be browsed broken down by hint.\nWhich hints are used?\nHLint uses the hlint.yaml file it ships with by default (containing things like the concatMap hint above), along with the first .hlint.yaml file it finds in the current directory or any parent thereof. To include other hints, pass --hint=filename.yaml.\nWhy do I sometimes get a \"Note\" with my hint?\nMost hints are perfect substitutions, and these are displayed without any notes. However, some hints change the semantics of your program - typically in irrelevant ways - but HLint shows a warning note. HLint does not warn when assuming typeclass laws (such as == being symmetric). Some notes you may see include:\n\nIncreases laziness - for example foldl (&&) True suggests and including this note. The new code will work on infinite lists, while the old code would not. Increasing laziness is usually a good idea.\nDecreases laziness - for example (fst a, snd a) suggests a including this note. On evaluation the new code will raise an error if a is an error, while the old code would produce a pair containing two error values. Only a small number of hints decrease laziness, and anyone relying on the laziness of the original code would be advised to include a comment.\nRemoves error - for example foldr1 (&&) suggests and including the note Removes error on []. The new code will produce True on the empty list, while the old code would raise an error. Unless you are relying on the exception thrown by the empty list, this hint is safe - and if you do rely on the exception, you would be advised to add a comment.\n\nWhat is the difference between error/warning/suggestion?\nEvery hint has a severity level:\n\nError - by default only used for parse errors.\nWarning - for example concat (map f x) suggests concatMap f x as a \"warning\" severity hint. From a style point of view, you should always replace a combination of concat and map with concatMap.\nSuggestion - for example x !! 0 suggests head x as a \"suggestion\" severity hint. Typically head is a simpler way of expressing the first element of a list, especially if you are treating the list inductively. However, in the expression f (x !! 4) (x !! 0) (x !! 7), replacing the middle argument with head makes it harder to follow the pattern, and is probably a bad idea. Suggestion hints are often worthwhile, but should not be applied blindly.\n\nThe difference between warning and suggestion is one of personal taste, typically my personal taste. If you already have a well developed sense of Haskell style, you should ignore the difference. If you are a beginner Haskell programmer you may wish to focus on warning hints before suggestion hints.\nIs it possible to use pragma annotations in code that is read by ghci (conflicts with OverloadedStrings)?\nShort answer: yes, it is!\nIf the language extension OverloadedStrings is enabled, ghci may however report error messages such as:\nAmbiguous type variable ‘t0’ arising from an annotation\nprevents the constraint ‘(Data.Data.Data t0)’ from being solved.\n\nIn this case, a solution is to add the :: String type annotation. For example:\n{-# ANN someFunc (\"HLint: ignore Use fmap\" :: String) #-}\n\nSee discussion in issue #372.\nWhy do I get a parse error?\nHLint enables/disables a set of extensions designed to allow as many files to parse as possible, but sometimes you'll need to enable an additional extension (e.g. Arrows, QuasiQuotes, ...), or disable some (e.g. MagicHash) to enable your code to parse.\nYou can enable extensions by specifying additional command line arguments in .hlint.yaml, e.g.: - arguments: [-XQuasiQuotes].\nCustomizing the hints\nTo customize the hints given by HLint, create a file .hlint.yaml in the root of your project. For a suitable default run:\nhlint --default > .hlint.yaml\n\nThis default configuration contains lots of examples, including:\n\nAdding command line arguments to all runs, e.g. --color or -XNoMagicHash.\nIgnoring certain hints, perhaps within certain modules/functions.\nRestricting use of GHC flags/extensions/functions, e.g. banning Arrows and unsafePerformIO.\nAdding additional project-specific hints.\n\nYou can see the output of --default here.\nIf you wish to use the Dhall configuration language to customize HLint, there is an example and type definition.\nIgnoring hints\nSome of the hints are subjective, and some users believe they should be ignored. Some hints are applicable usually, but occasionally don't always make sense. The ignoring mechanism provides features for suppressing certain hints. Ignore directives can either be written as pragmas in the file being analysed, or in the hint files. Examples of pragmas are:\n\n{-# ANN module \"HLint: ignore\" #-} or {-# HLINT ignore #-} or {- HLINT ignore -} - ignore all hints in this module (use module literally, not the name of the module).\n{-# ANN module \"HLint: ignore Eta reduce\" #-} or {-# HLINT ignore \"Eta reduce\" #-} or {- HLINT ignore \"Eta reduce\" -} - ignore all eta reduction suggestions in this module.\n{-# ANN myFunction \"HLint: ignore\" #-} or {-# HLINT ignore myFunction #-} or {- HLINT ignore myFunction -} - don't give any hints in the function myFunction.\n{-# ANN myFunction \"HLint: error\" #-} or {-# HLINT error myFunction #-} or {- HLINT error myFunction -} - any hint in the function myFunction is an error.\n{-# ANN module \"HLint: error Use concatMap\" #-} or {-# HLINT error \"Use concatMap\" #-} or {- HLINT error \"Use concatMap\" -} - the hint to use concatMap is an error (you may also use warn or suggest in place of error for other severity levels).\n\nFor ANN pragmas it is important to put them after any import statements. If you have the OverloadedStrings extension enabled you will need to give an explicit type to the annotation, e.g. {-# ANN myFunction (\"HLint: ignore\" :: String) #-}. The ANN pragmas can also increase compile times or cause more recompilation than otherwise required, since they are evaluated by TemplateHaskell.\nFor {-# HLINT #-} pragmas GHC may give a warning about an unrecognised pragma, which can be suppressed with -Wno-unrecognised-pragmas.\nFor {- HLINT -} comments they are likely to be treated as comments in syntax highlighting, which can lead to them being overlooked.\nIgnore directives can also be written in the hint files:\n\n- ignore: {name: Eta reduce} - suppress all eta reduction suggestions.\n- ignore: {name: Eta reduce, within: [MyModule1, MyModule2]} - suppress eta reduction hints in the MyModule1 and MyModule2 modules.\n- ignore: {within: MyModule.myFunction} - don't give any hints in the function MyModule.myFunction.\n- error: {within: MyModule.myFunction} - any hint in the function MyModule.myFunction is an error.\n- error: {name: Use concatMap} - the hint to use concatMap is an error (you may also use warn or suggest in place of error for other severity levels).\n\nThese directives are applied in the order they are given, with later hints overriding earlier ones.\nYou can choose to ignore all hints with - ignore: {} then selectively enable the ones you want (e.g. - warn: {name: Use const}), but it isn't a totally smooth experience (see #747 and #748).\nFinally, hlint defines the __HLINT__ preprocessor definition (with value 1), so problematic definitions (including those that don't parse) can be hidden with:\n#ifndef __HLINT__\nfoo = ( -- HLint would fail to parse this\n#endif\n\nAdding hints\nThe hint suggesting concatMap can be defined as:\n- warn: {lhs: concat (map f x), rhs: concatMap f x}\n\nThis line can be read as replace concat (map f x) with concatMap f x. All single-letter variables are treated as substitution parameters. For examples of more complex hints see the supplied hlint.yaml file in the data directory. This hint will automatically match concat . map f and concat $ map f x, so there is no need to give eta-reduced variants of the hints. Hints may tagged with error, warn or suggest to denote how severe they are by default. In addition, hint is a synonym for suggest. If you come up with interesting hints, please submit them for inclusion.\nYou can search for possible hints to add from a source file with the --find flag, for example:\n$ hlint --find=src/Utils.hs\n-- hints found in src/Util.hs\n- warn: {lhs: \"null (intersect a b)\", rhs: \"disjoint a b\"}\n- warn: {lhs: \"dropWhile isSpace\", rhs: \"trimStart\"}\n- fixity: \"infixr 5 !:\"\n\nThese hints are suitable for inclusion in a custom hint file. You can also include Haskell fixity declarations in a hint file, and these will also be extracted. If you pass only --find flags then the hints will be written out, if you also pass files/folders to check, then the found hints will be automatically used when checking.\nHints can specify more advanced aspects, with names and side conditions. To see examples and descriptions of these features look at the default hint file and the hint interpretation module comments.\nRestricting items\nHLint can restrict what Haskell code is allowed, which is particularly useful for larger projects which wish to enforce coding standards - there is a short example in the HLint repo itself. As an example of restricting extensions:\n- extensions:\n  - default: false\n  - name: [DeriveDataTypeable, GeneralizedNewtypeDeriving]\n  - {name: CPP, within: CompatLayer}\n\nThe above block declares that GHC extensions are not allowed by default, apart from DeriveDataTypeable and GeneralizedNewtypeDeriving which are available everywhere. The CPP extension is only allowed in the module CompatLayer. Much like extensions, you can use flags to limit the GHC_OPTIONS flags that are allowed to occur. You can also ban certain functions:\n- functions:\n  - {name: nub, within: []}\n  - {name: unsafePerformIO, within: CompatLayer}\n\nThis declares that the nub function can't be used in any modules, and thus is banned from the code. That's probably a good idea, as most people should use an alternative that isn't O(n^2) (e.g. nubOrd). We also whitelist where unsafePerformIO can occur, ensuring that there can be a centrally reviewed location to declare all such instances. Finally, we can restrict the use of modules with:\n- modules:\n  - {name: [Data.Set, Data.HashSet], as: Set}\n  - {name: Control.Arrow, within: []}\n  - {name: Control.Monad.State, badidents: [modify, get, put], message: \"Use Control.Monad.State.Class instead\"}\n\nThis fragment requires that all imports of Set must be qualified Data.Set as Set, enforcing consistency. It also ensures the module Control.Arrow can't be used anywhere. It also prevents explicit imports of the modify identifier from Control.Monad.State (this is meant to allow you to prevent people from importing reexported identifiers).\nYou can customize the Note: for restricted modules, functions and extensions, by providing a message field (default: may break the code).\nHacking HLint\nContributions to HLint are most welcome, following my standard contribution guidelines. You can run the tests either from within a ghci session by typing :test or by running the standalone binary's tests via cabal run -- hlint --test or stack run -- hlint --test. After changing hints, you will need to regenerate the hints.md file with hlint --generate-summary.\nNew tests for individual hints can be added directly to source and hint files by adding annotations bracketed in <TEST></TEST> code comment blocks. As some examples:\n{-\n    Tests to check the zipFrom hint works\n\n<TEST>\nzip [1..length x] x -- zipFrom 1 x\nzip [1..length y] x\nzip [1..length x] x -- ??? @Warning\n</TEST>\n-}\n\nThe general syntax is lhs -- rhs with lhs being the expression you expect to be rewritten as rhs. The absence of rhs means you expect no hints to fire. In addition ??? lets you assert a warning without a particular suggestion, while @ tags require a specific severity -- both these features are used less commonly.\nAcknowledgements\nMany improvements to this program have been made by Niklas Broberg in response to feature requests. Additionally, many people have provided help and patches, including Lennart Augustsson, Malcolm Wallace, Henk-Jan van Tuyl, Gwern Branwen, Alex Ott, Andy Stewart, Roman Leshchinskiy, Johannes Lippmann, Iustin Pop, Steve Purcell, Mitchell Rosen and others.\n\n\n \n\n\n\n\n\n\n\n    Produced by hackage and Cabal 3.0.2.99.\n  \n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# hlint\n\n> Tool for suggesting improvements to Haskell code.\n> More information: <http://hackage.haskell.org/package/hlint>.\n\n- Display suggestions for a given file:\n\n`hlint {{path/to/file}} options`\n\n- Check all Haskell files and generate a report:\n\n`hlint {{path/to/directory}} --report`\n\n- Automatically apply most suggestions:\n\n`hlint {{path/to/file}} --refactor`\n\n- Display additional options:\n\n`hlint {{path/to/file}} --refactor-options`\n\n- Generate a settings file ignoring all outstanding hints:\n\n`hlint {{path/to/file}} --default > {{.hlint.yaml}}`\n"
 },
 {
   "command": "microcom",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# microcom\n\n> A minimalistic terminal program, used to access remote devices via a serial, CAN or telnet connection from the console.\n\n- Open a serial port using the specified baud rate:\n\n`microcom --port {{path/to/serial_port}} --speed {{baud_rate}}`\n\n- Establish a telnet connection to the specified host:\n\n`microcom --telnet {{hostname}}:{{port}}`\n"
 },
 {
   "command": "getfacl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# getfacl\n\n> Get file access control lists.\n\n- Display the file access control list:\n\n`getfacl {{path/to/file_or_directory}}`\n\n- Display the file access control list with numeric user and group IDs:\n\n`getfacl -n {{path/to/file_or_directory}}`\n\n- Display the file access control list with tabular output format:\n\n`getfacl -t {{path/to/file_or_directory}}`\n"
 },
 {
   "command": "timedatectl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# timedatectl\n\n> Control the system time and date.\n\n- Check the current system clock time:\n\n`timedatectl`\n\n- Set the local time of the system clock directly:\n\n`timedatectl set-time {{\"yyyy-MM-dd hh:mm:ss\"}}`\n\n- List available timezones:\n\n`timedatectl list-timezones`\n\n- Set the system timezone:\n\n`timedatectl set-timezone {{timezone}}`\n\n- Enable Network Time Protocol (NTP) synchronization:\n\n`timedatectl set-ntp on`\n"
 },
 {
   "command": "a2ensite",
   "doc_url": "https://manpages.debian.org/buster/apache2/a2ensite.8.en.html",
   "doc_text": "\n\n\n\na2ensite(8) — apache2 — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / apache2\n     \n     \n     \n     / a2ensite(8)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXIT STATUS\n\n\nEXAMPLES\n\n\nFILES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.4.38-3+deb10u3\n\n\nbuster-backports 2.4.46-1~bpo10+1\n\n\ntesting 2.4.46-1\n\n\nunstable 2.4.46-1\n\n\n\n\n\n\nScroll to navigation\n\n\n\nA2ENSITE(8)\nSystem Manager's Manual\nA2ENSITE(8)\n\n\n\n\nNAME¶\na2ensite, a2dissite - enable or disable an apache2 site / virtual host\n\n\nSYNOPSIS¶\na2ensite [ [-q|--quiet] site]\na2dissite [ [-q|--quiet] site]\n\n\nDESCRIPTION¶\nThis manual page documents briefly the a2ensite and a2dissite\n  commands.\na2ensite is a script that enables the specified site (which\n    contains a <VirtualHost> block) within the apache2\n    configuration. It does this by creating symlinks within\n    /etc/apache2/sites-enabled. Likewise, a2dissite disables a\n    site by removing those symlinks. It is not an error to enable a site which\n    is already enabled, or to disable one which is already disabled.\nApache treats the very first virtual host enabled specially as\n    every request not matching any actual directive is being redirected there.\n    Thus it should be called 000-default in order to sort before the\n    remaining hosts to be loaded first.\n\n\nOPTIONS¶\n\n-q, --quiet\nDon't show informative messages.\n-m, --maintmode\nEnables the maintainer mode, that is the program invocation is effectuated\n      automatically by a maintainer script. This switch should not be used by\n      end users.\n-p, --purge\nWhen disabling a module, purge all traces of the module in the internal\n      state data base.\n\n\n\nEXIT STATUS¶\na2ensite and a2dissite exit with status 0 if all sites are\n  processed successfully, 1 if errors occur, 2 if an invalid option was used.\n\n\nEXAMPLES¶\na2dissite 000-default\nDisables the default site.\n\n\nFILES¶\n\n/etc/apache2/sites-available\nDirectory with files giving information on available sites.\n/etc/apache2/sites-enabled\nDirectory with links to the files in sites-available for enabled\n      sites.\n\n\n\nSEE ALSO¶\napache2ctl(8).\n\n\nAUTHOR¶\nThis manual page was written by Stefan Fritsch <sf@debian.org> (based on\n  the a2enmod manual page by Daniel Stone <daniel@sfarc.net>) for the\n  Debian GNU/Linux distribution.\n\n\n\n\n8 June 2007\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\na2ensite.8.en.gz (from apache2 2.4.38-3+deb10u3)\n\n\n\n\nSource last updated:\n\n\n2019-10-15T19:53:42Z\n\n\n\n\nConverted to HTML:\n\n\n2020-09-01T03:18:56Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# a2ensite\n\n> Enable an Apache virtual host on Debian-based OSes.\n> More information: <https://manpages.debian.org/buster/apache2/a2ensite.8.en.html>.\n\n- Enable a virtual host:\n\n`sudo a2ensite {{virtual_host}}`\n\n- Don't show informative messages:\n\n`sudo a2ensite --quiet {{virtual_host}}`\n"
 },
 {
   "command": "lvreduce",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lvreduce\n\n> Reduce the size of a logical volume.\n\n- Reduce a volume's size to 120GB:\n\n`lvreduce --size {{120G}} {{logical_volume}}`\n\n- Reduce a volume's size by 40GB as well as the underlying filesystem:\n\n`lvreduce --size -{{40G}} -r {{logical_volume}}`\n"
 },
 {
   "command": "xvfb-run",
   "doc_url": "https://www.x.org/wiki/",
   "doc_text": "\n\n\nX.Org\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX.Org\n\n\n\n\n\n\nEdit\nPage History\nRepo Info\n\n\n\n\n\nThe X.Org project provides an open source implementation of the X Window System. The development work is being done in conjunction with the freedesktop.org community.  The X.Org Foundation is the educational non-profit corporation whose Board serves this effort, and whose Members lead this work. \nThe last full release of the entire X.Org stack was X11R7.7 - since then individual X.Org modules have been released independently as needed - see the xorg-announce archives for details of those releases, and https://www.x.org/releases/individual/ for downloads. Information about all releases is available.  (Important: If you have an older release, please see the Security page for information on security updates.)\n\n\n\nFollow X.Org on:\n\n\n\nYou may be interested in: \n\n\nDocumentation \nDevelopment-related news. \nX.Org events. \nPress releases. \nThe Annual Report on the State of the X.Org Foundation \nRelated projects. \n\nReporting problems, asking questions and getting help\n\nCheck to see if your question is answered in the FAQ.\nCheck the issues for the xorg group in the freedesktop gitlab to report bugs against X.Org. \nCheck the Xorg mailing list archives \nSend other questions or comments to the xorg mailing list. \nOr get help on XorgIRC. \n\nDevelopment\n\nThe DeveloperStart page includes information for developers along with links to per-module developer pages. \n\nMailing Lists\nOn XorgMailingLists you can find a list of X-related mailing lists hosted on lists.freedesktop.org.  More mailing lists on X Window System and related technologies along with subscription directions are available at XOrg Foundation.\nGetting X\nThe best place to get X is from your operating system or distribution vendor.  X.Org currently provides no binaries. \nThere are many Mirrors from which you can download source code to the X Window System. If you would like to be a mirror, feel free to do so and add yourself to the Mirrors page. \nDevelopment snapshots are currently on hiatus; most modules now update slowly enough that frequent snapshots aren't needed. \nSecurity\nFor security advisories please check our SecurityPage. \nPlease notify us of any security issues by sending mail to xorg_security@x.org . \nSponsorship and Donations\nThe X.Org Foundation welcomes sponsorship (both cash and in-kind), and tries hard to put the donations of sponsors to transparent good use.  The Foundation is an extremely low-overhead all-volunteer organization.  If you are interested in contributing, please see our SponsorshipPage. \nDonate via SPI Paypal:\n\nDonate via SPI Click & Pledge:\n\nDonation via check or money order:\nMake your check payable to Software in the Public Interest, Inc. and\nwrite \"X.org\" in the memo or reference field.  For more information\nincluding the mailing address, please see\nhttps://spi-inc.org/donations/\nAcknowledgements\nOur thanks go to Portland State University and\nMassachusetts Institute of Technology for\nproviding the hosting of x.org/freedesktop.org, to\nSun and HP for providing the\nx.org/freedesktop.org hardware, and to Sun,\nDealsLands, and others who have\nprovided generous financial sponsorship and in-kind support.\nOur thanks also go to the contributors to the X Window System technology over the years. Many of these are acknowledged in previous distribution release notes. \nCopying\nThe content of this wiki is licensed under the MIT License unless stated otherwise by the author of specific wiki pages.\nThis license has been selected to ease documentation sharing with the xserver source code.\n\n\n\n\n\nLast edited Mon Nov 11 10:34:33 2019\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# xvfb-run\n\n> Run a command in a virtual X server environment.\n> More information: <https://www.x.org/wiki/>.\n\n- Run the specified command in a virtual X server:\n\n`xvfb-run {{command}}`\n\n- Try to get a free server number, if the default (99) is not available:\n\n`xvfb-run --auto-servernum {{command}}`\n\n- Pass arguments to the Xvfb server:\n\n`xvfb-run --server-args \"{{-screen 0 1024x768x24}}\" {{command}}`\n"
 },
 {
   "command": "sensible-editor",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# sensible-editor\n\n> Open the default editor.\n\n- Open a file in the default editor:\n\n`sensible-editor {{file}}`\n\n- Open a file in the default editor, with the cursor at the end of the file:\n\n`sensible-editor + {{file}}`\n\n- Open a file in the default editor, with the cursor at the beginning of line 10:\n\n`sensible-editor +10 {{file}}`\n\n- Open 3 files in vertically splitted editor windows at the same time:\n\n`sensible-editor -O3 {{file_1}} {{file_2}} {{file_3}}`\n"
 },
 {
   "command": "setxkbmap",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# setxkbmap\n\n> Set the keyboard using the X Keyboard Extension.\n\n- Set the keyboard in French AZERTY:\n\n`setxkbmap {{fr}}`\n\n- Set multiple keyboard layouts, their variants and switching option:\n\n`setxkbmap -layout {{us,de}} -variant {{,qwerty}} -option {{'grp:alt_caps_toggle'}}`\n\n- Get help:\n\n`setxkbmap -help`\n\n- List all layouts:\n\n`localectl list-x11-keymap-layouts`\n\n- List variants for the layout:\n\n`localectl list-x11-keymap-variants {{de}}`\n\n- List available switching options:\n\n`localectl list-x11-keymap-options | grep grp:`\n"
 },
 {
   "command": "ip-address",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ip address\n\n> IP Address management subcommand.\n\n- List network interfaces and their associated IP addresses:\n\n`ip address`\n\n- Filter to show only active network interfaces:\n\n`ip address show up`\n\n- Display information about a specific network interface:\n\n`ip address show dev {{eth0}}`\n\n- Add an IP address to a network interface:\n\n`ip address add {{ip_address}} dev {{eth0}}`\n\n- Remove an IP address from a network interface:\n\n`ip address delete {{ip_address}} dev {{eth0}}`\n\n- Delete all IP addresses in a given scope from a network interface:\n\n`ip address flush dev {{eth0}} scope {{global|host|link}}`\n"
 },
 {
   "command": "lrzuntar",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lrzuntar\n\n> A wrapper for `lrunzip` to simplify decompression of directories.\n> See also: `lrztar`, `lrzip`.\n\n- Decompress from a file to the current directory:\n\n`lrzuntar {{path/to/archive.tar.lrz}}`\n\n- Decompress from a file to the current directory using a specific number of processor threads:\n\n`lrzuntar -p {{8}} {{path/to/archive.tar.lrz}}`\n\n- Decompress from a file to the current directory and silently overwrite items that already exist:\n\n`lrzuntar -f {{archive.tar.lrz}}`\n\n- Specify the output path:\n\n`lrzuntar -O {{path/to/directory}} {{archive.tar.lrz}}`\n\n- Delete the compressed file after decompression:\n\n`lrzuntar -D {{path/to/archive.tar.lrz}}`\n"
 },
 {
   "command": "beep",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "curs_beep(3X)\t\t\t\t\t\t\t curs_beep(3X)\n\n\n\nNAME\n       beep, flash - curses bell and screen flash routines\n\nSYNOPSIS\n       #include <curses.h>\n\n       int beep(void);\n       int flash(void);\n\nDESCRIPTION\n       The  beep  and flash routines are used to alert the terminal user.  The\n       routine beep sounds an audible alarm on the terminal, if possible; oth-\n       erwise it flashes the screen (visible bell).  The routine flash flashes\n       the screen, and if that is not possible, sounds the alert.  If  neither\n       alert is possible, nothing happens.  Nearly all terminals have an audi-\n       ble alert (bell or beep), but only some can flash the screen.\n\nRETURN VALUE\n       These routines return OK if they succeed in beeping  or\tflashing,  ERR\n       otherwise.\n\nEXTENSIONS\n       SVr4's beep and flash routines always returned OK, so it was not possi-\n       ble to tell when the beep or flash failed.\n\nPORTABILITY\n       These functions are described in the  XSI  Curses  standard,  Issue  4.\n       Like SVr4, it specifies that they always return OK.\n\nSEE ALSO\n       curses(3X)\n\n\n\n\t\t\t\t\t\t\t\t curs_beep(3X)\n",
   "tldr_summary": "# beep\n\n> A utility to beep the PC speaker.\n\n- Play a beep:\n\n`beep`\n\n- Play a beep that repeats:\n\n`beep -r {{repetitions}}`\n\n- Play a beep at a specified frequency (Hz) and duration (milliseconds):\n\n`beep -f {{frequency}} -l {{duration}}`\n\n- Play each new frequency and duration as a distinct beep:\n\n`beep -f {{frequency}} -l {{duration}} -n -f {{frequency}} -l {{duration}}`\n\n- Play the C major scale:\n\n`beep -f 262 -n -f 294 -n -f 330 -n -f 349 -n -f 392 -n -f 440 -n -f 494 -n -f 523`\n"
 },
 {
   "command": "rc-update",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rc-update\n\n> Add and remove OpenRC services to and from runlevels.\n> See also `openrc`.\n\n- List all services and the runlevels they are added to:\n\n`rc-update show`\n\n- Add a service to a runlevel:\n\n`sudo rc-update add {{service_name}} {{runlevel}}`\n\n- Delete a service from a runlevel:\n\n`sudo rc-update delete {{service_name}} {{runlevel}}`\n\n- Delete a service from all runlevels:\n\n`sudo rc-update --all delete {{service_name}}`\n"
 },
 {
   "command": "rfkill",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rfkill\n\n> Enable and disable wireless devices.\n\n- List devices:\n\n`rfkill`\n\n- Filter by columns:\n\n`rfkill -o {{ID,TYPE,DEVICE}}`\n\n- Block devices by type (e.g. bluetooth, wlan):\n\n`rfkill block {{bluetooth}}`\n\n- Unblock devices by type (e.g. bluetooth, wlan):\n\n`rfkill unblock {{wlan}}`\n\n- Output in JSON format:\n\n`rfkill -J`\n"
 },
 {
   "command": "lsscsi",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lsscsi\n\n> List SCSI devices (or hosts) and their attributes.\n\n- List all SCSI devices:\n\n`lsscsi`\n\n- List all SCSI devices with detailed attributes:\n\n`lsscsi -L`\n\n- List all SCSI devices with human readable disk capacity:\n\n`lsscsi -s`\n"
 },
 {
   "command": "hexdump",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nHEXDUMP(1)\t\t  BSD General Commands Manual\t\t    HEXDUMP(1)\n\nNAME\n     hexdump -- ASCII, decimal, hexadecimal, octal dump\n\nSYNOPSIS\n     hexdump [-bcCdovx] [-e format_string] [-f format_file] [-n length]\n\t     [-s skip] file ...\n\nDESCRIPTION\n     The hexdump utility is a filter which displays the specified files, or\n     the standard input, if no files are specified, in a user specified for-\n     mat.\n\n     The options are as follows:\n\n     -b      One-byte octal display.  Display the input offset in hexadecimal,\n\t     followed by sixteen space-separated, three column, zero-filled,\n\t     bytes of input data, in octal, per line.\n\n     -C      Canonical hex+ASCII display.  Display the input offset in hexa-\n\t     decimal, followed by sixteen space-separated, two column, hexa-\n\t     decimal bytes, followed by the same sixteen bytes in %_p format\n\t     enclosed in ``|'' characters.\n\n     -c      One-byte character display.  Display the input offset in hexadec-\n\t     imal, followed by sixteen space-separated, three column, space-\n\t     filled, characters of input data per line.\n\n     -d      Two-byte decimal display.\tDisplay the input offset in hexadeci-\n\t     mal, followed by eight space-separated, five column, zero-filled,\n\t     two-byte units of input data, in unsigned decimal, per line.\n\n     -e format_string\n\t     Specify a format string to be used for displaying data.\n\n     -f format_file\n\t     Specify a file that contains one or more newline separated format\n\t     strings.  Empty lines and lines whose first non-blank character\n\t     is a hash mark (#) are ignored.\n\n     -n length\n\t     Interpret only length bytes of input.\n\n     -o      Two-byte octal display.  Display the input offset in hexadecimal,\n\t     followed by eight space-separated, six column, zero-filled, two\n\t     byte quantities of input data, in octal, per line.\n\n     -s offset\n\t     Skip offset bytes from the beginning of the input.  By default,\n\t     offset is interpreted as a decimal number.  With a leading 0x or\n\t     0X, offset is interpreted as a hexadecimal number, otherwise,\n\t     with a leading 0, offset is interpreted as an octal number.\n\t     Appending the character b, k, m, or g to offset causes it to be\n\t     interpreted as a multiple of 512, 1024, 1048576, or 1073741824,\n\t     respectively.\n\n     -v      Cause hexdump to display all input data.  Without the -v option,\n\t     any number of groups of output lines, which would be identical to\n\t     the immediately preceding group of output lines (except for the\n\t     input offsets), are replaced with a line comprised of a single\n\t     asterisk.\n\n     -x      Two-byte hexadecimal display.  Display the input offset in hexa-\n\t     decimal, followed by eight, space separated, four column, zero-\n\t     filled, two-byte quantities of input data, in hexadecimal, per\n\t     line.\n\n     For each input file, hexdump sequentially copies the input to standard\n     output, transforming the data according to the format strings specified\n     by the -e and -f options, in the order that they were specified.\n\n   Formats\n     A format string contains any number of format units, separated by white-\n     space.  A format unit contains up to three items: an iteration count, a\n     byte count, and a format.\n\n     The iteration count is an optional positive integer, which defaults to\n     one.  Each format is applied iteration count times.\n\n     The byte count is an optional positive integer.  If specified it defines\n     the number of bytes to be interpreted by each iteration of the format.\n\n     If an iteration count and/or a byte count is specified, a single slash\n     must be placed after the iteration count and/or before the byte count to\n     disambiguate them.  Any whitespace before or after the slash is ignored.\n\n     The format is required and must be surrounded by double quote (\" \")\n     marks.  It is interpreted as a fprintf-style format string (see\n     fprintf(3)), with the following exceptions:\n\n\t   o   An asterisk (*) may not be used as a field width or precision.\n\n\t   o   A byte count or field precision is required for each ``s'' con-\n\t       version character (unlike the fprintf(3) default which prints\n\t       the entire string if the precision is unspecified).\n\n\t   o   The conversion characters ``h'', ``l'', ``n'', ``p'' and ``q''\n\t       are not supported.\n\n\t   o   The single character escape sequences described in the C stan-\n\t       dard are supported:\n\n\t\t     NUL\t\t  \\0\n\t\t     <alert character>\t  \\a\n\t\t     <backspace>\t  \\b\n\t\t     <form-feed>\t  \\f\n\t\t     <newline>\t\t  \\n\n\t\t     <carriage return>\t  \\r\n\t\t     <tab>\t\t  \\t\n\t\t     <vertical tab>\t  \\v\n\n     The hexdump utility also supports the following additional conversion\n     strings:\n\n     _a[dox]\t Display the input offset, cumulative across input files, of\n\t\t the next byte to be displayed.  The appended characters d, o,\n\t\t and x specify the display base as decimal, octal or hexadeci-\n\t\t mal respectively.\n\n     _A[dox]\t Identical to the _a conversion string except that it is only\n\t\t performed once, when all of the input data has been pro-\n\t\t cessed.\n\n     _c \t Output characters in the default character set.  Nonprinting\n\t\t characters are displayed in three character, zero-padded\n\t\t octal, except for those representable by standard escape\n\t\t notation (see above), which are displayed as two character\n\t\t strings.\n\n     _p \t Output characters in the ASCII character set.\tNon-ASCII\n\t\t characters are displayed as a single ``.''.\n\n     _u \t Output US ASCII characters, with the exception that control\n\t\t characters are displayed using the following, lower-case,\n\t\t names.  Characters greater than 0xff, hexadecimal, are dis-\n\t\t played as hexadecimal strings.\n\n\t\t 000 NUL  001 SOH  002 STX  003 ETX  004 EOT  005 ENQ\n\t\t 006 ACK  007 BEL  008 BS   009 HT   00A LF   00B VT\n\t\t 00C FF   00D CR   00E SO   00F SI   010 DLE  011 DC1\n\t\t 012 DC2  013 DC3  014 DC4  015 NAK  016 SYN  017 ETB\n\t\t 018 CAN  019 EM   01A SUB  01B ESC  01C FS   01D GS\n\t\t 01E RS   01F US   0FF DEL\n\n     The default and supported byte counts for the conversion characters are\n     as follows:\n\n\t   %_c, %_p, %_u, %c\t   One byte counts only.\n\n\t   %d, %i, %o, %u, %X, %x  Four byte default, one, two and four byte\n\t\t\t\t   counts supported.\n\n\t   %E, %e, %f, %G, %g\t   Eight byte default, four and twelve byte\n\t\t\t\t   counts supported.\n\n     The amount of data interpreted by each format string is the sum of the\n     data required by each format unit, which is the iteration count times the\n     byte count, or the iteration count times the number of bytes required by\n     the format if the byte count is not specified.\n\n     The input is manipulated in ``blocks'', where a block is defined as the\n     largest amount of data specified by any format string.  Format strings\n     interpreting less than an input block's worth of data, whose last format\n     unit both interprets some number of bytes and does not have a specified\n     iteration count, have the iteration count incremented until the entire\n     input block has been processed or there is not enough data remaining in\n     the block to satisfy the format string.\n\n     If, either as a result of user specification or hexdump modifying the\n     iteration count as described above, an iteration count is greater than\n     one, no trailing whitespace characters are output during the last itera-\n     tion.\n\n     It is an error to specify a byte count as well as multiple conversion\n     characters or strings unless all but one of the conversion characters or\n     strings is _a or _A.\n\n     If, as a result of the specification of the -n option or end-of-file\n     being reached, input data only partially satisfies a format string, the\n     input block is zero-padded sufficiently to display all available data\n     (i.e., any format units overlapping the end of data will display some\n     number of the zero bytes).\n\n     Further output by such format strings is replaced by an equivalent number\n     of spaces.  An equivalent number of spaces is defined as the number of\n     spaces output by an s conversion character with the same field width and\n     precision as the original conversion character or conversion string but\n     with any ``+'', `` '', ``#'' conversion flag characters removed, and ref-\n     erencing a NULL string.\n\n     If no format strings are specified, the default display is a one-byte\n     hexadecimal display.\n\nDIAGNOSTICS\n     The hexdump utility exits 0 on success, and >0 if an error occurs.\n\nEXAMPLES\n     Note that the following format strings, used with -e, must be enclosed in\n     single quotes.\n\n     Display the input in perusal format:\n\n\t   \"%06.6_ao \"\t12/1 \"%3_u \"\n\t   \"\\t\\t\" \"%_p \"\n\t   \"\\n\"\n\n     Implement the -x option:\n\n\t   \"%07.7_Ax\\n\"\n\t   \"%07.7_ax  \" 8/2 \"%04x \" \"\\n\"\n\nSEE ALSO\n     gdb(1), od(1)\n\nBSD\t\t\t\t July 10, 2004\t\t\t\t   BSD\n",
   "tldr_summary": "# hexdump\n\n> An ASCII, decimal, hexadecimal, octal dump.\n\n- Print the hexadecimal representation of a file:\n\n`hexdump {{file}}`\n\n- Display the input offset in hexadecimal and its ASCII representation in two columns:\n\n`hexdump -C {{file}}`\n\n- Display the hexadecimal representation of a file, but interpret only n bytes of the input:\n\n`hexdump -C -n{{number_of_bytes}} {{file}}`\n"
 },
 {
   "command": "inxi",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# inxi\n\n> Print a summary of system information and resources for debugging purposes.\n\n- Print a short summary of CPU, memory, hard drive and kernel information:\n\n`inxi`\n\n- Print a full description of CPU, memory, disk, network and process information:\n\n`inxi -Fz`\n\n- Print information about the distribution's repository:\n\n`inxi -r`\n"
 },
 {
   "command": "vpnc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# vpnc\n\n> A VPN client for the Cisco 3000 VPN Concentrator.\n\n- Connect with a defined configuration file:\n\n`sudo vpnc {{config_file}}`\n\n- Terminate the previously created connection:\n\n`sudo vpnc-disconnect`\n"
 },
 {
   "command": "mkswap",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkswap\n\n> Sets up a Linux swap area on a device or in a file.\n\n- Setup a given partition as swap area:\n\n`sudo mkswap {{/dev/sdb7}}`\n\n- Use a given file as swap area:\n\n`sudo mkswap {{path/to/file}}`\n\n- Check a partition for bad blocks before creating the swap area:\n\n`sudo mkswap -c {{/dev/sdb7}}`\n\n- Specify a label for the file (to allow `swapon` to use the label):\n\n`sudo mkswap -L {{swap1}} {{path/to/file}}`\n"
 },
 {
   "command": "numlockx",
   "doc_url": "http://www.mike-devlin.com/linux/README-numlockx.htm",
   "doc_text": "Not Acceptable!Not Acceptable!An appropriate representation of the requested resource could not be found on this server. This error was generated by Mod_Security.",
   "man_entry": "",
   "tldr_summary": "# numlockx\n\n> Control the number lock key status in X11 sessions.\n> More information: <http://www.mike-devlin.com/linux/README-numlockx.htm>.\n\n- Show the current number lock status:\n\n`numlockx status`\n\n- Turn the number lock on:\n\n`numlockx on`\n\n- Turn the number lock off:\n\n`numlockx off`\n\n- Toggle the current state:\n\n`numlockx toggle`\n"
 },
 {
   "command": "imgp",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# imgp\n\n> Command line image resizer and rotator for JPEG and PNG images.\n\n- Convert single images and/or whole directories containing valid image formats:\n\n`imgp -x {{1366x1000}} {{path/to/dir}} {{path/to/file}}`\n\n- Scale an image by 75% and overwrite the source image to a target resolution:\n\n`imgp -x {{75}} -w {{path/to/file}}`\n\n- Rotate an image clockwise by 90 degrees:\n\n`imgp -o {{90}} {{path/to/file}}`\n"
 },
 {
   "command": "kpackagetool5",
   "doc_url": "https://techbase.kde.org/Development/Tutorials/Plasma5/QML2/GettingStarted#Kpackagetool5",
   "doc_text": "\n\n\nDevelopment/Tutorials/Plasma5/QML2/GettingStarted - KDE TechBase\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnglishLogin with Phabricator \n\n\n\n\n\n\n\n\n\n\n\n\n              KDE TechBase            \n\n\n\n\n\nActions\n\n\n\n\n                View              \n\n\n                    View source                  \n\n\n\n                    History                  \n\n\n\n\n                  Page                \n\n\n                    Discussion                  \n\n\n\n\n\n\nNavigation\n\n\nHomeHelpRecent changes \n\n\n\nContributor Help Pages\n\n\nTasks and ToolsModify a pageAdd new contentPage elementsTypographical guidelinesMore markup help \n\n\n\nTranslator Help Pages\n\n\nGet a Translator AccountLanguages representedTranslation WorkflowTranslate a PageOff-line TranslationTranslation StatisticsMore Help pages \n\n\n\nTools\n\n\nWhat links hereRelated changesSpecial pagesPrintable versionPermanent linkPage information \n\n\n\n\n\n< Development‎ | Tutorials‎ | Plasma5\n\nDevelopment/Tutorials/Plasma5/QML2/GettingStarted\n\nContents\n\n1 Abstract\n2 Package Structure\n3 The Code\n\n3.1 The .desktop file\n3.2 main.qml\n3.3 CMakeLists.txt\n\n\n4 Representations\n5 Minimum size\n6 Localization\n7 Install and Test\n\n7.1 Kpackagetool5\n\n\n8 Testing the Applet\n9 Wow that was fun!\n10 Find and try out existing Plasmoids\n\n10.1 plasmawindowed\n10.2 plasmoidviewer\n\n\n\n\nAbstract\nThis tutorial needs KDE Frameworks 5 / Plasma 5  to build.\nWe are going to create a simple plasmoid in this tutorial. To keep things simple, we are going to make have use QML 2.0 and it will use Plasma Components in our tutorial .\n\nPackage Structure\nYou create a .desktop file and the .qml file. They have to be in the usual Plasma package structure:\n\nplasmoid/metadata.desktop\nplasmoid/contents/ui/main.qml\n(where \"plasmoid\" should be replaced with the name of your package)\nYour directory structure should now be as follows:\n\nmyproject/CMakeLists.txt\nmyproject/plasmoid/\nmyproject/plasmoid/metadata.desktop\nmyproject/plasmoid/contents/\nmyproject/plasmoid/contents/ui/\nmyproject/plasmoid/contents/ui/main.qml\n\nThe Code\nThe .desktop file\nEvery Plasmoid needs a .desktop file to tell plasma how it should be started and what name it carries. \nmetadata.desktop\n\n[Desktop Entry]\nEncoding=UTF-8\nName=Tutorial\nComment=Tutorial on getting started with Plasma 5 plasmoids.\nType=Service\n\nX-KDE-Library=plasma_applet_tutorial\nX-KDE-ParentApp=\nX-KDE-PluginInfo-Author=Heena\nX-KDE-PluginInfo-Email=[email protected]\nX-KDE-PluginInfo-License=GPL\nX-KDE-PluginInfo-Name=org.kde.tutorial\nX-KDE-PluginInfo-Version=2.0\nX-KDE-PluginInfo-Website=plasma.kde.org\nX-KDE-ServiceTypes=Plasma/Applet\nX-Plasma-API=declarativeappletscript\nX-Plasma-MainScript=ui/main.qml\nX-KDE-PluginInfo-Category=Windows and Tasks\n\nThe most important bits are:-\n\nX-KDE-Library  which specifies which library will provide the configuration dialog. In this example then \"plasma_applet_tutorial\" assignment is just a place holder.\nX-KDE-PluginInfo-Name For X-KDE-PluginInfo-Category, refer to the  PIG.\n\nThese are the \"glue\" between your class and plasma, without it, nothing will start.\n\nmain.qml\nimport QtQuick 2.0\nimport org.kde.plasma.components 2.0 as PlasmaComponents\n\nPlasmaComponents.Label {\n    text: \"Hello world in Plasma 5 \";\n    color: \"black\";\n}\n\nCMakeLists.txt\nThis CMakeLists.txt file describes where your plasmoid will be installed.\n\n# Set minimum CMake version (required for CMake 3.0 or later)\ncmake_minimum_required(VERSION 2.8.12)\n\n# Use Extra CMake Modules (ECM) for common functionality.\n# See http://api.kde.org/ecm/manual/ecm.7.html\n# and http://api.kde.org/ecm/manual/ecm-kde-modules.7.html\nfind_package(ECM REQUIRED NO_MODULE)\n# Needed by find_package(KF5Plasma) below.\nset(CMAKE_MODULE_PATH ${ECM_MODULE_PATH} ${CMAKE_MODULE_PATH})\n\n# Locate plasma_install_package macro.\nfind_package(KF5Plasma REQUIRED)\n\n# Add installatation target (\"make install\").\nplasma_install_package(plasmoid org.kde.tutorial)\n\nFor more details on CMake please read Guidelines_and_HOWTOs/CMake\n\nRepresentations\nThe plasmoid can provide two components: compactRepresentation and FullRepresentation\n\nimport QtQuick 2.0\nimport QtQuick.Layouts 1.1\nimport org.kde.plasma.plasmoid 2.0\nimport org.kde.plasma.core 2.0 as PlasmaCore\n\nItem {\n    Plasmoid.compactRepresentation: CompactRepresentation {}\n    Plasmoid.fullRepresentation: FullRepresentation {}\n}\n\nwhere the files CompactRepresentation.qml and FullRepresentation.qml exist in the plasmoid package.\nThey are both optional: if compactRepresentation is not present, a default one will be created (the plasmoid icon) if fullRepresentation is not defined, the root item will be picked instead.\nIf a fullRepresentaion is defined, the root item will not contain any graphical element (they will be never shown) but is only supposed to contain models and data that must be accessible from both the compact and the full representation.\n\nMinimum size\nif the root object of the plasmoid (or the fullRepresentation if present) has the Layout attached property exposed, they will be used as the minimum size for the plasmoid. If they will change during the plasmoid execution, the plasmoid minimum size will be updated accordingly.\n\nimport QtQuick 2.0\nimport QtQuick.Layouts 1.1\nimport org.kde.plasma.components 2.0 as PlasmaComponents\nimport org.kde.plasma.plasmoid 2.0                                                                                                                                                                                                \nimport org.kde.plasma.core 2.0 as PlasmaCore\n\nPlasmaComponents.Label {\n    Layout.minimumWidth : plasmoid.formFactor == PlasmaCore.Types.Horizontal ? height : 1\n    Layout.minimumHeight : plasmoid.formFactor == PlasmaCore.Types.Vertical ? width  : 1\n    text: \"Hello world in plasma5\";\n}\n\nIn the above example, the minimum width will be the height in case the formFactor is Horizontal .Similarly , if the formFactor is Vertical then minimumHeight shall be the width as shown in the above example .\n\nLocalization\nIt is possible to localize strings with the usual i18n(), i18nc(), i18np() global functions.\n\n\nInstall and Test\nSince this plasmoid contains no native (compiled) code you can directly try and execute it using\n\nqmlscene main.qml\n\nKpackagetool5\nkpackagetool5 is the Plasma Package Manager, which you can use to install, test and remove your new plasmoid.\nYou can install your plasmoid into ~/.local/share/plasma as described in this section, though obviously this is just temporary. CMake, below, is recommended.\nFrom the myproject folder defined above, use the Plasma Package Manager:\n\nkpackagetool5 -t Plasma/Applet --install plasmoid\n\nYou can pass to the --install option of kpackagetool5 the full path of the directory containing the metadata.desktop file or any relative path to it.\nNotice that your Plasmoid is now available via the +Add Widgets function from the (Right Click Menu) on Plasma Desktop. For clarity of this tutorial, note that the name of your Plasmoid is Tutorial, as defined by the Name in your .desktop file\n\nName=Tutorial\nAfter updating your code, to install the new version of your Plasmoid, from the myproject folder defined above, use the Plasma Package Manager:\n\nkpackagetool5 -t Plasma/Applet --upgrade plasmoid\n\nTo remove the plasmoid, use the Plasma Package Manager:\n\nkpackagetool5 -t Plasma/Applet --remove org.kde.tutorial\n\nTesting the Applet\nYou can test your Plasmoid without installing it with the plasmoidviewer tool:\n\n\nplasmoidviewer --applet package\nThe --applet parameter can accept two options:\n\nthe path (full or relative) to your metadata.desktop file, or\nthe packaged version of your plasmoid, such as org.kde.tutorial,  which can usually be found in ~/.local/share/plasma/plasmoids/\nEither one will launch your plasmoid in a sample window, as shown above.\nThe \"FormFactors\" and \"Location\" buttons help to see how the Plasmoid behaves in different situations.\nIf your current Development Environment differs from the Test Installation, you have to run cmake with -DCMAKE_INSTALL_PREFIX=$KF5. Then run make. If successful the applet can be installed by running sudo make install\nand run kbuildsycoca5 (so that KDE apps will know about the new desktop files).\nIn order to test your Applet you can load the Plasma 5 plasmoid in plasmashell as shown :\n\nkbuildsycoca5 #Needed once to let KDE know there is a new plugin\nplasmashell\n\nYou can even find your plasmoid in ~./local5 after you build it .\nWhere applet_name is the value specified into .desktop for the X-KDE-PluginInfo-Name key.\n\nWow that was fun!\nCongrats! you just  made your first qml 2.0 Plasmoid.\n\nFind and try out existing Plasmoids\nHere you will learn how to find existing installed plasmoid packages and selectively start one from command line.\nIf you are working from within Plasma you can call\n\neval $(dbus-launch)\nfirst which will speed things up. But beware that a second DBUS can interfere with your existing Plasma session.\nTo get a list of installed Plasma packages call\n\nplasmapkg2 --list\nThe result will look similar to this:\n\norg.kde.desktopcontainment\norg.kde.milou\norg.kde.muonnotifier\norg.kde.panel\norg.kde.plasma.activitybar\norg.kde.plasma.analogclock\norg.kde.plasma.battery\norg.kde.plasma.calculator\norg.kde.plasma.calendar\norg.kde.plasma.clipboard\norg.kde.plasma.devicenotifier\norg.kde.plasma.digitalclock\norg.kde.plasma.fifteenpuzzle\norg.kde.plasma.folder\norg.kde.plasma.fuzzyclock\norg.kde.plasma.icon\norg.kde.plasma.katesessions\norg.kde.plasma.kicker\norg.kde.plasma.kickoff\norg.kde.plasma.kimpanel\norg.kde.plasma.lock_logout\norg.kde.plasma.mediacontroller\norg.kde.plasma.networkmanagement\norg.kde.plasma.notes\norg.kde.plasma.notifications\norg.kde.plasma.pager\norg.kde.plasma.panelspacer\norg.kde.plasma.printmanager\norg.kde.plasma.showActivityManager\norg.kde.plasma.showdesktop\norg.kde.plasma.systemloadviewer\norg.kde.plasma.systemmonitor.cpu\norg.kde.plasma.systemmonitor.diskactivity\norg.kde.plasma.systemmonitor.diskusage\norg.kde.plasma.systemmonitor.memory\norg.kde.plasma.systemmonitor.net\norg.kde.plasma.systemtray\norg.kde.plasma.taskmanager\norg.kde.plasma.timer\norg.kde.plasma.trash\norg.kde.plasma.webbrowser\norg.kde.plasma.windowlist\nplasmawindowed\nPick one of those lines of your choice and run for example\n\nplasmawindowed org.kde.plasma.kickoff\nwhich will launch the Kickoff Application Launcher in a separate window.\n\nplasmoidviewer\nInstead of plasmawindowed you can also use plasmoidviewer (in the plasmate repo):\n\nplasmoidviewer --applet org.kde.plasma.kickoff\n\nFor testing an installed Plasmoid, the --applet parameter takes the X-KDE-PluginInfo-Name of the plasmoid in its .desktop file.\nThe \"FormFactors\" and \"Location\" buttons help to see how the Plasmoid behaves in different situations.\n\n\n\n \n\n\n          Retrieved from \"https://techbase.kde.org/index.php?title=Development/Tutorials/Plasma5/QML2/GettingStarted&oldid=105983\"        \n\n\n\n\n\n                                 This page was last edited on 29 April 2020, at 12:59.                                Content is available under Creative Commons License SA 4.0 unless otherwise noted.                            \n\n\n\n\n\n\n\nDonate to KDE Why Donate?\n\n\n\n\n\n\n\n\n\n\n €\n             Donate via PayPal\n\nOther ways to donate\n\n\n\n\nVisit the KDE MetaStore\nShow your love for KDE! Purchase books, mugs, apparel, and more to support KDE.\nClick here to browse\n\n\n\n\n\n\nAbout Wiki\nPrivacy policyAbout KDE TechBaseDisclaimers \n\nProducts\nPlasma\nKDE Applications\nKDE Frameworks\nPlasma Mobile\nKDE neon\nWikiToLearn\n\n\nDevelop\nTechBase Wiki\nAPI Documentation\nQt Documentation\nInqlude Documentation\n\n\nNews & Press\nAnnouncements\nKDE.news\nPlanet KDE\nScreenshots\nPress Contact\n\n\nResources\nCommunity Wiki\nUserBase Wiki\nMiscellaneous Stuff\nSupport\nInternational Websites\nDownload KDE Software\nCode of Conduct\n\n\nDestinations\nKDE Store\nKDE e.V.\nKDE Free Qt Foundation\nKDE Timeline\n\n\n\n\n\n\n          Maintained by KDE Webmasters\n\n\n          KDE® and the K Desktop Environment® logo are registered trademarks of KDE e.V. |\n          Legal\n\n\n\n\n\n\n\n\n\n\n\n\n \n -->\n  \n\n",
   "man_entry": "",
   "tldr_summary": "# kpackagetool5\n\n> KPackage Manager: Install, list, remove Plasma packages.\n> More information: <https://techbase.kde.org/Development/Tutorials/Plasma5/QML2/GettingStarted#Kpackagetool5>.\n\n- List all known package types that can be installed:\n\n`kpackagetool5 --list-types`\n\n- Install the package from a directory:\n\n`kpackagetool5 --type {{package_type}} --install {{path/to/directory}}`\n\n- Update installed package from a directory:\n\n`kpackagetool5 --type {{package_type}} --upgrade {{path/to/directory}}`\n\n- List installed plasmoids (--global for all users):\n\n`kpackagetool5 --type Plasma/Applet --list --global`\n\n- Remove a plasmoid by name:\n\n`kpackagetool5 --type Plasma/Applet --remove \"{{name}}\"`\n"
 },
 {
   "command": "unix2mac",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# unix2mac\n\n> Change Unix-style line endings to macOS-style.\n> Replaces CR with LF.\n\n- Change the line endings of a file:\n\n`unix2mac {{filename}}`\n\n- Create a copy with macOS-style line endings:\n\n`unix2mac -n {{filename}} {{new_filename}}`\n"
 },
 {
   "command": "xbacklight",
   "doc_url": "https://gitlab.freedesktop.org/xorg/app/xbacklight",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjects · xorg / app / xbacklight · GitLab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\nGitLab\n\n\n\nProjects\nGroups\nSnippets\n\nHelp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoading...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp\n\n\n\n\n\n\nHelp\n\n\nSupport\n\n\nCommunity forum\n\n\n\nKeyboard shortcuts\n?\n\n\n\n\nSubmit feedback\n\n\nContribute to GitLab\n\n\n\n\n\n\n\nSign in / Register\n\n\n\n\n\nToggle navigation\n\n\n\n\n\n\n\n\n\n\n\nX\n\n\nxbacklight\n\n\n\n\n\n\n\nProject overview\n\n\n\nProject overview\n\n\nDetails\nActivity\nReleases\n\n\n\n\n\nRepository\n\n\n\nRepository\n\n\nFiles\nCommits\nBranches\nTags\nContributors\nGraph\nCompare\n\n\n\n\n\n\nIssues\n\n\n3\n\n\n\nIssues\n\n\n3\n\n\n\nList\n\n\nBoards\n\n\nLabels\n\nService Desk\n\n\nMilestones\n\n\n\n\n\n\n\nMerge Requests\n\n\n0\n\n\n\nMerge Requests\n\n\n0\n\n\n\n\n\n\n\nCI / CD\n\n\n\nCI / CD\n\n\n\nPipelines\n\n\nJobs\n\n\nSchedules\n\n\n\n\n\n\n\n\nOperations\n\n\n\nOperations\n\n\n\nEnvironments\n\n\n\n\n\n\n\nPackages & Registries\n\n\n\nPackages & Registries\n\n\nContainer Registry\n\n\n\n\n\n\nAnalytics\n\n\n\nAnalytics\n\n\nCI / CD\nRepository\nValue Stream\n\n\n\n\n\n\nSnippets\n\n\n\nSnippets\n\n\n\n\n\n\nMembers\n\n\n\nMembers\n\n\n\n\n\nCollapse sidebar\n\n\nClose sidebar\n\n\n\nActivity\n\n\n\nGraph\n\n\nCreate a new issue\n\n\nJobs\n\n\nCommits\n\n\nIssue Boards\n\n\n\n\n\n\n\n\n\nOpen sidebar\n\n\n\nxorgapp xbacklight\n\nDetails\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\n\n\n\n\nxbacklight\n\n\n\n\n\n\n\nProject ID: 487\n\n\n\n\nRand R\n\n\n\n\n\n\n\n\n\nStar\n\n0\n\n\n\n\n\n\n\n\n\n49 Commits\n\n1 Branch\n\n8 Tags\n\n328 KB Files\n\n328 KB Storage\n\n\n\n\n\n\nUtility to adjust backlight brightness using RandR extension\n\n\nRead more\n\n\n\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\nSwitch branch/tag\n\n\n\n\n\n\n\n\n\n\n\n\nFind file\n\n\n\nSelect Archive Format\n\n\n\n\nDownload source code\n\n\nzip\ntar.gz\ntar.bz2\ntar\n\n\n\n\n\n\n\n\n\nClone\n\n\n\n\n\n\nClone with SSH\n\n\n\n\n\n\n\n\n\n\nClone with HTTPS\n\n\n\n\n\n\n\n\n\n\n\n\nCopy HTTPS clone URL\n\n\n\n\n\nCopy SSH clone URLgit@gitlab.freedesktop.org:xorg/app/xbacklight.git\n\n\nCopy HTTPS clone URLhttps://gitlab.freedesktop.org/xorg/app/xbacklight.git\n\n\n\n\n\n\n\n\n\nREADME\n\nLICENSE\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# xbacklight\n\n> Utility to adjust backlight brightness using the RandR extension.\n> More information: <https://gitlab.freedesktop.org/xorg/app/xbacklight>.\n\n- Get the current screen brightness as a percentage:\n\n`xbacklight`\n\n- Set the screen brightness to 40%:\n\n`xbacklight -set {{40}}`\n\n- Increase current brightness by 25%:\n\n`xbacklight -inc {{25}}`\n\n- Decrease current brightness by 75%:\n\n`xbacklight -dec {{75}}`\n\n- Increase backlight to 100%, over 60 seconds (value given in ms), using 60 steps:\n\n`xbacklight -set {{100}} -time {{60000}} -steps {{60}}`\n"
 },
 {
   "command": "snapper",
   "doc_url": "http://snapper.io/manpages/snapper.html",
   "doc_text": "\n\n\nsnapper\n\n\n\n\n\n\n\nName\nsnapper — Command-line program for filesystem snapshot management\n\n\n\nSynopsis\n\nsnapper  [--global-opts]  command  [--command-opts] [command-arguments]\n\n\nsnapper  {--help}\n\n\n\n\nDESCRIPTION\nSnapper is a command-line program for filesystem snapshot management. It can\n    create, delete and compare snapshots and undo changes done between snapshots.\nSnapper never modifies the content of snapshots. Thus snapper creates\n    read-only snapshots if supported by the kernel. Supported filesystems are\n    btrfs and ext4 as well as snapshots of LVM logical volumes with\n    thin-provisioning. Some filesystems might not be supported depending on your\n    installation.\n\n\n\nCONCEPTS\n\n\nConfigurations\nFor each filesystem or subvolume that should be snapshotted by\n      snapper, a configuration file is required, see\n      snapper-configs(5). The\n      setup can be done with the create-config command.\n\n\n\nSnapshots\nSnapper distinguishes three types of snapshots.\n\n\n\npre\n\n\nPre snapshots should always have a corresponding post\n\t    snapshot. The intention of pre/post snapshot pairs is to snapshot the\n\t    filesystem before and after a modification.\n\n\npost\n\n\nSee pre type.\n\n\nsingle\n\n\nThese snapshots have no special relationship to other snapshots.\n\n\n\nNote that filesystem-wise all three types are the same.\n\n\n\nSnapshot Description and Userdata\nWith each snapshot a description and some userdata can be associated. The\n      description is a string. The userdata is a list of key-value pairs where the\n      keys and values are strings.\nDo not use non-ASCII characters for the snapshot description, userdata or\n      any other strings, unless you always use the UTF-8 character encoding.\n\n\n\nAutomatic Snapshot Creation\nNext to manual snapshot creation, snapshots are also created automatically.\n\n\n\nA cron-job creates hourly snapshots.\n\n\nCertain programs like YaST and zypper create pre/post\n\t  snapshot pairs when modifying the system.\n\n\n\n\n\n\nCleanup Algorithms\nSnapper provides several algorithms to clean up old snapshots. The\n      algorithms are executed in a daily cron-job. This can be configured in the\n      corresponding configurations files along with parameters for every\n      algorithm.\n\n\n\nnumber\n\n\nDeletes old snapshots when a certain number of snapshots is\n\t    reached.\n\n\ntimeline\n\n\nDeletes old snapshots but keeps a number of hourly, daily,\n\t    weekly, monthly and yearly snapshots.\n\n\nempty-pre-post\n\n\nDeletes pre/post snapshot pairs with empty diffs.\n\n\n\nThe number and timeline cleanup algorithms can also try to\n      keep the space used by snapshots below a limit and the free space of\n      the filesystem above a limit. For the first condition quota must be\n      setup, see command setup-quota. Additional the NUMBER_LIMIT and\n      TIMELINE_LIMIT variables in the config file must have ranges (min- and\n      max-value). The algorithms will then make two passes:\n\n      \n\n\n\nDelete snapshots above the max-value independent of\n\t  the snapshot and filesystem space.\n\n\nDelete snapshots above the min-value until the limits for\n\t  the snapshot and filesystem are reached.\n\n\n\n\n\n      The limit for the used space can be configured via the\n      SPACE_LIMIT variable. Note: Only snapshots that have a cleanup\n      algorithm set are taken into account when calculating the space\n      used by snapshots.\n\n      The limit for the free space can be configured via the\n      FREE_LIMIT variable.\n\n      \n\n\n\nFilters\nSome files keep state information of the system,\n      e.g. /etc/mtab. Such files should never be\n      reverted. To help users, snapper allows one to ignore these files.\nEach line in all\n      files /etc/snapper/filters/*.txt specifies a\n      pattern. When snapper computes the difference between two snapshots it\n      ignores all files and directories matching any of those patterns by\n      using\n      fnmatch(3)\n      with the flag FNM_LEADING_DIR.\nNote that filters do not exclude files or directories from being\n      snapshotted. For that, use subvolumes or mount points.\n\n\n\n\nGLOBAL OPTIONS\n\n\n\n\n-q, --quiet\n\n\n\nSuppress normal output. Error messages will still be printed, though.\n\n\n\n-v, --verbose\n\n\n\nIncrease verbosity.\n\n\n\n--utc\n\n\n\nDisplay dates and times in UTC. By default, local time is used.\n\n\n\n--iso\n\n\n\nDisplay dates and times in ISO format. ISO format is always used for machine-readable\n\t  outputs.\n\n\n\n-t, --table-style style\n\n\n\nSpecifies table style. Table style is identified by an integer number.\n\n\n\n--machine-readable format\n\n\n\nSpecifies a machine-readable output format. Possible options are csv and json.\n\n\n\n--csvout\n\n\n\nSets CSV output format. See\n                RFC 4180\n                for the details, except lines end with a LF, not CR+LF.\n\n\n\n--jsonout\n\n\n\nSets JSON output format.\n\n\n\n--separator character\n\n\n\nSpecifies the character separator for CSV output format.\n\n\n\n-c, --config name\n\n\n\nUse specified configuration instead of the default configuration. The default\n\t  configuration is named \"root\".\n\n\n\n--no-dbus\n\n\n\nOperate without a DBus connection.\nUse with caution since a running snapperd will not know about\n\t  modifications made to the system.\n\n\n\n-r, --root path\n\n\n\nOperate on target root. Only works together with no-dbus and only for some commands.\n\n\n\n-a, --ambit ambit\n\n\n\nOperate in the specified ambit. Can be used to override the ambit detection.\n\t  Allowed ambits are auto, classic and transactional.\n\n\n\n--version\n\n\n\nPrint version and exit.\n\n\n\n\n\n\nCOMMANDS\nSnapper provides a number of commands. Each\n    command accepts the options listed in the GLOBAL OPTIONS section. These options must\n    be specified before the command name. In addition,\n    many commands have specific options, which are listed in this\n    section. These command-specific options must be specified\n    after the name of the command and\n    before any of the command arguments.\n\n\n\n\nhelp\n\n\n\nShow short help text.\n\n\n\nlist-configs [options]\n\n\n\nList available configurations.\n\n\n\n--columns columns\n\n\nSelect columns to show separated by comma.\nPossible columns are: config, subvolume.\n\n\n\n\n\n\ncreate-config [options] subvolume\n\n\n\nCreate a new configuration for a filesystem or subvolume. For this command you\n\t  will likely need the global option --config, see\n\t  GLOBAL OPTIONS and\n\t  CONCEPTS.\n\n\n\n-f, --fstype fstype\n\n\nManually set filesystem type. Supported values are btrfs, ext4 and lvm. For\n\t\tlvm, snapper uses LVM thin-provisioned snapshots. The filesystem type on top of\n\t\tLVM must be provided in parentheses, e.g. lvm(xfs).\nWithout this option snapper tries to detect the filesystem.\n\n\n-t, --template name\n\n\nName of template for the new configuration file.\n\n\n\n\n\n\ndelete-config\n\n\n\nDelete a configuration for a filesystem or subvolume. For this\n\t  command you will likely need to global option\n\t  --config, see GLOBAL\n\t  OPTIONS and CONCEPTS.\n\n\n\nget-config [options]\n\n\n\nDisplays the settings of the configuration.\n\n\n\n--columns columns\n\n\nSelect columns to show separated by comma.\nPossible columns are: key, value.\nColumns are not selected when JSON format is used.\n\n\n\n\n\nset-config configdata\n\n\nChanges the settings of the configuration. The settings\n\t  configdata are a list of key-value-pairs separated\n\t  by spaces and the key and value must be separated by an equal sign,\n\t  e.g. \"NUMBER_CLEANUP=yes NUMBER_LIMIT=10\". The value of SUBVOLUME and FSTYPE\n\t  cannot be changed.\n\n\n\nlist (ls) [options]\n\n\n\nList snapshots.\n\n\n\n-t, --type type\n\n\nSelects type of snapshots to list. Possible values are\n\t\tall, single and pre-post.\n\n\n\n--disable-used-space\n\n\n\nDisable display of used space.\nCalculating the used space needs some time. Thus\n\t\tthis option can speedup the listing.\n\n\n\n-a, --all-configs\n\n\n\nList snapshots from all configs accessible by the user.\n\n\n--columns columns\n\n\nSelect columns to show separated by comma.\nPossible columns are: config, subvolume, number, default, active, date, user,\n                      used-space, cleanup, description, userdata, pre-number, post-number, post-date.\n\n\n\nFor each snapshot the output consists of several\n\t  columns. Some need explanation:\n\n\n\n#, Pre # and Post #\n\n\nThe number of the snapshot.\nFor btrfs the number can be followed by a sign.\n\t\tA \"-\" indicates that the snapshot is\n\t\tthe currently mounted snapshot and a\n\t\t\"+\" indicates that the snapshot will\n\t\tbe mounted next time (It is the btrfs default subvolume). If both\n\t\tconditions apply a\n\t\t\"*\" is displayed.\n\n\nUsed Space\n\n\nFor btrfs the exclusive space of the btrfs quota\n\t\tgroup corresponding to the snapshot.\nDisplay of used space is automatically disabled\n\t\tif not available, e.g. quota not enabled on btrfs.\n\n\n\n\n\n\ncreate [options]\n\n\n\nCreate a new snapshot.\n\n\n\n-t, --type type\n\n\nSpecifies the type of the new snapshot. Possible values\n\t\tare single, pre and post.\n\n\n--pre-number number\n\n\nFor post snapshots the number of the pre snapshot must\n\t\tbe provided.\n\n\n\n-p, --print-number\n\n\n\nPrint number of the created snapshot.\n\n\n-d, --description description\n\n\nDescription for the snapshot.\n\n\n-c, --cleanup-algorithm cleanup-algorithm\n\n\nSet the cleanup algorithm for the snapshot.\n\n\n-u, --userdata userdata\n\n\nSet userdata for the snapshot. The key-value pairs must\n\t\tbe separated by comma and the key and value must be separated\n\t\tby an equal sign, e.g. requestid=42,user=arthur.\n\n\n--command command\n\n\nCreate a pre and post snapshot and run command in between.\n\n\n\n--read-only\n\n\n\nCreate a read-only snapshot. This is the default.\n\n\n\n--read-write\n\n\n\nCreate a read-write snapshot.\n\n\n--from number\n\n\nCreate a snapshot from the snapshot with the\n\t\tprovided number instead of snapshot 0.\n\n\n\n\n\n\nmodify [options] number\n\n\n\nModify a snapshot.\n\n\n\n-d, --description description\n\n\nNew description for snapshot.\n\n\n-c, --cleanup-algorithm cleanup-algorithm\n\n\nSet the cleanup algorithm for the snapshot.\n\n\n-u, --userdata userdata\n\n\nSet userdata for the snapshot. The key-value pairs must\n\t\tbe separated by comma and the key and value must be separated\n\t\tby an equal sign, e.g. requestid=42,user=arthur.\n\n\n\n\n\n\ndelete (remove|rm) number |\n\tnumber1-number2\n\n\n\nDelete a snapshot or a range of snapshots.\n\n\n\n\n-s, --sync\n\n\n\nSync the filesystem after deleting the snapshots. The\n\t\tdetails depend on the filesystem type.\nBtrfs normally asynchronously frees space after deleting\n\t\tsnapshots. With this option snapper will wait until the space once used by the\n\t\tdeleted snapshots is actually available again.\n\n\n\nSnapshot 0 cannot be deleted. For btrfs the currently\n\t  mounted snapshot and the snapshot that will be mounted next time\n\t  (the btrfs default subvolume) can also not be deleted.\n\n\n\nmount number\n\n\n\nMount a snapshot. Not required for all filesystem types.\n\n\n\numount number\n\n\n\nUnmount a snapshot. Not required for all filesystem types.\n\n\n\nstatus [options] number1..number2\n\n\n\nCompare the snapshots number1 and\n\t  number2. This will show a list of files\n\t  and directories that have been created, modified or deleted in the\n\t  time between the two snapshots have been made.\n\n\n\n-o, --output file\n\n\nWrite output to file file.\n\n\n\nThe output consists of a string encoding the status followed by\n\t  the filename. The characters of the status string are:\n\n\n\nA \"+\" means the file was\n\t      created, a \"-\" means the file was deleted. A\n\t      \"c\" means the content of the file has changed\n\t      and a \"t\" means the type of the file has\n\t      changed (e.g. from regular file to directory).\n\n\nA \"p\" means the permissions\n\t      are have changed.\n\n\nAn \"u\" means the user\n\t      ownership has changed.\n\n\nA \"g\" means the group\n\t      ownership has changed.\n\n\nA \"x\" means the extended\n\t      attribute information has changed.\n\n\nAn \"a\" means the ACL\n\t      information has changed.\n\n\n\nIf there is no change a \".\" is outputted.\n\n\n\ndiff [options] number1..number2 [files]\n\n\n\nCompare the snapshots number1 and\n\t  number2. This will show a diff of the\n\t  content of files and directories that have been created, modified or\n\t  deleted in the time between the two snapshots have been made.\n\n\n\n-i, --input file\n\n\nRead files to diff from file file.\n\n\n--diff-cmd command\n\n\nCommand used for comparing files. The default is\n\t\t/usr/bin/diff --new-file --unified. The two files to\n\t\tcompare are passed as parameters to the command.\n\n\n-x, --extensions options\n\n\nExtra options passed to the diff command.\n\n\n\n\n\n\nundochange [options] number1..number2 [files]\n\n\n\nUndo changes done between snapshot number1 and number2.\n\n\n\n-i, --input file\n\n\nRead files for which to undo changes from file file.\n\n\n\n\n\n\nrollback [options] [number]\n\n\n\nCreates two new snapshots and sets the default subvolume. Per\n\t  default the system boots from the default subvolume of the root filesystem.\n\t  The exact actions depend on whether a number is provided or not:\n\n\n\nWithout a number, a first read-only snapshot of the\n\t      default subvolume is created. A second read-write snapshot of the current\n\t      system is created. The system is set to boot from the second snapshot.\n\n\nWith a number, a first read-only snapshot of the current\n\t      system is created. A second read-write snapshot is created of\n\t      number. The system is set to boot from the second\n\t      snapshot.\n\n\n\nRollback is only supported with btrfs and requires a properly\n\t  configured system.\n\n\n\n\n-p, --print-number\n\n\n\nPrint number of the second created snapshot.\n\n\n-d, --description description\n\n\nDescription for the snapshot.\n\n\n-c, --cleanup-algorithm cleanup-algorithm\n\n\nSet the cleanup algorithm for the snapshot.\n\n\n-u, --userdata userdata\n\n\nSet userdata for the snapshot. The key-value pairs must\n\t\tbe separated by comma and the key and value must be separated\n\t\tby an equal sign, e.g. requestid=42,user=arthur.\n\n\n\nThe rollback command also sets the description, the cleanup\n\t  algorithm and some userdata unless the values are specified on the command\n\t  line. This will automate cleanup of snapshots created by rollbacks.\nIn other ambits than classic the rollback command does what is required\n\t  to do a rollback. Anyway it is recommended to use specific programs in that\n\t  case.\n\n\n\nsetup-quota\n\n\n\nSets up quota. Currently only supported with btrfs.\n\n\n\ncleanup [options] cleanup-algorithm\n\n\n\nRun the cleanup algorithm\n\t  cleanup-algorithm. Currently implemented cleanup algorithms\n\t  are number, timeline and empty-pre-post. To run all cleanup algorithms, all can be\n\t  provided as cleanup-algorithm.\n\n\n\n--path path\n\n\nCleanup all configs affecting path. Only useful for btrfs.\n\n\n--free-space free-space\n\n\nTry to make free-space available. Only useful for btrfs.\n\n\n\n\n\n\nxadiff number1..number2 [files]\n\n\n\nCompare the extended attributes between snapshot\n\t  number1 and\n\t  number2. See examples below:\n\n\n\n +:user.foo for created attributes\n\n\n -:user.bar for removed attributes\n\n\n-+:security.selinux for modified attributes\n\n\n\n\n\n\n\n\n\nPERMISSIONS\nNon-root users can be allowed to use a configuration by setting\n    ALLOW_USERS or ALLOW_GROUPS in the config file. For all operations to work, the\n    user must also be able to read and access the .snapshots\n    directory inside the subvolume. The .snapshots directory\n    must be owned by root and must not be writable by anybody else.\nHere are some methods how to achieve that:\n\n\n\nMake the directory accessible for everyone:\n\n\nchmod a+rx .snapshots\n\n\n\n\nMake the directory accessible for a group the user belongs to, e.g.:\n\n\nchown :users .snapshots\n\n\n\n\nMake the directory accessible for the user using ACLs, e.g.:\n\n\nsetfacl -m u:tux:rx .snapshots\n\n\n\n\n\nThe last method can be performed by snapper, see the SYNC_ACL setting in\n    snapper-configs(5).\n\n\n\nFILES\n\n\n\n\n/etc/sysconfig/snapper\n\n\n\nGlobal configuration file.\n\n\n\n/etc/snapper/configs\n\n\n\nDirectory containing configuration files.\n\n\n\n/etc/snapper/config-templates\n\n\n\nDirectory containing configuration templates.\n\n\n\n/etc/snapper/filters/*.txt\n\n\n\nFilter files.\n\n\n\n/var/log/snapper.log\n\n\n\nLogfile. Please include this file in bug reports.\n\n\n\n\n\n\nNOTES\nThere is no mechanism to ensure consistency of the files while a\n    snapshot it made. E.g. the files of a database can be inconsistent while\n    the database is running.\nConsistency after undochange is not guaranteed. E.g. when the\n    creation of a user is undone, there might still exist files from that\n    user.\nSupport for individual filesystems, rollback and extended attributes\n    are compile-time options and may not be available.\n\n\n\nHOMEPAGE\n\nhttp://snapper.io/\n\n\n\n\nAUTHORS\nArvin Schnell <aschnell@suse.com>\n\n\n\nSEE ALSO\n\nsnapper-configs(5),\n      snapper-zypp-plugin(8),\n      pam_snapper(8),\n      btrfs(8),\n      lvm(8),\n      attr(5),\n      acl(5)\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# snapper\n\n> Filesystem snapshot management tool.\n> More information: <http://snapper.io/manpages/snapper.html>.\n\n- List snapshot configs:\n\n`snapper list-configs`\n\n- Create snapper config:\n\n`snapper -c {{config}} create-config {{path/to/directory}}`\n\n- Create a snapshot with a description:\n\n`snapper -c {{config}} create -d {{\"snapshot_description\"}}`\n\n- List snapshots for a config:\n\n`snapper -c {{config}} list`\n\n- Delete a snapshot:\n\n`snapper -c {{config}} delete {{snapshot_number}}`\n\n- Delete a range of snapshots:\n\n`snapper -c {{config}} delete {{snapshot_X}}-{{snapshot_Y}}`\n"
 },
 {
   "command": "sam",
   "doc_url": "https://github.com/awslabs/aws-sam-cli",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - aws/aws-sam-cli: CLI tool to build, test, debug, and deploy Serverless applications using AWS SAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naws\n\n/\n\naws-sam-cli\n\n\n\n\n\n\n\n    Watch\n \n      169\n    \n\n\n\n\n      Star\n\n\n      5.2k\n    \n\n\n\n\n          Fork\n\n\n        816\n      \n\n\n\n\n\n        CLI tool to build, test, debug, and deploy Serverless applications using AWS SAM\n      \n\n\n\naws.amazon.com/serverless/sam/\n\n\n\n\n\n            View license\n        \n\n\n\n\n5.2k\n        stars\n \n\n816\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n285\n \n\n\n\nPull requests\n30\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\ndevelop\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14\nbranches\n\n\n\n73\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nwchengru\n\nchore: bump SAM CLI version to 1.3.2 (#2251)\n\n\n\n…\n\n\n\nda31b4f\n\nSep 24, 2020\n\n\n\n\n\nchore: bump SAM CLI version to 1.3.2 (#2251)\n\n\nda31b4f\n\n\n\nGit stats\n\n\n\n\n\n984\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github\n\n\n\nfeat: Allow pinned requirements for linux installs from source (#1917)\n\n\n\nApr 13, 2020\n\n\n\n\n\n\n\nbuild-image-src\n\n\n\nAdd SAM_CLI_VERSION build arg to provided image (#2245)\n\n\n\nSep 23, 2020\n\n\n\n\n\n\n\ndesigns\n\n\n\nfix(docs): md table-format for sam-build-cmd design (#1984)\n\n\n\nJun 15, 2020\n\n\n\n\n\n\n\ndocs\n\n\n\ndesign: samconfig (#1503)\n\n\n\nNov 23, 2019\n\n\n\n\n\n\n\nmedia\n\n\n\nfix: set youtube link in readme (#1378)\n\n\n\nAug 27, 2019\n\n\n\n\n\n\n\nrequirements\n\n\n\nChore: Bumped aws-sam-translator to version 1.27.0 and aws-sam-cli to…\n\n\n\nSep 22, 2020\n\n\n\n\n\n\n\nsamcli\n\n\n\nchore: bump SAM CLI version to 1.3.2 (#2251)\n\n\n\nSep 24, 2020\n\n\n\n\n\n\n\nsnap\n\n\n\nfeat(install): Add snapcraft config and link to snap package in README (\n\n\n\nApr 4, 2019\n\n\n\n\n\n\n\ntests\n\n\n\nfix: use parameter overrides from configuration file or command line (#…\n\n\n\nSep 23, 2020\n\n\n\n\n\n\n\n.coveragerc\n\n\n\nSAM CLI Refresh 🎉 (#383)\n\n\n\nMay 8, 2018\n\n\n\n\n\n\n\n.gitignore\n\n\n\nMatdumsa/gitpod setup (#2039)\n\n\n\nJul 24, 2020\n\n\n\n\n\n\n\n.gitpod.Dockerfile\n\n\n\nMatdumsa/gitpod setup (#2039)\n\n\n\nJul 24, 2020\n\n\n\n\n\n\n\n.gitpod.yml\n\n\n\nMatdumsa/gitpod setup (#2039)\n\n\n\nJul 24, 2020\n\n\n\n\n\n\n\n.pre-commit-config.yaml\n\n\n\nchore: Apply Black automatic code formatting (#1186)\n\n\n\nSep 4, 2019\n\n\n\n\n\n\n\n.pylintrc\n\n\n\nBuild for Layers (#1936)\n\n\n\nMay 15, 2020\n\n\n\n\n\n\n\nCODE_OF_CONDUCT.md\n\n\n\nAdding standard files (#335)\n\n\n\nMar 22, 2018\n\n\n\n\n\n\n\nCONTRIBUTING.md\n\n\n\nMatdumsa/gitpod setup (#2039)\n\n\n\nJul 24, 2020\n\n\n\n\n\n\n\nDESIGN.md\n\n\n\nfeat: Telemetry Implementation (#1287)\n\n\n\nJul 24, 2019\n\n\n\n\n\n\n\nDEVELOPMENT_GUIDE.md\n\n\n\nMatdumsa/gitpod setup (#2039)\n\n\n\nJul 24, 2020\n\n\n\n\n\n\n\nLICENSE\n\n\n\nfix: Update copyright in LICENSE (#1295)\n\n\n\nJul 26, 2019\n\n\n\n\n\n\n\nMANIFEST.in\n\n\n\nRelease v1.0.0 (#2111)\n\n\n\nJul 20, 2020\n\n\n\n\n\n\n\nMakefile\n\n\n\nBuild for Layers (#1936)\n\n\n\nMay 15, 2020\n\n\n\n\n\n\n\nNOTICE\n\n\n\nRelease v1.0.0 (#2111)\n\n\n\nJul 20, 2020\n\n\n\n\n\n\n\nREADME.md\n\n\n\nchore: Updated Slack #samdev Invite Link (#2225)\n\n\n\nSep 16, 2020\n\n\n\n\n\n\n\nTHIRD-PARTY-LICENSES\n\n\n\nRelease v1.0.0 (#2111)\n\n\n\nJul 20, 2020\n\n\n\n\n\n\n\nappveyor-windows-build-dotnet.yml\n\n\n\nfeat: dotnetcore3.1 support (#1908)\n\n\n\nMar 31, 2020\n\n\n\n\n\n\n\nappveyor-windows-build-go.yml\n\n\n\nfix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n\nappveyor-windows-build-java-container.yml\n\n\n\nfix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n\nappveyor-windows-build-java-ruby-inprocess.yml\n\n\n\nfix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n\nappveyor-windows-build-nodejs.yml\n\n\n\nfix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n\nappveyor-windows-build-python.yml\n\n\n\nchore: Bump aws-lambda-builders and SAM CLI to 1.0.0 (#2116)\n\n\n\nJul 20, 2020\n\n\n\n\n\n\n\nappveyor-windows-build-ruby.yml\n\n\n\nfix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n\nappveyor-windows.yml\n\n\n\nfeat: allow a custom builder workflow selection (#1957)\n\n\n\nMay 20, 2020\n\n\n\n\n\n\n\nappveyor.yml\n\n\n\nRemoving hack for docker issue as it is fixed by AppVeyor. (#2050)\n\n\n\nJun 16, 2020\n\n\n\n\n\n\n\npyproject.toml\n\n\n\nrefactor: init, generate_event and providers code move (#1685)\n\n\n\nDec 18, 2019\n\n\n\n\n\n\n\npytest.ini\n\n\n\nfix: removing object deletion and using same stack name for integrati…\n\n\n\nMar 9, 2020\n\n\n\n\n\n\n\nsetup.cfg\n\n\n\nfix: update license key in setup() to expected value by PyPi (#966)\n\n\n\nJan 29, 2019\n\n\n\n\n\n\n\nsetup.py\n\n\n\nchore: Support Python3.8 (#1519)\n\n\n\nDec 24, 2019\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\n\n\nAWS SAM\n\n\nThe AWS Serverless Application Model (SAM) is an open-source framework for building serverless applications.\nIt provides shorthand syntax to express functions, APIs, databases, and event source mappings.\nWith just a few lines of configuration, you can define the application you want and model it.\n\n\nGet Started\nTo get started with building SAM-based applications, use the SAM CLI. SAM CLI provides a Lambda-like execution\nenvironment that lets you locally build, test, debug, and deploy applications defined by SAM templates.\n\nInstall SAM CLI\nBuild & Deploy a \"Hello World\" Web App\nInstall AWS Toolkit to use SAM with your favorite IDEs.\n\nNext Steps: Learn to build a more complex serverless application.\n\nExtract text from images and store in a database using Amazon S3 and Amazon Rekognition services.\nDetect when records are added to a database using Amazon DynamoDB database and asynchronous stream processing.\n\nDetailed References: Explains SAM commands and usage in depth.\n\nCLI Commands\nSAM Template Specification\nPolicy Templates\n\nWhy SAM\n\n\nSingle-deployment configuration. SAM makes it easy to organize related components and resources, and operate on a single stack. You can use SAM to share configuration (such as memory and timeouts) between resources, and deploy all related resources together as a single, versioned entity.\n\n\nLocal debugging and testing. Use SAM CLI to locally build, test, and debug SAM applications on a Lambda-like execution environment. It tightens the development loop by helping you find & troubleshoot issues locally that you might otherwise identify only after deploying to the cloud.\n\n\nDeep integration with development tools. You can use SAM with a suite of tools you love and use.\n\nIDEs: PyCharm, IntelliJ, Visual Studio Code, Visual Studio, AWS Cloud9\nBuild: CodeBuild\nDeploy: CodeDeploy, Jenkins\nContinuous Delivery Pipelines: CodePipeline\nDiscover Serverless Apps & Patterns: AWS Serverless Application Repository\n\n\n\nBuilt-in best practices. You can use SAM to define and deploy your infrastructure as configuration. This makes it possible for you to use and enforce best practices through code reviews. Also, with a few lines of configuration, you can enable safe deployments through CodeDeploy, and can enable tracing using AWS X-Ray.\n\n\nExtension of AWS CloudFormation. Because SAM is an extension of AWS CloudFormation, you get the reliable deployment capabilities of AWS CloudFormation. You can define resources by using CloudFormation in your SAM template. Also, you can use the full suite of resources, intrinsic functions, and other template features that are available in CloudFormation.\n\n\nWhat is this Github repository? 💻\nThis Github Repository contains source code for SAM CLI. Here is the development team talking about this code:\n\nSAM CLI code is written in Python. Source code is well documented, very modular, with 95% unit test coverage.\nIt uses this awesome Python library called Click to manage the command line interaction and uses Docker to run Lambda functions locally.\nWe think you'll like the code base. Clone it and run make pr!\n\nContribute to SAM\nWe love our contributors ❤️ We have over 100 contributors who have built various parts of the product.\nRead this testimonial from @ndobryanskyy to learn\nmore about what it was like contributing to SAM.\nDepending on your interest and skill, you can help build the different parts of the SAM project;\nEnhance the SAM Specification\nMake pull requests, report bugs, and share ideas to improve the full SAM template specification.\nSource code is located on Github at awslabs/serverless-application-model.\nRead the SAM Specification Contributing Guide\nto get started.\nStrengthen SAM CLI\nAdd new commands or enhance existing ones, report bugs, or request new features for the SAM CLI.\nSource code is located on Github at awslabs/aws-sam-cli. Read the SAM CLI Contributing Guide to\nget started.\nUpdate SAM Developer Guide\nSAM Developer Guide provides comprehensive getting started guide and reference documentation.\nSource code is located on Github at awsdocs/aws-sam-developer-guide.\nRead the SAM Documentation Contribution Guide to get\nstarted.\nJoin the SAM Community on Slack\nJoin the SAM developers channel (#samdev) on Slack to collaborate with fellow community members and the AWS SAM team.\n\n\n\n\n\n\n\n\nAbout\n\n      CLI tool to build, test, debug, and deploy Serverless applications using AWS SAM\n    \n\n\n\naws.amazon.com/serverless/sam/\n\n\nTopics\n\n\n\n  serverless\n\n\n  aws\n\n\n  lambda\n\n\n  serverlessapplicationmodel\n\n\n  sam\n\n\n  docker\n\n\n  api-gateway\n\n\n  python\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n      73\n\n\n\n\n\nRelease 1.3.2\n\n          Latest\n \nSep 24, 2020\n\n \n\n        + 72 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n        Used by 659\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            + 651\n          \n\n\n\n\n\n\n\n    Contributors 176\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 165 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython\n97.0%\n\n\n\n\n\nGo\n2.0%\n\n\n\n\n\nJava\n0.3%\n\n\n\n\n\nRuby\n0.2%\n\n\n\n\n\nC#\n0.2%\n\n\n\n\n\nShell\n0.1%\n\n\n\n\n\nOther\n0.2%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# sam\n\n> AWS Serverless Application Model (SAM) CLI.\n> More information: <https://github.com/awslabs/aws-sam-cli>.\n\n- Initialize a serverless application:\n\n`sam init`\n\n- Initialize a serverless application with a specific runtime:\n\n`sam init --runtime {{python3.7}}`\n\n- Package a SAM application:\n\n`sam package`\n\n- Build your Lambda function code:\n\n`sam build`\n\n- Run your serverless application locally:\n\n`sam local start-api`\n\n- Deploy an AWS SAM application:\n\n`sam deploy`\n"
 },
 {
   "command": "chkconfig",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# chkconfig\n\n> Manage the runlevel of services on CentOS 6.\n\n- List services with runlevel:\n\n`chkconfig --list`\n\n- Show a service's runlevel:\n\n`chkconfig --list {{ntpd}}`\n\n- Enable service at boot:\n\n`chkconfig {{sshd}} on`\n\n- Enable service at boot for runlevels 2, 3, 4, and 5:\n\n`chkconfig --level {{2345}} {{sshd}} on`\n\n- Disable service at boot:\n\n`chkconfig {{ntpd}} off`\n\n- Disable service at boot for runlevel 3:\n\n`chkconfig --level {{3}} {{ntpd}} off`\n"
 },
 {
   "command": "kexec",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# kexec\n\n> Directly reboot into a new kernel.\n\n- Load a new kernel:\n\n`kexec -l {{path/to/kernel}} --initrd={{path/to/initrd}} --command-line={{arguments}}`\n\n- Load a new kernel with current boot parameters:\n\n`kexec -l {{path/to/kernel}} --initrd={{path/to/initrd}} --reuse-cmdline`\n\n- Execute a currently loaded kernel:\n\n`kexec -e`\n\n- Unload current kexec target kernel:\n\n`kexec -u`\n"
 },
 {
   "command": "chage",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# chage\n\n> Change user account and password expiry information.\n\n- List password information for the user:\n\n`chage -l {{username}}`\n\n- Enable password expiration in 10 days:\n\n`sudo chage -M {{10}} {{username}}`\n\n- Disable password expiration:\n\n`sudo chage -M -1 {{username}}`\n\n- Set account expiration date:\n\n`sudo chage -E {{YYYY-MM-DD}}`\n\n- Force user to change password on next log in:\n\n`sudo chage -d 0`\n"
 },
 {
   "command": "script",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nSCRIPT(1)\t\t  BSD General Commands Manual\t\t     SCRIPT(1)\n\nNAME\n     script -- make typescript of terminal session\n\nSYNOPSIS\n     script [-adkpqr] [-F pipe] [-t time] [file [command ...]]\n\nDESCRIPTION\n     The script utility makes a typescript of everything printed on your ter-\n     minal.  It is useful for students who need a hardcopy record of an inter-\n     active session as proof of an assignment, as the typescript file can be\n     printed out later with lpr(1).\n\n     If the argument file is given, script saves all dialogue in file.\tIf no\n     file name is given, the typescript is saved in the file typescript.\n\n     If the argument command is given, script will run the specified command\n     with an optional argument vector instead of an interactive shell.\n\n     The following options are available:\n\n     -a      Append the output to file or typescript, retaining the prior con-\n\t     tents.\n\n     -d      When playing back a session with the -p flag, do not sleep\n\t     between records when playing back a timestamped session.\n\n     -F pipe\n\t     Immediately flush output after each write.  This will allow a\n\t     user to create a named pipe using mkfifo(1) and another user may\n\t     watch the live session using a utility like cat(1).\n\n     -k      Log keys sent to the program as well as output.\n\n     -p      Play back a session recorded with the -r flag in real time.\n\n     -q      Run in quiet mode, omit the start, stop and command status mes-\n\t     sages.\n\n     -r      Record a session with input, output, and timestamping.\n\n     -t time\n\t     Specify the interval at which the script output file will be\n\t     flushed to disk, in seconds.  A value of 0 causes script to flush\n\t     after every character I/O event.  The default interval is 30 sec-\n\t     onds.\n\n     The script ends when the forked shell (or command) exits (a control-D to\n     exit the Bourne shell (sh(1)), and exit, logout or control-D (if\n     ignoreeof is not set) for the C-shell, csh(1)).\n\n     Certain interactive commands, such as vi(1), create garbage in the type-\n     script file.  The script utility works best with commands that do not\n     manipulate the screen.  The results are meant to emulate a hardcopy ter-\n     minal, not an addressable one.\n\nENVIRONMENT\n     The following environment variables are utilized by script:\n\n     SCRIPT\n\t    The SCRIPT environment variable is added to the sub-shell.\tIf\n\t    SCRIPT already existed in the users environment, its value is\n\t    overwritten within the sub-shell.  The value of SCRIPT is the name\n\t    of the typescript file.\n\n     SHELL  If the variable SHELL exists, the shell forked by script will be\n\t    that shell.  If SHELL is not set, the Bourne shell is assumed.\n\t    (Most shells set this variable automatically).\n\nSEE ALSO\n     csh(1)\n\nHISTORY\n     The script command appeared in 3.0BSD.\n\n     The -d, -p and -r options first appeared in NetBSD 2.0 and were ported to\n     FreeBSD 9.2.\n\nBUGS\n     The script utility places everything in the log file, including linefeeds\n     and backspaces.  This is not what the naive user expects.\n\n     It is not possible to specify a command without also naming the script\n     file because of argument parsing compatibility issues.\n\n     When running in -k mode, echo cancelling is far from ideal.  The slave\n     terminal mode is checked for ECHO mode to check when to avoid manual echo\n     logging.  This does not work when the terminal is in a raw mode where the\n     program being run is doing manual echo.\n\n     If script reads zero bytes from the terminal, it switches to a mode when\n     it only attempts to read once a second until there is data to read.  This\n     prevents script from spinning on zero-byte reads, but might cause a\n     1-second delay in processing of user input.\n\nBSD\t\t\t       December 4, 2013 \t\t\t   BSD\n",
   "tldr_summary": "# script\n\n> Record all terminal output to file.\n\n- Record a new session to a file named `typescript` in the current directory:\n\n`script`\n\n- Record a new session to a custom filepath:\n\n`script {{path/to/session.out}}`\n\n- Record a new session, appending to an existing file:\n\n`script -a {{path/to/session.out}}`\n\n- Record timing information (data is outputted to the standard error):\n\n`script -t 2> {{path/to/timingfile}}`\n"
 },
 {
   "command": "file-rename",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rename\n\n> Rename multiple files.\n> NOTE: this page refers to the command from the `file-rename` Debian package.\n\n- Rename files using a Perl Common Regular Expression (substitute 'foo' with 'bar' wherever found):\n\n`rename {{'s/foo/bar/'}} {{*}}`\n\n- Dry-run - display which renames would occur without performing them:\n\n`rename -n {{'s/foo/bar/'}} {{*}}`\n\n- Force renaming even if the operation would remove existing destination files:\n\n`rename -f {{'s/foo/bar/'}} {{*}}`\n\n- Convert filenames to lower case (use `-f` in case-insensitive filesystems to prevent \"already exists\" errors):\n\n`rename 'y/A-Z/a-z/' {{*}}`\n\n- Replace whitespace with underscores:\n\n`rename 's/\\s+/_/g' {{*}}`\n"
 },
 {
   "command": "cmus",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# cmus\n\n> Commandline Music Player.\n> Use arrow keys to navigate, `<enter/return>` to select, and numbers 1-8 switch between different views.\n\n- Open cmus from specified directory:\n\n`cmus {{path/to/directory}}`\n\n- Add file/directory to library:\n\n`:add {{path/to/file_or_directory}}`\n\n- Pause/unpause current song:\n\n`c`\n\n- Toggle shuffle mode on/off:\n\n`s`\n\n- Quit cmus:\n\n`q`\n"
 },
 {
   "command": "lldb",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nLLDB(1) \t\t  BSD General Commands Manual\t\t       LLDB(1)\n\nNAME\n     lldb -- The debugger\n\nSYNOPSIS\n     lldb [-hvdexw] [-a arch] [-c core-file] [-l script-language]\n\t  [-s lldb-commands] [-n process-name] [-p pid] [[--] <PROGRAM-ARG1>\n\t  <PROGRAM-ARG2> ...]\n\nDESCRIPTION\n     lldb is the command line interface for the LLDB debugger library.\tlldb\n     can debug C, C++, Objective-C, Objective-C++ and Swift programs.\n\n     The following options are available:\n\n     -h, --help\n\t     Prints out the usage information for the lldb debugger.  The\n\t     --help text may be more up-to-date and authoritative than the\n\t     command line options described in this man page.\n\n     -v, --version\n\t     Prints out the version number of the lldb debugger.\n\n     -a, --arch arch\n\t     Specifies which architecture lldb will use when launching the\n\t     specified program (assuming the provided executable is built for\n\t     multiple architectures.)\n\n     -f, --file filename\n\t     Specifies the executable file that lldb will be launching /\n\t     attaching to.\n\n     -n, --attach-name process-name\n\t     Specifies the name of a currently-running process to attach to.\n\t     (or the name of a process to wait for if -w is used.)\n\n     -w, --wait-for\n\t     When used in concert with -n process-name, indicates that lldb\n\t     should wait for a new process of that name to be started -- and\n\t     attach to it as early in the process-launch as possible.\n\n     -p, --attach-pid pid\n\t     Specifies a currently running process that lldb should attach to.\n\n     -c, --core core-file\n\t     Specifies the core file to examine.\n\n     -l, --script-language language\n\t     Tells the debugger to use the specified scripting language for\n\t     user-defined scripts, rather than the default.  Valid scripting\n\t     languages that can be specified include Python, Perl, Ruby and\n\t     Tcl.  Currently only the Python extensions have been implemented.\n\n     -d, --debug\n\t     Tells the debugger to print out extra information for debugging\n\t     itself.\n\n     -s, --source filename\n\t     Tells lldb to read in and execute the file \"filename\", which\n\t     should contain lldb commands.\n\n     -e, --editor\n\t     Instructs lldb to open source files using the host's \"external\n\t     editor\" mechanism.\n\n     -x, --no-lldbinit\n\t     Do not automatically parse any '.lldbinit' files.\n\n\t     (If you do not provide -f then the first argument will be the\n\t     file to be debugged so 'lldb -- <filename> [<ARG1> [<ARG2>]]'\n\t     also works.  Remember to end the options with \"--\" if any of your\n\t     arguments have a \"-\" in them.)\n\nUSING LLDB\n     In lldb there is a help command which can be used to find descriptions\n     and examples of all lldb commands.  To get help on \"breakpoint set\" you\n     would type \"help breakpoint set\".\n\n     There is also an apropos command which will search the help text of all\n     commands for a given term -- this is useful for locating a command by\n     topic.  For instance, \"apropos breakpoint\" will list any command that has\n     the word \"breakpoint\" in its help text.\n\nFILES\n     lldb will read settings/aliases/commands from three files at startup, if\n     they exist.\n\n     First, it will read a ~/.lldbinit-debugger command file.  If you are\n     using the lldb command line interface, this is ~/.lldbinit-lldb.  If you\n     are using lldb inside a GUI debugger like Xcode this will be\n     ~/.lldbinit-Xcode.  This is a useful place to put settings that you want\n     to apply only when a given lldb command interpreter is used.\n\n     Second, ~/.lldbinit is read.\n\n     Third, an .lldbinit file in the current working directory (where lldb is\n     started) will be read.\n\nSEE ALSO\n     The LLDB project page http://lldb.llvm.org/ has many different resources\n     for lldb users -- the gdb/lldb command equivalence page\n     http://lldb.llvm.org/lldb-gdb.html can be especially helpful for users\n     coming from gdb.\n\nBUGS\n     To report bugs, please visit http://llvm.org/bugs/\n\nAUTHOR\n     Maintained by the LLDB Team, http://lldb.llvm.org/\n\nBSD\t\t\t       December 16, 2015\t\t\t   BSD\n",
   "tldr_summary": "# lldb\n\n> The LLVM Low-Level Debugger.\n\n- Debug an executable:\n\n`lldb {{executable}}`\n\n- Attach `lldb` to a running process with a given PID:\n\n`lldb -p {{pid}}`\n\n- Wait for a new process to launch with a given name, and attach to it:\n\n`lldb -w -n {{process_name}}`\n"
 },
 {
   "command": "ssh-add",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nSSH-ADD(1)\t\t  BSD General Commands Manual\t\t    SSH-ADD(1)\n\nNAME\n     ssh-add -- adds private key identities to the authentication agent\n\nSYNOPSIS\n     ssh-add [-cDdkLlqXx] [-E fingerprint_hash] [-t life] [file ...]\n     ssh-add -s pkcs11\n     ssh-add -e pkcs11\n\nDESCRIPTION\n     ssh-add adds private key identities to the authentication agent,\n     ssh-agent(1).  When run without arguments, it adds the files\n     ~/.ssh/id_rsa, ~/.ssh/id_dsa, ~/.ssh/id_ecdsa, and ~/.ssh/id_ed25519.\n     After loading a private key, ssh-add will try to load corresponding cer-\n     tificate information from the filename obtained by appending -cert.pub to\n     the name of the private key file.\tAlternative file names can be given on\n     the command line.\n\n     If any file requires a passphrase, ssh-add asks for the passphrase from\n     the user.\tThe passphrase is read from the user's tty.  ssh-add retries\n     the last passphrase if multiple identity files are given.\n\n     The authentication agent must be running and the SSH_AUTH_SOCK environ-\n     ment variable must contain the name of its socket for ssh-add to work.\n\n     The options are as follows:\n\n     -c      Indicates that added identities should be subject to confirmation\n\t     before being used for authentication.  Confirmation is performed\n\t     by ssh-askpass(1).  Successful confirmation is signaled by a zero\n\t     exit status from ssh-askpass(1), rather than text entered into\n\t     the requester.\n\n     -D      Deletes all identities from the agent.\n\n     -d      Instead of adding identities, removes identities from the agent.\n\t     If ssh-add has been run without arguments, the keys for the\n\t     default identities and their corresponding certificates will be\n\t     removed.  Otherwise, the argument list will be interpreted as a\n\t     list of paths to public key files to specify keys and certifi-\n\t     cates to be removed from the agent.  If no public key is found at\n\t     a given path, ssh-add will append .pub and retry.\n\n     -E fingerprint_hash\n\t     Specifies the hash algorithm used when displaying key finger-\n\t     prints.  Valid options are: ``md5'' and ``sha256''.  The default\n\t     is ``sha256''.\n\n     -e pkcs11\n\t     Remove keys provided by the PKCS#11 shared library pkcs11.\n\n     -k      When loading keys into or deleting keys from the agent, process\n\t     plain private keys only and skip certificates.\n\n     -L      Lists public key parameters of all identities currently repre-\n\t     sented by the agent.\n\n     -l      Lists fingerprints of all identities currently represented by the\n\t     agent.\n\n     -q      Be quiet after a successful operation.\n\n     -s pkcs11\n\t     Add keys provided by the PKCS#11 shared library pkcs11.\n\n     -t life\n\t     Set a maximum lifetime when adding identities to an agent.  The\n\t     lifetime may be specified in seconds or in a time format speci-\n\t     fied in sshd_config(5).\n\n     -X      Unlock the agent.\n\n     -x      Lock the agent with a password.\n\n     -K      When adding identities, each passphrase will also be stored in\n\t     the user's keychain.  When removing identities with -d, each\n\t     passphrase will be removed from it.\n\n     -A      Add identities to the agent using any passphrase stored in the\n\t     user's keychain.\n\nENVIRONMENT\n     DISPLAY and SSH_ASKPASS\n\t     If ssh-add needs a passphrase, it will read the passphrase from\n\t     the current terminal if it was run from a terminal.  If ssh-add\n\t     does not have a terminal associated with it but DISPLAY and\n\t     SSH_ASKPASS are set, it will execute the program specified by\n\t     SSH_ASKPASS (by default ``ssh-askpass'') and open an X11 window\n\t     to read the passphrase.  This is particularly useful when calling\n\t     ssh-add from a .xsession or related script.  (Note that on some\n\t     machines it may be necessary to redirect the input from /dev/null\n\t     to make this work.)\n\n     SSH_AUTH_SOCK\n\t     Identifies the path of a UNIX-domain socket used to communicate\n\t     with the agent.\n\nFILES\n     ~/.ssh/id_dsa\n\t     Contains the DSA authentication identity of the user.\n\n     ~/.ssh/id_ecdsa\n\t     Contains the ECDSA authentication identity of the user.\n\n     ~/.ssh/id_ed25519\n\t     Contains the Ed25519 authentication identity of the user.\n\n     ~/.ssh/id_rsa\n\t     Contains the RSA authentication identity of the user.\n\n     Identity files should not be readable by anyone but the user.  Note that\n     ssh-add ignores identity files if they are accessible by others.\n\nEXIT STATUS\n     Exit status is 0 on success, 1 if the specified command fails, and 2 if\n     ssh-add is unable to contact the authentication agent.\n\nSEE ALSO\n     ssh(1), ssh-agent(1), ssh-askpass(1), ssh-keygen(1), sshd(8)\n\nAUTHORS\n     OpenSSH is a derivative of the original and free ssh 1.2.12 release by\n     Tatu Ylonen.  Aaron Campbell, Bob Beck, Markus Friedl, Niels Provos, Theo\n     de Raadt and Dug Song removed many bugs, re-added newer features and cre-\n     ated OpenSSH.  Markus Friedl contributed the support for SSH protocol\n     versions 1.5 and 2.0.\n\nBSD\t\t\t      September 25, 2020\t\t\t   BSD\n",
   "tldr_summary": "# ssh-add\n\n> Manage loaded ssh keys in the ssh-agent.\n> Ensure that ssh-agent is up and running for the keys to be loaded in it.\n\n- Add the default ssh keys in \"~/.ssh\" to the ssh-agent:\n\n`ssh-add`\n\n- Add a specific key to the ssh-agent:\n\n`ssh-add {{path/to/private_key}}`\n\n- List fingerprints of currently loaded keys:\n\n`ssh-add -l`\n\n- Delete a key from the ssh-agent:\n\n`ssh-add -d {{path/to/private_key}}`\n\n- Delete all currently loaded keys from the ssh-agent:\n\n`ssh-add -D`\n"
 },
 {
   "command": "certbot",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# certbot\n\n> The Let's Encrypt Agent for automatically obtaining and renewing TLS certificates.\n> Successor to `letsencrypt`.\n\n- Obtain a new certificate via webroot authorization, but do not install it automatically:\n\n`sudo certbot certonly --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}}`\n\n- Obtain a new certificate via nginx authorization, installing the new certificate automatically:\n\n`sudo certbot --nginx --domain {{subdomain.example.com}}`\n\n- Obtain a new certificate via apache authorization, installing the new certificate automatically:\n\n`sudo certbot --apache --domain {{subdomain.example.com}}`\n\n- Renew all Let's Encrypt certificates that expire in 30 days or less (don't forget to restart any servers that use them afterwards):\n\n`sudo certbot renew`\n\n- Simulate the obtaining of a new certificate, but don't actually save any new certificates to disk:\n\n`sudo certbot --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}} --dry-run`\n\n- Obtain an untrusted test certificate instead:\n\n`sudo certbot --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}} --test-cert`\n"
 },
 {
   "command": "runsvdir",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# runsvdir\n\n> Run an entire directory of services.\n\n- Start and manage all services in a directory as the current user:\n\n`runsvdir {{path/to/services}}`\n\n- Start and manage all services in a directory as root:\n\n`sudo runsvdir {{path/to/services}}`\n\n- Start services in separate sessions:\n\n`runsvdir -P {{path/to/services}}`\n"
 },
 {
   "command": "debchange",
   "doc_url": "https://manpages.debian.org/debchange",
   "doc_text": "\n\n\n\ndebchange(1) — devscripts — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / devscripts\n     \n     \n     \n     / debchange(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nDirectory name checking\n\n\nOPTIONS\n\n\nCONFIGURATION VARIABLES\n\n\nENVIRONMENT\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.19.5+deb10u1\n\n\nbuster-backports 2.20.4~bpo10+1\n\n\ntesting 2.20.4\n\n\nunstable 2.20.4\n\n\n\n\n\n\nother languages\n\n\n\n\nDeutsch\n\n\nEnglish\n\n\nfrançais\n\n\n\n\n\n\nScroll to navigation\n\n\n\nDEBCHANGE(1)\nGeneral Commands Manual\nDEBCHANGE(1)\n\n\n\n\nNAME¶\ndebchange - Tool for maintenance of the debian/changelog file in a source\n  package\n\n\nSYNOPSIS¶\ndebchange [options] [text ...]\n\ndch [options] [text ...]\n\n\nDESCRIPTION¶\ndebchange or its alias dch will add a new comment line to the\n  Debian changelog in the current source tree. This command must be run from\n  within that tree. If the text of the change is given on the command line,\n  debchange will run in batch mode and simply add the text, with line\n  breaks as necessary, at the appropriate place in debian/changelog (or\n  the changelog specified by options, as described below). If the text given on\n  the command line is a null string, debchange will run in batch mode\n  without adding any text. If the text given on the command line is a space\n  string, debchange will run in batch mode and add a blank changelog\n  entry. If no text is specified then debchange will run the editor as\n  determined by sensible-editor for you to edit the file. (The\n  environment variables VISUAL and EDITOR are used in this order\n  to determine which editor to use.) Editors which understand the +n\n  option for starting the editing on a specified line will use this to move to\n  the correct line of the file for editing. If the editor is quit without\n  modifying the temporary file, debchange will exit without touching the\n  existing changelog. Note that the changelog is assumed to be encoded\n  with the UTF-8 encoding. If it is not, problems may occur. Please see the\n  iconv(1) manpage to find out how to convert changelogs from legacy\n  encodings. Finally, a changelog or NEWS file can be created from\n  scratch using the --create option described below.\ndebchange also supports automatically producing bug-closing\n    changelog entries, using the --closes option. This will usually query\n    the BTS, the Debian Bug Tracking System (see https://bugs.debian.org/) to\n    determine the title of the bug and the package in which it occurs. This\n    behaviour can be stopped by giving a --noquery option or by setting\n    the configuration variable DEBCHANGE_QUERY_BTS to no, as\n    described below. In either case, the editor (as described above) will always\n    be invoked to give an opportunity to modify the entries, and the changelog\n    will be accepted whether or not modifications are made. An extra changelog\n    entry can be given on the command line in addition to the closes\n  entries.\nAt most one of --append, --increment, --edit,\n    --release, and --newversion may be specified as listed below.\n    If no options are specified, debchange will use heuristics to guess\n    whether or not the package has been successfully released, and behave as if\n    --increment had been specified if the package has been released, or\n    otherwise as if --append has been specified.\nTwo different sets of heuristics can be used, as controlled by the\n    --release-heuristic option or the DEBCHANGE_RELEASE_HEURISTIC\n    configuration variable. The default changelog heuristic assumes the\n    package has been released unless its changelog contains UNRELEASED in\n    the distribution field. If this heuristic is enabled then the distribution\n    will default to UNRELEASED in new changelog entries, and the\n    --mainttrailer option described below will be automatically enabled.\n    This can be useful if a package can be released by different maintainers, or\n    if you do not keep the upload logs. The alternate log heuristic\n    determines if a package has been released by looking for an appropriate\n    dupload(1) or dput(1) log file in the parent directory. A\n    warning will be issued if the log file is found but a successful upload is\n    not recorded. This may be because the previous upload was performed with a\n    version of dupload prior to 2.1 or because the upload failed.\nIf either --increment or --newversion is used, the\n    name and email for the new version will be determined as follows. If the\n    environment variable DEBFULLNAME is set, this will be used for the\n    maintainer full name; if not, then NAME will be checked. If the\n    environment variable DEBEMAIL is set, this will be used for the email\n    address. If this variable has the form \"name <email>\", then\n    the maintainer name will also be taken from here if neither\n    DEBFULLNAME nor NAME is set. If this variable is not set, the\n    same test is performed on the environment variable EMAIL. Next, if\n    the full name has still not been determined, then use getpwuid(3) to\n    determine the name from the password file. If this fails, use the previous\n    changelog entry. For the email address, if it has not been set from\n    DEBEMAIL or EMAIL, then look in /etc/mailname, then\n    attempt to build it from the username and FQDN, otherwise use the email\n    address in the previous changelog entry. In other words, it's a good idea to\n    set DEBEMAIL and DEBFULLNAME when using this script.\nSupport is included for changelogs that record changes by multiple\n    co-maintainers of a package. If an entry is appended to the current\n    version's entries, and the maintainer is different from the maintainer who\n    is listed as having done the previous entries, then lines will be added to\n    the changelog to tell which maintainers made which changes. Currently only\n    one of the several such styles of recording this information is supported,\n    in which the name of the maintainer who made a set of changes appears on a\n    line before the changes, inside square brackets. This can be switched on and\n    off using the --[no]multimaint option or the\n    DEBCHANGE_MULTIMAINT configuration file option; the default is to\n    enable it. Note that if an entry has already been marked in this way, then\n    this option will be silently ignored.\nIf the directory name of the source tree has the form\n    package-version, then debchange will also attempt to\n    rename it if the (upstream) version number changes. This can be prevented by\n    using the --preserve command line or configuration file option as\n    described below.\nIf --force-bad-version or --allow-lower-version is\n    used, debchange will not stop if the new version is less than the\n    current one. This is especially useful while doing backports.\n\n\nDirectory name checking¶\nIn common with several other scripts in the devscripts package,\n  debchange will climb the directory tree until it finds a\n  debian/changelog file. As a safeguard against stray files causing\n  potential problems, it will examine the name of the parent directory once it\n  finds the debian/changelog file, and check that the directory name\n  corresponds to the package name. Precisely how it does this is controlled by\n  two configuration file variables DEVSCRIPTS_CHECK_DIRNAME_LEVEL and\n  DEVSCRIPTS_CHECK_DIRNAME_REGEX, and their corresponding command-line\n  options --check-dirname-level and --check-dirname-regex.\nDEVSCRIPTS_CHECK_DIRNAME_LEVEL can take the following\n    values:\n\n0\nNever check the directory name.\n1\nOnly check the directory name if we have had to change directory in our\n      search for debian/changelog. This is the default behaviour.\n2\nAlways check the directory name.\n\nThe directory name is checked by testing whether the current\n    directory name (as determined by pwd(1)) matches the regex given by\n    the configuration file option DEVSCRIPTS_CHECK_DIRNAME_REGEX or by\n    the command line option --check-dirname-regex regex. Here\n    regex is a Perl regex (see perlre(3perl)), which will be\n    anchored at the beginning and the end. If regex contains a\n    '/', then it must match the full directory path. If not, then it must\n    match the full directory name. If regex contains the string\n    ´PACKAGE', this will be replaced by the source package name,\n    as determined from the changelog. The default value for the regex is:\n    ´PACKAGE(-.+)?', thus matching directory names such as\n    PACKAGE and PACKAGE-version.\nThe default changelog to be edited is debian/changelog;\n    however, this can be changed using the --changelog or --news\n    options or the CHANGELOG environment variable, as described\n  below.\n\n\nOPTIONS¶\n\n--append, -a\nAdd a new changelog entry at the end of the current version's\n    entries.\n--increment, -i\nIncrement either the final component of the Debian release number or, if\n      this is a native Debian package, the version number. On Ubuntu or Tanglu,\n      this will also change the suffix from buildX to ubuntu1/tanglu1. Use\n      -R, --rebuild for a no change rebuild increment. This\n      creates a new section at the beginning of the changelog with appropriate\n      headers and footers. Also, if this is a new version of a native Debian\n      package, the directory name is changed to reflect this. If\n      DEBCHANGE_RELEASE_HEURISTIC is changelog (default) and the\n      current release is UNRELEASED, this will only change the version of\n      the current changelog stanza. Otherwise, this will create a new changelog\n      stanza with the new version.\n--newversion version, -v version\nThis specifies the version number (including the Debian release part)\n      explicitly and behaves as the --increment option in other respects.\n      It will also change the directory name if the upstream version number has\n      changed. If DEBCHANGE_RELEASE_HEURISTIC is changelog\n      (default) and the current release is UNRELEASED, this will only\n      change the version of the current changelog stanza. Otherwise, this will\n      create a new changelog stanza with the new version.\n--edit, -e\nEdit the changelog in an editor.\n--release, -r\nFinalize the changelog for a release. Update the changelog timestamp. If\n      the distribution is set to UNRELEASED, change it to the\n      distribution from the previous changelog entry (or another distribution as\n      specified by --distribution). If there are no previous changelog\n      entries and an explicit distribution has not been specified,\n      unstable will be used.\n--force-save-on-release\nWhen --release is used, an editor is opened to allow inspection of\n      the changelog. The user is required to save the file to accept the\n      modified changelog, otherwise the original will be kept (default).\n--no-force-save-on-release\nDo not do so. Note that a dummy changelog entry may be supplied in order\n      to achieve the same effect - e.g. debchange --release \"\".\n      The entry will not be added to the changelog but its presence will\n      suppress the editor.\n--create\nThis will create a new debian/changelog file (or NEWS if the\n      --news option is used). You must be in the top-level directory to\n      use this; no directory name checking will be performed. The package name\n      and version can either be specified using the --package and\n      --newversion options, determined from the directory name using the\n      --fromdirname option or entered manually into the generated\n      changelog file. The maintainer name is determined from the\n      environment if this is possible, and the distribution is specified either\n      using the --distribution option or in the generated\n      changelog file.\n--empty\nWhen used in combination with --create, suppress the automatic\n      addition of an \"initial release\" changelog entry (so that\n      the next invocation of debchange adds the first entry). Note that\n      this will cause a dpkg-parsechangelog warning on the next\n      invocation due to the lack of changes.\n--package package\nThis specifies the package name to be used in the new changelog; this may\n      only be used in conjunction with the --create, --increment\n      and --newversion options.\n--nmu, -n\nIncrement the Debian release number for a non-maintainer upload by either\n      appending a \".1\" to a non-NMU version number (unless the\n      package is Debian native, in which case \"+nmu1\" is\n      appended) or by incrementing an NMU version number, and add an NMU\n      changelog comment. This happens automatically if the packager is neither\n      in the Maintainer nor the Uploaders field in\n      debian/control, unless DEBCHANGE_AUTO_NMU is set to\n      no or the --no-auto-nmu option is used.\n--bin-nmu\nIncrement the Debian release number for a binary non-maintainer upload by\n      either appending a \"+b1\" to a non-binNMU version number\n      or by incrementing a binNMU version number, and add a binNMU changelog\n      comment.\n--qa, -q\nIncrement the Debian release number for a Debian QA Team upload, and add a\n      QA upload changelog comment.\n--rebuild, -R\nIncrement the Debian release number for a no-change rebuild by appending a\n      \"build1\" or by incrementing a rebuild version number.\n--security, -s\nIncrement the Debian release number for a Debian Security Team\n      non-maintainer upload, and add a Security Team upload changelog\n      comment.\n--lts\nIncrement the Debian release number for a LTS Security Team non-maintainer\n      upload, and add a LTS Security Team upload changelog comment.\n--team\nIncrement the Debian release number for a team upload, and add a Team\n      upload changelog comment.\n--upstream, -U\nDon't append distro-name1 to the version on a derived distribution.\n      Increment the Debian version.\n--bpo\nIncrement the Debian release number for an upload to buster-backports, and\n      add a backport upload changelog comment.\n--stable\nIncrement the Debian release number for an upload to the current stable\n      release.\n--local, -lsuffix\n\n     Add a suffix to the Debian version number for a local build.\n--force-bad-version, -b\nForce a version number to be less than the current one (e.g., when\n      backporting).\n--allow-lower-version pattern\nAllow a version number to be less than the current one if the new version\n      matches the specified pattern.\n--force-distribution\nForce the provided distribution to be used, even if it doesn't match the\n      list of known distributions (e.g. for unofficial distributions).\n--auto-nmu\nAttempt to automatically determine whether a change to the changelog\n      represents a Non Maintainer Upload. This is the default.\n--no-auto-nmu\nDisable automatic NMU detection. Equivalent to setting\n      DEBCHANGE_AUTO_NMU to no.\n--fromdirname, -d\nThis will take the upstream version number from the directory name, which\n      should be of the form package-version. If the\n      upstream version number has increased from the most recent changelog\n      entry, then a new entry will be made with version number\n      version-1 (or version if the package is Debian\n      native), with the same epoch as the previous package version. If the\n      upstream version number is the same, this option will behave in the same\n      way as -i.\n--closes nnnnn[,nnnnn ...]\nAdd changelog entries to close the specified bug numbers. Also invoke the\n      editor after adding these entries. Will generate warnings if the BTS\n      cannot be contacted (and --noquery has not been specified), or if\n      there are problems with the bug report located.\n--[no]query\nShould we attempt to query the BTS when generating closes entries?\n--preserve, -p\nPreserve the source tree directory name if the upstream version number (or\n      the version number of a Debian native package) changes. See also the\n      configuration variables section below.\n --no-preserve, --nopreserve\nDo not preserve the source tree directory name (default).\n--vendor vendor\nOverride the distributor ID over the default returned by dpkg-vendor. This\n      name is used for heuristics applied to new package versions and for sanity\n      checking of the target distribution.\n--distribution dist, -D dist\nUse the specified distribution in the changelog entry being edited,\n      instead of using the previous changelog entry's distribution for new\n      entries or the existing value for existing entries.\n--urgency urgency, -u urgency\nUse the specified urgency in the changelog entry being edited, instead of\n      using the default \"medium\" for new entries or the\n      existing value for existing entries.\n--changelog file, -c file\nThis will edit the changelog file instead of the standard\n      debian/changelog. This option overrides any CHANGELOG\n      environment variable setting. Also, no directory traversing or checking\n      will be performed when this option is used.\n--news [newsfile]\nThis will edit newsfile (by default, debian/NEWS) instead of\n      the regular changelog. Directory searching will be performed. The\n      changelog will be examined in order to determine the current package\n      version.\n--[no]multimaint\nShould we indicate that parts of a changelog entry have been made by\n      different maintainers? Default is yes; see the discussion above and also\n      the DEBCHANGE_MULTIMAINT configuration file option below.\n--[no]multimaint-merge\nShould all changes made by the same author be merged into the same\n      changelog section? Default is no; see the discussion above and also the\n      DEBCHANGE_MULTIMAINT_MERGE configuration file option below.\n--maintmaint, -m\nDo not modify the maintainer details previously listed in the changelog.\n      This is useful particularly for sponsors wanting to automatically add a\n      sponsorship message without disrupting the other changelog details. Note\n      that there may be some interesting interactions if multi-maintainer mode\n      is in use; you will probably wish to check the changelog manually before\n      uploading it in such cases.\n--controlmaint, -M\nUse maintainer details from the debian/control Maintainer\n      field rather than relevant environment variables (DEBFULLNAME,\n      DEBEMAIL, etc.). This option might be useful to restore details of\n      the main maintainer in the changelog trailer after a bogus edit (e.g. when\n      -m was intended but forgot) or when releasing a package in the name\n      of the main maintainer (e.g. the team).\n--[no]mainttrailer, -t\nIf mainttrailer is set, it will avoid modifying the existing\n      changelog trailer line (i.e. the maintainer and date-stamp details),\n      unless used with options that require the trailer to be modified (e.g.\n      --create, --release, -i, --qa, etc.) This\n      option differs from --maintmaint in that it will use\n      multi-maintainer mode if appropriate, with the exception of editing the\n      trailer. See also the DEBCHANGE_MAINTTRAILER configuration file\n      option below.\n--check-dirname-level N\nSee the above section \"Directory name checking\" for an\n      explanation of this option.\n--check-dirname-regex regex\nSee the above section \"Directory name checking\" for an\n      explanation of this option.\n--no-conf, --noconf\nDo not read any configuration files. This can only be used as the first\n      option given on the command-line.\n--release-heuristic log|changelog\nControls how debchange determines if a package has been released,\n      when deciding whether to create a new changelog entry or append to an\n      existing changelog entry.\n--help, -h\nDisplay a help message and exit successfully.\n--version\nDisplay version and copyright information and exit successfully.\n\n\n\nCONFIGURATION VARIABLES¶\nThe two configuration files /etc/devscripts.conf and ~/.devscripts\n  are sourced in that order to set configuration variables. Command line options\n  can be used to override configuration file settings. Environment variable\n  settings are ignored for this purpose. The currently recognised variables are:\n\nDEBCHANGE_PRESERVE\nIf this is set to yes, then it is the same as the --preserve\n      command line parameter being used.\nDEBCHANGE_QUERY_BTS\nIf this is set to no, then it is the same as the --noquery\n      command line parameter being used.\nDEVSCRIPTS_CHECK_DIRNAME_LEVEL,\n    DEVSCRIPTS_CHECK_DIRNAME_REGEX\nSee the above section \"Directory name checking\" for an\n      explanation of these variables. Note that these are package-wide\n      configuration variables, and will therefore affect all devscripts\n      scripts which check their value, as described in their respective manpages\n      and in devscripts.conf(5).\nDEBCHANGE_RELEASE_HEURISTIC\nControls how debchange determines if a package has been released,\n      when deciding whether to create a new changelog entry or append to an\n      existing changelog entry. Can be either log or\n    changelog.\nDEBCHANGE_MULTIMAINT\nIf set to no, debchange will not introduce\n      multiple-maintainer distinctions when a different maintainer appends an\n      entry to an existing changelog. See the discussion above. Default is\n      yes.\nDEBCHANGE_MULTIMAINT_MERGE\nIf set to yes, when adding changes in multiple-maintainer mode\n      debchange will check whether previous changes by the current\n      maintainer exist and add the new changes to the existing block rather than\n      creating a new block. Default is no.\nDEBCHANGE_MAINTTRAILER\nIf this is set to no, then it is the same as the\n      --nomainttrailer command line parameter being used.\nDEBCHANGE_TZ\nUse this timezone for changelog entries. Default is the user/system\n      timezone as shown by `date -R` and affected by the environment\n      variable TZ.\nDEBCHANGE_LOWER_VERSION_PATTERN\nIf this is set, then it is the same as the --allow-lower-version\n      command line parameter being used.\nDEBCHANGE_AUTO_NMU\nIf this is set to no then debchange will not attempt to\n      automatically determine whether the current changelog stanza represents an\n      NMU. The default is yes. See the discussion of the --nmu\n      option above.\nDEBCHANGE_FORCE_SAVE_ON_RELEASE\nIf this is set to no, then it is the same as the\n      --no-force-save-on-release command line parameter being used.\nDEBCHANGE_VENDOR\nUse this vendor instead of the default (dpkg-vendor output). See\n      --vendor for details.\n\n\n\nENVIRONMENT¶\n\nDEBEMAIL, EMAIL, DEBFULLNAME, NAME\nSee the above description of the use of these environment variables.\nCHANGELOG\nThis variable specifies the changelog to edit in place of\n      debian/changelog. No directory traversal or checking is performed\n      when this variable is set. This variable is overridden by the\n      --changelog command-line setting.\nVISUAL, EDITOR\nThese environment variables (in this order) determine the editor used by\n      sensible-editor.\n\n\n\nSEE ALSO¶\ndebc(1), debclean(1), dput(1), dupload(1),\n  devscripts.conf(5)\n\n\nAUTHOR¶\nThe original author was Christoph Lameter <clameter@debian.org>. Many\n  substantial changes and improvements were made by Julian Gilbey\n  <jdg@debian.org>.\n\n\n\n\nDebian Utilities\nDEBIAN\n\n\n\n\n\n\n\n\n\nSource file:\n\n\ndebchange.1.en.gz (from devscripts 2.19.5+deb10u1)\n\n\n\n\nSource last updated:\n\n\n2019-08-04T21:15:44Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:08:51Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# debchange\n\n> Tool for maintenance of the debian/changelog file in a Debian source package.\n> More information: <https://manpages.debian.org/debchange>.\n\n- Add a new version for a non-maintainer upload to the changelog:\n\n`debchange --nmu`\n\n- Add a changelog entry to the current version:\n\n`debchange --append`\n\n- Add a changelog entry to close the bug with specified ID:\n\n`debchange --closes {{bug_id}}`\n"
 },
 {
   "command": "dnsrecon",
   "doc_url": "https://github.com/darkoperator/dnsrecon",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - darkoperator/dnsrecon: DNS Enumeration Script\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndarkoperator\n\n/\n\ndnsrecon\n\n\n\n\n\n\n\n    Watch\n \n      86\n    \n\n\n\n\n      Star\n\n\n      1.3k\n    \n\n\n\n\n          Fork\n\n\n        347\n      \n\n\n\n\n\n        DNS Enumeration Script\n      \n\n\n\n1.3k\n        stars\n \n\n347\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n11\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nbranches\n\n\n\n9\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nL1ghtn1ng\n\nMerge pull request #141 from L1ghtn1ng/dev\n\n\n\n…\n\n\n\n8df2617\n\nSep 21, 2020\n\n\n\n\n\nMerge pull request #141 from L1ghtn1ng/dev\n\nFix deprication warnings\n\n8df2617\n\n\n\nGit stats\n\n\n\n\n\n421\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github\n\n\n \n\n\n \n\n\n\n\n\n\n\nlib\n\n\n \n\n\n \n\n\n\n\n\n\n\nmsf_plugin\n\n\n \n\n\n \n\n\n\n\n\n\n\ntools\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitattributes\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\n.lgtm.yml\n\n\n \n\n\n \n\n\n\n\n\n\n\nChangelog.md\n\n\n \n\n\n \n\n\n\n\n\n\n\nDockerfile\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\ndnsrecon.py\n\n\n \n\n\n \n\n\n\n\n\n\n\nnamelist.txt\n\n\n \n\n\n \n\n\n\n\n\n\n\nrequirements.txt\n\n\n \n\n\n \n\n\n\n\n\n\n\nsetup.cfg\n\n\n \n\n\n \n\n\n\n\n\n\n\nsetup.py\n\n\n \n\n\n \n\n\n\n\n\n\n\nsnoop.txt\n\n\n \n\n\n \n\n\n\n\n\n\n\nsubdomains-top1mil-20000.txt\n\n\n \n\n\n \n\n\n\n\n\n\n\nsubdomains-top1mil-5000.txt\n\n\n \n\n\n \n\n\n\n\n\n\n\nsubdomains-top1mil.txt\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\nDNSRecon\n\nDNSRecon is a Python port of a Ruby script that I wrote to learn the language and about DNS in early 2007.\nThis time I wanted to learn about Python and extend the functionality of the original tool and in the process re-learn how DNS works and how could it be used in the process of a security assessment and network troubleshooting.\nThis script provides the ability to perform:\n\nCheck all NS Records for Zone Transfers.\nEnumerate General DNS Records for a given Domain (MX, SOA, NS, A, AAAA, SPF and TXT).\nPerform common SRV Record Enumeration.\nTop Level Domain (TLD) Expansion.\nCheck for Wildcard Resolution.\nBrute Force subdomain and host A and AAAA records given a domain and a wordlist.\nPerform a PTR Record lookup for a given IP Range or CIDR.\nCheck a DNS Server Cached records for A, AAAA and CNAME Records provided a list of host records in a text file to check.\n\nPython Version\nDNSRecon requires python3.6+\n\n\n\n\n\n\n\n\nAbout\n\n      DNS Enumeration Script\n    \nResources\n\n\n\n      Readme\n \n\n\n\n\n\n\n    Releases\n      9\n\n\n\n\n\nVersion 0.9.1\n\n          Latest\n \nApr 25, 2019\n\n \n\n        + 8 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 40\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 29 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\nPython\n94.9%\n\n\n\n\n\nRuby\n4.9%\n\n\n\n\n\nDockerfile\n0.2%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# dnsrecon\n\n> DNS enumeration tool.\n> More information: <https://github.com/darkoperator/dnsrecon>.\n\n- Scan a domain and save the results to a SQLite database:\n\n`dnsrecon --domain {{example.com}} --db {{path/to/database.sqlite}}`\n\n- Scan a domain, specifying the nameserver and performing a zone transfer:\n\n`dnsrecon --domain {{example.com}} --name_server {{nameserver.example.com}} --type axfr`\n\n- Scan a domain, using a dictionary of subdomains and hostnames for bruteforcing:\n\n`dnsrecon --domain {{example.com}} --dictionary {{path/to/dictionary.txt}} --type brt`\n\n- Scan a domain, performing a reverse lookup of IP ranges from the SPF record and saving the results to a JSON file:\n\n`dnsrecon --domain {{example.com}} -s --json`\n\n- Scan a domain, performing a Google enumeration and saving the results to a CSV file:\n\n`dnsrecon --domain {{example.com}} -g --csv`\n\n- Scan a domain, performing DNS cache snooping:\n\n`dnsrecon --domain {{example.com}} --type snoop --name_server {{nameserver.example.com}} --dictionary {{path/to/dictionary.txt}}`\n\n- Scan a domain, performing zone walking:\n\n`dnsrecon --domain {{example.com}} --type zonewalk`\n"
 },
 {
   "command": "xdotool",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xdotool\n\n> Command line automation for X11.\n\n- Retrieve the X-Windows window ID of the running Firefox window(s):\n\n`xdotool search --onlyvisible --name {{firefox}}`\n\n- Click the right mouse button:\n\n`xdotool click {{3}}`\n\n- Get the id of the currently active window:\n\n`xdotool getactivewindow`\n\n- Focus on the window with id of 12345:\n\n`xdotool windowfocus --sync {{12345}}`\n\n- Type a message, with a 500ms delay for each letter:\n\n`xdotool type --delay {{500}} \"Hello world\"`\n\n- Press the enter key:\n\n`xdotool key {{KP_Enter}}`\n"
 },
 {
   "command": "lshw",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lshw\n\n> List detailed information about hardware configurations as root user.\n\n- Launch the GUI:\n\n`sudo lshw -X`\n\n- List all hardwares in tabular format:\n\n`sudo lshw -short`\n\n- List all disks and storage controllers in tabular format:\n\n`sudo lshw -class disk -class storage -short`\n\n- Save all network interfaces to an HTML file:\n\n`sudo lshw -class network -html > {{interfaces.html}}`\n"
 },
 {
   "command": "flameshot",
   "doc_url": "https://flameshot.js.org",
   "doc_text": "\n\n\nFlameshot\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# flameshot \n\n> Screenshot utility with a gui interface.\n> Supports basic image editing, such as text, shapes, colors, and imgur.\n> More information: <https://flameshot.js.org>.\n\n- Launch flameshot in gui mode:\n\n`flameshot launcher`\n\n- Take a screenshot by clicking and dragging:\n\n`flameshot gui`\n\n- Take a full screen screenshot:\n\n`flameshot full`\n\n- Set the save path to write screenshots to:\n\n`flameshot full --path {{path/to/directory}}`\n\n- Delay the screenshot for N milliseconds and output to clipboard:\n\n`flameshot full --delay {{2000}} --clipboard`\n"
 },
 {
   "command": "useradd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# useradd\n\n> Create a new user.\n\n- Create new user:\n\n`useradd {{name}}`\n\n- Create new user with a default home directory:\n\n`useradd --create-home {{name}}`\n\n- Create new user with specified shell:\n\n`useradd --shell {{/path/to/shell}} {{name}}`\n\n- Create new user belonging to additional groups (mind the lack of whitespace):\n\n`useradd --groups {{group1,group2}} {{name}}`\n\n- Create new system user without a home directory:\n\n`useradd --no-create-home --system {{name}}`\n"
 },
 {
   "command": "x11vnc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# x11vnc\n\n> A VNC server that will enable VNC on an existing display ser.\n> By default, the server will automatically terminate once all clients disconnect from it.\n\n- Launch a VNC server that allows multiple clients to connect:\n\n`x11vnc -shared`\n\n- Launch a VNC server in view-only mode, and which won't terminate once the last client disconnects:\n\n`x11vnc -forever -viewonly`\n\n- Launch a VNC server on a specific display and screen (both starting at index zero):\n\n`x11vnc -display :{{display}}.{{screen}}`\n\n- Launch a VNC server on the third display's default screen:\n\n`x11vnc -display :{{2}}`\n\n- Launch a VNC server on the first display's second screen:\n\n`x11vnc -display :{{0}}.{{1}}`\n"
 },
 {
   "command": "tic",
   "doc_url": "https://pubs.opengroup.org/onlinepubs/007908799/xcurses/terminfo.html",
   "doc_text": "\n\n\nTerminfo\n\n\n\nThe Single UNIX ® Specification, Version 2\nCopyright © 1997 The Open Group\n\n\n\n\n Terminfo Source Format (ENHANCED CURSES)\n\nThe requirements in this chapter are in effect only for implementations\nthat claim Enhanced Curses compliance.\n\nThe terminfo database contains a description of the capabilities of a\nvariety of devices, such as terminals and printers.  Devices are described by\nspecifying a set of capabilities, by quantifying certain aspects of the\ndevice, and by specifying character sequences that effect particular results.\n\nThis chapter specifies the format of terminfo source files.\n\nX/Open-compliant implementations must provide a facility that accepts\nsource files in the format specified in this chapter as a means of\nentering information into the terminfo database.\nThe facility for installing this information into the database\nis implementation-specific.  A valid terminfo entry describing\na given model of terminal can be added to terminfo on any\nX/Open-compliant implementation to permit use of the same terminal model.\n\n\n\nSource File Syntax\n\ndescribes the syntax of terminfo source files.  A grammar\nand lexical conventions appear in\n\nFormal Grammar\n.\nA list of all terminal capabilities defined by X/Open appears in\n\nDefined Capabilities\n.\nAn example follows in\n\nSample Entry\n.\n\ndescribes the specification of devices in general, such as video terminals.\n\ndescribes the specification of printers.\n\nThe terminfo database is often used by screen-oriented applications such\nas vi and Curses\nprograms, as well as by some utilities such as ls and more.  This\nusage allows them to work with a variety of devices without changes to the\nprograms.\n Source File Syntax\n\nSource files can use the ISO 8859-1 codeset.  The behaviour when the source\nfile is in another codeset is unspecified.  Traditional practice has been to\ntranslate information from other codesets into the source file syntax.\n\nterminfo source files consist of one or more device descriptions.\nEach description defines a mnemonic name for the terminal model.  Each\ndescription consists of a header (beginning in column 1) and one or more lines\nthat list the features for that particular device.  Every line in a\nterminfo source file must end in a comma.  Every line in a\nterminfo source file except the header must be indented with one or more\nwhite spaces (either spaces or tabs).\n\nEntries in terminfo source files consist of a number of comma-separated\nfields.  White space after each comma is ignored.  Embedded commas must be\nescaped by using a backslash.  The following example shows the format of a\nterminfo source file:\ndelim $$\ndelim off\nThe first line, commonly referred to as the header line, must begin in column\none and must contain at least two aliases separated by vertical bars.  The\nlast field in the header line must be the long name of the device and it may\ncontain any string.\n\nAlias names must be unique in the terminfo database\nand they must conform to file naming conventions established by\nimplementation-specific terminfo compilation utilities.\nImplementations will recognise alias names consisting only of characters\nfrom the portable filename character set except that implementations \nneed not accept a first character  of minus (-).\nFor example, a\ntypical restriction is that they cannot contain white space or\nslashes.  There may be further constraints imposed on source file values by\nthe implementation-specific terminfo compilation utilities.\n\nprovides conventions for choosing alias names.\n\nEach capability in terminfo is of one of the following types:\n\n\n\nBoolean capabilities show that a device has or does not have a particular\nfeature.\n\n\nNumeric capabilities quantify particular features of a device.\n\n\nString capabilities provide sequences that can be used to perform\nparticular operations on devices.\n\n\n\nCapability names adhere to an informal length limit of five\ncharacters.  Whenever possible, capability\nnames are chosen to be the same as or similar to those specified by the\nANSI X3.64-1979 standard.  Semantics are also intended to match those of the ANSI standard.\n\nAll string capabilities may have padding specified, with the exception of\nthose used for input.  Input capabilities, listed under the Strings\nsection in the following tables, have names beginning with key_.  These\ncapabilities are defined in\n<term.h>.\n\n Minimum Guaranteed Limits\n\nAll X/Open-compliant implementations support at least the following limits\nfor the terminfo source file:\nSource File Characteristic\nMinimum Guaranteed Value\nLength of a line\n1023 bytes\nLength of a terminal alias\n14 bytes\nLength of a terminal model name\n128 bytes\nWidth of a single field\n128 bytes\nLength of a string value\n1000 bytes\nLength of a string representing a numeric value\n99 digits\nMagnitude of a numeric value\n0 up to and including 32767\n\nAn implementation may support higher limits than those specified above.\n Formal Grammar\n\nThe grammar and lexical conventions in this section together\ndescribe the syntax for terminfo terminal descriptions within a terminfo\nsource file.  A terminal description that satisfies the requirements of this\nsection will be accepted by all implementations.\n\n\ndescriptions : START_OF_HEADER_LINE  rest_of_header_line feature_lines\n          | descriptions START_OF_HEADER_LINE rest_of_header_line \n          | feature_lines\n          ;\nAn ALIAS that begins in column one.  This is handled by the lexical analyzer.\n\nrest_of_header_line : PIPE LONGNAME COMMA NEWLINE\n          | aliases PIPE LONGNAME COMMA NEWLINE\n          ;\n\nfeature_lines : start_feature_line rest_of_feature_line\n          | feature_lines start_feature_line rest_of_feature_line\n          ;\n\nstart_feature_line : START_FEATURE_LINE_BOOLEAN\nA BOOLEAN feature that begins after column one but is the first\nfeature on the feature line.  This is handled by the lexical analyzer.\n          | START_FEATURE_LINE_NUMERIC\nA NUMERIC feature that begins after column one but is the first\nfeature on the feature line.  This is handled by the lexical analyzer.\n          | START_FEATURE_LINE_STRING\nA STRING feature that begins after column one but is the first\nfeature on the feature line.  This is handled by the lexical analyzer.\n          ;\n\nrest_of_feature_line : features COMMA NEWLINE\n          | COMMA NEWLINE\n          ;\n\nfeatures : COMMA feature\n          | features COMMA feature\n          ;\n\naliases : PIPE ALIAS\n          | aliases PIPE ALIAS\n          ;\n\nfeature : BOOLEAN\n          | NUMERIC\n          | STRING\n          ;\n\n\nThe lexical conventions for terminfo descriptions are as follows:\n\n\n\nWhite space consists of the ' ' and <tab> character.\n\n\nAn ALIAS may contain any graph characters other than ',','/' and '|'.\nGraph characters are those characters for which\nisgraph()\nreturns non-zero.\n\n\nA LONGNAME may contain any print characters other than ',' and '|'.\nPrint characters are those characters for which\nisprint()\nreturns non-zero.\n\n\nA BOOLEAN feature may contain any print characters other\nthan ',', '=', and '#'.\n\n\nA NUMERIC feature consists of:\n\n\n\nA name which may contain any print character other than ',', '=', and '#'.\n\n\nThe '#' character.\n\n\nA positive integer which conforms to the C language\nconvention for integer constants.\n\n\n\n\nA STRING feature consists of:\n\n\n\nA name which may contain any print character other than ',', '=', and '#'.\n\n\nThe '=' character.\n\n\nA string which may contain any print characters other than ','.\n\n\n\n\nWhite space immediately following a ',' is ignored.\n\n\nComments consist of <bol>, optional whitespace, a required '#',\nand a terminating <eol>.\n\n\nA header line must begin in column one.\n\n\nA feature line must not begin in column one.\n\n\nBlank lines are ignored.\n\n\n Defined Capabilities\n\nX/Open defines the capabilities listed in the following table.  All\nX/Open-compliant implementations must accept each of these capabilities in an\nentry in a terminfo source file.\nImplementations use this information to determine how properly to operate\nthe current terminal.  In addition, implementations return any of the current\nterminal's capabilities when the application calls the query functions listed\nin\n\nSource File Syntax\n\n(in the cases where the following table lists a\nTermcap\ncode) and\n\nSource File Syntax\n.\n\nThe table of capabilities has the following columns:\n\nVariableNames for use by the Curses functions that operate on the terminfo\ndatabase.  These names are reserved and the application must not define them.\n\nCapnameThe short name for a capability specified in the terminfo source file.\nIt is used for updating the source file and by the tput command.\n\nTermcapCodes provided for compatibility with older applications.  These codes\nare TO BE WITHDRAWN.  Because of this, not all Capnames have\nTermcap codes.\n\n\n Booleans\n\nCap-\nTerm-\n\nVariable\nname\ncap\nDescription\nauto_left_margin\nbw\nbw\ncub1 wraps from column 0 to last column\nauto_right_margin\nam\nam\nTerminal has automatic margins\nback_color_erase\nbce\nut\nScreen erased with background colour\ncan_change\nccc\ncc\nTerminal can re-define existing colour\nceol_standout_glitch\nxhp\nxs\nStandout not erased by overwriting (hp)\ncol_addr_glitch\nxhpa\nYA\nOnly positive motion for hpa/mhpa caps\ncpi_changes_res\ncpix\nYF\nChanging character pitch changes resolution\ncr_cancels_micro_mode\ncrxm\nYB\nUsing cr turns off micro mode\ndest_tabs_magic_smso\nxt\nxt\nDestructive tabs, magic smso char (t1061)\neat_newline_glitch\nxenl\nxn\nNewline ignored after 80 columns (Concept)\nerase_overstrike\neo\neo\nCan erase overstrikes with a blank\ngeneric_type\ngn\ngn\nGeneric line type (e.g., dialup, switch)\nhard_copy\nhc\nhc\nHardcopy terminal\nhard_cursor\nchts\nHC\nCursor is hard to see\nhas_meta_key\nkm\nkm\nHas a meta key (shift, sets parity bit)\nhas_print_wheel\ndaisy\nYC\nPrinter needs operator to change\n\n\n\ncharacter set\nhas_status_line\nhs\nhs\nHas extra \"status line\"\nhue_lightness_saturation\nhls\nhl\nTerminal uses only HLS colour\n\n\n\nnotation (Tektronix)\ninsert_null_glitch\nin\nin\nInsert mode distinguishes nulls\nlpi_changes_res\nlpix\nYG\nChanging line pitch changes resolution\nmemory_above\nda\nda\nDisplay may be retained above the screen\nmemory_below\ndb\ndb\nDisplay may be retained below the screen\nmove_insert_mode\nmir\nmi\nSafe to move while in insert mode\nmove_standout_mode\nmsgr\nms\nSafe to move in standout modes\nneeds_xon_xoff\nnxon\nnx\nPadding won't work, xon/xoff required\nno_esc_ctlc\nxsb\nxb\nBeehive (f1=escape, f2=ctrl C)\nno_pad_char\nnpc\nNP\nPad character doesn't exist\nnon_dest_scroll_region\nndscr\nND\nScrolling region is nondestructive\nnon_rev_rmcup\nnrrmc\nNR\nsmcup does not reverse rmcup\nover_strike\nos\nos\nTerminal overstrikes on hard-copy terminal\nprtr_silent\nmc5i\n5i\nPrinter won't echo on screen\nrow_addr_glitch\nxvpa\nYD\nOnly positive motion for vpa/mvpa caps\nsemi_auto_right_margin\nsam\nYE\nPrinting in last column causes cr\nstatus_line_esc_ok\neslok\nes\nEscape can be used on the status line\ntilde_glitch\nhz\nhz\nHazeltine; can't print tilde (~)\ntransparent_underline\nul\nul\nUnderline character overstrikes\nxon_xoff\nxon\nxo\nTerminal uses xon/xoff handshaking\n\n Numbers\n\nCap-\nTerm-\n\nVariable\nname\ncap\nDescription\nbit_image_entwining\nbitwin\nYo\nNumber of passes for each bit-map row\nbit_image_type\nbitype\nYp\nType of bit image device\nbuffer_capacity\nbufsz\nYa\nNumber of bytes buffered before printing\nbuttons\nbtns\nBT\nNumber of buttons on the mouse\ncolumns\ncols\nco\nNumber of columns in a line\ndot_horz_spacing\nspinh\nYc\nSpacing of dots horizontally in dots per inch\ndot_vert_spacing\nspinv\nYb\nSpacing of pins vertically in pins per inch\ninit_tabs\nit\nit\nTabs initially every # spaces\nlabel_height\nlh\nlh\nNumber of rows in each label\nlabel_width\nlw\nlw\nNumber of columns in each label\nlines\nlines\nli\nNumber of lines on a screen or a page\nlines_of_memory\nlm\nlm\nLines of memory if > lines; 0 means varies\nmax_attributes\nma\nma\n Maximum combined video attributes terminal can display \nmagic_cookie_glitch\nxmc\nsg\nNumber of blank characters left by smso or rmso\nmax_colors\ncolors\nCo\nMaximum number of colours on the screen\nmax_micro_address\nmaddr\nYd\nMaximum value in micro_..._address\nmax_micro_jump\nmjump\nYe\nMaximum value in parm_..._micro\nmax_pairs\npairs\npa\nMaximum number of colour-pairs on the screen\nmaximum_windows\nwnum\nMW\nMaximum number of definable windows\nmicro_col_size\nmcs\nYf\nCharacter step size when in micro mode\nmicro_line_size\nmls\nYg\nLine step size when in micro mode\nno_color_video\nncv\nNC\nVideo attributes that can't be used with colours\nnum_labels\nnlab\nNl\nNumber of labels on screen (start at 1)\nnumber_of_pins\nnpins\nYh\nNumber of pins in print-head\noutput_res_char\norc\nYi\nHorizontal resolution in units per character\noutput_res_line\norl\nYj\nVertical resolution in units per line\noutput_res_horz_inch\norhi\nYk\nHorizontal resolution in units per inch\noutput_res_vert_inch\norvi\nYl\nVertical resolution in units per inch\npadding_baud_rate\npb\npb\nLowest baud rate where padding needed\nprint_rate\ncps\nYm\nPrint rate in characters per second\nvirtual_terminal\nvt\nvt\nVirtual terminal number\nwide_char_size\nwidcs\nYn\nCharacter step size when in double-wide mode\nwidth_status_line\nwsl\nws\nNumber of columns in status line\n\n Strings\n\nCap-\nTerm-\n\nVariable\nname\ncap\nDescription\nacs_chars\nacsc\nac\nGraphic charset pairs aAbBcC\nalt_scancode_esc\nscesa\nS8\nAlternate escape for scancode emulation\n\n\n\n(default is for VT100)\nback_tab\ncbt\nbt\nBack tab\nbell\nbel\nbl\nAudible signal (bell)\nbit_image_carriage_return\nbicr\nYv\nMove to beginning of same row\nbit_image_newline\nbinel\nZz\nMove to next row of the bit image\nbit_image_repeat\nbirep\nXy\nRepeat bit-image cell #1 #2 times\ncarriage_return\ncr\ncr\nCarriage return\nchange_char_pitch\ncpi\nZA\nChange number of characters per inch\nchange_line_pitch\nlpi\nZB\nChange number of lines per inch\nchange_res_horz\nchr\nZC\nChange horizontal resolution\nchange_res_vert\ncvr\nZD\nChange vertical resolution\nchange_scroll_region\ncsr\ncs\nChange to lines #1 through #2 (VT100)\nchar_padding\nrmp\nrP\nLike ip but when in replace mode\nchar_set_names\ncsnm\nZy\nReturns a list of character set names\nclear_all_tabs\ntbc\nct\nClear all tab stops\nclear_margins\nmgc\nMC\nClear all margins (top, bottom,\n\n\n\nand sides)\nclear_screen\nclear\ncl\nClear screen and home cursor\nclr_bol\nel1\ncb\nClear to beginning of line, inclusive\nclr_eol\nel\nce\nClear to end of line\nclr_eos\ned\ncd\nClear to end of display\ncode_set_init\ncsin\nci\nInit sequence for multiple codesets\ncolor_names\ncolornm\nYw\nGive name for colour #1\ncolumn_address\nhpa\nch\nSet horizontal position to absolute #1\ncommand_character\ncmdch\nCC\nTerminal settable cmd character\n\n\n\nin prototype\ncreate_window\ncwin\n\nDefine win #1 to go from #2,#3 to #4,#5\ncursor_address\ncup\ncm\nMove to row #1 col #2\ncursor_down\ncud1\ndo\nDown one line\ncursor_home\nhome\nho\nHome cursor (if no cup)\ncursor_invisible\ncivis\nvi\nMake cursor invisible\ncursor_left\ncub1\nle\nMove left one space.\ncursor_mem_address\nmrcup\nCM\nMemory relative cursor addressing\ncursor_normal\ncnorm\nve\nMake cursor appear normal\n\n\n\n(undo vs/vi)\ncursor_right\ncuf1\nnd\nNon-destructive space (cursor or\n\n\n\ncarriage right)\ncursor_to_ll\nll\nll\nLast line, first column (if no cup)\ncursor_up\ncuu1\nup\nUpline (cursor up)\ncursor_visible\ncvvis\nvs\nMake cursor very visible\ndefine_bit_image_region\ndefbi\nYx\nDefine rectangular bit-image region\ndefine_char\ndefc\nZE\nDefine a character in a character set\ndelete_character\ndch1\ndc\nDelete character\ndelete_line\ndl1\ndl\nDelete line\ndevice_type\ndevt\ndv\nIndicate language/codeset support\ndial_phone\ndial\nDI\nDial phone number #1\ndis_status_line\ndsl\nds\nDisable status line\ndisplay_clock\ndclk\nDK\nDisplay time-of-day clock\ndisplay_pc_char\ndispc\nS1\nDisplay PC character\ndown_half_line\nhd\nhd\nHalf-line down (forward 1/2 linefeed)\nena_acs\nenacs\neA\nEnable alternate character set\nend_bit_image_region\nendbi\nYy\nEnd a bit-image region\nenter_alt_charset_mode\nsmacs\nas\nStart alternate character set\nenter_am_mode\nsmam\nSA\nTurn on automatic margins\nenter_blink_mode\nblink\nmb\nTurn on blinking\nenter_bold_mode\nbold\nmd\nTurn on bold (extra bright) mode\nenter_ca_mode\nsmcup\nti\nString to begin programs that use cup\nenter_delete_mode\nsmdc\ndm\nDelete mode (enter)\nenter_dim_mode\ndim\nmh\nTurn on half-bright mode\nenter_doublewide_mode\nswidm\nZF\nEnable double wide printing\nenter_draft_quality\nsdrfq\nZG\nSet draft quality print\nenter_horizontal_hl_mode\nehhlm\n\nTurn on horizontal highlight mode\nenter_insert_mode\nsmir\nim\nInsert mode (enter)\nenter_italics_mode\nsitm\nZH\nEnable italics\nenter_left_hl_mode\nelhlm\n\nTurn on left highlight mode\nenter_leftward_mode\nslm\nZI\nEnable leftward carriage motion\nenter_low_hl_mode\nelohlm\n\nTurn on low highlight mode\nenter_micro_mode\nsmicm\nZJ\nEnable micro motion capabilities\nenter_near_letter_quality\nsnlq\nZK\nSet near-letter quality print\nenter_normal_quality\nsnrmq\nZL\nSet normal quality print\nenter_pc_charset_mode\nsmpch\nS2\nEnter PC character display mode\nenter_protected_mode\nprot\nmp\nTurn on protected mode\nenter_reverse_mode\nrev\nmr\nTurn on reverse video mode\nenter_right_hl_mode\nerhlm\n\nTurn on right highlight mode\nenter_scancode_mode\nsmsc\nS4\nEnter PC scancode mode\nenter_secure_mode\ninvis\nmk\nTurn on blank mode (characters invisible)\nenter_shadow_mode\nsshm\nZM\nEnable shadow printing\nenter_standout_mode\nsmso\nso\nBegin standout mode\nenter_subscript_mode\nssubm\nZN\nEnable subscript printing\nenter_superscript_mode\nssupm\nZO\nEnable superscript printing\nenter_top_hl_mode\nethlm\n\nTurn on top highlight mode\nenter_underline_mode\nsmul\nus\nStart underscore mode\nenter_upward_mode\nsum\nZP\nEnable upward carriage motion\nenter_vertical_hl_mode\nevhlm\n\nTurn on vertical highlight mode\nenter_xon_mode\nsmxon\nSX\nTurn on xon/xoff handshaking\nerase_chars\nech\nec\nErase #1 characters\nexit_alt_charset_mode\nrmacs\nae\nEnd alternate character set\nexit_am_mode\nrmam\nRA\nTurn off automatic margins\nexit_attribute_mode\nsgr0\nme\nTurn off all attributes\nexit_ca_mode\nrmcup\nte\nString to end programs that use cup\nexit_delete_mode\nrmdc\ned\nEnd delete mode\nexit_doublewide_mode\nrwidm\nZQ\nDisable double wide printing\nexit_insert_mode\nrmir\nei\nEnd insert mode\nexit_italics_mode\nritm\nZR\nDisable italics\nexit_leftward_mode\nrlm\nZS\nEnable rightward (normal)\n\n\n\ncarriage motion\nexit_micro_mode\nrmicm\nZT\nDisable micro motion capabilities\nexit_pc_charset_mode\nrmpch\nS3\nDisable PC character display mode\nexit_scancode_mode\nrmsc\nS5\nDisable PC scancode mode\nexit_shadow_mode\nrshm\nZU\nDisable shadow printing\nexit_standout_mode\nrmso\nse\nEnd standout mode\nexit_subscript_mode\nrsubm\nZV\nDisable subscript printing\nexit_superscript_mode\nrsupm\nZW\nDisable superscript printing\nexit_underline_mode\nrmul\nue\nEnd underscore mode\nexit_upward_mode\nrum\nZX\nEnable downward (normal)\n\n\n\ncarriage motion\nexit_xon_mode\nrmxon\nRX\nTurn off xon/xoff handshaking\nfixed_pause\npause\nPA\nPause for 2-3 seconds\nflash_hook\nhook\nfh\nFlash the switch hook\nflash_screen\nflash\nvb\nVisible bell (may move cursor)\nform_feed\nff\nff\nHardcopy terminal page eject\nfrom_status_line\nfsl\nfs\nReturn from status line\nget_mouse\ngetm\nGm\nCurses should get button events\ngoto_window\nwingo\nWG\nGo to window #1\nhangup\nhup\nHU\nHang-up phone\ninit_1string\nis1\ni1\nTerminal or printer initialisation string\ninit_2string\nis2\nis\nTerminal or printer initialisation string\ninit_3string\nis3\ni3\nTerminal or printer initialisation string\ninit_file\nif\nif\nName of initialisation file\ninit_prog\niprog\niP\nPath name of program for initialisation\ninitialize_color\ninitc\nIC\nSet colour #1 to RGB #2, #3, #4\ninitialize_pair\ninitp\nIp\nSet colour-pair #1 to fg #2, bg #3\ninsert_character\nich1\nic\nInsert character\ninsert_line\nil1\nal\nAdd new blank line\ninsert_padding\nip\nip\nInsert pad after character inserted\n\n\nThe \"key_\" strings are sent by specific keys.  The \"key_\"\ndescriptions include the macro, defined in\n<curses.h>,\nfor the code returned by\ngetch()\nwhen the key is pressed (see\ngetch()).\n\nCap-\nTerm-\n\nVariable\nname\ncap\nDescription\nkey_a1\nka1\nK1\nupper left of keypad\nkey_a3\nka3\nK3\nupper right of keypad\nkey_b2\nkb2\nK2\ncenter of keypad\nkey_backspace\nkbs\nkb\nsent by backspace key\nkey_beg\nkbeg\n\n1\nkey_btab\nkcbt\nkB\nsent by back-tab key\nkey_c1\nkc1\nK4\nlower left of keypad\nkey_c3\nkc3\nK5\nlower right of keypad\nkey_cancel\nkcan\n\n2\nkey_catab\nktbc\nka\nsent by clear-all-tabs key\nkey_clear\nkclr\nkC\nsent by clear-screen or erase key\nkey_close\nkclo\n\n3\nkey_command\nkcmd\n\n4\nkey_copy\nkcpy\n\n5\nkey_create\nkcrt\n\n6\nkey_ctab\nkctab\nkt\nsent by clear-tab key\nkey_dc\nkdch1\nkD\nsent by delete-character key\nkey_dl\nkdl1\nkL\nsent by delete-line key\nkey_down\nkcud1\nkd\nsent by terminal down-arrow key\nkey_eic\nkrmir\nkM\nsent by rmir or smir in insert mode\nkey_end\nkend\n\n7\nkey_enter\nkent\n\n8\nkey_eol\nkel\nkE\nsent by clear-to-end-of-line key\nkey_eos\nked\nkS\nsent by clear-to-end-of-screen key\nkey_exit\nkext\n\n9\nkey_f0\nkf0\nk0\nsent by function key f0\nkey_f1\nkf1\nk1\nsent by function key f1\n .\n .\n.\n .\n .\n .\n.\n .\n .\n .\n.\n .\nkey_f62\nkf62\nFq\nsent by function key f62\nkey_f63\nkf63\nFr\nsent by function key f63\nkey_find\nkfnd\n\n0\nkey_help\nkhlp\n%1\nsent by help key\nkey_home\nkhome\nkh\nsent by home key\nkey_ic\nkich1\nkI\nsent by ins-char/enter ins-mode key\nkey_il\nkil1\nkA\nsent by insert-line key\nkey_left\nkcub1\nkl\nsent by terminal left-arrow key\nkey_ll\nkll\nkH\nsent by home-down key\nkey_mark\nkmrk\n%2\nsent by mark key\nkey_message\nkmsg\n%3\nsent by message key\nkey_mouse\nkmous\nKm\n0631, Mouse event has occured\nkey_move\nkmov\n%4\nsent by move key\nkey_next\nknxt\n%5\nsent by next-object key\nkey_npage\nknp\nkN\nsent by next-page key\nkey_open\nkopn\n%6\nsent by open key\nkey_options\nkopt\n%7\nsent by options key\nkey_ppage\nkpp\nkP\nsent by previous-page key\nkey_previous\nkprv\n%8\nsent by previous-object key\nkey_print\nkprt\n%9\nsent by print or copy key\nkey_redo\nkrdo\n%0\nsent by redo key\nkey_reference\nkref\n&1\nsent by ref(erence) key\nkey_refresh\nkrfr\n&2\nsent by refresh key\nkey_replace\nkrpl\n&3\nsent by replace key\nkey_restart\nkrst\n&4\nsent by restart key\nkey_resume\nkres\n&5\nsent by resume key\nkey_right\nkcuf1\nkr\nsent by terminal right-arrow key\nkey_save\nksav\n&6\nsent by save key\nkey_sbeg\nkBEG\n&9\nsent by shifted beginning key\nkey_scancel\nkCAN\n&0\nsent by shifted cancel key\nkey_scommand\nkCMD\n*1\nsent by shifted command key\nkey_scopy\nkCPY\n*2\nsent by shifted copy key\nkey_screate\nkCRT\n*3\nsent by shifted create key\nkey_sdc\nkDC\n*4\nsent by shifted delete-char key\nkey_sdl\nkDL\n*5\nsent by shifted delete-line key\nkey_select\nkslt\n*6\nsent by select key\nkey_send\nkEND\n*7\nsent by shifted end key\nkey_seol\nkEOL\n*8\nsent by shifted clear-line key\nkey_sexit\nkEXT\n*9\nsent by shifted exit key\nkey_sf\nkind\nkF\nsent by scroll-forward/down key\nkey_sfind\nkFND\n*0\nsent by shifted find key\nkey_shelp\nkHLP\n#1\nsent by shifted help key\nkey_shome\nkHOM\n#2\nsent by shifted home key\nkey_sic\nkIC\n#3\nsent by shifted input key\nkey_sleft\nkLFT\n#4\nsent by shifted left-arrow key\nkey_smessage\nkMSG\n%a\nsent by shifted message key\nkey_smove\nkMOV\n%b\nsent by shifted move key\nkey_snext\nkNXT\n%c\nsent by shifted next key\nkey_soptions\nkOPT\n%d\nsent by shifted options key\nkey_sprevious\nkPRV\n%e\nsent by shifted prev key\nkey_sprint\nkPRT\n%f\nsent by shifted print key\nkey_sr\nkri\nkR\nsent by scroll-backward/up key\nkey_sredo\nkRDO\n%g\nsent by shifted redo key\nkey_sreplace\nkRPL\n%h\nsent by shifted replace key\nkey_sright\nkRIT\n%i\nsent by shifted right-arrow key\nkey_srsume\nkRES\n%j\nsent by shifted resume key\nkey_ssave\nkSAV\n!1\nsent by shifted save key\nkey_ssuspend\nkSPD\n!2\nsent by shifted suspend key\nkey_stab\nkhts\nkT\nsent by set-tab key\nkey_sundo\nkUND\n!3\nsent by shifted undo key\nkey_suspend\nkspd\n&7\nsent by suspend key\nkey_undo\nkund\n&8\nsent by undo key\nkey_up\nkcuu1\nku\nsent by terminal up-arrow key\nkeypad_local\nrmkx\nke\nOut of \"keypad-transmit\" mode\nkeypad_xmit\nsmkx\nks\nPut terminal in \"keypad-transmit\" mode\nlab_f0\nlf0\nl0\nLabels on function key f0 if not f0\nlab_f1\nlf1\nl1\nLabels on function key f1 if not f1\nlab_f2\nlf2\nl2\nLabels on function key f2 if not f2\nlab_f3\nlf3\nl3\nLabels on function key f3 if not f3\nlab_f4\nlf4\nl4\nLabels on function key f4 if not f4\nlab_f5\nlf5\nl5\nLabels on function key f5 if not f5\nlab_f6\nlf6\nl6\nLabels on function key f6 if not f6\nlab_f7\nlf7\nl7\nLabels on function key f7 if not f7\nlab_f8\nlf8\nl8\nLabels on function key f8 if not f8\nlab_f9\nlf9\nl9\nLabels on function key f9 if not f9\nlab_f10\nlf10\nla\nLabels on function key f10 if not f10\nlabel_format\nfln\nLf\nLabel format\nlabel_off\nrmln\nLF\nTurn off soft labels\nlabel_on\nsmln\nLO\nTurn on soft labels\nmeta_off\nrmm\nmo\nTurn off \"meta mode\"\nmeta_on\nsmm\nmm\nTurn on \"meta mode\" (8th bit)\nmicro_column_address\nmhpa\nZY\nLike column_address for micro adjustment\nmicro_down\nmcud1\nZZ\nLike cursor_down for micro adjustment\nmicro_left\nmcub1\nZa\nLike cursor_left for micro adjustment\nmicro_right\nmcuf1\nZb\nLike cursor_right for micro adjustment\nmicro_row_address\nmvpa\nZc\nLike row_address for micro adjustment\nmicro_up\nmcuu1\nZd\nLike cursor_up for micro adjustment\nmouse_info\nminfo\nMi\nMouse status information\nnewline\nnel\nnw\nNewline (behaves like cr followed by lf)\norder_of_pins\nporder\nZe\nMatches software bits to print-head pins\norig_colors\noc\noc\nSet all colour(-pair)s to the original ones\norig_pair\nop\nop\nSet default colour-pair to the original one\npad_char\npad\npc\nPad character (rather than null)\nparm_dch\ndch\nDC\nDelete #1 chars\nparm_delete_line\ndl\nDL\nDelete #1 lines\nparm_down_cursor\ncud\nDO\nMove down #1 lines.\nparm_down_micro\nmcud\nZf\nLike parm_down_cursor for micro adjust.\nparm_ich\nich\nIC\nInsert #1 blank chars\nparm_index\nindn\nSF\nScroll forward #1 lines.\nparm_insert_line\nil\nAL\nAdd #1 new blank lines\nparm_left_cursor\ncub\nLE\nMove cursor left #1 spaces\nparm_left_micro\nmcub\nZg\nLike parm_left_cursor for micro adjust.\nparm_right_cursor\ncuf\nRI\nMove right #1 spaces.\nparm_right_micro\nmcuf\nZh\nLike parm_right_cursor for micro adjust.\nparm_rindex\nrin\nSR\nScroll backward #1 lines.\nparm_up_cursor\ncuu\nUP\nMove cursor up #1 lines.\nparm_up_micro\nmcuu\nZi\nLike parm_up_cursor for micro adjust.\npc_term_options\npctrm\nS6\nPC terminal options\npkey_key\npfkey\npk\nProg funct key #1 to type string #2\npkey_local\npfloc\npl\nProg funct key #1 to execute string #2\npkey_plab\npfxl\nxl\nProg key #1 to xmit string #2 and show string #3\npkey_xmit\npfx\npx\nProg funct key #1 to xmit string #2\nplab_norm\npln\npn\nProg label #1 to show string #2\nprint_screen\nmc0\nps\nPrint contents of the screen\nprtr_non\nmc5p\npO\nTurn on the printer for #1 bytes\nprtr_off\nmc4\npf\nTurn off the printer\nprtr_on\nmc5\npo\nTurn on the printer\npulse\npulse\nPU\nSelect pulse dialing\nquick_dial\nqdial\nQD\n Dial phone number #1, without progress detection \nremove_clock\nrmclk\nRC\nRemove time-of-day clock\nrepeat_char\nrep\nrp\nRepeat char #1 #2 times\nreq_for_input\nrfi\nRF\nSend next input char (for ptys)\nreq_mouse_pos\nreqmp\nRQ\nRequest mouse position report\nreset_1string\nrs1\nr1\nReset terminal completely to sane modes\nreset_2string\nrs2\nr2\nReset terminal completely to sane modes\nreset_3string\nrs3\nr3\nReset terminal completely to sane modes\nreset_file\nrf\nrf\nName of file containing reset string\nrestore_cursor\nrc\nrc\nRestore cursor to position of last sc\nrow_address\nvpa\ncv\nSet vertical position to absolute #1\nsave_cursor\nsc\nsc\nSave cursor position\nscancode_escape\nscesc\nS7\nEscape for scancode emulation\nscroll_forward\nind\nsf\nScroll text up\nscroll_reverse\nri\nsr\nScroll text down\nselect_char_set\nscs\nZj\nSelect character set\nset0_des_seq\ns0ds\ns0\nShift into codeset 0 (EUC set 0, ASCII)\nset1_des_seq\ns1ds\ns1\nShift into codeset 1\nset2_des_seq\ns2ds\ns2\nShift into codeset 2\nset3_des_seq\ns3ds\ns3\nShift into codeset 3\nset_a_attributes\nsgr1\n\nDefine second set of video attributes #1-#6\nset_a_background\nsetab\nAB\nSet background colour to #1 using ANSI escape\nset_a_foreground\nsetaf\nAF\nSet foreground colour to #1 using ANSI escape\nset_attributes\nsgr\nsa\nDefine first set of video attributes #1-#9\nset_background\nsetb\nSb\nSet background colour to #1\nset_bottom_margin\nsmgb\nZk\nSet bottom margin at current line\nset_bottom_margin_parm\nsmgbp\nZl\nSet bottom margin at line #1 or #2\n\n\n\nlines from bottom\nset_clock\nsclk\nSC\nSet clock to hours (#1), minutes (#2), seconds (#3)\nset_color_band\nsetcolor\nYz\nChange to ribbon colour #1\nset_color_pair\nscp\nsp\nSet current colour pair to #1\nset_foreground\nsetf\nSf\nSet foreground colour to #1\nset_left_margin\nsmgl\nML\nSet left margin at current column\nset_left_margin_parm\nsmglp\nZm\nSet left (right) margin at column #1 (#2)\nset_lr_margin\nsmglr\nML\nSets both left and right margins\nset_page_length\nslines\nYZ\nSet page length to #1 lines\nset_pglen_inch\nslength\nYI\nSet page length to #1 hundredth of an inch\nset_right_margin\nsmgr\nMR\nSet right margin at current column\nset_right_margin_parm\nsmgrp\nZn\nSet right margin at column #1\nset_tab\nhts\nst\nSet a tab in all rows, current column\nset_tb_margin\nsmgtb\nMT\nSets both top and bottom margins\nset_top_margin\nsmgt\nZo\nSet top margin at current line\nset_top_margin_parm\nsmgtp\nZp\nSet top (bottom) margin at line #1 (#2)\nset_window\nwind\nwi\nCurrent window is lines #1-#2 cols #3-#4\nstart_bit_image\nsbim\nZq\nStart printing bit image graphics\nstart_char_set_def\nscsd\nZr\nStart definition of a character set\nstop_bit_image\nrbim\nZs\nEnd printing bit image graphics\nstop_char_set_def\nrcsd\nZt\nEnd definition of a character set\nsubscript_characters\nsubcs\nZu\nList of \"subscript-able\" characters\nsuperscript_characters\nsupcs\nZv\nList of \"superscript-able\" characters\ntab\nht\nta\nTab to next 8-space hardware tab stop\nthese_cause_cr\ndocr\nZw\nPrinting any of these chars causes cr\nto_status_line\ntsl\nts\nGo to status line, col #1\ntone\ntone\nTO\nSelect touch tone dialing\nuser0\nu0\nu0\nUser string 0\nuser1\nu1\nu1\nUser string 1\nuser2\nu2\nu2\nUser string 2\nuser3\nu3\nu3\nUser string 3\nuser4\nu4\nu4\nUser string 4\nuser5\nu5\nu5\nUser string 5\nuser6\nu6\nu6\nUser string 6\nuser7\nu7\nu7\nUser string 7\nuser8\nu8\nu8\nUser string 8\nuser9\nu9\nu9\nUser string 9\nunderline_char\nuc\nuc\nUnderscore one char and move past it\nup_half_line\nhu\nhu\nHalf-line up (reverse 1/2 linefeed)\nwait_tone\nwait\nWA\nWait for dial tone\nxoff_character\nxoffc\nXF\nX-off character\nxon_character\nxonc\nXN\nX-on character\nzero_motion\nzerom\nZx\nNo motion for the subsequent character\n\n Sample Entry\n\nThe following entry describes the AT&T 610 terminal.\n\n\n610|610bct|ATT610|att610|AT&T610;80column;98key keyboard,\n\tam, eslok, hs, mir, msgr, xenl, xon,\n\tcols#80, it#8, lh#2, lines#24, lw#8, nlab#8, wsl#80,\n\tacsc=\"aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~,\n\tbel=^G, blink=\\E[5m, bold=\\E[1m, cbt=\\E[Z,\n\tcivis=\\E[?25l, clear=\\E[H\\E[J, cnorm=\\E[?25h\\E[?12l,\n\tcr=\\r, csr=\\E[%i%p1%d;%p2%dr, cub=\\E[%p1%dD, cub1=\\b,\n\tcud=\\E[%p1%dB, cud1=\\E[B, cuf=\\E[%p1%dC, cuf1=\\E[C,\n\tcup=\\E[%i%p1%d;%p2%dH, cuu=\\E[%p1%dA, cuu1=\\E[A,\n\tcvvis=\\E[?12;25h, dch=\\E[%p1%dP, dch1=\\E[P, dim=\\E[2m,\n\tdl=\\E[%p1%dM, dl1=\\E[M, ed=\\E[J, el=\\E[K, el1=\\E[1K,\n\tflash=\\E[?5h$<200>\\E[?5l, fsl=\\E8, home=\\E[H, ht=\\t,\n\tich=\\E[%p1%d@, il=\\E[%p1%dL, il1=\\E[L, ind=\\ED, .ind=\\ED$<9>,\n\tinvis=\\E[8m,\n\tis1=\\E[8;0 | \\E[?3;4;5;13;15l\\E[13;20l\\E[?7h\\E[12h\\E(B\\E)0,\n\tis2=\\E[0m^O, is3=\\E(B\\E)0, kLFT=\\E[\\s@, kRIT=\\E[\\sA,\n\tkbs=^H, kcbt=\\E[Z, kclr=\\E[2J, kcub1=\\E[D, kcud1=\\E[B,\n\tkcuf1=\\E[C, kcuu1=\\E[A, kfP=\\EOc, kfP0=\\ENp,\n\tkfP1=\\ENq, kfP2=\\ENr, kfP3=\\ENs, kfP4=\\ENt, kfI=\\EOd,\n\tkfB=\\EOe, kf4=\\EOf, kf=\\EOg, kf6=\\EOh, kf7=\\EOi,\n\tkf8=\\EOj, kf9=\\ENo, khome=\\E[H, kind=\\E[S, kri=\\E[T,\n\tll=\\E[24H, mc4=\\E[?4i, mc5=\\E[?5i, nel=\\EE,\n\tpfxl=\\E[%p1%d;%p2%l%02dq%?%p1%{9}%<%t\\s\\s\\sF%p1%1d\\s\\s\\s\\s\\s\n\\s\\s\\s\\s\\s\\s%;%p2%s,\n\tpln=\\E[%p1%d;0;0;0q%p2%:-16.16s, rc=\\E8, rev=\\E[7m,\n\tri=\\EM, rmacs=^O, rmir=\\E[4l, rmln=\\E[2p, rmso=\\E[m,\n\trmul=\\E[m, rs2=\\Ec\\E[?3l, sc=\\E7,\n\tsgr=\\E[0%?%p6%t;1%;%?%p5%t;2%;%?%p2%t;4%;%?%p4%t;5%;\n%?%p3%p1% | %t;7%;%?%p7%t;8%;m%?%p9%t^N%e^O%;,\n\tsgr0=\\E[m^O, smacs=^N, smir=\\E[4h, smln=\\E[p,\n\tsmso=\\E[7m, smul=\\E[4m, tsl=\\E7\\E[25;%i%p1%dx,\n\n\n Types of Capabilities in the Sample Entry\nThe sample entry shows the formats for the three types of terminfo\ncapabilities:  Boolean, numeric, and string.  All capabilities specified in\nthe terminfo source file must be followed by commas, including the last\ncapability in the source file.  In terminfo source files, capabilities\nare referenced by their capability names (as shown in the\nCapname\ncolumn of the previous tables).\n Boolean Capabilities\nA boolean capability is true if its\nCapname\nis present in the entry, and false if its\nCapname\nis not present in the entry.\n\nThe `@' character following a\nCapname\nis used to explicitly declare that a boolean capability is false, in\nsituations described in\n.\n Numeric Capabilities\nNumeric capabilities are followed by the character `#' and then a positive\ninteger value.  The example assigns the value 80 to the cols numeric\ncapability by coding:\n\n\ncols#80\n\n\nValues for numeric capabilities may be specified in decimal, octal or\nhexadecimal, using normal C-language conventions.\n String Capabilities\nString-valued capabilities such as el (clear to end of line\nsequence) are listed by the\nCapname,\nan `=', and a string\nended by the next occurrence of a comma.\n\nA delay in milliseconds may appear anywhere in such a capability,\npreceded by $ and enclosed in angle brackets, as in el=\\EK$<3>.\nThe Curses implementation achieves delays by outputting to the terminal an\nappropriate number of system-defined padding characters.  The\ntputs()\nfunction provides delays when used to send such a capability to the terminal.\n\nThe delay can be any of the following:  a number, a number\nfollowed by an asterisk, such as 5*, a number followed by a slash,\nsuch as 5/, or a number followed by both, such as 5*/.\n\n\n\nA `*' shows that the required delay is proportional to the\nnumber of lines affected by the operation, and the amount given is the\ndelay required per affected unit.  (In the case of insert characters, the\nfactor is still the number of lines affected.  This is always 1 unless the\ndevice has in and the software uses it.) When a `*' is specified, it\nis sometimes useful to give a delay of the form 3.5 to specify a delay\nper unit to tenths of milliseconds.  (Only one decimal place is allowed.)\n\n\nA `/' indicates that the delay is mandatory and padding characters are\ntransmitted regardless of the setting of xon.\nIf `/' is not specified or if a device has xon\ndefined, the delay information is advisory and is only used for cost\nestimates or when the device is in raw mode.  However, any delay specified\nfor bel or flash is treated as mandatory.\n\n\n\nThe following notation is valid in terminfo source files for specifying\nspecial characters:\nNotation\nRepresents Character\n^x\nControl-x (for any appropriate x)\n\\a\nAlert\n\\b\nBackspace\n\\E or \\e\nAn ESCAPE character\n\\f\nForm feed\n\\l\nLinefeed\n\\n\nNewline\n\\r\nCarriage return\n\\s\nSpace\n\\t\nTab\n\\^\nCaret (^)\n\\\\\nBackslash (\\)\n\\,\nComma (,)\n\\:\nColon (:)\n\\0\nNull\n\\nnn\nAny character, specified as three octal digits\n\n(See the XBD specification, General Terminal Interface  .)\n Commented-out Capabilities\nSometimes individual capabilities must be commented out.  To do this, put a\nperiod before the capability name.  For example, see the second ind in\nthe example in\n\nSample Entry\n.\nNote that capabilities are defined in a left-to-right\norder and, therefore, a prior definition will override a later definition.\n\n\n\nUNIX ® is a registered Trademark of The Open Group.\nCopyright © 1997 The Open Group\n [ Main Index | XSH | XCU | XBD | XCURSES | XNS ]\n\n\n",
   "man_entry": "tic(1M) \t\t\t\t\t\t\t       tic(1M)\n\n\n\nNAME\n       tic - the terminfo entry-description compiler\n\nSYNOPSIS\n       tic  [-1CGILNTUVacfgrstx]  [-e  names]  [-o  dir]  [-R  subset] [-v[n]]\n       [-w[n]] file\n\nDESCRIPTION\n       The command tic translates a terminfo file from source format into com-\n       piled  format.\tThe  compiled  format  is  necessary  for use with the\n       library routines in ncurses(3X).\n\n       The results are\tnormally  placed  in  the  system  terminfo  directory\n       /usr/share/terminfo.  There are two ways to change this behavior.\n\n       First, you may override the system default by setting the variable TER-\n       MINFO in your shell environment to a valid (existing) directory name.\n\n       Secondly, if tic cannot get access to /usr/share/terminfo or your  TER-\n       MINFO  directory,  it  looks for the directory $HOME/.terminfo; if that\n       directory exists, the entry is placed there.\n\n       Libraries that read terminfo entries are expected to check for  a  TER-\n       MINFO  directory first, look at $HOME/.terminfo if TERMINFO is not set,\n       and finally look in /usr/share/terminfo.\n\n       -1     restricts the output to a single column\n\n       -a     tells tic to retain commented-out capabilities rather than  dis-\n\t      carding them.  Capabilities are commented by prefixing them with\n\t      a period.  This sets the -x option, because it treats  the  com-\n\t      mented-out  entries  as  user-defined  names.   If the source is\n\t      termcap, accept the 2-character names  required  by  version  6.\n\t      Otherwise these are ignored.\n\n       -C     Force  source translation to termcap format.  Note: this differs\n\t      from the -C option of infocmp(1M) in that  it  does  not\tmerely\n\t      translate capability names, but also translates terminfo strings\n\t      to termcap format.  Capabilities that are not  translatable  are\n\t      left  in\tthe entry under their terminfo names but commented out\n\t      with two preceding dots.\n\n       -c     tells tic to only check file for errors, including syntax  prob-\n\t      lems  and  bad  use  links.   If\tyou  specify -C (-I) with this\n\t      option, the code will print warnings about entries which,  after\n\t      use  resolution, are more than 1023 (4096) bytes long.  Due to a\n\t      fixed buffer length in older termcap libraries (and a documented\n\t      limit in terminfo), these entries may cause core dumps.\n\n       -e names\n\t      Limit  writes  and translations to the following comma-separated\n\t      list of terminals.  If any name or alias of a  terminal  matches\n\t      one  of  the  names  in  the  list, the entry will be written or\n\t      translated as normal.  Otherwise no output will be generated for\n\t      it.   The  option  value is interpreted as a file containing the\n\t      list if it contains a '/'.  (Note: depending on how tic was com-\n\t      piled, this option may require -I or -C.)\n\n       -f     Display\t  complex     terminfo\t   strings    which    contain\n\t      if/then/else/endif expressions indented for readability.\n\n       -G     Display constant literals in  decimal  form  rather  than  their\n\t      character equivalents.\n\n       -g     Display  constant  character literals in quoted form rather than\n\t      their decimal equivalents.\n\n       -I     Force source translation to terminfo format.\n\n       -L     Force source translation to terminfo format  using  the  long  C\n\t      variable names listed in <term.h>\n\n       -N     Disable smart defaults.  Normally, when translating from termcap\n\t      to terminfo, the compiler makes a number\tof  assumptions  about\n\t      the   defaults   of   string  capabilities  reset1_string,  car-\n\t      riage_return,  cursor_left,  cursor_down,  scroll_forward,  tab,\n\t      newline, key_backspace, key_left, and key_down, then attempts to\n\t      use obsolete termcap capabilities to deduce correct values.   It\n\t      also normally suppresses output of obsolete termcap capabilities\n\t      such as bs.  This option forces a more literal translation  that\n\t      also preserves the obsolete capabilities.\n\n       -odir  Write  compiled  entries to given directory.  Overrides the TER-\n\t      MINFO environment variable.\n\n       -Rsubset\n\t      Restrict output to a given subset.  This option is for use  with\n\t      archaic  versions  of  terminfo  like  those on SVr1, Ultrix, or\n\t      HP/UX that do not support the full set of SVR4/XSI  Curses  ter-\n\t      minfo;  and  outright  broken ports like AIX 3.x that have their\n\t      own extensions incompatible with\tSVr4/XSI.   Available  subsets\n\t      are \"SVr1\", \"Ultrix\", \"HP\", \"BSD\" and \"AIX\"; see terminfo(5) for\n\t      details.\n\n       -r     Force entry resolution (so there are no remaining  tc  capabili-\n\t      ties)  even  when doing translation to termcap format.  This may\n\t      be needed if you are preparing a\ttermcap  file  for  a  termcap\n\t      library  (such as GNU termcap through version 1.3 or BSD termcap\n\t      through 4.3BSD) that does not handle  multiple  tc  capabilities\n\t      per entry.\n\n       -s     Summarize  the  compile  by  showing  the  directory  into which\n\t      entries are written, and the number of entries  which  are  com-\n\t      piled.\n\n       -T     eliminates  size-restrictions  on  the  generated text.  This is\n\t      mainly useful for  testing  and  analysis,  since  the  compiled\n\t      descriptions  are limited (e.g., 1023 for termcap, 4096 for ter-\n\t      minfo).\n\n       -t     tells tic to discard commented-out capabilities.\tNormally  when\n\t      translating  from  terminfo to termcap, untranslatable capabili-\n\t      ties are commented-out.\n\n       -U   tells tic to not post-process the data after  parsing  the\tsource\n\t    file.  Normally, it infers data which is commonly missing in older\n\t    terminfo data, or in termcaps.\n\n       -V   reports the version of ncurses which was used in this program, and\n\t    exits.\n\n       -vn  specifies that (verbose) output be written to standard error trace\n\t    information showing tic's progress.  The optional parameter n is a\n\t    number  from  1  to 10, inclusive, indicating the desired level of\n\t    detail of information.  If n is omitted, the default level\tis  1.\n\t    If\tn  is  specified  and  greater\tthan 1, the level of detail is\n\t    increased.\n\n       -wn  specifies the width of the output.\tThe parameter is optional.  If\n\t    it is omitted, it defaults to 60.\n\n       -x   Treat  unknown capabilities as user-defined.  That is, if you sup-\n\t    ply a capability name which tic does not recognize, it will  infer\n\t    its  type  (boolean, number or string) from the syntax and make an\n\t    extended table entry for that.   User-defined  capability  strings\n\t    whose name begins with ``k'' are treated as function keys.\n\n       file contains one or more terminfo terminal descriptions in source for-\n\t    mat [see terminfo(5)].  Each description in the file describes the\n\t    capabilities of a particular terminal.\n\n       The debug flag levels are as follows:\n\n       1      Names of files created and linked\n\n       2      Information related to the ``use'' facility\n\n       3      Statistics from the hashing algorithm\n\n       5      String-table memory allocations\n\n       7      Entries into the string-table\n\n       8      List of tokens encountered by scanner\n\n       9      All values computed in construction of the hash table\n\n       If the debug level n is not given, it is taken to be one.\n\n       All  but  one  of  the capabilities recognized by tic are documented in\n       terminfo(5).  The exception is the use capability.\n\n       When a use=entry-name field is discovered in a terminal entry currently\n       being  compiled,  tic  reads  in the binary from /usr/share/terminfo to\n       complete the entry.  (Entries created from file will be used first.  If\n       the  environment  variable  TERMINFO is set, that directory is searched\n       instead of /usr/share/terminfo.)  tic duplicates  the  capabilities  in\n       entry-name for the current entry, with the exception of those capabili-\n       ties that explicitly are defined in the current entry.\n\n       When an entry, e.g., entry_name_1, contains a  use=entry_name_2\tfield,\n       any   canceled\tcapabilities  in  entry_name_2\tmust  also  appear  in\n       entry_name_1 before use= for  these  capabilities  to  be  canceled  in\n       entry_name_1.\n\n       If  the\tenvironment variable TERMINFO is set, the compiled results are\n       placed there instead of /usr/share/terminfo.\n\n       Total compiled entries cannot exceed 4096 bytes.  The name field cannot\n       exceed  512  bytes.   Terminal names exceeding the maximum alias length\n       (32 characters on systems with long filenames, 14 characters otherwise)\n       will  be  truncated  to\tthe maximum alias length and a warning message\n       will be printed.\n\nCOMPATIBILITY\n       There is  some  evidence  that  historic  tic  implementations  treated\n       description  fields with no whitespace in them as additional aliases or\n       short names.  This tic does not do that, but it does warn when descrip-\n       tion  fields may be treated that way and check them for dangerous char-\n       acters.\n\nEXTENSIONS\n       Unlike the stock SVr4 tic command,  this  implementation  can  actually\n       compile termcap sources.  In fact, entries in terminfo and termcap syn-\n       tax can be mixed in a single source file.  See terminfo(5) for the list\n       of termcap names taken to be equivalent to terminfo names.\n\n       The  SVr4  manual  pages  are not clear on the resolution rules for use\n       capabilities.  This implementation of tic will find  use  targets  any-\n       where  in  the source file, or anywhere in the file tree rooted at TER-\n       MINFO (if TERMINFO is defined), or in the user's $HOME/.terminfo direc-\n       tory (if it exists), or (finally) anywhere in the system's file tree of\n       compiled entries.\n\n       The error messages from this tic have the same format as  GNU  C  error\n       messages, and can be parsed by GNU Emacs's compile facility.\n\n       The  -C,  -G, -I, -N, -R, -T, -V, -a, -e, -f, -g, -o, -r, -s, -t and -x\n       options are not supported under SVr4.  The SVr4 -c mode does not report\n       bad use links.\n\n       System  V  does\tnot  compile  entries  to  or  read  entries from your\n       $HOME/.terminfo directory unless TERMINFO is explicitly set to it.\n\nFILES\n       /usr/share/terminfo/?/*\n\t    Compiled terminal description database.\n\nSEE ALSO\n       infocmp(1M), captoinfo(1M), infotocap(1M),  toe(1M),  curses(3X),  ter-\n       minfo(5).\n\n       This describes ncurses version 5.7 (patch 20081102).\n\n\n\n\t\t\t\t\t\t\t\t       tic(1M)\n",
   "tldr_summary": "# tic\n\n> Compile terminfo and install for ncurses.\n> More information: <https://pubs.opengroup.org/onlinepubs/007908799/xcurses/terminfo.html>.\n\n- Compile and install terminfo for a terminal:\n\n`tic -xe {{terminal}} {{path/to/terminal.info}}`\n\n- Check terminfo file for errors:\n\n`tic -c {{path/to/terminal.info}}`\n\n- Print database locations:\n\n`tic -D`\n"
 },
 {
   "command": "unshadow",
   "doc_url": "https://www.openwall.com/john/",
   "doc_text": "\n\nJohn the Ripper password cracker\n\n\n\n\n\n\n\n\n\n\n\n\nProducts\n\nOpenwall GNU/*/Linux   server OS\nLinux Kernel Runtime Guard\nJohn the Ripper   password cracker\n\nFree & Open Source for any platform\nin the cloud\nPro for Linux\nPro for macOS\n\nWordlists   for password cracking\npasswdqc   policy enforcement\n\nFree & Open Source for Unix\nPro for Windows (Active Directory)\n\nyescrypt   KDF & password hashing\nyespower   Proof-of-Work (PoW)\ncrypt_blowfish   password hashing\nphpass   ditto in PHP\ntcb   better password shadowing\nPluggable Authentication Modules\nscanlogd   port scan detector\npopa3d   tiny POP3 daemon\nblists   web interface to mailing lists\nmsulogin   single user mode login\nphp_mt_seed   mt_rand() cracker\n\nServices\nPublications\n\nArticles\nPresentations\n\nResources\n\nMailing lists\nCommunity wiki\nSource code repositories (GitHub)\nSource code repositories (CVSweb)\nFile archive & mirrors\nHow to verify digital signatures\nOVE IDs\n\nWhat's new\n\n\n\nJohn the Ripper password cracker\n\nJohn the Ripper is an Open Source password security auditing and password recovery tool available for many operating systems.\nJohn the Ripper jumbo supports hundreds of hash and cipher types, including for: user passwords of Unix flavors\n(Linux, *BSD, Solaris, AIX, QNX, etc.), macOS, Windows, \"web apps\" (e.g., WordPress), groupware (e.g., Notes/Domino), and\ndatabase servers (SQL, LDAP, etc.);\nnetwork traffic captures (Windows network authentication, WiFi WPA-PSK, etc.);\nencrypted private keys (SSH, GnuPG, cryptocurrency wallets, etc.),\nfilesystems and disks (macOS .dmg files and \"sparse bundles\", Windows BitLocker, etc.),\narchives (ZIP, RAR, 7z), and document files (PDF, Microsoft Office's, etc.)\nThese are just some of the examples - there are many more.\n\n\n\n\n\nPassword authentication for web and mobile apps (e-book)\n\n\n\nJohn the Ripper is free and Open Source software,\ndistributed primarily in source code form.\nIf you would rather use a commercial product, please consider\nJohn the Ripper Pro,\nwhich is distributed primarily in the form of \"native\" packages\nfor the target operating systems and in general is meant to be easier to\ninstall and use while delivering optimal performance.\n\n\nProceed to John the Ripper Pro homepage for your OS:\n\nJohn the Ripper Pro for Linux\nJohn the Ripper Pro for macOS\n\n\nOn Windows, consider Hash Suite\n\n(developed by a contributor to John the Ripper)\n\n\nOn Android, consider Hash Suite Droid\n\n\nDownload the latest John the Ripper jumbo release\n(release notes) or development snapshot:\n\n\n1.9.0-jumbo-1 sources in\ntar.xz, 33 MB (signature) or\ntar.gz, 43 MB (signature)\n\n\n1.9.0-jumbo-1 64-bit Windows binaries in\n7z, 22 MB (signature) or\nzip, 63 MB (signature)\n\n\n\n1.9.0-jumbo-1 32-bit Windows binaries in\n7z, 21 MB (signature) or\nzip, 61 MB (signature)\n\nDevelopment source code in GitHub repository\n(download as\ntar.gz or\nzip)\n\n\nRun John the Ripper jumbo in the cloud (AWS):\n\nJohn the Ripper in the cloud homepage\n\n\nDownload the latest John the Ripper core release\n(release notes):\n\n\n1.9.0 core sources in\ntar.xz, 8.6 MB (signature) or\ntar.gz, 13 MB (signature)\nDevelopment source code in CVS repository\n\n\nTo verify authenticity and integrity of your John the Ripper downloads, please\nuse our\nGnuPG public key.\n\nPlease refer to these pages on\n\nhow to extract John the Ripper source code from the tar.gz and tar.xz archives and\nhow to build (compile) John the Ripper core\n(for jumbo, please refer to instructions inside the archive).\nYou may also consider the unofficial builds on the contributed resources list further down this page.\n\nThese and older versions of John the Ripper, patches, unofficial builds, and many other related files are also\navailable from the Openwall file archive.\n\nYou may browse the documentation for John the Ripper core online, including a\nsummary of changes between core versions.\nAlso relevant is our\npresentation on the history of password security.\n\nThere's a collection of wordlists for use with John the Ripper.\nIt includes lists of common passwords, wordlists for 20+ human languages, and files with the common passwords and\nunique words for all the languages combined, also with mangling rules applied and any duplicates purged.\n\nyescrypt and crypt_blowfish\nare implementations of yescrypt, scrypt, and bcrypt - some of the strong password hashes also found in John the Ripper -\nreleased separately for defensive use in your software or on your servers.\n\npasswdqc is a proactive password/passphrase strength checking and policy enforcement toolset,\nwhich can prevent your users from choosing passwords that would be easily cracked with programs like John the Ripper.\n\nWe may help you integrate modern password hashing with\nyescrypt or crypt_blowfish,\nand/or proactive password strength checking with\npasswdqc,\ninto your OS installs, software, or online services.\nPlease check out our services.\n\nThere's a mailing list where you can share your experience with John the Ripper and ask questions.\n\nPlease be sure to specify an informative message subject whenever\nyou post to the list\n(that is, something better than \"question\" or \"problem\").\nTo subscribe, enter your e-mail address below or send an empty message to\n<john-users-subscribe at lists.openwall.com>.\nYou will be required to confirm your subscription by \"replying\"\nto the automated confirmation request that will be sent to you.\nYou will be able to\nunsubscribe\nat any time and we will not use your e-mail\naddress for any other purpose or share it with a third party.\nHowever, if you post to the list, other subscribers and those\nviewing the archives may see your address(es) as specified on your message.\n\nThe list archive is available\nlocally and via\nMARC.\nAdditionally, there's a\n\nlist of selected most useful and currently relevant postings on the\ncommunity wiki.\n\n\n\nYour e-mail address:\n\n\n\n\n\n\nContributed resources for John the Ripper:\n\nCommunity wiki with\ncustom builds,\nbenchmarks, and more\nCustom builds for Windows (up to 1.8.0.13-jumbo)\nCustom builds for macOS (up to 1.8.0.9-jumbo)\nCustom builds for Solaris (packages up to 1.7.6, non-packaged up to 1.7.8-jumbo-7)\nCustom builds for Android (up to 1.8.0)\nUbuntu snap package\n(documentation,\nannouncement)\n\nOpenVMS and SYSUAF.DAT support\n(signature)\nby Jean-loup Gailly\n\nOpenVMS executables for Alpha and VAX\n(signature)\nLocal copies of\nthe above files by Jean-loup Gailly and\na much newer implementation by David Jones\n\n\n\nLocal copies of these and many other related packages are also\n\navailable from the Openwall file archive.\n\nJohn the Ripper is part of\nOwl,\nDebian GNU/Linux, Fedora Linux, Gentoo Linux, Mandriva Linux, SUSE Linux,\nand a number of other Linux distributions.\nIt is in the ports/packages collections of FreeBSD, NetBSD, and OpenBSD.\n\nJohn the Ripper is a registered project with\nOpen Hub\nand it is listed at\nSecTools.\n\n\n\n\nQuick Comment:\n\n\n\n\n\n\n\nPowered by Openwall GNU/*/Linux -\nPowered by OpenVZ\n\n\n29439148\n\n\n",
   "man_entry": "",
   "tldr_summary": "# unshadow\n\n> Utility provided by the John the Ripper project to obtain the traditional Unix password file if the system uses shadow passwords.\n> More information: <https://www.openwall.com/john/>.\n\n- Combine the /etc/shadow and /etc/passwd of the current system:\n\n`sudo unshadow /etc/passwd /etc/shadow`\n\n- Combine two arbitrary shadow and password files:\n\n`sudo unshadow {{/path/to/passwd}} {{/path/to/shadow}}`\n"
 },
 {
   "command": "ltrace",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ltrace\n\n> Display dynamic library calls of a process.\n\n- Print (trace) library calls of a program binary:\n\n`ltrace ./{{program}}`\n\n- Count library calls. Print a handy summary at the bottom:\n\n`ltrace -c {{/path/to/program}}`\n\n- Trace calls to malloc and free, omit those done by libc:\n\n`ltrace -e malloc+free-@libc.so* {{/path/to/program}}`\n\n- Write to file instead of terminal:\n\n`ltrace -o {{file}} {{/path/to/program}}`\n"
 },
 {
   "command": "firewall-cmd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# firewall-cmd\n\n> The firewalld command line client.\n\n- View the available firewall zones:\n\n`firewall-cmd --get-active-zones`\n\n- View the rules which are currently applied:\n\n`firewall-cmd --list-all`\n\n- Permanently move the interface into the block zone, effectively blocking all communication:\n\n`firewall-cmd --permanent --zone={{block}} --change-interface={{enp1s0}}`\n\n- Permanently open the port for a service in the specified zone (like port `443` when in the `public` zone):\n\n`firewall-cmd --permanent --zone={{public}} --add-service={{https}}`\n\n- Permanently close the port for a service in the specified zone (like port `80` when in the `public` zone):\n\n`firewall-cmd --permanent --zone={{public}} --remove-service={{http}}`\n\n- Permanently open two arbitrary ports in the specified zone:\n\n`firewall-cmd --permanent --zone={{public}} --add-port={{25565/tcp}} --add-port={{19132/udp}}`\n\n- Reload firewalld to force rule changes to take effect:\n\n`firewall-cmd --reload`\n"
 },
 {
   "command": "findfs",
   "doc_url": "https://mirrors.edge.kernel.org/pub/linux/utils/util-linux",
   "doc_text": "\nIndex of /pub/linux/utils/util-linux/\n\nIndex of /pub/linux/utils/util-linux/../\nv2.13/                                             19-Jan-2012 11:54       -\nv2.14/                                             19-Jan-2012 11:42       -\nv2.15/                                             19-Jan-2012 11:31       -\nv2.16/                                             19-Jan-2012 11:18       -\nv2.17/                                             19-Jan-2012 11:21       -\nv2.18/                                             19-Jan-2012 10:59       -\nv2.19/                                             19-Jan-2012 10:53       -\nv2.20/                                             19-Jan-2012 12:02       -\nv2.21/                                             25-May-2012 11:10       -\nv2.22/                                             13-Dec-2012 12:02       -\nv2.23/                                             31-Jul-2013 12:40       -\nv2.24/                                             24-Apr-2014 10:18       -\nv2.25/                                             24-Oct-2014 13:08       -\nv2.26/                                             30-Apr-2015 10:44       -\nv2.27/                                             02-Nov-2015 11:06       -\nv2.28/                                             07-Sep-2016 12:06       -\nv2.29/                                             22-Feb-2017 15:26       -\nv2.30/                                             21-Sep-2017 09:51       -\nv2.31/                                             19-Dec-2017 15:18       -\nv2.32/                                             16-Jul-2018 11:29       -\nv2.33/                                             09-Apr-2019 13:57       -\nv2.34/                                             14-Jun-2019 10:46       -\nv2.35/                                             20-May-2020 14:00       -\nv2.36/                                             23-Jul-2020 09:59       -\n\n",
   "man_entry": "",
   "tldr_summary": "# findfs\n\n> Finds a filesystem by label or UUID.\n> More information: <https://mirrors.edge.kernel.org/pub/linux/utils/util-linux>.\n\n- Search block devices by filesystem label:\n\n`findfs LABEL={{label}}`\n\n- Search by filesystem UUID:\n\n`findfs UUID={{uuid}}`\n\n- Search by partition label (GPT or MAC partition table):\n\n`findfs PARTLABEL={{partition_label}}`\n\n- Search by partition UUID (GPT partition table only):\n\n`findfs PARTUUID={{partition_uuid}}`\n"
 },
 {
   "command": "ntfsfix",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ntfsfix\n\n> Fix common problems on an NTFS partition.\n\n- Fix a given NTFS partition:\n\n`sudo ntfsfix {{/dev/sdb2}}`\n"
 },
 {
   "command": "n",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# n\n\n> Tool to manage multiple node versions.\n\n- Install a given version of node. If the version is already installed, it will be activated:\n\n`n {{version}}`\n\n- Display installed versions and interactively activate one of them:\n\n`n`\n\n- Remove a version:\n\n`n rm {{version}}`\n\n- Execute a file with a given version:\n\n`n use {{version}} {{file.js}}`\n\n- Output binary path for a version:\n\n`n bin {{version}}`\n"
 },
 {
   "command": "arp-scan",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# arp-scan\n\n> Send ARP packets to hosts (specified as IP addresses or hostnames) to scan the local network.\n\n- Scan the current local network:\n\n`arp-scan --localnet`\n\n- Scan an IP network with a custom bitmask:\n\n`arp-scan {{192.168.1.1}}/{{24}}`\n\n- Scan an IP network within a custom range:\n\n`arp-scan {{127.0.0.0}}-{{127.0.0.31}}`\n\n- Scan an IP network with a custom net mask:\n\n`arp-scan {{10.0.0.0}}:{{255.255.255.0}}`\n"
 },
 {
   "command": "lxc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lxc\n\n> Manage Linux containers using the lxd REST API.\n> Any container names or patterns can be prefixed with the name of a remote server.\n\n- List local containers matching a string. Omit the string to list all local containers:\n\n`lxc list {{match_string}}`\n\n- List images matching a string. Omit the string to list all images:\n\n`lxc image list [{{remote}}:]{{match_string}}`\n\n- Create a new container from an image:\n\n`lxc init [{{remote}}:]{{image}} {{container}}`\n\n- Start a container:\n\n`lxc start [{{remote}}:]{{container}}`\n\n- Stop a container:\n\n`lxc stop [{{remote}}:]{{container}}`\n\n- Show detailed info about a container:\n\n`lxc info [{{remote}}:]{{container}}`\n\n- Take a snapshot of a container:\n\n`lxc snapshot [{{remote}}:]{{container}} {{snapshot}}`\n"
 },
 {
   "command": "trizen",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# trizen\n\n> Arch Linux utility for building packages from the Arch User Repository (AUR).\n\n- Synchronize and update all AUR packages:\n\n`trizen -Syua`\n\n- Install a new package:\n\n`trizen -S {{package}}`\n\n- Remove a package and its dependencies:\n\n`trizen -Rs {{package}}`\n\n- Search the package database for a keyword:\n\n`trizen -Ss {{keyword}}`\n\n- Show information about a package:\n\n`trizen -Si {{package}}`\n\n- List installed packages and versions:\n\n`trizen -Qe`\n"
 },
 {
   "command": "sbatch",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# sbatch\n\n> Submit a batch job to the SLURM scheduler.\n\n- Submit a batch job:\n\n`sbatch {{path/to/job.sh}}`\n\n- Submit a batch job with a custom name:\n\n`sbatch --job-name={{myjob}} {{path/to/job.sh}}`\n\n- Submit a batch job with a time limit of 30 minutes:\n\n`sbatch --time={{00:30:00}} {{path/to/job.sh}}`\n\n- Submit a job and request multiple nodes:\n\n`sbatch --nodes={{3}} {{path/to/job.sh}}`\n"
 },
 {
   "command": "dmesg",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nDMESG(8)\t\t  BSD System Manager's Manual\t\t      DMESG(8)\n\nNAME\n     dmesg -- display the system message buffer\n\nSYNOPSIS\n     dmesg [-M core] [-N system]\n\nDESCRIPTION\n     Dmesg displays the contents of the system message buffer.\tThis command\n     needs to be run as root.\n\nSEE ALSO\n     syslogd(8)\n\nHISTORY\n     The dmesg command appeared in 4.0BSD.\n\n4th Berkeley Distribution\t June 5, 1993\t     4th Berkeley Distribution\n",
   "tldr_summary": "# dmesg\n\n> Write the kernel messages to standard output.\n\n- Show kernel messages:\n\n`dmesg`\n\n- Show kernel error messages:\n\n`dmesg --level err`\n\n- Show kernel messages and keep reading new ones, similar to `tail -f` (available in kernels 3.5.0 and newer):\n\n`dmesg -w`\n\n- Show how much physical memory is available on this system:\n\n`dmesg | grep -i memory`\n\n- Show kernel messages 1 page at a time:\n\n`dmesg | less`\n\n- Show kernel messages with a timestamp (available in kernels 3.5.0 and newer):\n\n`dmesg -T`\n\n- Show kernel messages in human-readable form (available in kernels 3.5.0 and newer):\n\n`dmesg -H`\n\n- Colorize output (available in kernels 3.5.0 and newer):\n\n`dmesg -L`\n"
 },
 {
   "command": "pidstat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pidstat\n\n> Show system resource usage, including CPU, memory, IO etc.\n\n- Show CPU statistics at a 2 second interval for 10 times:\n\n`pidstat {{2}} {{10}}`\n\n- Show page faults and memory utilization:\n\n`pidstat -r`\n\n- Show input/output usage per process id:\n\n`pidstat -d`\n\n- Show information on a specific PID:\n\n`pidstat -p {{PID}}`\n\n- Show memory statistics for all processes whose command name include \"fox\" or \"bird\":\n\n`pidstat -C \"{{fox|bird}}\" -r -p ALL`\n"
 },
 {
   "command": "hdparm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# hdparm\n\n> Get and set SATA and IDE hard drive parameters.\n\n- Request the identification info of a given device:\n\n`sudo hdparm -I /dev/{{device}}`\n\n- Get the Advanced Power Management level:\n\n`sudo hdparm -B /dev/{{device}}`\n\n- Set the Advanced Power Management value (values 1-127 permit spin-down, and values 128-254 do not):\n\n`sudo hdparm -B {{1}} /dev/{{device}}`\n\n- Display the device's current power mode status:\n\n`sudo hdparm -C /dev/{{device}}`\n\n- Force a drive to immediately enter standby mode (usually causes a drive to spin down):\n\n`sudo hdparm -y /dev/{{device}}`\n\n- Put the drive into idle (low-power) mode, also setting its standby timeout:\n\n`sudo hdparm -S {{standby_timeout}} {{device}}`\n"
 },
 {
   "command": "units",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nUNITS(1)\t\t  BSD General Commands Manual\t\t      UNITS(1)\n\nNAME\n     units -- conversion program\n\nSYNOPSIS\n     units [-f filename] [-qv] [from-unit to-unit]\n\nOPTIONS\n     The following options are available:\n\n     -f filename\n\t     Specify the name of the units data file to load.\n\n     -q      Suppress prompting of the user for units and the display of sta-\n\t     tistics about the number of units loaded.\n\n     -v      Print the version number.\n\n     from-unit to-unit\n\t     Allow a single unit conversion to be done directly from the com-\n\t     mand line.  The program will not print prompts.  It will print\n\t     out the result of the single specified conversion.\n\nDESCRIPTION\n     The units program converts quantities expressed in various scales to\n     their equivalents in other scales.  The units program can only handle\n     multiplicative scale changes.  It cannot convert Celsius to Fahrenheit,\n     for example.  It works interactively by prompting the user for input:\n\n\t You have: meters\n\t You want: feet\n\t\t * 3.2808399\n\t\t / 0.3048\n\n\t You have: cm^3\n\t You want: gallons\n\t\t * 0.00026417205\n\t\t / 3785.4118\n\n\t You have: meters/s\n\t You want: furlongs/fortnight\n\t\t * 6012.8848\n\t\t / 0.00016630952\n\n\t You have: 1|2 inch\n\t You want: cm\n\t\t * 1.27\n\t\t / 0.78740157\n\n     Powers of units can be specified using the '^' character as shown in the\n     example, or by simple concatenation: 'cm3' is equivalent to 'cm^3'.  Mul-\n     tiplication of units can be specified by using spaces, a dash or an\n     asterisk.\tDivision of units is indicated by the slash ('/').  Note that\n     multiplication has a higher precedence than division, so 'm/s/s' is the\n     same as 'm/s^2' or 'm/s s'.  Division of numbers must be indicated using\n     the vertical bar ('|').  To convert half a meter, you would write '1|2\n     meter'.  If you write '1/2 meter' then the units program would interpret\n     that as equivalent to '0.5/meter'.  If you enter incompatible unit types,\n     the units program will print a message indicating that the units are not\n     conformable and it will display the reduced form for each unit:\n\n\t You have: ergs/hour\n\t You want: fathoms kg^2 / day\n\t conformability error\n\t\t 2.7777778e-11 kg m^2 / sec^3\n\t\t 2.1166667e-05 kg^2 m / sec\n\n     The conversion information is read from a units data file.  The default\n     file includes definitions for most familiar units, abbreviations and met-\n     ric prefixes.  Some constants of nature included are:\n\n\t   pi\t      ratio of circumference to diameter\n\t   c\t      speed of light\n\t   e\t      charge on an electron\n\t   g\t      acceleration of gravity\n\t   force      same as g\n\t   mole       Avogadro's number\n\t   water      pressure per unit height of water\n\t   mercury    pressure per unit height of mercury\n\t   au\t      astronomical unit\n\n     The unit 'pound' is a unit of mass.  Compound names are run together so\n     'pound force' is a unit of force.\tThe unit 'ounce' is also a unit of\n     mass.  The fluid ounce is 'floz'.\tBritish units that differ from their\n     US counterparts are prefixed with 'br', and currency is prefixed with its\n     country name: 'belgiumfranc', 'britainpound'.  When searching for a unit,\n     if the specified string does not appear exactly as a unit name, then\n     units will try to remove a trailing 's' or a trailing 'es' and check\n     again for a match.\n\n     To find out what units are available read the standard units file.  If\n     you want to add your own units you can supply your own file.  A unit is\n     specified on a single line by giving its name and an equivalence.\tBe\n     careful to define new units in terms of old ones so that a reduction\n     leads to the primitive units which are marked with '!' characters.  The\n     units program will not detect infinite loops that could be caused by\n     careless unit definitions.  Comments in the unit definition file begin\n     with a '/' character at the beginning of a line.\n\n     Prefixes are defined in the same was as standard units, but with a trail-\n     ing dash at the end of the prefix name.  If a unit is not found even\n     after removing trailing 's' or 'es', then it will be checked against the\n     list of prefixes.\tPrefixes will be removed until a legal base unit is\n     identified.\n\n     Here is an example of a short units file that defines some basic units.\n\n\t   m\t     !a!\n\t   sec\t     !b!\n\t   micro-    1e-6\n\t   minute    60 sec\n\t   hour      60 min\n\t   inch      0.0254 m\n\t   ft\t     12 inches\n\t   mile      5280 ft\n\nFILES\n     /usr/share/misc/units.lib\tthe standard units library\n\nAUTHORS\n     Adrian Mariano <adrian@cam.cornell.edu>\n\nBUGS\n     The effect of including a '/' in a prefix is surprising.\n\n     Exponents entered by the user can be only one digit.  You can work around\n     this by multiplying several terms.\n\n     The user must use | to indicate division of numbers and / to indicate\n     division of symbols.  This distinction should not be necessary.\n\n     The program contains various arbitrary limits on the length of the units\n     converted and on the length of the data file.\n\n     The program should use a hash table to store units so that it does not\n     take so long to load the units list and check for duplication.\n\nBSD\t\t\t\t July 14, 1993\t\t\t\t   BSD\n",
   "tldr_summary": "# units\n\n> Provide the conversion between two units of measure.\n> Typing 'search {{text}}' in the prompt will display a list of all of the units containing {{text}}.\n\n- Run in interactive mode:\n\n`units`\n\n- Show the conversion between two simple units:\n\n`units {{quarts}} {{tablespoons}}`\n\n- Convert between units with quantities:\n\n`units {{15 pounds}} {{kilograms}}`\n\n- Show the conversion between two compound units:\n\n`units {{\"meters / second\"}} {{\"inches / hour\"}}`\n\n- Show the conversion between units with different dimensions:\n\n`units {{\"acres\"}} {{\"ft^2\"}}`\n"
 },
 {
   "command": "ebuild",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ebuild\n\n> A low level interface to the Gentoo Portage system.\n\n- Create or update the package manifest:\n\n`ebuild {{path/to/file.ebuild}} manifest`\n\n- Clean the temporary build directories for the build file:\n\n`ebuild {{path/to/file.ebuild}} clean`\n\n- Fetch sources if they do not exist:\n\n`ebuild {{path/to/file.ebuild}} fetch`\n\n- Extract the sources to a temporary build directory:\n\n`ebuild {{path/to/file.ebuild}} unpack`\n\n- Compile the extracted sources:\n\n`ebuild {{path/to/file.ebuild}} compile`\n\n- Install the package to a temporary install directory:\n\n`ebuild {{path/to/file.ebuild}} install`\n\n- Install the temporary files to the live filesystem:\n\n`ebuild {{path/to/file.ebuild}} qmerge`\n\n- Fetch, unpack, compile, install and qmerge the specified ebuild file:\n\n`ebuild {{path/to/file.ebuild}} merge`\n"
 },
 {
   "command": "rc-status",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rc-status\n\n> Show status info about runlevels.\n> See also `openrc`.\n\n- Show a summary of services and their status:\n\n`rc-status`\n\n- Include services in all runlevels in the summary:\n\n`rc-status --all`\n\n- List services that have crashed:\n\n`rc-status --crashed`\n\n- List manually started services:\n\n`rc-status --manual`\n\n- List supervised services:\n\n`rc-status --supervised`\n\n- Get the current runlevel:\n\n`rc-status --runlevel`\n\n- List all runlevels:\n\n`rc-status --list`\n"
 },
 {
   "command": "duperemove",
   "doc_url": "https://markfasheh.github.io/duperemove/",
   "doc_text": "\n\n\nDuperemove by markfasheh\n\n\n\n\n\n\n\n\nDuperemove\nTools for deduping file systems\nView on GitHub\nDownload .zip\nDownload .tar.gz\n\n\n\nDuperemove\nDuperemove is a simple tool for finding duplicated extents and\nsubmitting them for deduplication. When given a list of files it will\nhash their contents on a block by block basis and compare those hashes\nto each other, finding and categorizing extents that match each\nother. When given the -d option, duperemove will submit those\nextents for deduplication using the Linux kernel extent-same ioctl.\nDuperemove can store the hashes it computes in a 'hashfile'. If\ngiven an existing hashfile, duperemove will only compute hashes\nfor those files which have changed since the last run.  Thus you can run\nduperemove repeatedly on your data as it changes, without having to\nre-checksum unchanged data.\nDuperemove can also take input from the fdupes program.\nSee the duperemove man page for further details about running duperemove.\n\nRequirements\nThe latest stable code (v0.11) can be found\n  in master branch.\nKernel: Duperemove needs a kernel version equal to or greater than 3.13\nLibraries: Duperemove uses glib2 and sqlite3.\n\nFAQ\nPlease see the FAQ section\n  in the\n    duperemove man page\nFor bug reports and feature requests please use the github issue tracker\n\nExamples\nPlease see the examples section of the duperemove man\npage\nfor a complete set of usage examples, including hashfile usage.\n\nA simple example, with program output\nDuperemove takes a list of files and directories to scan for\ndedupe. If a directory is specified, all regular files within it will\nbe scanned. Duperemove can also be told to recursively scan\ndirectories with the '-r' switch. If '-h' is provided, duperemove will\nprint numbers in powers of 1024 (e.g., \"128K\").\nAssume this abitrary layout for the following examples.\n.\n├── dir1\n│   ├── file3\n│   ├── file4\n│   └── subdir1\n│       └── file5\n├── file1\n└── file2\n\nThis will dedupe files 'file1' and 'file2':\nduperemove -dh file1 file2\n\nThis does the same but adds any files in dir1 (file3 and file4):\nduperemove -dh file1 file2 dir1\n\nThis will dedupe exactly the same as above but will recursively walk\ndir1, thus adding file5.\nduperemove -dhr file1 file2 dir1/\n\nAn actual run, output will differ according to duperemove version.\nUsing 128K blocks\nUsing hash: murmur3\nUsing 4 threads for file hashing phase\ncsum: /btrfs/file1  [1/5] (20.00%)\ncsum: /btrfs/file2  [2/5] (40.00%)\ncsum: /btrfs/dir1/subdir1/file5     [3/5] (60.00%)\ncsum: /btrfs/dir1/file3     [4/5] (80.00%)\ncsum: /btrfs/dir1/file4     [5/5] (100.00%)\nTotal files:  5\nTotal hashes: 80\nLoading only duplicated hashes from hashfile.\nHashing completed. Calculating duplicate extents - this may take some time.\nSimple read and compare of file data found 3 instances of extents that might benefit from deduplication.\nShowing 2 identical extents of length 512.0K with id 0971ffa6\nStart       Filename\n512.0K  \"/btrfs/file1\"\n1.5M    \"/btrfs/dir1/file4\"\nShowing 2 identical extents of length 1.0M with id b34ffe8f\nStart       Filename\n0.0 \"/btrfs/dir1/file4\"\n0.0 \"/btrfs/dir1/file3\"\nShowing 3 identical extents of length 1.5M with id f913dceb\nStart       Filename\n0.0 \"/btrfs/file2\"\n0.0 \"/btrfs/dir1/file3\"\n0.0 \"/btrfs/dir1/subdir1/file5\"\nUsing 4 threads for dedupe phase\n[0x147f4a0] Try to dedupe extents with id 0971ffa6\n[0x147f770] Try to dedupe extents with id b34ffe8f\n[0x147f680] Try to dedupe extents with id f913dceb\n[0x147f4a0] Dedupe 1 extents (id: 0971ffa6) with target: (512.0K, 512.0K), \"/btrfs/file1\"\n[0x147f770] Dedupe 1 extents (id: b34ffe8f) with target: (0.0, 1.0M), \"/btrfs/dir1/file4\"\n[0x147f680] Dedupe 2 extents (id: f913dceb) with target: (0.0, 1.5M), \"/btrfs/file2\"\nKernel processed data (excludes target files): 4.5M\nComparison of extent info shows a net change in shared extents of: 5.5M\n\n\nLinks of interest\nThe duperemove wiki\nhas both design and performance documentation.\nduperemove-tests has\na growing assortment of regression tests.\nDuperemove web page\n\nDuperemove is maintained by markfasheh.\nThis page was generated by GitHub Pages using the Cayman theme by Jason Long.\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# duperemove\n\n> Finds duplicate file system extents and optionally schedule them for deduplication.\n> An extent is small part of a file inside the file system.\n> On some file systems one extent can be referenced multiple times, when parts of the content of the files are identical.\n> More information: <https://markfasheh.github.io/duperemove/>.\n\n- Search for duplicate extents in a directory and show them:\n\n`duperemove -r {{path/to/directory}}`\n\n- Deduplicate duplicate extents on a Btrfs or XFS (experimental) file system:\n\n`duperemove -r -d {{path/to/directory}}`\n\n- Use a hash file to store extent hashes (less memory usage and can be reused on subsequent runs):\n\n`duperemove -r -d --hashfile={{path/to/hashfile}} {{path/to/directory}}`\n\n- Limit I/O threads (for hashing and dedupe stage) and CPU threads (for duplicate extent finding stage):\n\n`duperemove -r -d --hashfile={{path/to/hashfile}} --io-threads={{N}} --cpu-threads={{N}} {{path/to/directory}}`\n"
 },
 {
   "command": "logwatch",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# logwatch\n\n> Summarizes many different logs for common services (e.g., apache, pam_unix, sshd, etc.) in a single report.\n\n- Analyze logs for a range of dates at certain level of detail:\n\n`logwatch --range {{yesterday|today|all|help}} --detail {{low|medium|others}}'`\n\n- Restrict report to only include information for a selected service:\n\n`logwatch --range {{all}} --service {{apache|pam_unix|etc}}`\n"
 },
 {
   "command": "lscpu",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lscpu\n\n> Displays information about the CPU architecture.\n\n- Display information about all CPUs:\n\n`lscpu`\n\n- Display information in a table:\n\n`lscpu --extended`\n\n- Display only information about offline CPUs in a table:\n\n`lscpu --extended --offline`\n"
 },
 {
   "command": "sar",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# sar\n\n> Monitor performance of various Linux subsystems.\n\n- Report I/O and transfer rate issued to physical devices, one per second (press CTRL+C to quit):\n\n`sar -b {{1}}`\n\n- Report a total of 10 network device statistics, one per 2 seconds:\n\n`sar -n DEV {{2}} {{10}}`\n\n- Report CPU utilization, one per 2 seconds:\n\n`sar -u ALL {{2}}`\n\n- Report a total of 20 memory utilization statistics, one per second:\n\n`sar -r ALL {{1}} {{20}}`\n\n- Report the run queue length and load averages, one per second:\n\n`sar -q {{1}}`\n\n- Report paging statistics, one per 5 seconds:\n\n`sar -B {{5}}`\n"
 },
 {
   "command": "yaourt",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# yaourt\n\n> Arch Linux utility for building packages from the Arch User Repository.\n\n- Synchronize and update all packages (including AUR):\n\n`yaourt -Syua`\n\n- Install a new package (includes AUR):\n\n`yaourt -S {{package_name}}`\n\n- Remove a package and its dependencies (includes AUR packages):\n\n`yaourt -Rs {{package_name}}`\n\n- Search the package database for a keyword (including AUR):\n\n`yaourt -Ss {{package_name}}`\n\n- List installed packages, versions, and repositories (AUR packages will be listed under the repository name 'local'):\n\n`yaourt -Q`\n"
 },
 {
   "command": "urxvt",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# urxvt\n\n> Rxvt-unicode.\n> A customizable terminal emulator.\n\n- Open a new urxvt window:\n\n`urxvt`\n\n- Run in a specific directory:\n\n`urxvt -cd {{path/to/directory}}`\n\n- Run a command in a new urxvt window:\n\n`urxvt -e {{command}}`\n\n- Run a command and keep the window open:\n\n`urxvt --hold -e {{command}}`\n\n- Run a command within the \"sh\" shell:\n\n`urxvt -e {{sh}} -c {{command}}`\n"
 },
 {
   "command": "zypper",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# zypper\n\n> SUSE & openSUSE package management utility.\n\n- Synchronize list of packages and versions available:\n\n`zypper refresh`\n\n- Install a new package:\n\n`zypper install {{package}}`\n\n- Remove a package:\n\n`zypper remove {{package}}`\n\n- Upgrade installed packages to newest available versions:\n\n`zypper update`\n\n- Search package via keyword:\n\n`zypper search {{keyword}}`\n"
 },
 {
   "command": "xrandr",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xrandr\n\n> Set the size, orientation and/or reflection of the outputs for a screen.\n\n- Display the current state of the system (known screens, resolutions, ...):\n\n`xrandr --query`\n\n- Disable disconnected outputs and enable connected ones with default settings:\n\n`xrandr --auto`\n\n- Change the resolution and update frequency of DisplayPort 1 to 1920x1080, 60Hz:\n\n`xrandr --output {{DP1}} --mode {{1920x1080}} --rate {{60}}`\n\n- Set the resolution of HDMI2 to 1280x1024 and put it on the right of DP1:\n\n`xrandr --output {{HDMI2}} --mode {{1280x1024}} --right-of {{DP1}}`\n\n- Disable the VGA1 output:\n\n`xrandr --output {{VGA1}} --off`\n"
 },
 {
   "command": "google-chrome",
   "doc_url": "https://chrome.google.com",
   "doc_text": " \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoogle Chrome - Download the Fast, Secure Browser from Google\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMenu\n\n\n\nMenu\n\n\n\n\n\n\n\n\nicon chrome logo\n\n\n\n\nJump to content\n\n\n\n\n\nHome\n\nThe Browser by Google\n\nFeatures\n          \nicon-expand-features\n\n\n\nOverview\n\nGoogle address bar\n\nPassword check\n\nSync\n\nDark mode\n\nTabs\n\nArticles for you\n\nExtensions\n\n\n\nSupport\n          \n\n\n\n\n\n\nDownload Chrome\n\n\n\n\nclose drawer\n\n\n\n\n\n\n\nicon chrome logo\n\n\n\n\n\n\nHome\n\nThe Browser by Google\n\nFeatures\n          \nicon-expand-features\n\n\n\nOverview\n\nGoogle address bar\n\nPassword check\n\nSync\n\nDark mode\n\nTabs\n\nArticles for you\n\nExtensions\n\n\n\nSupport\n          \n\n\n\n\n\nDownload Chrome\n\n\n\n\n\n\n\n      Google uses cookies to deliver its services, to personalize ads, and to analyze traffic. You can adjust your privacy controls anytime in your  Google settings or learn more.\n\n\nOk, got it\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n        The browser built by Google\n\nDownload Chrome\n\n\nFor Windows 10/8.1/8/7 32-bit.\nFor Windows 10/8.1/8/7 64-bit.\nThis computer will no longer receive Google Chrome updates because Windows XP and Windows Vista are no longer supported.\n\n\nFor Mac OS X 10.10 or later.\nThis computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.\nThis computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.\n\n\nDebian/Ubuntu/Fedora/openSUSE.\n\n\n\n\n\n\nSet Google Chrome as my default browser\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nSet Google Chrome as my default browser\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\n\nSet Google Chrome as my default browser\n\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilt by google\nBrowse with the power of Google\nWith Google apps like Gmail, Google Pay, and Google Assistant, Chrome can help you stay productive and get more out of your browser.\nExplore Google tools\n          \n\n\n\n\n\n\n\n\n\n\n\nSafety by design\nTake control of your online safety\nChrome works hard to protect your data and privacy online. With easy-to-use privacy controls, Chrome lets you customize your settings and browsing experience to how you see fit.\nExplore safety\n          \n\n\n\n\n\n\n\n\n\n\n\nHelpful features built-in\nFast, easy-to-use tools for browsing\nFrom password check, dark mode, and the Google address bar, Chrome helps you get things done and stay safe online.\nExplore features\n          \n\n\n\n\n\n\n\n\n\n\n\nMore from chrome\nDiscover more tools and resources\n\n\n\n\n\n\n\n\n\n\nFor enterprises\nKeep people and data secure with seamless updates and intuitive policy enforcement.\n\n\nGo to Chrome Enterprise\n          \n\n\n\n\n\n\n\n\n\n\n\nFor developers\nDevelop websites for the next version of the open web with Chrome for developers.\n\n\nGo to Chrome Dev\n          \n\n\n\n\n\n\n\n\n\n\n\nFor early adopters\nPreview upcoming Chrome features before they are released with Chrome Beta.\n\n\nGo to Chrome Beta\n          \n\n\n\n\n\n\n\n\n\n\n\nFor explorers\nGet on the bleeding edge of the web and get nightly updates with Chrome Canary.\n\n\nGo to Chrome Canary\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrev\n\n\n\n\nNext\n\n\n\n\n\n\n\n\n\n\n\n\n\n            Get the Browser by Google\n\nDownload Chrome now\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Follow us\n\n\n\n\nYoutube\n\n\n\n\n\n\nTwitter\n\n\n\n\n\n\nFacebook\n\n\n\n\n\n\n\n\n\n\n              Chrome Family\n\n\n\n\n\nOther Platforms\n\nChromebooks\n          \n\n\n\nChromecast\n          \n\n\n\nChrome Cleanup Tool\n          \n\n\n\n\n\n\n              Enterprise\n\n\n\n\n\nDownload Chrome Browser\n          \n\n\n\nChrome Browser for Enterprise\n          \n\n\n\nChrome Devices\n          \n\n\n\nChrome OS\n          \n\n\n\nGoogle Cloud\n          \n\n\n\nG Suite\n          \n\n\n\n\n\n\n              Education\n\n\n\n\n\nGoogle Chrome Browser\n          \n\n\n\nDevices\n          \n\n\n\nWeb Store\n          \n\n\n\n\n\n\n              Dev and Partners\n\n\n\n\n\nChromium\n          \n\n\n\nChrome OS\n          \n\n\n\nChrome Web Store\n          \n\n\n\nChrome Experiments\n          \n\n\n\nChrome Beta\n\nChrome Dev\n\nChrome Canary\n\n\n\n\n              Stay Connected\n\n\n\n\n\nGoogle Chrome Blog\n          \n\n\n\nUpdate Chrome\n\nChrome Help\n          \n\n\n\n\n\n\n\n\n\n\nGoogle\n\n\n\n\n\n\nPrivacy and Terms\n\nAbout Google\n\nGoogle Products\n\n\n\n\n\n\nHelp\n\n\nHelp\n\nChange language or region\n\n\nBahasa Melayu - Malaysia\n\nCatalÃ  - Espanya\n\nDansk - Danmark\n\nDeutsch - Deutschland\n\nEesti - Eesti\n\nEnglish - Australia\n\nEnglish - Canada\n\nEnglish - United Kingdom\n\nEnglish - Hong Kong SAR China\n\nEnglish - Ireland\n\nEnglish - India\n\nEnglish - Philippines\n\nEnglish - Pakistan\n\nEnglish - Singapore\n\nEnglish - United States\n\nEspaÃ±ol - LatinoamÃ©rica\n\nEspaÃ±ol - EspaÃ±a\n\nFilipino - Pilipinas\n\nFranÃ§ais - France\n\nHrvatski - Hrvatska\n\nIndonesia - Indonesia\n\nItaliano - Italia\n\nLatvieÅ¡u - Latvija\n\nLietuviÅ³ - Lietuva\n\nMagyar - MagyarorszÃ¡g\n\nNederlands - Nederland\n\nNorsk BokmÃ¥l - Norge\n\nPolski - Polska\n\nPortuguÃªs - Portugal\n\nPortuguÃªs - Brasil\n\nRomÃ¢nÄ - RomÃ¢nia\n\nSlovenÄina - Slovensko\n\nSlovenÅ¡Äina - Slovenija\n\nSuomi - Suomi\n\nSvenska - Sverige\n\nTiáº¿ng Viá»t - Viá»t Nam\n\nTÃ¼rkÃ§e - TÃ¼rkiye\n\nÄeÅ¡tina - Äesko\n\nÎÎ»Î»Î·Î½Î¹ÎºÎ¬ - ÎÎ»Î»Î¬Î´Î±\n\nÐÑÐ»Ð³Ð°ÑÑÐºÐ¸ - ÐÑÐ»Ð³Ð°ÑÐ¸Ñ\n\nÐ ÑÑÑÐºÐ¸Ð¹ - Ð Ð¾ÑÑÐ¸Ñ\n\nÐ¡ÑÐ¿ÑÐºÐ¸ - Ð¡ÑÐ±Ð¸ÑÐ°\n\nÐ£ÐºÑÐ°ÑÐ½ÑÑÐºÐ° - Ð£ÐºÑÐ°ÑÐ½Ð°\n\n×¢××¨××ª\n\nØ§ÙØ¹Ø±Ø¨ÙØ© - Ø§ÙÙÙÙÙØ© Ø§ÙØ¹Ø±Ø¨ÙØ© Ø§ÙØ³Ø¹ÙØ¯ÙØ©\n\nÙØ§Ø±Ø³Û\n\nà¤¹à¤¿à¤¨à¥à¤¦à¥ - à¤­à¤¾à¤°à¤¤\n\nà¹à¸à¸¢ - à¹à¸à¸¢\n\nä¸­æ - ä¸­å½\n\nä¸­æ - ä¸­å½é¦æ¸¯ç¹å«è¡æ¿åº\n\nä¸­æ - å°ç£\n\næ¥æ¬èª - æ¥æ¬\n\níêµ­ì´ - ëíë¯¼êµ­\n\n\n\n\n\n\n\n\nClose\n\n\nDownload Chrome for Windows\nFor Windows 10/8.1/8/7 32-bit.\nFor Windows 10/8.1/8/7 64-bit.\nThis computer will no longer receive Google Chrome updates because Windows XP and Windows Vista are no longer supported.\n\n\nDownload Chrome for Mac\nFor Mac OS X 10.10 or later.\nThis computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.\nThis computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.\n\n\nDownload Chrome for Linux\nDebian/Ubuntu/Fedora/openSUSE.\nPlease select your download package:\n\n\n\n64 bit .deb (For Debian/Ubuntu)\n\n\n64 bit .rpm (For Fedora/openSUSE)\nNot Debian/Ubuntu or Fedora/openSUSE? There may be a community-supported version for your distribution here.\n\n\nDownload Chrome for iOS\n\n\nBy downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service\n\nNote: Installing Google Chrome will add the Google repository so your system will automatically keep Google Chrome up to date. If you donât want Google's repository, do âsudo touch /etc/default/google-chromeâ before installing the package.\n\n\n\n\nSet Google Chrome as my default browser\n\n\n\nHelp make Google Chrome better by automatically sending usage statistics and crash reports to Google.\n        Learn more\n\n\n\nAccept and Install\n\n\n\n\n\nDownload Chrome\n\nDownload for Windows\nFor Windows 10/8.1/8/7 32-bit\n\nFor Windows 10/8.1/8/7 64-bit\n\nThis computer will no longer receive Google Chrome updates because Windows XP and Windows Vista are no longer supported.\n\n\n\nDownload for Mac\nMac OS X 10.10 or later\n\nThis computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.\n\n\nThis computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.\n\n\n\nDownload for Linux\nDebian/Ubuntu/Fedora/openSUSE\n\n\n\nDownload for phone or tablet\n\n\nAndroid\n\niOS\n\nDownload for another desktop OS\n\n\nWindows 10/8.1/8/7 64-bit\n\nWindows 10/8.1/8/7 32-bit\n\nMac OS X 10.10 or later\n\nLinux\n\nFrozen versions\n\n\nWindows XP\n\nWindows Vista\n\nMac 10.6 - 10.8\n\nMac 10.9\n\n\n\n\n\nLooks like youâre already using Chrome browser. Nice!\n\n\nThe device you have runs on Chrome OS, which already has Chrome browser built-in. No need to manually install or update it â with automatic updates, youâll always get the latest version. Learn more about automatic updates.\nLooking for Chrome for a different operating system?\nSee the full list of supported operating systems.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# google-chrome\n\n> The web browser from Google.\n> More information: <https://chrome.google.com>.\n\n- Run with a custom profile directory:\n\n`google-chrome --user-data-dir={{path/to/directory}}`\n\n- Run without CORS validation, useful to test an API:\n\n`google-chrome --user-data-dir={{path/to/directory}} --disable-web-security`\n"
 },
 {
   "command": "rofi",
   "doc_url": "https://github.com/davatorium/rofi",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - davatorium/rofi: Rofi: A window switcher, application launcher and dmenu replacement\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndavatorium\n\n/\n\nrofi\n\n\n\n\n\n\n\n    Watch\n \n      95\n    \n\n\n\n\n      Star\n\n\n      6.4k\n    \n\n\n\n\n          Fork\n\n\n        338\n      \n\n\n\n\n\n        Rofi: A window switcher, application launcher and dmenu replacement\n      \n\n\n\n            View license\n        \n\n\n\n\n6.4k\n        stars\n \n\n338\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n64\n \n\n\n\nPull requests\n14\n \n\n\n\nActions\n\n \n\n\n\nProjects\n2\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nnext\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n30\nbranches\n\n\n\n30\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nDaveDavenport\n\nAdd list with packaged version (thx @zero77)\n\n\n\n…\n\n\n\n58a51f7\n\nSep 21, 2020\n\n\n\n\n\nAdd list with packaged version (thx @zero77)\n\nFixes: #1197\n\n58a51f7\n\n\n\nGit stats\n\n\n\n\n\n3,240\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github\n\n\n\nUpdate bug_report.md\n\n\n\nSep 1, 2020\n\n\n\n\n\n\n\nExamples\n\n\n\n[Script] Add 'info' row option, that gets passed to ROFI_INFO environ…\n\n\n\nMay 24, 2020\n\n\n\n\n\n\n\nconfig\n\n\n\nRun indenter.\n\n\n\nAug 28, 2020\n\n\n\n\n\n\n\ndata\n\n\n\nAdd png version of logo.\n\n\n\nOct 31, 2016\n\n\n\n\n\n\n\ndoc\n\n\n\n[Man] update-rofi-sensible-terminal.1 manpage\n\n\n\nSep 19, 2020\n\n\n\n\n\n\n\ninclude\n\n\n\n[Calc] Add min/max operator support to calc()\n\n\n\nSep 14, 2020\n\n\n\n\n\n\n\nlexer\n\n\n\n[Calc] Add min/max operator support to calc()\n\n\n\nSep 14, 2020\n\n\n\n\n\n\n\nm4\n\n\n\nAdd lex version check.\n\n\n\nApr 4, 2017\n\n\n\n\n\n\n\npkgconfig\n\n\n\nMake -plugin-path commandline flag be read before loading plugins\n\n\n\nOct 16, 2017\n\n\n\n\n\n\n\nreleasenotes\n\n\n\nFix release note error of supported prefix\n\n\n\nSep 11, 2020\n\n\n\n\n\n\n\nresources\n\n\n\nFirst testing to use GResource to load default theme.\n\n\n\nOct 31, 2017\n\n\n\n\n\n\n\nscript\n\n\n\n[ThemeSelector] Use rasi config file format, not xresources.\n\n\n\nJun 17, 2020\n\n\n\n\n\n\n\nsource\n\n\n\n[HELP] Fix typo in help msgs (#1198)\n\n\n\nSep 17, 2020\n\n\n\n\n\n\n\nsubprojects\n\n\n\n[meson] Test possible 'workaround' for meson 0.55 issue\n\n\n\nAug 1, 2020\n\n\n\n\n\n\n\ntest\n\n\n\n[Test] fix theme parser test for latest change in grammar parser\n\n\n\nSep 13, 2020\n\n\n\n\n\n\n\nthemes\n\n\n\nRemove unneeded '# from shipped themes.\n\n\n\nAug 29, 2020\n\n\n\n\n\n\n\n.gitignore\n\n\n\nAdd support for additional field on script entries `meta` (#1052)\n\n\n\nFeb 1, 2020\n\n\n\n\n\n\n\n.gitlab-ci.yml\n\n\n\nAdd texinfo.\n\n\n\nSep 24, 2017\n\n\n\n\n\n\n\n.gitmodules\n\n\n\nchanged ligbwater's url from git to https\n\n\n\nDec 4, 2017\n\n\n\n\n\n\n\n.travis.yml\n\n\n\n[Travis] Add coverage for meson build\n\n\n\nMay 14, 2020\n\n\n\n\n\n\n\nAUTHORS\n\n\n\nUpdate authors list.\n\n\n\nSep 26, 2017\n\n\n\n\n\n\n\nCODE_OF_CONDUCT.md\n\n\n\nCreate CODE_OF_CONDUCT.md (#608)\n\n\n\nJun 17, 2017\n\n\n\n\n\n\n\nCOPYING\n\n\n\nUpdate copyright dates.\n\n\n\nJan 1, 2020\n\n\n\n\n\n\n\nChangelog\n\n\n\nUpdate Changelog\n\n\n\nSep 6, 2020\n\n\n\n\n\n\n\nINSTALL.md\n\n\n\nRemove xenial warning from INSTALL.md\n\n\n\nSep 13, 2020\n\n\n\n\n\n\n\nMakefile.am\n\n\n\n[Man] update-rofi-sensible-terminal.1 manpage\n\n\n\nSep 19, 2020\n\n\n\n\n\n\n\nREADME.md\n\n\n\nAdd list with packaged version (thx @zero77)\n\n\n\nSep 21, 2020\n\n\n\n\n\n\n\nconfigure.ac\n\n\n\nUpdate version in configure.ac to 1.6.0-dev\n\n\n\nSep 6, 2020\n\n\n\n\n\n\n\nlibgwater-xcb-nolibtool.mk\n\n\n\ngitmodules: Move to subprojects/\n\n\n\nMay 4, 2017\n\n\n\n\n\n\n\nmeson.build\n\n\n\n[Man] update-rofi-sensible-terminal.1 manpage\n\n\n\nSep 19, 2020\n\n\n\n\n\n\n\nmeson_options.txt\n\n\n\n[Timings] Move into new debug system. (#961)\n\n\n\nMay 11, 2019\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\n\n\n\n\nA window switcher, Application launcher and dmenu replacement\nRofi started as a clone of simpleswitcher, written by Sean Pringle - a\npopup window switcher roughly based on superswitcher.\nSimpleswitcher laid the foundations, and therefore Sean Pringle deserves most of the credit for this tool. Rofi\n(renamed, as it lost the simple property) has been extended with extra features, like an application launcher and\nssh-launcher, and can act as a drop-in dmenu replacement, making it a very versatile tool.\nRofi, like dmenu, will provide the user with a textual list of options where one or more can be selected.\nThis can either be running an application, selecting a window, or options provided by an external script.\nIts main features are:\n\nFully configurable keyboard navigation\nType to filter\n\nTokenized: type any word in any order to filter\nCase insensitive (togglable)\nSupport for fuzzy-, regex-, and glob matching\n\n\nUTF-8 enabled\n\nUTF-8-aware string collating\nInternational keyboard support (`e -> è)\n\n\nRTL language support\nCairo drawing and Pango font rendering\nBuilt-in modes:\n\nWindow switcher mode\n\nEWMH compatible WM\n\n\nApplication launcher\nDesktop file application launcher\nSSH launcher mode\nCombi mode, allowing several modes to be merged into one list\n\n\nHistory-based ordering — last 25 choices are ordered on top based on use (optional)\nLevenshtein distance ordering of matches (optional)\nDrop-in dmenu replacement\n\nMany added improvements\n\n\nEasily extensible using scripts\nTheming\n\nRofi has several built-in modes implementing common use cases and can be extended by scripts (either called from\nRofi or calling Rofi).\nBelow is a list of the different modes:\nWindow Switcher\n\nThe window switcher shows the following informations in columns (can be customized):\n\nDesktop name\nWindow class\nWindow title\n\nWindow mode features:\n\nClosing applications with Shift-Delete\nCustom command with Shift-Return\n\nApplication launcher\n\nThe run mode allows users to quickly search for and launch a program.\nRun mode features:\n\nShift-Return to run the selected program in a terminal\nFavorites list, with frequently used programs sorted on top\nCustom entries, like aliases, added by executing a command\n\nDesktop File Application launcher\nThe desktop run mode allows users to quickly search and launch an application from the freedesktop.org Desktop\nEntries. These are used by most Desktop Environments to populate launchers and menus.\nDrun mode features:\n\nFavorites list, with frequently used programs sorted on top\nAuto starting terminal applications in a terminal\n\nSSH launcher\n\nQuickly ssh into remote machines. Parses ~/.ssh/config and ~/.ssh/known_hosts to find hosts.\nScript mode\nLoads external scripts to add modes to Rofi, for example a file-browser.\nrofi  -show fb -modi fb:../Examples/rofi-file-browser.sh\n\nCOMBI mode\nCombine multiple modes in one view. This is especially useful when merging the window and run mode into one view.\nAllowing to quickly switch to an application, either by switching to it when it is already running or starting it.\nExample to combine Desktop run and the window switcher:\nrofi -combi-modi window,drun -show combi -modi combi\n\ndmenu replacement\n\nDrop in dmenu replacement. (Screenshot shows rofi used by\nteiler ).\nRofi features several improvements over dmenu to improve usability. There is the option to add\nan extra message bar (-mesg), pre-entering of text (-filter), or selecting entries based on a\npattern (-select). Also highlighting (-u and -a) options and modi to force user to select one\nprovided option (-only-match). In addition to this, rofi's dmenu mode can select multiple lines and\nwrite them to stdout.\nUsage\nIf used with -show [mode], rofi will immediately open in the specified [mode].\nIf used with -dmenu, rofi will use data from STDIN to let the user select an option.\nFor example, to show a run dialog:\nrofi -show run\nTo show a ssh dialog:\nrofi -show ssh\ndmenu\nIf rofi is passed the -dmenu option, or run as dmenu (ie, /usr/bin/dmenu is symlinked to /usr/bin/rofi),\nit will use the data passed from STDIN.\n~/scripts/my_script.sh | rofi -dmenu\necho -e \"Option #1\\nOption #2\\nOption #3\" | rofi -dmenu\n\nIn both cases, rofi will output the user's selection to STDOUT.\nSwitching Between Modi\nType Shift-/Left/Right to switch between active modi.\nKey bindings\n\n\n\nKey\nAction\n\n\n\n\nCtrl-v, Insert\nPaste from clipboard\n\n\nCtrl-Shift-v, Shift-Insert\nPaste primary selection\n\n\nCtrl-w\nClear the line\n\n\nCtrl-u\nDelete till the start of line\n\n\nCtrl-a\nMove to beginning of line\n\n\nCtrl-e\nMove to end of line\n\n\nCtrl-f, Right\nMove forward one character\n\n\nAlt-f, Ctrl-Right\nMove forward one word\n\n\nCtrl-b, Left\nMove back one character\n\n\nAlt-b, Ctrl-Left\nMove back one word\n\n\nCtrl-d, Delete\nDelete character\n\n\nCtrl-Alt-d\nDelete word\n\n\nCtrl-h, Backspace, Shift-Backspace\nBackspace (delete previous character)\n\n\nCtrl-Alt-h\nDelete previous word\n\n\nCtrl-j,Ctrl-m,Enter\nAccept entry\n\n\nCtrl-n,Down\nSelect next entry\n\n\nCtrl-p,Up\nSelect previous entry\n\n\nPage Up\nGo to the previous page\n\n\nPage Down\nGo to the next page\n\n\nCtrl-Page Up\nGo to the previous column\n\n\nCtrl-Page Down\nGo to the next column\n\n\nCtrl-Enter\nUse entered text as a command (in ssh/run modi)\n\n\nShift-Enter\nLaunch the application in a terminal (in run mode)\n\n\nShift-Enter\nReturn the selected entry and move to the next item while keeping Rofi open. (in dmenu)\n\n\nShift-Right\nSwitch to the next modi. The list can be customized with the -modi option.\n\n\nShift-Left\nSwitch to the previous modi. The list can be customized with the -modi option.\n\n\nCtrl-Tab\nSwitch to the next modi. The list can be customized with the -modi option.\n\n\nCtrl-Shift-Tab\nSwitch to the previous modi. The list can be customized with the -modi option.\n\n\nCtrl-space\nSet selected item as input text.\n\n\nShift-Del\nDelete entry from history.\n\n\ngrave\nToggle case sensitivity.\n\n\nAlt-grave\nToggle levenshtein sort.\n\n\nAlt-Shift-S\nTake a screenshot and store it in the Pictures directory.\n\n\n\nFor the full list of key bindings, see: rofi -show keys or rofi -help.\nConfiguration\nThere are currently three methods of setting configuration options:\n\nLocal configuration. Normally, depending on XDG, in ~/.config/rofi/config. This uses the Xresources format.\nXresources: A method of storing key values in the Xserver. See\nhere for more information.\nCommand line options: Arguments are passed to Rofi.\n\nA distribution can ship defaults in /etc/rofi.conf.\nThe Xresources options and the command line options are aliased. To define option X set:\n`rofi.X: value`\n\nIn the Xresources file. To set/override this from command line pass the same key\nprefixed with '-':\n`rofi -X value`\n\nTo get a list of available options formatted as Xresources entries, run:\n`rofi -dump-Xresources`\n\nor in a more readable format:\n`rofi -help`\n\nThe configuration system supports the following types:\n\nString\nInteger (signed and unsigned)\nChar\nBoolean\n\nThe Boolean option has a non-default command line syntax, to enable option X you do:\n`rofi -X`\n\nto disable it:\n`rofi -no-X`\n\nManpage\nFor more detailed information, please see the manpage, the wiki, or the forum.\nInstallation\nPlease see the installation guide for instructions on how to\ninstall Rofi.\nWhat is rofi not?\nRofi is not:\n\nA preview application. In other words, it will not show a (small) preview of images, movies or other files.\nA UI toolkit.\nA library to be used in other applications.\nAn application that can support every possible use-case. It tries to be generic enough to be usable by everybody.\nSpecific functionality can be added using scripts.\nJust a dmenu replacement. The dmenu functionality is a nice 'extra' to rofi, not its main purpose.\n\n\n\n\n\n\n\n\n\nAbout\n\n      Rofi: A window switcher, application launcher and dmenu replacement\n    \nTopics\n\n\n\n  rofi\n\n\n  dmenu\n\n\n  dmenu-replacement\n\n\n  application-launcher\n\n\n  window-switcher\n\n\n  c\n\n\n  i3\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n      30\n\n\n\n\n\nThe Masked Launcher\n\n          Latest\n \nSep 6, 2020\n\n \n\n        + 29 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 101\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 90 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC\n87.5%\n\n\n\n\n\nYacc\n2.8%\n\n\n\n\n\nLex\n2.4%\n\n\n\n\n\nShell\n2.4%\n\n\n\n\n\nM4\n1.6%\n\n\n\n\n\nMakefile\n1.4%\n\n\n\n\n\nOther\n1.9%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# rofi\n\n> An application launcher and window switcher.\n> More Information: <https://github.com/davatorium/rofi>.\n\n- Show the list of apps:\n\n`rofi -show drun`\n\n- Show the list of all commands:\n\n`rofi -show run`\n\n- Switch between windows:\n\n`rofi -show window`\n\n- Pipe a list of items to stdin and print the selected item to stdout:\n\n`printf \"{{Choice1\\nChoice2\\nChoice3}}\" | rofi -dmenu`\n"
 },
 {
   "command": "firejail",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# firejail\n\n> Securely sandboxes processes to containers using built-in Linux capabilities.\n\n- Integrate firejail with your desktop environment:\n\n`sudo firecfg`\n\n- Open a restricted Mozilla Firefox:\n\n`firejail {{firefox}}`\n\n- Start a restricted Apache server on a known interface and address:\n\n`firejail --net={{eth0}} --ip={{192.168.1.244}} {{/etc/init.d/apache2}} {{start}}`\n\n- List running sandboxes:\n\n`firejail --list`\n\n- List network activity from running sandboxes:\n\n`firejail --netstats`\n\n- Shutdown a running sandbox:\n\n`firejail --shutdown={{7777}}`\n"
 },
 {
   "command": "bitwise",
   "doc_url": "https://github.com/mellowcandle/bitwise",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - mellowcandle/bitwise: Terminal based bit manipulator in ncurses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmellowcandle\n\n/\n\nbitwise\n\n\n\n\n\n\n\n    Watch\n \n      9\n    \n\n\n\n\n      Star\n\n\n      352\n    \n\n\n\n\n          Fork\n\n\n        17\n      \n\n\n\n\n\n        Terminal based bit manipulator in ncurses\n      \n\n\n\n            GPL-3.0 License\n        \n\n\n\n\n352\n        stars\n \n\n17\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n6\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\nbranches\n\n\n\n14\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n \n \nGit stats\n\n\n\n\n\n232\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github/ISSUE_TEMPLATE\n\n\n \n\n\n \n\n\n\n\n\n\n\ndebian\n\n\n \n\n\n \n\n\n\n\n\n\n\ninc\n\n\n \n\n\n \n\n\n\n\n\n\n\nm4\n\n\n \n\n\n \n\n\n\n\n\n\n\nresources\n\n\n \n\n\n \n\n\n\n\n\n\n\nsrc\n\n\n \n\n\n \n\n\n\n\n\n\n\ntests\n\n\n \n\n\n \n\n\n\n\n\n\n\n.editorconfig\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\n.travis.yml\n\n\n \n\n\n \n\n\n\n\n\n\n\nAUTHORS\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING\n\n\n \n\n\n \n\n\n\n\n\n\n\nChangeLog\n\n\n \n\n\n \n\n\n\n\n\n\n\nLICENSE\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile.am\n\n\n \n\n\n \n\n\n\n\n\n\n\nNEWS\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\nbitwise.1\n\n\n \n\n\n \n\n\n\n\n\n\n\nbootstrap.sh\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfigure.ac\n\n\n \n\n\n \n\n\n\n\n\n\n\nsnapcraft.yaml\n\n\n \n\n\n \n\n\n\n\n\n\n\nubuntu_release.sh\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\nBitwise\nTerminal based bitwise calculator in curses\n\n\n\n\n\n\nBitwise is multi base interactive calculator supporting dynamic base conversion and bit manipulation.\nIt's a handy tool for low level hackers, kernel developers and device drivers developers.\nSome of the features include:\n\nInteractive ncurses interface\nCommand line calculator supporting all bitwise operations.\nIndividual bit manipulator.\nBitwise operations such as NOT, OR, AND, XOR, and shifts.\n\n\n\nUsage\nbitwise can be used both Interactively and in command line mode.\nCommand line calculator mode\nIn command line mode, bitwise will calculate the given expression and will output the result in all bases including binary representation.\nbitwise detects the base by the preface of the input (0x/0X for hexadecimal, leading 0 for octal, b for binary, and the rest is decimal).\nExamples:\nSimple base conversion\n\nC style syntax Calculator\n\nInteractive mode\nbitwise starts in interactive mode if no command line parameters are passed or if the -i | --interactive flag is passed.\nIn this mode, you can input a number and manipulate it and see the other bases change dynamically.\nIt also allows changing individual bits in the binary.\nYou can show the help screen by pressing  F1 .\nNavigation in interactive mode\nTo move around use the arrow keys, or use vi key bindings :  h   j   k   l .\nLeave the program by pressing  q .\nBinary specific movement\nYou can toggle a bit bit using the  space  key.\nYou can jump a byte forward using  w  and backwards one byte using  b .\nBitwise operation in interactive mode\nSetting the bit width:\nReducing or extending the bit width interactively is also very easy, just use:\n !  for 8bit,  @   for 16Bit,  $  for 32Bit and  *  for 64Bit.\nWhen changing the bit width, the number is masked with the new width, so you might lost precision, use with care.\nNOT:\nPress  ~  to perform the NOT operator.\nShifts\nPress  <  and  >  to perform the left or right shift.\nexpression calculator in interactive mode\nYou can enter expression calculator mode by typing  :  (Just like in vim).\nTo exit the mode, just press  ESC .\nIn this mode, you can type any expression you like to be evaluated.\nThe result will be printed in the history window and also printed in the binary and various bases on top.\noperators and functions\n\nAll C operators are supported, additionally, you can use the \"$\" symbol to refer to the last result.\nRefer to a specific bit by using the function BIT(x).\n\ncommands\n\nhelp - Show the help screen.\nclear - Clear the history window.\nwidth [8 | 16 | 32 | 64] - Set the required width mask\noutput [decimal | hex | octal | binary | all] - Set the default output for results.\nq - Exit\n\nIntegration with other software\nVim\n\nvim-bitwise\n\nInstallation\nLinux\nUbuntu\nsudo add-apt-repository ppa:ramon-fried/bitwise\nsudo apt-get update\nsudo apt-get install bitwise\n\nSnap\nIf your distribution supports Snap just type:\nsudo snap install bitwise\nArch\nYou can use the AUR repository: https://aur.archlinux.org/packages/bitwise/\nmacOS\nMacPorts\nsudo port install bitwise\n\nHomebrew\nbrew install bitwise\n\nWindows\nNCurses doesn't support windows. You can use the windows subsystem for Linux as a workaround.\nBuilding from source\nPrerequisites\n\nlibreadline\nlibncurses (with forms)\nlibcunit (only needed for testing)\n\nOn Ubuntu/Debian system you can just paste:\nsudo apt-get install build-essential\nsudo apt-get install libncurses5-dev\nsudo apt-get install libreadline-dev\nsudo apt-get install libcunit1-dev\n\nOn Mac systems:\nbrew install automake\nbrew install autoconf\nbrew install readline\nexport LDFLAGS=\"-L/usr/local/opt/readline/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/readline/include\"\n\n\nDownload the latest release\n\ntar xfz RELEASE-FILE.TAR.GZ\ncd RELEASE-DIR\n./configure\nmake\nsudo make install\nRunning unit tests by typing\nmake check\nContribution\n\nInstal prerequisites\nFork the repo\nRun ./bootstrap.sh\nFollow the building from source section.\ncommit and send pull request\n\n\n\n\n\n\n\n\n\nAbout\n\n      Terminal based bit manipulator in ncurses\n    \nTopics\n\n\n\n  curses\n\n\n  c\n\n\n  bitwise\n\n\n  bitwise-operation\n\n\n  linux\n\n\n  terminal-app\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-3.0 License\n    \n\n\n\n\n\n\n\n    Releases\n      14\n\n\n\n\n\nv0.41\n\n          Latest\n \nDec 18, 2019\n\n \n\n        + 13 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\nC\n54.6%\n\n\n\n\n\nM4\n42.6%\n\n\n\n\n\nOther\n2.8%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# bitwise\n\n> Multi base interactive calculator supporting dynamic base conversion and bit manipulation.\n> More information: <https://github.com/mellowcandle/bitwise>.\n\n- Run using interactive mode:\n\n`bitwise`\n\n- Convert from decimal:\n\n`bitwise {{12345}}`\n\n- Convert from hexadecimal:\n\n`bitwise {{0x563d}}`\n\n- Convert a C-style calculation:\n\n`bitwise  {{\"0x123 + 0x20 - 30 / 50\"}}`\n"
 },
 {
   "command": "rdesktop",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rdesktop\n\n> Remote Desktop Protocol client.\n> It can be used to connect the remote computer using the RDP protocol.\n\n- Connect to a remote computer (default port is 3389):\n\n`rdesktop -u {{username}} -p {{password}} {{host:port}}`\n\n- Simple Examples:\n\n`rdesktop -u Administrator -p passwd123 192.168.1.111:3389`\n\n- Connect to a remote computer with full screen (press `Ctrl + Alt + Enter` to exist):\n\n`rdesktop -u {{username}} -p {{password}} -f {{host:port}}`\n\n- Use the customed resolution (use the letter 'x' between the number):\n\n`rdesktop -u {{username}} -p {{password}} -g 1366x768 {{host:port}}`\n\n- Connect to a remote computer using domain user:\n\n`rdesktop -u {{username}} -p {{password}} -d {{domainname}} {{host:port}}`\n\n- Use the 16 bit color (speed up):\n\n`rdesktop -u {{username}} -p {{password}} -a 16 {{host:port}}`\n"
 },
 {
   "command": "updatedb",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# updatedb\n\n> Create or update the database used by `locate`.\n> It is usually run daily by cron.\n\n- Refresh database content:\n\n`sudo updatedb`\n\n- Display file names as soon as they are found:\n\n`sudo updatedb --verbose`\n"
 },
 {
   "command": "silentcast",
   "doc_url": "https://github.com/colinkeenan/silentcast",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - colinkeenan/silentcast: Create silent mkv screencast and animated gif.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncolinkeenan\n\n/\n\nsilentcast\n\n\n\n\n\n\n\n    Watch\n \n      16\n    \n\n\n\n\n      Star\n\n\n      488\n    \n\n\n\n\n          Fork\n\n\n        20\n      \n\n\n\n\n\n        Create silent mkv screencast and animated gif.\n      \n\n\n\n            GPL-3.0 License\n        \n\n\n\n\n488\n        stars\n \n\n20\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n12\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nbranches\n\n\n\n23\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n \n \nGit stats\n\n\n\n\n\n300\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\nlib\n\n\n\ngit add . and figured out how to move on to next temptoanim function …\n\n\n\nApr 13, 2017\n\n\n\n\n\n\n\nscpkg\n\n\n\nmore reorganizing files and wrote install and uninstall scripts along…\n\n\n\nApr 16, 2017\n\n\n\n\n\n\n\nsrc\n\n\n\nprevious \"more sensible\" algorithm failed due to poor precision so fi…\n\n\n\nOct 28, 2017\n\n\n\n\n\n\n\n.gitignore\n\n\n\nmore reorganizing files and wrote install and uninstall scripts along…\n\n\n\nApr 16, 2017\n\n\n\n\n\n\n\nCOPYING\n\n\n\ngit add . and figured out how to move on to next temptoanim function …\n\n\n\nApr 13, 2017\n\n\n\n\n\n\n\nREADME.md\n\n\n\nKDE Plasma 5 workaround explained in README.md\n\n\n\nSep 1, 2017\n\n\n\n\n\n\n\nSilencast_v3.02_Screenshot.png\n\n\n\nforgot to add screenshot png\n\n\n\nApr 17, 2017\n\n\n\n\n\n\n\ninstall\n\n\n\nremoved bashisms from install and uninstall scripts\n\n\n\nApr 17, 2017\n\n\n\n\n\n\n\nmakefile\n\n\n\nmore reorganizing files and wrote install and uninstall scripts along…\n\n\n\nApr 16, 2017\n\n\n\n\n\n\n\nsilentcast.svg\n\n\n\nmore reorganizing files and wrote install and uninstall scripts along…\n\n\n\nApr 16, 2017\n\n\n\n\n\n\n\ntags\n\n\n\nmore reorganizing files and wrote install and uninstall scripts along…\n\n\n\nApr 16, 2017\n\n\n\n\n\n\n\nuninstall\n\n\n\nremoved bashisms from install and uninstall scripts\n\n\n\nApr 17, 2017\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\nSilentcast\nThis is not a full README (yet) for v3.0 which has a completely different GUI than previous versions.\nIt's more intuitive than previous versions and explains itself well enough.\nIt does not support running multiple copies of itself, however, and so cannot record itself the way that\nthe previous version did: bad things will happen if you try to run Silentcast v3.0 while it is already running.\nIf you make the mistake of trying to run Silentcast v3.0 while it is already running, make sure you run\npkill -f ffmpeg\n\nwhen it closes (crashes) so that silentcast/temp.mkv. doesn't take over your hard drive. Due to a bug that\nshows on some systems where silencast is unable to kill the ffmpeg process it spawned directly, v3.02 is currently\nalso killing all instances of ffmpeg so that it's not possible to get a full recording of silentcast in action\nusing ffmpeg either.\nThis problem will be fixed in a future release, but other bugs will probably be fixed first because not many\npeople need to record Silentcast in action.\nWhen ran, you will instantly get a green rectangle surrounding the active window. If that's what you wanted to\nrecord, just press Return to start and then click the minimized Silentcast icon to stop. Here is a screenshot\nshowing the F1->Rectangle Preferences dialog and green rectangle.\n\nDependencies\n\ngtk3\nffmpeg\nimagemagick\n\nTiling Window Managers\nStarting with v3.05, it is possible to use Silentcast in Tiling Window Managers that can't iconify a window and don't show any windows behind a maximaized window. To make it work, you will have to define 3 new keybindings. The first will make Silentcast a floating window that fills the display. The second will \"iconify\" Silentcast by putting it on an empty workspace (named Silentcast if possible) and putting it back to fullscreen instead of floating (this will trigger Silentcast to begin recording). The third will \"deiconify\" Silentcast by putting back on the original workspace as a floating window that fills the display. This has only been tested in i3wm. I will provide keybindings for other tiling window managers if an issue is opened for it. The following keybindings should be added to ~/.config/i3/config:\n# Silentcast Workaround (because i3wm can't iconify)\n#\n# After copy and pasting this, make sure to change the display size at the end\n# of the first definition ($enable_floating_fullscreen) to match your display size\n#\n# Use these keybindings as follows:\n#   1. Start Silentcast\n#   2. $mod+Shift+s to make Silentcast a floating window filling the display \n#      (which allows other windows to be seen below it)\n#   3. Select the region to be recorded using standard Silentcast controls\n#   4. $mod+z to \"iconify\" silentcast to start recording (actually putting it on a\n#      workspace named Silencast and making it fullscreen again instead of floating)\n#   5. When done recording, $mod+x to \"deiconify\" Silentcast which will stop\n#      recording and move on to the next step as usual.\n#   \n\n# define what fullscreen means for floating window - have to manually set the display size\nset $enable_floating_fullscreen  border none,fullscreen disable,floating enable,move absolute position 0 0,resize set 1920 1080\n\n# more definitions (i3wm doesn't seem to support using $variables in definitions of other $variables)\nset $work_in_temp move container to workspace Silentcast,workspace Silentcast\n\nset $return_from_temp move container to workspace back_and_forth,workspace back_and_forth\n\nset $iconify move container to workspace Silentcast,workspace Silentcast,floating disable,fullscreen enable,workspace back_and_forth\n\nset $deiconify workspace Silentcast,border none,fullscreen disable,floating enable,move absolute position 0 0,resize set 1920 1080,move container to workspace back_and_forth,workspace back_and_forth\n\n# change from fullscreen to floating_fullscreen because iw3m won't show other windows under it otherwise\nbindsym $mod+Shift+s [class=\"Silentcast\"] $work_in_temp,$enable_floating_fullscreen,$return_from_temp\n\n# \"iconify\"\nbindsym $mod+z [class=\"Silentcast\"] $iconify\n\n# \"deiconify\" to stop ffmpeg and continue\nbindsym $mod+x [class=\"Silentcast\"] $deiconify\n\n#\n# End of Silentcast Workaround\n#\n\nKDE Plasma 5 - How to stop recording using the keyboard\nPlasma 5 previews minimized windows when the mouse is over the icon which is a problem when you're trying to stop a Silentcast recording. To stop Silentcast in Plasma 5 without having to click the minimized icon, define the following keyboard shortcut: System Settings -> (Workspace) Shortcuts -> Global Shortcuts -> KWin -> Setup Window Shortcut -> Global -> Custom and put whatever keys are available for that. I set it to Meta+Space.\nFor example, if Setup Window Shortcut is set to Meta+Space, and you want to stop the recording with Alt+A, then here are the steps to stopping a Silentcast recording without using the mouse:\n\nStart Silentcast\nMeta+Space\nClick in the \"Press shortcut\" field in the dialog that pops up in the top left corner\nAlt+A\nClick on the \"OK\" button in that dialog\nSelect the area to be recorded and press Return on your keyboard to start the recording\nAlt+A to stop the recording\nCtrl+Alt+A to Activate Window Demanding Attention (which is the Silentcast Edit Pngs dialog at this point)\n. . .\n\nSomething similar can probably be done on other desktops. I will look into it if an issue is raised.\nManual Installation\n\nInstall the dependencies, Download Latest Release of Silentcast from github.com, and extract. If extracted in your Downloads directory, this is how you would complete the installation:\n\n$ cd ~/Downloads/silentcast-3.0\n$ make\n$ sudo ./install\n\nYou should then find silentcast in your launcher. You can uninstall it with sudo ./uninstall in the same directory.\nYou can also test what these scripts do passing a destination directory (that doesn't need to exist already).\nFor example, install to test, use tree to see what it did, and then uninstall from test. (You will probably need to install tree.)\n$ ./install test\n$ tree test\ntest\n├── etc\n│   ├── silentcast.conf\n│   └── silentcast_presets\n└── usr\n    ├── bin\n    │   └── silentcast\n    └── share\n        ├── applications\n        │   └── silentcast.desktop\n        ├── doc\n        │   └── silentcast\n        │       └── README.md\n        ├── icons\n        │   └── hicolor\n        │       ├── 128x128\n        │       │   └── apps\n        │       │       └── silentcast.png\n        │       ├── 24x24\n        │       │   └── apps\n        │       │       └── silentcast.png\n        │       ├── 256x256\n        │       │   └── apps\n        │       │       └── silentcast.png\n        │       ├── 32x32\n        │       │   └── apps\n        │       │       └── silentcast.png\n        │       ├── 48x48\n        │       │   └── apps\n        │       │       └── silentcast.png\n        │       └── 64x64\n        │           └── apps\n        │               └── silentcast.png\n        └── licenses\n            └── COPYING\n\n22 directories, 12 files\n$./uinstall test\n$tree test\ntest\n├── etc\n└── usr\n    ├── bin\n    └── share\n        ├── applications\n        ├── doc\n        ├── icons\n        │   └── hicolor\n        │       ├── 128x128\n        │       │   └── apps\n        │       ├── 24x24\n        │       │   └── apps\n        │       ├── 256x256\n        │       │   └── apps\n        │       ├── 32x32\n        │       │   └── apps\n        │       ├── 48x48\n        │       │   └── apps\n        │       └── 64x64\n        │           └── apps\n        └── licenses\n\n21 directories, 0 files\n\nNotice that ./uninstall test deleted all the files, but only deleted the one subdirectory named silentcast. Don't forget to specify test when uninstalling, and don't use sudo when not doing a system-wide install or uninstall.\n\n\n\n\n\n\n\n\nAbout\n\n      Create silent mkv screencast and animated gif.\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-3.0 License\n    \n\n\n\n\n\n\n\n    Releases\n      23\n\n\n\n\n\nv3.07 bug fixes\n\n          Latest\n \nOct 27, 2017\n\n \n\n        + 22 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\nC\n97.6%\n\n\n\n\n\nShell\n1.9%\n\n\n\n\n\nMakefile\n0.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# silentcast\n\n> Silent screencast creator. Saves in `.mkv` and animated gif formats.\n> More information: <https://github.com/colinkeenan/silentcast>.\n\n- Launch silentcast:\n\n`silentcast`\n\n- Launch silentcast on a specific display:\n\n`silentcast --display={{display}}`\n"
 },
 {
   "command": "autorandr",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# autorandr\n\n> Automatically change screen layout.\n\n- Save the current screen layout:\n\n`autorandr -s {{profile_name}}`\n\n- Show the saved profiles:\n\n`autorandr`\n\n- Change the profile:\n\n`autorandr -l {{profile_name}}`\n\n- Set the default profile:\n\n`autorandr -d {{profile_name}}`\n"
 },
 {
   "command": "paccache",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# paccache\n\n> A pacman cache cleaning utility.\n\n- Remove all but the 3 most recent package versions from the pacman cache:\n\n`paccache -r`\n\n- Set the number of package versions to keep:\n\n`paccache -rk {{num_versions}}`\n\n- Perform a dry-run and show the number of candidate packages for deletion:\n\n`paccache -d`\n\n- Move candidate packages to a directory instead of deleting them:\n\n`paccache -m {{path/to/directory}}`\n"
 },
 {
   "command": "steghide",
   "doc_url": "https://github.com/StefanoDeVuono/steghide",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - StefanoDeVuono/steghide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStefanoDeVuono\n\n/\n\nsteghide\n\n\n\n\n\n\n\n    Watch\n \n      7\n    \n\n\n\n\n      Star\n\n\n      159\n    \n\n\n\n\n          Fork\n\n\n        30\n      \n\n\n\n\n\n\n\n            GPL-2.0 License\n        \n\n\n\n\n159\n        stars\n \n\n30\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n4\n \n\n\n\nPull requests\n1\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n0\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nStefanoDeVuono\n\nfirst commit\n\n\n\n…\n\n\n\n8df774d\n\nOct 25, 2013\n\n\n\n\n\nfirst commit\n\n\n8df774d\n\n\n\nGit stats\n\n\n\n\n\n1\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\ndoc\n\n\n \n\n\n \n\n\n\n\n\n\n\nintl\n\n\n \n\n\n \n\n\n\n\n\n\n\nm4\n\n\n \n\n\n \n\n\n\n\n\n\n\npo\n\n\n \n\n\n \n\n\n\n\n\n\n\nsrc\n\n\n \n\n\n \n\n\n\n\n\n\n\ntests\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\nABOUT-NLS\n\n\n \n\n\n \n\n\n\n\n\n\n\nBUGS\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING\n\n\n \n\n\n \n\n\n\n\n\n\n\nCREDITS\n\n\n \n\n\n \n\n\n\n\n\n\n\nHISTORY\n\n\n \n\n\n \n\n\n\n\n\n\n\nINSTALL\n\n\n \n\n\n \n\n\n\n\n\n\n\nLEAME\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile.am\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME\n\n\n \n\n\n \n\n\n\n\n\n\n\nTODO\n\n\n \n\n\n \n\n\n\n\n\n\n\naclocal.m4\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.guess\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.h.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.rpath\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.sub\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfigure\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfigure.in\n\n\n \n\n\n \n\n\n\n\n\n\n\ndepcomp\n\n\n \n\n\n \n\n\n\n\n\n\n\ninstall-sh\n\n\n \n\n\n \n\n\n\n\n\n\n\nmissing\n\n\n \n\n\n \n\n\n\n\n\n\n\nmkinstalldirs\n\n\n \n\n\n \n\n\n\n\n\n\n\nsteghide.doxygen.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nsteghide.spec.in\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README\n      \n\n\nIntroduction :\n==============\n\nSteghide is a steganography program that is able to hide data in various kinds\nof image- and audio-files. The color- respectivly sample-frequencies are not\nchanged thus making the embedding resistant against first-order statistical\ntests.\n\nThe current version of steghide is 0.5.1\n\nFeatures:\n*) compression of embedded data\n*) encryption of embedded data\n*) embedding of a checksum to verify the integrity of the extraced data\n*) support for JPEG, BMP, WAV and AU files\n\nSteganography :\n===============\n\nSteganography literally means covered writing. Its goal is to hide the fact\nthat communication is taking place. This is often achieved by using a (rather\nlarge) cover file and embedding the (rather short) secret message into this\nfile. The result is a innocuous looking file (the stego file) that contains\nthe secret message.\n\nCompilation and Installation :\n==============================\n\nDependencies :\n--------------\nYou should have the following libraries installed to use steghide.\n\n* libmhash\n  A library that provides various hash algorithms and cryptographic key\n  generation algorithms. Steghide needs this library to convert a passphrase\n  into a form that can be used as input for cryptographic and steganographic\n  algorithms.\n  Available at: http://mhash.sourceforge.net/\n\n* libmcrypt  \n  A library that provides a lot of symmetric encryption algorithms. If you\n  compile steghide without libmcrypt you will not be able to use steghide to\n  encrypt data before embedding nor to extract encrypted data (even if you know\n  the correct passphrase).\n  Available at: http://mcrypt.sourceforge.net/\n\n* libjpeg\n  A library implementing jpeg image compression. Without this library you will\n  not be able to embed data in jpeg files nor to extract data from jpeg files.\n  Available at: http://www.ijg.org/\n\n* zlib\n  A lossless data compression library. If you compile steghide without having\n  this library installed you will not be able to use steghide to compress data\n  before embedding nor to extract compressed data from a stego-file.\n  Available at: http://www.gzip.org/zlib/\n\nLibmhash is absolutely required to compile steghide. While you can compile it\nwithout the other libraries they are highly recommended as major functionality\nwill not be available without them.\n\nLinux / Unix :\n--------------\nAfter unpacking the source distribution, enter the following commands:\n\n1) ./configure \n2) make\n3) make check\n4) make install (as root)\n\nFor more information see the generic installation instructions in the file\nINSTALL that came with the distribution.\n\nIf any of these commands fails, please send a mail to the steghide development\nmailing list (steghide-devel@lists.sourceforge.net) describing the error.\n \nWindows :\n---------\nThe easiest way is to download the precompiled binary (including Windows\nversions of the necessary libraries) from the steghide website at:\nhttp://steghide.sourceforge.net/index.php\n\nIf you want to compile the sources yourself you need a C++ compiler. How you\nneed to compile the source code depends on the compiler you are using: Please\nconsult your compiler's documentation.\n\nSteghide can be compiled with gcc in the cygwin environment\n(http://www.cygwin.com/) which is a unix emulation layer for Windows using the\nprocedure mentioned above for the Linux/Unix compilation.\n\nQuick-Start :\n=============\n\nHere are some examples of how steghide can be used. Take a look at these to get\na first impression. If you want more detailed information please read the\nmanpage.\n\nThe basic usage is as follows:\n\n  $ steghide embed -cf picture.jpg -ef secret.txt\n  Enter passphrase:\n  Re-Enter passphrase:\n  embedding \"secret.txt\" in \"picture.jpg\"... done\n\nThis command will embed the file secret.txt in the cover file picture.jpg.\n\nAfter you have embedded your secret data as shown above you can send the file\npicture.jpg to the person who should receive the secret message. The receiver\nhas to use steghide in the following way:\n\n  $ steghide extract -sf picture.jpg\n  Enter passphrase:\n  wrote extracted data to \"secret.txt\".\n\nIf the supplied passphrase is correct, the contents of the original file\nsecret.txt will be extracted from the stego file picture.jpg and saved\nin the current directory.\n\nIf you have received a file that contains embedded data and you want to get\nsome information about it before extracting it, use the info command:\n\n  $ steghide info received_file.wav\n  \"received_file.wav\":\n    format: wave audio, PCM encoding\n    capacity: 3.5 KB\n  Try to get information about embedded data ? (y/n) y\n  Enter passphrase:\n    embedded file \"secret.txt\":\n      size: 1.6 KB\n      encrypted: rijndael-128, cbc\n      compressed: yes\n\nAfter printing some general information about the stego file (format, capacity) you will be\nasked if steghide should try to get information about the embedded data. If you answer with\nyes you have to supply a passphrase. Steghide will then try to extract the embedded data\nwith that passphrase and - if it succeeds - print some information about it.\n\nContact :\n=========\n\nWebsite :\n---------\nYou can get the latest version of steghide as well as some additional\ninformation and documentation from the steghide website at:\nhttp://steghide.sourceforge.net/\n\nMailing Lists :\n---------------\nIf you have found a bug or if you have questions, comments, suggestions, etc.\nplease send a mail to the development mailing list:\nsteghide-devel@lists.sourceforge.net\nTo receive mails sent to this list, subscribe to it at:\nhttp://lists.sourceforge.net/lists/listinfo/steghide-devel\n\nIf you want to be informed, when a new version of steghide is released please\nsubscribe to the steghide announcement mailing list at:\nhttp://lists.sourceforge.net/lists/listinfo/steghide-announce\n\nAnonymous CVS access :\n----------------------\n\nYou can access the most recent development source code via anonymous cvs. Just\ntype the following lines:\n\n$ cvs -d:pserver:anonymous@cvs.steghide.sourceforge.net:/cvsroot/steghide login\nCVS password:  [ Hit RETURN here ]\n\n$ cvs -z3 -d:pserver:anonymous@cvs.steghide.sourceforge.net:/cvsroot/steghide co steghide\n\nYou can also browse the cvs repository on the web:\nhttp://cvs.sourceforge.net/cgi-bin/viewcvs.cgi/steghide/\n\nAuthor :\n--------\nYou can contact me (Stefan Hetzl) via e-mail: shetzl@chello.at\n\n\n\n\n\n\n\n\nAbout\n\n      No description, website, or topics provided.\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-2.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\nNo releases published\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\nC++\n68.5%\n\n\n\n\n\nC\n27.3%\n\n\n\n\n\nShell\n3.4%\n\n\n\n\n\nPerl\n0.8%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# steghide\n\n> Steganography tool for JPEG, BMP, WAV and AU file formats.\n> More information: <https://github.com/StefanoDeVuono/steghide>.\n\n- Embed data in a PNG image, prompting for a passphrase:\n\n`steghide embed --coverfile {{path/to/image.png}} --embedfile {{path/to/data.txt}}`\n\n- Extract data from a WAV audio file:\n\n`steghide extract --stegofile {{path/to/sound.wav}}`\n\n- Display file information, trying to detect an embedded file:\n\n`steghide info {{path/to/file.jpg}}`\n\n- Embed data in a JPEG image, using maximum compression:\n\n`steghide embed --coverfile {{path/to/image.jpg}} --embedfile {{path/to/data.txt}} --compress {{9}}`\n\n- Get the list of supported encryption algorithms and modes:\n\n`steghide encinfo`\n\n- Embed encrypted data in a JPEG image, e.g. with Blowfish in CBC mode:\n\n`steghide embed --coverfile {{path/to/image.jpg}} --embedfile {{path/to/data.txt}} --encryption {{blowfish|...}} {{cbc|...}}`\n"
 },
 {
   "command": "light",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# light\n\n> CLI to control the backlight of your screen.\n\n- Get the current backlight value in percent:\n\n`light`\n\n- Set the backlight value to 50 percent:\n\n`light -S {{50}}`\n\n- Reduce 20 percent from the current backlight value:\n\n`light -U {{20}}`\n\n- Add 20 percent to the current backlight value:\n\n`light -A {{20}}`\n"
 },
 {
   "command": "fc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# fc\n\n> Open the most recent command and edit it.\n\n- Open in the default system editor:\n\n`fc`\n\n- Specify an editor to open with:\n\n`fc -e {{'emacs'}}`\n\n- List recent commands from history:\n\n`fc -l`\n"
 },
 {
   "command": "nmcli-device",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# nmcli device\n\n> Hardware device management with NetworkManager.\n\n- Print the statuses of all network interfaces:\n\n`nmcli device status`\n\n- Print the available Wi-Fi access points:\n\n`nmcli device wifi`\n\n- Connect to the Wi-Fi network with a specified name and password:\n\n`nmcli device wifi connect {{ssid}} password {{password}}`\n"
 },
 {
   "command": "dget",
   "doc_url": "https://manpages.debian.org/dget",
   "doc_text": "\n\n\n\ndget(1) — devscripts — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / devscripts\n     \n     \n     \n     / dget(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nCONFIGURATION VARIABLES\n\n\nEXAMPLES\n\n\nBUGS AND COMPATIBILITY\n\n\nAUTHOR\n\n\nSEE ALSO\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.19.5+deb10u1\n\n\nbuster-backports 2.20.4~bpo10+1\n\n\ntesting 2.20.4\n\n\nunstable 2.20.4\n\n\n\n\n\n\nother languages\n\n\n\n\nDeutsch\n\n\nEnglish\n\n\nfrançais\n\n\n\n\n\n\nScroll to navigation\n\n\n\nDGET(1)\n \nDGET(1)\n\n\n\n\n\nNAME¶\ndget -- Download Debian source and binary packages\n\n\nSYNOPSIS¶\n\ndget [options] URL ...\n\ndget [options] [--all]\n    package[=version] ...\n\n\n\n\nDESCRIPTION¶\ndget downloads Debian packages. In the first form, dget fetches\n  the requested URLs. If this is a .dsc or .changes file, then dget acts\n  as a source-package aware form of wget: it also fetches any files\n  referenced in the .dsc/.changes file. The downloaded source is then checked\n  with dscverify and, if successful, unpacked by dpkg-source.\nIn the second form, dget downloads a binary package\n    (i.e., a .deb file) from the Debian mirror configured in\n    /etc/apt/sources.list(.d). Unlike apt-get install -d, it does not\n    require root privileges, writes to the current directory, and does not\n    download dependencies. If a version number is specified, this version of the\n    package is requested. With --all, the list of all binaries for the\n    source package package is extracted from the output of\n    \"apt-cache showsrc package\".\nIn both cases dget is capable of getting several packages and/or\n    URLs at once.\n(Note that .udeb packages used by debian-installer are\n    located in separate packages files from .deb packages. In order to\n    use .udebs with dget, you will need to have configured\n    apt to use a packages file for\n    component/debian-installer).\nBefore downloading files listed in .dsc and .changes files, and\n    before downloading binary packages, dget checks to see whether any of\n    these files already exist. If they do, then their md5sums are compared to\n    avoid downloading them again unnecessarily. dget also looks for\n    matching files in /var/cache/apt/archives and directories given by\n    the --path option or specified in the configuration files (see\n    below). Finally, if downloading (.orig).tar.gz or .diff.gz files fails, dget\n    consults apt-get source --print-uris. Download backends used are\n    curl and wget, looked for in that order.\ndget was written to make it easier to retrieve source\n    packages from the web for sponsor uploads. For checking the package with\n    debdiff, the last binary version is available via dget\npackage, the last source version via apt-get source\npackage.\n\n\nOPTIONS¶\n\n-a, --all\nInterpret package as a source package name, and download all\n      binaries as found in the output of \"apt-cache showsrc\n      package\". If package is arch-qualified, then only\n      binary packages which are \"Arch: all\", \"Arch: any\", or\n      \"Arch: $arch\" will be downloaded.\n-b, --backup\nMove files that would be overwritten to ./backup.\n-q, --quiet\nSuppress wget/curl non-error output.\n-d, --download-only\nDo not run dpkg-source -x on the downloaded source package. This\n      can only be used with the first method of calling dget.\n-x, --extract\nRun dpkg-source -x on the downloaded source package to unpack it.\n      This option is the default and can only be used with the first method of\n      calling dget.\n-u, --allow-unauthenticated\nDo not attempt to verify the integrity of downloaded source packages using\n      dscverify.\n--build\nRun dpkg-buildpackage -b -uc on the downloaded source package.\n--path DIR[:DIR ...]\nIn addition to /var/cache/apt/archives, dget uses the\n      colon-separated list given as argument to --path to find files with\n      a matching md5sum. For example: \"--path\n      /srv/pbuilder/result:/home/cb/UploadQueue\". If DIR is empty (i.e.,\n      \"--path ''\" is specified), then any previously listed\n      directories or directories specified in the configuration files will be\n      ignored. This option may be specified multiple times, and all of the\n      directories listed will be searched; hence, the above example could have\n      been written as: \"--path /srv/pbuilder/result --path\n      /home/cb/UploadQueue\".\n--insecure\nAllow SSL connections to untrusted hosts.\n--no-cache\nBypass server-side HTTP caches by sending a Pragma: no-cache\n      header.\n-h, --help\nShow a help message.\n-V, --version\nShow version information.\n\n\n\nCONFIGURATION VARIABLES¶\nThe two configuration files /etc/devscripts.conf and ~/.devscripts\n  are sourced by a shell in that order to set configuration variables. Command\n  line options can be used to override configuration file settings. Environment\n  variable settings are ignored for this purpose. The currently recognised\n  variable is:\n\nDGET_PATH\nThis can be set to a colon-separated list of directories in which to\n      search for files in addition to the default\n      /var/cache/apt/archives. It has the same effect as the\n      --path command line option. It is not set by default.\nDGET_UNPACK\nSet to 'no' to disable extracting downloaded source packages. Default is\n      'yes'.\nDGET_VERIFY\nSet to 'no' to disable checking signatures of downloaded source packages.\n      Default is 'yes'.\n\n\n\nEXAMPLES¶\nDownload all .deb files for the previous version of a package and run\n  debdiff on them:\n\n  dget --all mypackage=1.2-1\n  debdiff --from *_1.2-1_*.deb --to *_1.2-2_*.deb\n\n\n\nBUGS AND COMPATIBILITY¶\ndget package should be implemented in apt-get install -d.\nBefore devscripts version 2.10.17, the default was not to extract\n    the downloaded source. Set DGET_UNPACK=no to revert to the old\n  behaviour.\n\n\nAUTHOR¶\nThis program is Copyright (C) 2005-2013 by Christoph Berg\n  <myon@debian.org>. Modifications are Copyright (C) 2005-06 by Julian\n  Gilbey <jdg@debian.org>.\nThis program is licensed under the terms of the GPL, either\n    version 2 of the License, or (at your option) any later version.\n\n\nSEE ALSO¶\napt-get(1), curl(1), debcheckout(1), debdiff(1),\n  dpkg-source(1), wget(1)\n\n\n\n\n2019-08-04\nDebian Utilities\n\n\n\n\n\n\n\n\n\nSource file:\n\n\ndget.1.en.gz (from devscripts 2.19.5+deb10u1)\n\n\n\n\nSource last updated:\n\n\n2019-08-04T21:15:44Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:08:51Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# dget\n\n> Download Debian packages.\n> More information: <https://manpages.debian.org/dget>.\n\n- Download a binary package:\n\n`dget {{package_name}}`\n\n- Download and extract a package source from its .dsc file:\n\n`dget {{http://deb.debian.org/debian/pool/main/h/haskell-tldr/haskell-tldr_0.4.0-2.dsc}}`\n\n- Download a package source tarball from its .dsc file but don't extract it:\n\n`dget -d {{http://deb.debian.org/debian/pool/main/h/haskell-tldr/haskell-tldr_0.4.0-2.dsc}}`\n"
 },
 {
   "command": "rename",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nRENAME(2)\t\t    BSD System Calls Manual\t\t     RENAME(2)\n\nNAME\n     rename, renameat, renamex_np, renameatx_np -- change the name of a file\n\nSYNOPSIS\n     #include <stdio.h>\n\n     int\n     rename(const char *old, const char *new);\n\n     int\n     renameat(int fromfd, const char *from, int tofd, const char *to);\n\n     int\n     renamex_np(const char *from, const char *to, unsigned int flags);\n\n     int\n     renameatx_np(int fromfd, const char *from, int tofd, const char *to,\n\t unsigned int flags);\n\nDESCRIPTION\n     The rename() system call causes the link named old to be renamed as new.\n     If new exists, it is first removed.  Both old and new must be of the same\n     type (that is, both must be either directories or non-directories) and\n     must reside on the same file system.\n\n     The rename() system call guarantees that an instance of new will always\n     exist, even if the system should crash in the middle of the operation.\n\n     If the final component of old is a symbolic link, the symbolic link is\n     renamed, not the file or directory to which it points.\n\n     The renameat() system call is equivalent to rename() except in the case\n     where either from or to specifies a relative path.  If from is a relative\n     path, the file to be renamed is located relative to the directory associ-\n     ated with the file descriptor fromfd instead of the current working\n     directory.  If the to is a relative path, the same happens only relative\n     to the directory associated with tofd.  If the renameat() is passed the\n     special value AT_FDCWD in the fromfd or tofd parameter, the current work-\n     ing directory is used in the determination of the file for the respective\n     path parameter.\n\n     The renamex_np() and renameatx_np() system calls are similar to their\n     counterparts except that they take a flags argument.  Values for flags\n     are constructed with below bits set:\n\n\t   RENAME_SWAP\t On file systems that support it (see getattrlist(2)\n\t\t\t VOL_CAP_INT_RENAME_SWAP), it will cause the source\n\t\t\t and target to be atomically swapped.  Source and tar-\n\t\t\t get need not be of the same type, i.e. it is possible\n\t\t\t to swap a file with a directory.  EINVAL is returned\n\t\t\t in case of bitwise-inclusive OR with RENAME_EXCL.\n\n\t   RENAME_EXCL\t On file systems that support it (see getattrlist(2)\n\t\t\t VOL_CAP_INT_RENAME_EXCL), it will cause EEXIST to be\n\t\t\t returned if the destination already exists. EINVAL is\n\t\t\t returned in case of bitwise-inclusive OR with\n\t\t\t RENAME_SWAP.\n\nCAVEATS\n     The system can deadlock if a loop is present in the file system graph.\n     This loop takes the form of an entry in directory `a', say `a/foo', being\n     a hard link to directory `b', and an entry in directory `b', say `b/bar',\n     being a hard link to directory `a'.  When such a loop exists and two sep-\n     arate processes attempt to perform `rename a/foo b/bar' and `rename b/bar\n     a/foo', respectively, the system may deadlock attempting to lock both\n     directories for modification.\n\n     Whether or not hard links to directories are supported is specific to the\n     underlying filesystem implementation.\n\n     It is recommended that any hard links to directories in an underlying\n     filesystem should be replaced by symbolic links by the system administra-\n     tor to avoid the possibility of deadlocks.\n\n     Moving or renaming a file or directory into a directory with inheritable\n     ACLs does not result in ACLs being set on the file or directory. Use\n     acl(3) in conjunction with rename() to set ACLs on the file or directory.\n\nRETURN VALUES\n     A 0 value is returned if the operation succeeds, otherwise rename()\n     returns -1 and the global variable errno indicates the reason for the\n     failure.\n\nERRORS\n     The rename() system call will fail and neither of the argument files will\n     be affected if:\n\n     [EACCES]\t\tA component of either path prefix denies search per-\n\t\t\tmission.\n\n     [EACCES]\t\tThe requested operation requires writing in a direc-\n\t\t\ttory (e.g., new, new/.., or old/..) whose modes disal-\n\t\t\tlow this.\n\n     [EDQUOT]\t\tThe directory in which the entry for the new name is\n\t\t\tbeing placed cannot be extended because the user's\n\t\t\tquota of disk blocks on the file system containing the\n\t\t\tdirectory has been exhausted.\n\n     [EEXIST]\t\tflags has RENAME_EXCL set but new already exists.\n\n     [EFAULT]\t\tPath points outside the process's allocated address\n\t\t\tspace.\n\n     [EINVAL]\t\tOld is a parent directory of new, or an attempt is\n\t\t\tmade to rename `.' or `..'.  If RENAME_SWAP is used,\n\t\t\tthen EINVAL will also be returned if new is a parent\n\t\t\tdirectory of old.  If both RENAME_SWAP and RENAME_EXCL\n\t\t\tbits are set in flags, then EINVAL will be returned.\n\n     [EINVAL]\t\tflags has an invalid value.\n\n     [EIO]\t\tAn I/O error occurs while making or updating a direc-\n\t\t\ttory entry.\n\n     [EISDIR]\t\tnew is a directory, but old is not a directory.\n\n     [ELOOP]\t\tToo many symbolic links are encountered in translating\n\t\t\teither pathname.  This is taken to be indicative of a\n\t\t\tlooping symbolic link.\n\n     [ENAMETOOLONG]\tA component of a pathname exceeds {NAME_MAX} charac-\n\t\t\tters, or an entire path name exceeds {PATH_MAX} char-\n\t\t\tacters.\n\n     [ENOENT]\t\tA component of the old path does not exist, or a path\n\t\t\tprefix of new does not exist.\n\n     [ENOENT]\t\tflags has RENAME_SWAP set but new does not exist.\n\n     [ENOSPC]\t\tThe directory in which the entry for the new name is\n\t\t\tbeing placed cannot be extended because there is no\n\t\t\tspace left on the file system containing the direc-\n\t\t\ttory.\n\n     [ENOTDIR]\t\tA component of either path prefix is not a directory.\n\n     [ENOTDIR]\t\told is a directory, but new is not a directory.\n\n     [ENOTEMPTY]\tNew is a directory and is not empty.\n\n     [ENOTSUP]\t\tflags has a value that is not supported by the file\n\t\t\tsystem.\n\n     [EPERM]\t\tThe directory containing old is marked sticky, and\n\t\t\tneither the containing directory nor old are owned by\n\t\t\tthe effective user ID.\n\n     [EPERM]\t\tThe new file exists, the directory containing new is\n\t\t\tmarked sticky, and neither the containing directory\n\t\t\tnor new are owned by the effective user ID.\n\n     [EROFS]\t\tThe requested link requires writing in a directory on\n\t\t\ta read-only file system.\n\n     [EXDEV]\t\tThe link named by new and the file named by old are on\n\t\t\tdifferent logical devices (file systems).  Note that\n\t\t\tthis error code will not be returned if the implemen-\n\t\t\ttation permits cross-device links.\n\n     The renameat() and renameatx_np() calls may also fail with:\n\n     [EBADF]\t\tThe from argument does not specify an absolute path\n\t\t\tand the fromfd argument is neither AT_FDCWD nor a\n\t\t\tvalid file descriptor open for searching, or the to\n\t\t\targument does not specify an absolute path and the\n\t\t\ttofd argument is neither AT_FDCWD nor a valid file\n\t\t\tdescriptor open for searching.\n\n     [ENOTDIR]\t\tThe from argument is not an absolute path and fromfd\n\t\t\tis neither AT_FDCWD nor a file descriptor associated\n\t\t\twith a directory, or the to argument is not an abso-\n\t\t\tlute path and tofd is neither AT_FDCWD nor a file\n\t\t\tdescriptor associated with a directory.\n\nCONFORMANCE\n     The restriction on renaming a directory whose permissions disallow writ-\n     ing is based on the fact that UFS directories contain a \"..\" entry.  If\n     renaming a directory would move it to another parent directory, this\n     entry needs to be changed.\n\n     This restriction has been generalized to disallow renaming of any write-\n     disabled directory, even when this would not require a change to the \"..\"\n     entry.  For consistency, HFS+ directories emulate this behavior.\n\nSEE ALSO\n     open(2), symlink(7)\n\nSTANDARDS\n     The rename() function conforms to IEEE Std 1003.1-1988 (``POSIX.1'').\n     The renameat() system call is expected to conform to POSIX.1-2008 .\n\n4.2 Berkeley Distribution     September 18, 2008     4.2 Berkeley Distribution\n",
   "tldr_summary": "# rename\n\n> Rename multiple files.\n> NOTE: this page refers to the command from the `util-linux` package.\n> For the Perl version, see `file-rename` or `perl-rename`.\n> Warning: This command has no safeguards and will overwrite files without prompting.\n\n- Rename files using simple substitutions (substitute 'foo' with 'bar' wherever found):\n\n`rename {{foo}} {{bar}} {{*}}`\n\n- Dry-run - display which renames would occur without performing them:\n\n`rename -vn {{foo}} {{bar}} {{*}}`\n\n- Do not overwrite existing files:\n\n`rename -o {{foo}} {{bar}} {{*}}`\n\n- Change file extensions:\n\n`rename {{.ext}} {{.bak}} {{*.ext}}`\n\n- Prepend \"foo\" to all filenames in the current directory:\n\n`rename {{''}} {{'foo'}} {{*}}`\n\n- Rename a group of increasingly numbered files zero-padding the numbers up to 3 digits:\n\n`rename {{foo}} {{foo00}} {{foo?}} && rename {{foo}} {{foo0}} {{foo??}}`\n"
 },
 {
   "command": "arecord",
   "doc_url": "https://linux.die.net/man/1/arecord",
   "doc_text": "\n\narecord(1) - Linux man page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\narecord(1) - Linux man page\nName\narecord, aplay - command-line sound recorder and player for ALSA soundcard driver\nSynopsis\narecord [flags] [filename]\naplay [flags] [filename [filename]] ...\nDescription\n\n\n\n\n\narecord is a command-line soundfile recorder for the ALSA soundcard driver. It supports\nseveral file formats and multiple soundcards with multiple devices. If recording with interleaved mode samples the file is automatically split before the 2GB\nfilesize.\naplay is much the same, only it plays instead of recording. For supported soundfile formats, the sampling rate, bit depth, and so forth can be\nautomatically determined from the soundfile header.\nIf filename is not specified, the standard output or input is used. The aplay utility accepts multiple filenames.\nOptions\n\n-h, --help\nHelp: show syntax.\n--version\nPrint current version.\n-l, --list-devices\nList all soundcards and digital audio devices\n-L, --list-pcms\nList all PCMs defined\n-D, --device=NAME\nSelect PCM by name\n-q --quiet\nQuiet mode. Suppress messages (not sound :))\n-t, --file-type TYPE\nFile type (voc, wav, raw or au). If this parameter is omitted the WAVE format is used.\n-c, --channels=#\nThe number of channels. The default is one channel. Valid values are 1 through 32.\n-f --format=FORMAT\nSample format\nRecognized sample formats are: S8 U8 S16_LE S16_BE U16_LE U16_BE S24_LE S24_BE U24_LE U24_BE S32_LE S32_BE U32_LE U32_BE FLOAT_LE FLOAT_BE FLOAT64_LE\nFLOAT64_BE IEC958_SUBFRAME_LE IEC958_SUBFRAME_BE MU_LAW A_LAW IMA_ADPCM MPEG GSM SPECIAL S24_3LE S24_3BE U24_3LE U24_3BE S20_3LE S20_3BE U20_3LE U20_3BE\nS18_3LE S18_3BE U18_3LE\nSome of these may not be available on selected hardware\nThe available format shortcuts are:-f cd (16 bit little endian, 44100, stereo) [-f S16_LE -c2 -r44100]\n-f cdr (16 bit big endian, 44100, stereo) [-f S16_BE -c2 -f44100]\n-f dat (16 bit little endian, 48000, stereo) [-f S16_LE -c2 -r48000]\nIf no format is given U8 is used.\n-r, --rate=#<Hz>\nSampling rate in Hertz. The default rate is 8000 Hertz. If the value specified is less than 300, it is taken as the rate in kilohertz. Valid values are\n2000 through 192000 Hertz.\n-d, --duration=#\nInterrupt after # seconds. A value of zero means infinity. The default is zero, so if this option is omitted then the arecord process will run until it is\nkilled.\n-s, --sleep-min=#\nMin ticks to sleep. The default is not to sleep.\n-M, --mmap\nUse memory-mapped (mmap) I/O mode for the audio stream. If this option is not set, the read/write I/O mode will be used.\n-N, --nonblock\nOpen the audio device in non-blocking mode. If the device is busy the program will exit immediately. If this option is not set the program will block until\nthe audio device is available again.\n-F, --period-time=#\nDistance between interrupts is # microseconds. If no period time and no period size is given then a quarter of the buffer time is set.\n-B, --buffer-time=#\nBuffer duration is # microseconds If no buffer time and no buffer size is given then the maximal allowed buffer time but not more than 500ms is set.\n--period-size=#\nDistance between interrupts is # frames If no period size and no period time is given then a quarter of the buffer size is set.\n--buffer-size=#\nBuffer duration is # frames If no buffer time and no buffer size is given then the maximal allowed buffer time but not more than 500ms is set.\n-A, --avail-min=#\nMin available space for wakeup is # microseconds\n-R, --start-delay=#\nDelay for automatic PCM start is # microseconds (relative to buffer size if <= 0)\n-T, --stop-delay=#\nDelay for automatic PCM stop is # microseconds from xrun\n-v, --verbose\nShow PCM structure and setup. This option is accumulative. The VU meter is displayed when this is given twice or three times.\n-V, --vumeter=TYPE\nSpecifies the VU-meter type, either stereo or mono. The stereo VU-meter is available only for 2-channel stereo samples with interleaved\nformat.\n-I, --separate-channels\nOne file for each channel. This option disables max-file-time and use-strftime, and ignores SIGUSR1. The stereo VU meter is not available with separate\nchannels.\n-P\nPlayback. This is the default if the program is invoked by typing aplay.\n-C\nRecord. This is the default if the program is invoked by typing arecord.\n-i, --interactive\nAllow interactive operation via stdin. Currently only pause/resume via space or enter key is implemented.\n--disable-resample\nDisable automatic rate resample.\n--disable-channels\nDisable automatic channel conversions.\n--disable-format\nDisable automatic format conversions.\n--disable-softvol\nDisable software volume control (softvol).\n--test-position\nTest ring buffer position.\n--test-coef=<coef>\nTest coefficient for ring buffer position; default is 8. Expression for validation is: coef * (buffer_size / 2). Minimum value is 1.\n--test-nowait\nDo not wait for the ring buffer--eats the whole CPU.\n--max-file-time\nWhile recording, when the output file has been accumulating sound for this long, close it and open a new output file. Default is the maximum size supported\nby the file format: 2 GiB for WAV files. This option has no effect if --separate-channels is specified.\n--process-id-file <file name>\naplay writes its process ID here, so other programs can send signals to it.\n--use-strftime\nWhen recording, interpret %-codes in the file name parameter using the strftime facility whenever the output file is opened. The important strftime codes\nare: %Y is the year, %m month, %d day of the month, %H hour, %M minute and %S second. In addition, %v is the file number, starting at 1. When this option is\nspecified, intermediate directories for the output file are created automatically. This option has no effect if --separate-channels is specified.\n--dump-hw-params\nDump hw_params of the device preconfigured status to stderr. The dump lists capabilities of the selected device such as supported formats, sampling rates,\nnumbers of channels, period and buffer bytes/sizes/times. For raw device hw:X this option basically lists hardware capabilities of the soundcard.\n--fatal-errors\nDisables recovery attempts when errors (e.g. xrun) are encountered; the aplay process instead aborts immediately.\nSignals\nWhen recording, SIGINT, SIGTERM and SIGABRT will close the output file and exit. SIGUSR1 will close\nthe output file, open a new one, and continue recording. However, SIGUSR1 does not work with --separate-channels.\nExamples\n\naplay -c 1 -t raw -r 22050 -f mu_law foobar\nwill play the raw file \"foobar\" as a 22050-Hz, mono, 8-bit, Mu-Law .au file.\narecord -d 10 -f cd -t wav -D copy foobar.wav\nwill record foobar.wav as a 10-second, CD-quality wave file, using the PCM \"copy\" (which might be defined in the user's .asoundrc file as:pcm.copy {\n  type plug\n  slave {\n    pcm hw\n  }\n  route_policy copy\n}\narecord -t wav --max-file-time 30 mon.wav\nRecord from the default audio source in monaural, 8,000 samples per second, 8 bits per sample. Start a new file every 30 seconds. File names are\nmon-nn.wav, where nn increases from 01. The file after mon-99.wav is mon-100.wav.\narecord -f cd -t wav --max-file-time 3600 --use-strftime %Y/%m/%d/listen-%H-%M-%v.wav\nRecord in stereo from the default audio source. Create a new file every hour. The files are placed in directories based on their start dates and have names\nwhich include their start times and file numbers.\nSee Also\nalsamixer(1), amixer(1)\nBugs\nNote that .aiff files are not currently supported.\nAuthor\narecord and aplay are by Jaroslav Kysela <perex@perex.cz> This document is by\nPaul Winkler <zarmzarm@erols.com>. Updated for Alsa 0.9 by James Tappin <james@xena.uklinux.net>\n\n\n\n\n\n\n\n\n\n\nSite Search\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nlinux docs\nlinux man pages\npage load time\n\n\nToys\nworld sunlight\nmoon phase\ntrace explorer\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# arecord\n\n> Sound recorder for ALSA soundcard driver.\n> More information: <https://linux.die.net/man/1/arecord>.\n\n- Record a snippet in \"CD\" quality (finish with Ctrl-C when done):\n\n`arecord -vv --format=cd {{path/to/file.wav}}`\n\n- Record a snippet in \"CD\" quality, with a fixed duration of 10 seconds:\n\n`arecord -vv --format=cd --duration={{10}} {{path/to/file.wav}}`\n\n- Record a snippet and save it as mp3 (finish with Ctrl-C when done):\n\n`arecord -vv --format=cd --file-type raw | lame -r - {{path/to/file.mp3}}`\n"
 },
 {
   "command": "compose",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# compose\n\n> An alias to a `run-mailcap`'s action compose.\n> Originally `run-mailcap` is used to mime-type/file.\n\n- Compose action can be used to compose any existing file or new on default mailcap edit tool:\n\n`compose {{filename}}`\n\n- With `run-mailcap`:\n\n`run-mailcap --action=compose {{filename}}`\n"
 },
 {
   "command": "groupmod",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# groupmod\n\n> Modify existing user groups in the system.\n\n- Change the group name:\n\n`groupmod -n {{new_group_name}} {{old_group_name}}`\n\n- Change the group id:\n\n`groupmod -g {{new_group_id}} {{old_group_name}}`\n"
 },
 {
   "command": "btrfs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# btrfs\n\n> A filesystem based on the copy-on-write (COW) principle for Linux.\n\n- Create subvolume:\n\n`sudo btrfs subvolume create {{path/to/subvolume}}`\n\n- List subvolumes:\n\n`sudo btrfs subvolume list {{path/to/mount_point}}`\n\n- Show space usage information:\n\n`sudo btrfs filesystem df {{path/to/mount_point}}`\n\n- Enable quota:\n\n`sudo btrfs quota enable {{path/to/subvolume}}`\n\n- Show quota:\n\n`sudo btrfs qgroup show {{path/to/subvolume}}`\n"
 },
 {
   "command": "rtcwake",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rtcwake\n\n> Enter a system sleep state until specified wakeup time relative to your bios clock.\n\n- Show whether an alarm is set or not:\n\n`sudo rtcwake -m show -v`\n\n- Suspend to ram and wakeup after 10 seconds:\n\n`sudo rtcwake -m mem -s {{10}}`\n\n- Suspend to disk (higher power saving) and wakeup 15 minutes later:\n\n`sudo rtcwake -m disk --date +{{15}}min`\n\n- Freeze the system (more efficient than suspend-to-ram but linux > 3.9 required) and wakeup at a given date and time:\n\n`sudo rtcwake -m freeze --date {{YYYYMMDDhhmm}}`\n\n- Disable a previously set alarm:\n\n`sudo rtcwake -m disable`\n\n- Perform a dry run to wakup the computer at a given time. (Press Ctrl + C to abort):\n\n`sudo rtcwake -m on --date {{hh:ss}}`\n"
 },
 {
   "command": "sensors",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# sensors\n\n> Report sensors information.\n\n- Show the current readings of all sensor chips:\n\n`sensors`\n\n- Show temperatures in degrees Fahrenheit:\n\n`sensors --fahrenheit`\n"
 },
 {
   "command": "uuidgen",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nUUIDGEN(1)\t\t  BSD General Commands Manual\t\t    UUIDGEN(1)\n\nNAME\n     uuidgen -- generates new UUID strings\n\nSYNOPSIS\n     uuidgen [-hdr]\n\nDESCRIPTION\n     The uuidgen command generates a Universally Unique IDentifier (UUID), a\n     128-bit value guaranteed to be unique over both space and time.\n\n     The following options are available:\n\n     -hdr      Emit CoreFoundation CFUUID-based source code for using the uuid\n\t       in a header.\n\nRETURN VALUE\n     The UUID is printed to standard output as a hyphen-punctuated ASCII\n     string of the form: EEF45689-BBE5-4FB6-9E80-41B78F6578E2 (in printf(3)\n     format \"%08X-%04X-%04X-%04X-%012X\"), unless the -hdr option is given, in\n     which case a fragment of source code is output.\n\nMac OS X\t\t\t July 1, 2005\t\t\t      Mac OS X\n",
   "tldr_summary": "# uuidgen\n\n> Generate unique identifiers (UUIDs).\n\n- Create a random UUID:\n\n`uuidgen --random`\n\n- Create a UUID based on the current time:\n\n`uuidgen --time`\n\n- Create a UUID based on the hash of a URL:\n\n`uuidgen --sha1 --namespace {{@url}} --name {{object_name}}`\n"
 },
 {
   "command": "fc-cache",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "FC-CACHE(1)\t\t\t\t\t\t\t   FC-CACHE(1)\n\n\n\nNAME\n       fc-cache - build font information cache files\n\nSYNOPSIS\n       fc-cache  [  -EfrsvVh  ]   [  --error-on-no-fonts  ]   [  --force  ]  [\n       --really-force ]  [  [ -y dir ]\t[ --sysroot dir ]  ]  [  --system-only\n       ]  [ --verbose ]  [ --version ]\t[ --help ]  [ dir... ]\n\nDESCRIPTION\n       fc-cache  scans\tthe  font  directories\ton  the system and builds font\n       information cache files for applications  using\tfontconfig  for  their\n       font handling.\n\n       If  directory  arguments are not given, fc-cache uses each directory in\n       the current font configuration. Each  directory\tis  scanned  for  font\n       files  readable\tby FreeType. A cache is created which contains proper-\n       ties of each font and the associated filename.  This cache is  used  to\n       speed up application startup when using the fontconfig library.\n\n       Note  that  fc-cache must be executed once per architecture to generate\n       font information customized for that architecture.\n\nOPTIONS\n       This program follows the usual  GNU  command  line  syntax,  with  long\n       options\tstarting  with\ttwo  dashes  (`-').  A\tsummary  of options is\n       included below.\n\n       -E     Raise an error if there are no fonts in dir  or  directories  in\n\t      the configuration if not given.\n\n       -f     Force  re-generation of apparently up-to-date cache files, over-\n\t      riding the timestamp checking.\n\n       -r     Erase all existing cache files and rescan.\n\n       -s     Only scan system-wide directories, omitting the  places  located\n\t      in the user's home directory.\n\n       -v     Display status information while busy.\n\n       -y     Prepend dir to all paths for scanning.\n\n       -h     Show summary of options.\n\n       -V     Show version of the program and exit.\n\n       dir    Directory to scan for fonts.\n\nRETURN CODES\n       fc-cache  returns  zero if the caches successfully generated. otherwise\n       non-zero.\n\nFILES\n       %cachedir%/*-%arch%.cache-%version%\n\t      These files are generated by fc-cache and contain maps from file\n\t      names  to  font  properties.  They  are  read  by the fontconfig\n\t      library at application startup to locate appropriate fonts.\n\nSEE ALSO\n       fc-cat(1) fc-list(1) fc-match(1) fc-pattern(1) fc-query(1) fc-scan(1)\n\n       The fontconfig user's guide, in\tHTML  format:  /usr/share/doc/fontcon-\n       fig/fontconfig-user.html.\n\nAUTHOR\n       This  manual  page was written by Keith Packard <keithp@keithp.com> and\n       Josselin Mouette <joss@debian.org>.\n\n\n\n\t\t\t\t Aug 13, 2008\t\t\t   FC-CACHE(1)\n",
   "tldr_summary": "# fc-cache\n\n> Scan font directories in order to build font cache files.\n\n- Generate font cache files:\n\n`fc-cache`\n\n- Force a rebuild of all font cache files, without checking if cache is up-to-date:\n\n`fc-cache -f`\n\n- Erase font cache files, then generate new font cache files:\n\n`fc-cache -r`\n"
 },
 {
   "command": "amixer",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# amixer\n\n> Mixer for ALSA soundcard driver.\n\n- Turn up the master volume by 10%:\n\n`amixer -D pulse sset Master {{10%+}}`\n\n- Turn down the master volume by 10%:\n\n`amixer -D pulse sset Master {{10%-}}`\n"
 },
 {
   "command": "iwconfig",
   "doc_url": "https://linux.die.net/man/8/iwconfig",
   "doc_text": "\n\niwconfig(8) - Linux man page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niwconfig(8) - Linux man page\nName\niwconfig - configure a wireless network interface\nSynopsis\n\n\n\n\n\niwconfig [interface]\niwconfig interface [essid X] [nwid N] [mode M] [freq F]\n[channel C][sens S ][ap A ][nick NN ]\n[rate R] [rts RT] [frag FT] [txpower T]\n[enc E] [key K] [power P] [retry R]\n[modu M] [commit]\niwconfig --help\niwconfig --version\nDescription\nIwconfig is similar to ifconfig(8), but is dedicated to the wireless interfaces.\nIt is used to set the parameters of the network interface which are specific to the wireless operation (for example : the frequency). Iwconfig may also\nbe used to display those parameters, and the wireless statistics (extracted from /proc/net/wireless).\nAll these parameters and statistics are device dependent. Each driver will provide only some of them depending on hardware support, and the range of values\nmay change. Please refer to the man page of each device for details.\nParameters\n\nessid\nSet the ESSID (or Network Name - in some products it may also be called Domain ID). The ESSID is used to identify cells which are part of the same virtual\nnetwork.\nAs opposed to the AP Address or NWID which define a single cell, the ESSID defines a group of cells connected via repeaters or infrastructure, where the user\nmay roam transparently.\nWith some cards, you may disable the ESSID checking (ESSID promiscuous) with off or any (and on to reenable it).\nIf the ESSID of your network is one of the special keywords (off, on or any), you should use -- to escape it.\nExamples :\n   iwconfig eth0 essid any\n   iwconfig eth0 essid \"My Network\"\"\n   iwconfig eth0 essid -- \"ANY\"\"\nnwid\nSet the Network ID. As all adjacent wireless networks share the same medium, this parameter is used to differentiate them (create logical colocated\nnetworks) and identify nodes belonging to the same cell.\nThis parameter is only used for pre-802.11 hardware, the 802.11 protocol uses the ESSID and AP Address for this function.\nWith some cards, you may disable the Network ID checking (NWID promiscuous) with off (and on to reenable it).\nExamples :\n   iwconfig eth0 nwid AB34\n   iwconfig eth0 nwid off\nnick[name]\nSet the nickname, or the station name. Some 802.11 products do define it, but this is not used as far as the protocols (MAC, IP, TCP) are concerned and\ncompletely useless as far as configuration goes. Only some wireless diagnostic tools may use it.\nExample :\n   iwconfig eth0 nickname \"My Linux Node\"\"\nmode\nSet the operating mode of the device, which depends on the network topology. The mode can be Ad-Hoc (network composed of only one cell and without\nAccess Point), Managed (node connects to a network composed of many Access Points, with roaming), Master (the node is the synchronisation master\nor acts as an Access Point), Repeater (the node forwards packets between other wireless nodes), Secondary (the node acts as a backup\nmaster/repeater), Monitor (the node is not associated with any cell and passively monitor all packets on the frequency) or Auto.\nExample :\n   iwconfig eth0 mode Managed\n   iwconfig eth0 mode Ad-Hoc\nfreq/channel\nSet the operating frequency or channel in the device. A value below 1000 indicates a channel number, a value greater than 1000 is a frequency in Hz. You\nmay append the suffix k, M or G to the value (for example, \"2.46G\" for 2.46 GHz frequency), or add enough '0'.\nChannels are usually numbered starting at 1, and you may use iwlist(8) to get the total number of channels, list the available frequencies, and display\nthe current frequency as a channel. Depending on regulations, some frequencies/channels may not be available.\nWhen using Managed mode, most often the Access Point dictates the channel and the driver may refuse the setting of the frequency. In Ad-Hoc mode, the frequency\nsetting may only be used at initial cell creation, and may be ignored when joining an existing cell.\nYou may also use off or auto to let the card pick up the best channel (when supported).\nExamples :\n   iwconfig eth0 freq 2422000000\n   iwconfig eth0 freq 2.422G\n   iwconfig eth0 channel 3\n   iwconfig eth0 channel auto\nap\nForce the card to register to the Access Point given by the address, if it is possible. This address is the cell identity of the Access Point, as reported\nby wireless scanning, which may be different from its network MAC address. If the wireless link is point to point, set the address of the other end of the\nlink. If the link is ad-hoc, set the cell identity of the ad-hoc network.\nWhen the quality of the connection goes too low, the driver may revert back to automatic mode (the card selects the best Access Point in range).\nYou may also use off to re-enable automatic mode without changing the current Access Point, or you may use any or auto to force the card\nto reassociate with the currently best Access Point.\nExample :\n   iwconfig eth0 ap 00:60:1D:01:23:45\n   iwconfig eth0 ap any\n   iwconfig eth0 ap off\nrate/bit[rate]\nFor cards supporting multiple bit rates, set the bit-rate in b/s. The bit-rate is the speed at which bits are transmitted over the medium, the user speed\nof the link is lower due to medium sharing and various overhead.\nYou may append the suffix k, M or G to the value (decimal multiplier : 10^3, 10^6 and 10^9 b/s), or add enough '0'. Values below 1000 are card specific,\nusually an index in the bit-rate list. Use auto to select automatic bit-rate mode (fallback to lower rate on noisy channels), which is the default for\nmost cards, and fixed to revert back to fixed setting. If you specify a bit-rate value and append auto, the driver will use all bit-rates lower\nand equal than this value.\nExamples :\n   iwconfig eth0 rate 11M\n   iwconfig eth0 rate auto\n   iwconfig eth0 rate 5.5M auto\ntxpower\nFor cards supporting multiple transmit powers, sets the transmit power in dBm. If W is the power in Watt, the power in dBm is P = 30 +\n10.log(W). If the value is postfixed by mW, it will be automatically converted to dBm.\nIn addition, on and off enable and disable the radio, and auto and fixed enable and disable power control (if those features are\navailable).\nExamples :\n   iwconfig eth0 txpower 15\n   iwconfig eth0 txpower 30mW\n   iwconfig eth0 txpower auto\n   iwconfig eth0 txpower off\nsens\nSet the sensitivity threshold. This define how sensitive is the card to poor operating conditions (low signal, interference). Positive values are assumed\nto be the raw value used by the hardware or a percentage, negative values are assumed to be dBm. Depending on the hardware implementation, this parameter may\ncontrol various functions.\nOn modern cards, this parameter usually control handover/roaming threshold, the lowest signal level for which the hardware remains associated with the current\nAccess Point. When the signal level goes below this threshold the card starts looking for a new/better Access Point. Some cards may use the number of missed\nbeacons to trigger this. For high density of Access Points, a higher threshold make sure the card is always associated with the best AP, for low density of\nAPs, a lower threshold minimise the number of failed handoffs.\nOn more ancient card this parameter usually controls the defer threshold, the lowest signal level for which the hardware considers the channel busy. Signal\nlevels above this threshold make the hardware inhibits its own transmission whereas signals weaker than this are ignored and the hardware is free to transmit.\nThis is usually strongly linked to the receive threshold, the lowest signal level for which the hardware attempts packet reception. Proper setting of these\nthresholds prevent the card to waste time on background noise while still receiving weak transmissions. Modern designs seems to control those thresholds\nautomatically.\nExample :\n   iwconfig eth0 sens -80\n   iwconfig eth0 sens 2\nretry\nMost cards have MAC retransmissions, and some allow to set the behaviour of the retry mechanism.\nTo set the maximum number of retries, enter limit 'value'. This is an absolute value (without unit), and the default (when nothing is specified). To set\nthe maximum length of time the MAC should retry, enter lifetime 'value'. By defaults, this value in in seconds, append the suffix m or u to specify\nvalues in milliseconds or microseconds.\nYou can also add the short, long, min and max modifiers. If the card supports automatic mode, they define the bounds of the limit\nor lifetime. Some other cards define different values depending on packet size, for example in 802.11 min limit is the short retry limit (non RTS/CTS\npackets).\nExamples :\n   iwconfig eth0 retry 16\n   iwconfig eth0 retry lifetime 300m\n   iwconfig eth0 retry short 12\n   iwconfig eth0 retry min limit 8\nrts[_threshold]\nRTS/CTS adds a handshake before each packet transmission to make sure that the channel is clear. This adds overhead, but increases performance in case of\nhidden nodes or a large number of active nodes. This parameter sets the size of the smallest packet for which the node sends RTS ; a value equal to the maximum\npacket size disables the mechanism. You may also set this parameter to auto, fixed or off.\nExamples :\n   iwconfig eth0 rts 250\n   iwconfig eth0 rts off\nfrag[mentation_threshold]\nFragmentation allows to split an IP packet in a burst of smaller fragments transmitted on the medium. In most cases this adds overhead, but in a very noisy\nenvironment this reduces the error penalty and allow packets to get through interference bursts. This parameter sets the maximum fragment size which is always\nlower than the maximum packet size.\nThis parameter may also control Frame Bursting available on some cards, the ability to send multiple IP packets together. This mechanism would be enabled if\nthe fragment size is larger than the maximum packet size.\nYou may also set this parameter to auto, fixed or off.\nExamples :\n   iwconfig eth0 frag 512\n   iwconfig eth0 frag off\nkey/enc[ryption]\nUsed to manipulate encryption or scrambling keys and security mode.\nTo set the current encryption key, just enter the key in hex digits as XXXX-XXXX-XXXX-XXXX or XXXXXXXX. To set a key other than the current key,\nprepend or append [index] to the key itself (this won't change which is the active key). You can also enter the key as an ASCII string by using the\ns: prefix. Passphrase is currently not supported.\nTo change which key is the currently active key, just enter [index] (without entering any key value).\noff and on disable and reenable encryption.\nThe security mode may be open or restricted, and its meaning depends on the card used. With most cards, in open mode no authentication is\nused and the card may also accept non-encrypted sessions, whereas in restricted mode only encrypted sessions are accepted and the card will use\nauthentication if available.\nIf you need to set multiple keys, or set a key and change the active key, you need to use multiple key directives. Arguments can be put in any order,\nthe last one will take precedence.\nExamples :\n   iwconfig eth0 key 0123-4567-89\n   iwconfig eth0 key [3] 0123-4567-89\n   iwconfig eth0 key s:password [2]\n   iwconfig eth0 key [2]\n   iwconfig eth0 key open\n   iwconfig eth0 key off\n   iwconfig eth0 key restricted [3] 0123456789\n   iwconfig eth0 key 01-23 key 45-67 [4] key [4]\npower\nUsed to manipulate power management scheme parameters and mode.\nTo set the period between wake ups, enter period 'value'. To set the timeout before going back to sleep, enter timeout 'value'. To set the\ngeneric level of power saving, enter saving 'value'. You can also add the min and max modifiers. By default, those values are in seconds,\nappend the suffix m or u to specify values in milliseconds or microseconds. Sometimes, those values are without units (number of beacon periods, dwell,\npercentage or similar).\noff and on disable and reenable power management. Finally, you may set the power management mode to all (receive all packets),\nunicast (receive unicast packets only, discard multicast and broadcast) and multicast (receive multicast and broadcast only, discard unicast\npackets).\nExamples :\n   iwconfig eth0 power period 2\n   iwconfig eth0 power 500m unicast\n   iwconfig eth0 power timeout 300u all\n   iwconfig eth0 power saving 3\n   iwconfig eth0 power off\n   iwconfig eth0 power min period 2 power max period 4\nmodu[lation]\nForce the card to use a specific set of modulations. Modern cards support various modulations, some which are standard, such as 802.11b or 802.11g, and\nsome proprietary. This command force the card to only use the specific set of modulations listed on the command line. This can be used to fix interoperability\nissues.\nThe list of available modulations depend on the card/driver and can be displayed using iwlist modulation. Note that some card/driver may not be able to\nselect each modulation listed independantly, some may come as a group. You may also set this parameter to auto let the card/driver do its best.\nExamples :\n   iwconfig eth0 modu 11g\n   iwconfig eth0 modu CCK OFDMa\n   iwconfig eth0 modu auto\ncommit\nSome cards may not apply changes done through Wireless Extensions immediately (they may wait to aggregate the changes or apply it only when the card is\nbrought up via ifconfig). This command (when available) forces the card to apply all pending changes.\nThis is normally not needed, because the card will eventually apply the changes, but can be useful for debugging.\nDisplay\nFor each device which supports wireless extensions, iwconfig will display the name of the\nMAC protocol used (name of device for proprietary protocols), the ESSID (Network Name), the NWID, the frequency (or channel), the\nsensitivity, the mode of operation, the Access Point address, the bit-rate, the RTS threshold, the fragmentation\nthreshold, the encryption key and the power management settings (depending on availability).\nThe parameters displayed have the same meaning and values as the parameters you can set, please refer to the previous part for a detailed explanation of\nthem.\nSome parameters are only displayed in short/abbreviated form (such as encryption). You may use iwlist(8) to get all the details.\nSome parameters have two modes (such as bitrate). If the value is prefixed by '=', it means that the parameter is fixed and forced to that value, if it\nis prefixed by ':', the parameter is in automatic mode and the current value is shown (and may change).\n\nAccess Point/Cell\nAn address equal to 00:00:00:00:00:00 means that the card failed to associate with an Access Point (most likely a configuration issue). The Access\nPoint parameter will be shown as Cell in ad-hoc mode (for obvious reasons), but otherwise works the same.\nIf /proc/net/wireless exists, iwconfig will also display its content. Note that those values will depend on the driver and the hardware\nspecifics, so you need to refer to your driver documentation for proper interpretation of those values.\n\nLink quality\nOverall quality of the link. May be based on the level of contention or interference, the bit or frame error rate, how good the received signal is, some\ntiming synchronisation, or other hardware metric. This is an aggregate value, and depends totally on the driver and hardware.\nSignal level\nReceived signal strength (RSSI - how strong the received signal is). May be arbitrary units or dBm, iwconfig uses driver meta information to\ninterpret the raw value given by /proc/net/wireless and display the proper unit or maximum value (using 8 bit arithmetic). In Ad-Hoc mode, this\nmay be undefined and you should use iwspy.\nNoise level\nBackground noise level (when no packet is transmitted). Similar comments as for Signal level.\nRx invalid nwid\nNumber of packets received with a different NWID or ESSID. Used to detect configuration problems or adjacent network existence (on the same frequency).\nRx invalid crypt\nNumber of packets that the hardware was unable to decrypt. This can be used to detect invalid encryption settings.\nRx invalid frag\nNumber of packets for which the hardware was not able to properly re-assemble the link layer fragments (most likely one was missing).\nTx excessive retries\nNumber of packets that the hardware failed to deliver. Most MAC protocols will retry the packet a number of times before giving up.\nInvalid misc\nOther packets lost in relation with specific wireless operations.\nMissed beacon\nNumber of periodic beacons from the Cell or the Access Point we have missed. Beacons are sent at regular intervals to maintain the cell coordination,\nfailure to receive them usually indicates that the card is out of range.\nAuthor\nJean Tourrilhes - jt@hpl.hp.com\nFiles\n/proc/net/wireless\nSee Also\nifconfig(8), iwspy(8), iwlist(8),\niwevent(8), iwpriv(8), wireless(7).\n\n\nReferenced By\niftab(5),\niwgetid(8),\nwaproamd(8),\nwavelan(4),\nwicd(8),\nwicd-wireless-settings.conf(5)\n\n\n\n\n\n\n\n\nSite Search\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nlinux docs\nlinux man pages\npage load time\n\n\nToys\nworld sunlight\nmoon phase\ntrace explorer\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# iwconfig\n\n> Configure and show the parameters of a wireless network interface.\n> More information: <https://linux.die.net/man/8/iwconfig>.\n\n- Show the parameters and statistics of all the interfaces:\n\n`iwconfig`\n\n- Show the parameters and statistics of the specified interface:\n\n`iwconfig {{interface}}`\n\n- Set the ESSID (network name) of the specified interface (e.g., eth0 or wlp2s0):\n\n`iwconfig {{interface}} {{new_network_name}}`\n\n- Set the operating mode of the specified interface:\n\n`ifconfig {{interface}} mode {{ad hoc|Managed|Master|Repeater|Secondary|Monitor|Auto}}`\n"
 },
 {
   "command": "emerge",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# emerge\n\n> Gentoo Linux package manager utility.\n\n- Synchronize all packages:\n\n`emerge --sync`\n\n- Update all packages, including dependencies:\n\n`emerge -uDNav @world`\n\n- Resume a failed updated, skipping the failing package:\n\n`emerge --resume --skipfirst`\n\n- Install a new package, with confirmation:\n\n`emerge -av {{package_name}}`\n\n- Remove a package, with confirmation:\n\n`emerge -Cav {{package_name}}`\n\n- Remove orphaned packages (that were installed only as dependencies):\n\n`emerge -avc`\n\n- Search the package database for a keyword:\n\n`emerge -S {{keyword}}`\n"
 },
 {
   "command": "pkgadd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pkgadd\n\n> Add a package to a CRUX system.\n\n- Install a local software package:\n\n`pkgadd {{package_name}}`\n\n- Update an already installed package from a local package:\n\n`pkgadd -u {{package_name}}`\n"
 },
 {
   "command": "uprecords",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# uprecords\n\n> Displays a summary of historical uptime records.\n\n- Display a summary of the top 10 historical uptime records:\n\n`uprecords`\n\n- Display the top 25 records:\n\n`uprecords -m {{25}}`\n\n- Display the downtime between reboots instead of the kernel version:\n\n`uprecords -d`\n\n- Show the most recent reboots:\n\n`uprecords -B`\n\n- Don't truncate information:\n\n`uprecords -w`\n"
 },
 {
   "command": "pacman",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pacman\n\n> Arch Linux package manager utility.\n\n- Synchronize and update all packages:\n\n`pacman -Syu`\n\n- Install a new package:\n\n`pacman -S {{package_name}}`\n\n- Remove a package and its dependencies:\n\n`pacman -Rs {{package_name}}`\n\n- Search the package database for a regular expression or keyword:\n\n`pacman -Ss \"{{search_pattern}}\"`\n\n- List installed packages and versions:\n\n`pacman -Q`\n\n- List only the explicitly installed packages and versions:\n\n`pacman -Qe`\n\n- Find which package owns a certain file:\n\n`pacman -Qo {{filename}}`\n\n- Empty package cache to free up space:\n\n`pacman -Scc`\n"
 },
 {
   "command": "colrm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nCOLRM(1)\t\t  BSD General Commands Manual\t\t      COLRM(1)\n\nNAME\n     colrm -- remove columns from a file\n\nSYNOPSIS\n     colrm [start [stop]]\n\nDESCRIPTION\n     The colrm utility removes selected columns from the lines of a file.  A\n     column is defined as a single character in a line.  Input is read from\n     the standard input.  Output is written to the standard output.\n\n     If only the start column is specified, columns numbered less than the\n     start column will be written.  If both start and stop columns are speci-\n     fied, columns numbered less than the start column or greater than the\n     stop column will be written.  Column numbering starts with one, not zero.\n\n     Tab characters increment the column count to the next multiple of eight.\n     Backspace characters decrement the column count by one.\n\nENVIRONMENT\n     The LANG, LC_ALL and LC_CTYPE environment variables affect the execution\n     of colrm as described in environ(7).\n\nEXIT STATUS\n     The colrm utility exits 0 on success, and >0 if an error occurs.\n\nSEE ALSO\n     awk(1), column(1), cut(1), paste(1)\n\nHISTORY\n     The colrm command appeared in 3.0BSD.\n\nBSD\t\t\t\tAugust 4, 2004\t\t\t\t   BSD\n",
   "tldr_summary": "# colrm\n\n> Remove columns from `stdin`.\n\n- Remove first column of `stdin`:\n\n`colrm {{1 1}}`\n\n- Remove from 3rd column till the end of each line:\n\n`colrm {{3}}`\n\n- Remove from the 3rd column till the 5th column of each line:\n\n`colrm {{3 5}}`\n"
 },
 {
   "command": "nemo",
   "doc_url": "https://github.com/linuxmint/nemo",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - linuxmint/nemo: File browser for Cinnamon\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinuxmint\n\n/\n\nnemo\n\n\n\n\n\n\n\n    Watch\n \n      77\n    \n\n\n\n\n      Star\n\n\n      613\n    \n\n\n\n\n          Fork\n\n\n        233\n      \n\n\n\n\n\n        File browser for Cinnamon\n      \n\n\n\n            View license\n        \n\n\n\n\n613\n        stars\n \n\n233\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n284\n \n\n\n\nPull requests\n4\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\nbranches\n\n\n\n117\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n \n\n\n\n\nSoapux\n\n\n   and   mtwebster\n\nMisc cleanup\n\n\n\n…\n\n\n\n3795d63\n\nSep 14, 2020\n\n\n\n\n\nMisc cleanup\n\nRemove autotools INSTALL file.  Cleanup formatting of summary.\nAdd newline to end of meson_options.txt.\n\n3795d63\n\n\n\nGit stats\n\n\n\n\n\n2,009\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.circleci\n\n\n \n\n\n \n\n\n\n\n\n\n\n.github\n\n\n \n\n\n \n\n\n\n\n\n\n\ncut-n-paste-code\n\n\n \n\n\n \n\n\n\n\n\n\n\ndata\n\n\n \n\n\n \n\n\n\n\n\n\n\ndebian\n\n\n \n\n\n \n\n\n\n\n\n\n\ndocs\n\n\n \n\n\n \n\n\n\n\n\n\n\neel\n\n\n \n\n\n \n\n\n\n\n\n\n\nfiles\n\n\n \n\n\n \n\n\n\n\n\n\n\ngresources\n\n\n \n\n\n \n\n\n\n\n\n\n\ninstall-scripts\n\n\n \n\n\n \n\n\n\n\n\n\n\nlibnemo-extension\n\n\n \n\n\n \n\n\n\n\n\n\n\nlibnemo-private\n\n\n \n\n\n \n\n\n\n\n\n\n\npo\n\n\n \n\n\n \n\n\n\n\n\n\n\nsrc\n\n\n \n\n\n \n\n\n\n\n\n\n\ntest\n\n\n \n\n\n \n\n\n\n\n\n\n\nutils\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\nAUTHORS\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING-DOCS\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING.EXTENSIONS\n\n\n \n\n\n \n\n\n\n\n\n\n\nCOPYING.LIB\n\n\n \n\n\n \n\n\n\n\n\n\n\nChangeLog\n\n\n \n\n\n \n\n\n\n\n\n\n\nNEWS\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\nTHANKS\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfig.h.meson.in\n\n\n \n\n\n \n\n\n\n\n\n\n\ngenerate_additional_file\n\n\n \n\n\n \n\n\n\n\n\n\n\nmakepot\n\n\n \n\n\n \n\n\n\n\n\n\n\nmeson.build\n\n\n \n\n\n \n\n\n\n\n\n\n\nmeson_options.txt\n\n\n \n\n\n \n\n\n\n\n\n\n\nnemo.pot\n\n\n \n\n\n \n\n\n\n\n\n\n\npolkit.its\n\n\n \n\n\n \n\n\n\n\n\n\n\npolkit.loc\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\nNemo\nFile Manager for Cinnamon\nNemo is the file manager for the Cinnamon desktop environment.\n\n\n\n\n\n\n\n\nAbout\n\n      File browser for Cinnamon\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n      117\n\n\n\n\n\nmaster.lmde4: Misc cleanup\n\n          Latest\n \nSep 14, 2020\n\n \n\n        + 116 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 89\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 78 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\nC\n99.1%\n\n\n\n\n\nOther\n0.9%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# nemo\n\n> File manager and graphical shell for Cinnamon.\n> More information: <https://github.com/linuxmint/nemo>.\n\n- Open a new window showing the user's home directory:\n\n`nemo`\n\n- Open a new window showing the current directory:\n\n`nemo .`\n\n- Close all open nemo windows:\n\n`nemo --quit`\n"
 },
 {
   "command": "binwalk",
   "doc_url": "https://github.com/ReFirmLabs/binwalk",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - ReFirmLabs/binwalk: Firmware Analysis Tool\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReFirmLabs\n\n/\n\nbinwalk\n\n\n\n\n\n\n\n    Watch\n \n      357\n    \n\n\n\n\n      Star\n\n\n      6.5k\n    \n\n\n\n\n          Fork\n\n\n        996\n      \n\n\n\n\n\n        Firmware Analysis Tool\n      \n\n\n\n            MIT License\n        \n\n\n\n\n6.5k\n        stars\n \n\n996\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n78\n \n\n\n\nPull requests\n18\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nbranches\n\n\n\n5\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\ndevttys0\n\nMerge pull request #481 from sviehb/patch-1\n\n\n\n…\n\n\n\n578e5f7\n\nSep 17, 2020\n\n\n\n\n\nMerge pull request #481 from sviehb/patch-1\n\nUpdate deps.sh for Python 3 jefferson\n\n578e5f7\n\n\n\nGit stats\n\n\n\n\n\n1,150\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\nimages\n\n\n\nAdded images/README.md\n\n\n\nDec 23, 2015\n\n\n\n\n\n\n\nsrc\n\n\n\nAdded size check for arcadyan decryptor\n\n\n\nAug 11, 2020\n\n\n\n\n\n\n\ntesting\n\n\n\nAdded LZMA tests\n\n\n\nNov 21, 2017\n\n\n\n\n\n\n\n.editorconfig\n\n\n\nAdded .editorconfig\n\n\n\nNov 29, 2018\n\n\n\n\n\n\n\n.gitignore\n\n\n\nMerged multiple .gitignore files into one\n\n\n\nSep 13, 2017\n\n\n\n\n\n\n\n.travis.yml\n\n\n\ntravis: Update Python versions\n\n\n\nDec 1, 2019\n\n\n\n\n\n\n\nAPI.md\n\n\n\nmake API example python3 compliant\n\n\n\nFeb 25, 2019\n\n\n\n\n\n\n\nINSTALL.md\n\n\n\nFixed unstuff link in INSTALL.md\n\n\n\nSep 17, 2020\n\n\n\n\n\n\n\nLICENSE\n\n\n\nFix perm messup\n\n\n\nApr 30, 2016\n\n\n\n\n\n\n\nREADME.md\n\n\n\nUpdate README.md\n\n\n\nJun 14, 2019\n\n\n\n\n\n\n\ndeps.sh\n\n\n\nMerge pull request #481 from sviehb/patch-1\n\n\n\nSep 17, 2020\n\n\n\n\n\n\n\nsetup.py\n\n\n\nMerge pull request #387 from bannsec/master\n\n\n\nNov 8, 2019\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\nBinwalk\n\n\n\n\nBinwalk is a fast, easy to use tool for analyzing, reverse engineering, and extracting firmware images.\nInstallation and Usage\n\nInstallation\nAPI\nSupported Platforms\nGetting Started\nBinwalk Command Line Usage\nBinwalk IDA Plugin Usage\n\nMore information on Wiki\nBinwalk Professional Edition\nAfter years of developing and supporting binwalk as an open source project we have finally sold out to the man and released a cloud-based firmware extraction engine called Binwalk Pro. After all someone needs to pay devttys0 so he can buy more milling equipment and feed his children (in that order). Please consider subscribing and reap the benefits of getting actual customer support for all your firmware extraction needs. Please visit https://www.refirmlabs.com/binwalk-pro/ for more information.\n\n\n\n\n\n\n\n\nAbout\n\n      Firmware Analysis Tool\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        MIT License\n    \n\n\n\n\n\n\n\n    Releases\n      5\n\n\n\n\n\nBinwalk v2.2.0 Release\n\n          Latest\n \nOct 14, 2019\n\n \n\n        + 4 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n        Used by 244\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n            + 236\n          \n\n\n\n\n\n\n\n    Contributors 61\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 50 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\nPython\n97.4%\n\n\n\n\n\nShell\n2.6%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# binwalk\n\n> Firmware Analysis Tool.\n> More information: <https://github.com/ReFirmLabs/binwalk>.\n\n- Scan a binary file:\n\n`binwalk {{path/to/binary}}`\n\n- Extract files from a binary, specifying the output directory:\n\n`binwalk --extract --directory {{output_directory}} {{path/to/binary}}`\n\n- Recursively extract files from a binary limiting the recursion depth to 2:\n\n`binwalk --extract --matryoshka --depth {{2}} {{path/to/binary}}`\n\n- Extract files from a binary with the specified file signature:\n\n`binwalk --dd '{{png image:png}}' {{path/to/binary}}`\n\n- Analyze the entropy of a binary, saving the plot with the same name as the binary and `.png` extension appended:\n\n`binwalk --entropy --save {{path/to/binary}}`\n\n- Combine entropy, signature and opcodes analysis in a single command:\n\n`binwalk --entropy --signature --opcodes {{path/to/binary}}`\n"
 },
 {
   "command": "cpufreq-aperf",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# cpufreq-aperf\n\n> Calculate the average CPU frequency over a time period.\n> Requires root privileges.\n\n- Start calculating, defaulting to all CPU cores and 1 second refresh interval:\n\n`sudo cpufreq-aperf`\n\n- Start calculating for CPU 1 only:\n\n`sudo cpufreq-aperf -c {{1}}`\n\n- Start calculating with a 3 seconds refresh interval for all CPU cores:\n\n`sudo cpufreq-aperf -i {{3}}`\n\n- Calculate only once:\n\n`sudo cpufreq-aperf -o`\n"
 },
 {
   "command": "mkfs.fat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs.fat\n\n> Creates an MS-DOS filesystem inside a partition.\n\n- Create a fat filesystem inside partition 1 on device b (`sdb1`):\n\n`mkfs.fat {{/dev/sdb1}}`\n\n- Create filesystem with a volume-name:\n\n`mkfs.fat -n {{volume_name}} {{/dev/sdb1}}`\n\n- Create filesystem with a volume-id:\n\n`mkfs.fat -i {{volume_id}} {{/dev/sdb1}}`\n\n- Use 5 instead of 2 file allocation tables:\n\n`mkfs.fat -f 5 {{/dev/sdb1}}`\n"
 },
 {
   "command": "pdfgrep",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pdfgrep\n\n> Search text in PDF files.\n\n- Find lines that match pattern in a PDF:\n\n`pdfgrep {{pattern}} {{file.pdf}}`\n\n- Include file name and page number for each matched line:\n\n`pdfgrep --with-filename --page-number {{pattern}} {{file.pdf}}`\n\n- Do a case insensitive search for lines that begin with \"foo\" and return the first 3 matches:\n\n`pdfgrep --max-count {{3}} --ignore-case {{'^foo'}} {{file.pdf}}`\n\n- Find pattern in files with a .pdf extension in the current directory recursively:\n\n`pdfgrep --recursive {{pattern}}`\n\n- Find pattern on files that match a specific glob in the current directory recursively:\n\n`pdfgrep --recursive --include {{'*book.pdf'}} {{pattern}}`\n"
 },
 {
   "command": "e4defrag",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# e4defrag\n\n> Defragment an ext4 filesystem.\n\n- Defragment the filesystem:\n\n`e4defrag {{/dev/sdXN}}`\n\n- See how fragmented a filesystem is:\n\n`e4defrag -c {{/dev/sdXN}}`\n\n- Print errors and the fragmentation count before and after each file:\n\n`e4defrag -v {{/dev/sdXN}}`\n"
 },
 {
   "command": "scrot",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# scrot\n\n> Screen capture utility.\n\n- Capture a screenshot and save it to the current directory with the current date as the filename:\n\n`scrot`\n\n- Capture a screenshot and save it as \"capture.png\":\n\n`scrot {{capture.png}}`\n\n- Capture a screenshot interactively:\n\n`scrot --select`\n\n- Capture a screenshot from the currently focused window:\n\n`scrot --focused`\n"
 },
 {
   "command": "perf",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# perf\n\n> Framework for linux performance counter measurements.\n\n- Display basic performance counter stats for a command:\n\n`perf stat {{gcc hello.c}}`\n\n- Display system-wide real time performance counter profile:\n\n`sudo perf top`\n\n- Run a command and record its profile into \"perf.data\":\n\n`sudo perf record {{command}}`\n\n- Read \"perf.data\" (created by `perf record`) and display the profile:\n\n`sudo perf report`\n"
 },
 {
   "command": "lsblk",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lsblk\n\n> Lists information about devices.\n\n- List all storage devices in a tree-like format:\n\n`lsblk`\n\n- Also list empty devices:\n\n`lsblk -a`\n\n- Print the SIZE column in bytes rather than in a human-readable format:\n\n`lsblk -b`\n\n- Output info about filesystems:\n\n`lsblk -f`\n\n- Use ASCII characters for tree formatting:\n\n`lsblk -i`\n\n- Output info about block-device topology:\n\n`lsblk -t`\n\n- Exclude the devices specified by the comma-separated list of major device numbers:\n\n`lsblk -e {{1,7}}`\n"
 },
 {
   "command": "mons",
   "doc_url": "https://github.com/Ventto/mons",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - Ventto/mons: POSIX Shell script to quickly manage monitors on X\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVentto\n\n/\n\nmons\n\n\n\n\n\n\n\n    Watch\n \n      7\n    \n\n\n\n\n      Star\n\n\n      422\n    \n\n\n\n\n          Fork\n\n\n        28\n      \n\n\n\n\n\n        POSIX Shell script to quickly manage monitors on X\n      \n\n\n\n            MIT License\n        \n\n\n\n\n422\n        stars\n \n\n28\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n16\n \n\n\n\nPull requests\n2\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nbranches\n\n\n\n5\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n \n\n\n\n\nmschneiderwng\n\n\n   and   Ventto\n\nadded PREFIX in Makefile\n\n\n\n…\n\n\n\n375bbba\n\nMar 20, 2020\n\n\n\n\n\nadded PREFIX in Makefile\n\n\n375bbba\n\n\n\nGit stats\n\n\n\n\n\n120\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\nimg\n\n\n\nreadme: Update img\n\n\n\nApr 17, 2018\n\n\n\n\n\n\n\nlibshlist @ 1d0bdb7\n\n\n\ngit: Update submodule\n\n\n\nOct 7, 2018\n\n\n\n\n\n\n\n.gitignore\n\n\n\nmake: Remove all artefacts\n\n\n\nApr 17, 2018\n\n\n\n\n\n\n\n.gitmodules\n\n\n\nmisc: Update submodule\n\n\n\nNov 5, 2017\n\n\n\n\n\n\n\nCONTRIBUTING.md\n\n\n\nmisc: Add CONTRIBUTING.md\n\n\n\nJan 24, 2017\n\n\n\n\n\n\n\nLICENSE\n\n\n\nmisc: Update copyright\n\n\n\nApr 17, 2018\n\n\n\n\n\n\n\nMakefile\n\n\n\nadded PREFIX in Makefile\n\n\n\nMar 20, 2020\n\n\n\n\n\n\n\nREADME.md\n\n\n\nAdd FreeBSD installation instructions (#35)\n\n\n\nJan 7, 2020\n\n\n\n\n\n\n\nmons.sh\n\n\n\nmake: fix non-default install (#34)\n\n\n\nJan 7, 2020\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\nMons\n\n\n\n\n\"Mons is a Shell script to quickly manage 2-monitors display using xrandr.\"\nPerks\n\n No requirement: POSIX-compliant (minimal: xorg-xrandr)\n Useful: Perfectly fit for laptops, quick and daily use\n Well known: Laptop mode, projector mode, duplicate, mirror and extend\n More:  Select one or two monitors over several others\n Extra: Cycle through every mode with only one shortcut\n Auto: Daemon mode to automatically reset display\n\nInstallation\n\nPackage (AUR)\n\n$ pacaur -S mons\n\n\nPackage (FreeBSD)\n\n# pkg install mons\n\n\nManual\n\n$ git clone --recursive https://github.com/Ventto/mons.git\n$ cd mons\n$ sudo make install\n\nNote: --recursive is needed for git submodule\n\nUsage\nWithout argument, it prints connected monitors list with their names and ids.\nOptions are exclusive and can be used in conjunction with extra options.\n\nInformation:\n  -h    Prints this help and exits.\n  -v    Prints version and exits.\n\nTwo monitors:\n  -o    Primary monitor only.\n  -s    Second monitor only.\n  -d    Duplicates the primary monitor.\n  -m    Mirrors the primary monitor.\n  -e <side>\n         Extends the primary monitor to the selected side\n         [ top | left | right | bottom ].\n  -n <side>\n         This mode selects the previous ones, one after another. The argument\n         sets the side for the extend mode.\n\nMore monitors:\n  -O <mon>\n        Only enables the monitor with a specified id.\n  -S <mon1>,<mon2>:<pos>\n        Only enables two monitors with specified ids. The specified position\n        places the second monitor on the right (R) or at the top (T).\n\nDaemon mode:\n  -a    Performs an automatic display if it detects only one monitor.\n  -x <script>\n        Must be used in conjunction with the -a option. Every time the number\n        of connected monitors changes, mons calls the given script with the\n        MONS_NUMBER environment variable.\n\nExtra (in-conjunction or alone):\n  --dpi <dpi>\n        Set the DPI, a strictly positive value within the range [0 ; 27432].\n  --primary <mon_name>\n        Select a connected monitor as the primary output. Run the script\n        without argument to print monitors information, the names are in the\n        second column between ids and status. The primary monitor is marked\n        by an asterisk.\n\nExamples\nTwo monitors\nDisplays monitor list:\n$ mons\n0: LVDS-1   (enabled)\n5: VGA-1\n\nYou have an enabled one, you want to extends the second one on the right:\n$ mons -e right\n\nYou want to only display the second one:\n$ mons -s\n\nWith the -n option, go through every 2-mons mode consecutively:\n\nPrimary monitor only\nSecond monitor only\nExtend mode whose the side is set with -n <side>\nMirror\nDuplicate\n\nThis mode is useful if you want to switch to every mode with only one shortcut.\n\n# Now in 'Second monitor mode'\n$ mons -n right # -> 'Extend mode'\n# Now in 'Extend mode'\n$ mons -n right # -> 'Mirror mode'\nThree monitors (selection mode)\nDisplays monitor list:\n$ mons\nMonitors: 3\nMode: Selection\n0:* LVDS-1   (enabled)\n1: DP-1      (enabled)\n5: VGA-1\n\nYou may need to display only the third one:\n$ mons -O 5\n\nYou may need to display the first and the third one on the right:\n$ mons -S 0,5:R\n\nLike above but you want to inverse the placement:\n$ mons -S 5,0:R\n\nDPI value\nYou might want to switch mode and set the DPI value.\nUse the --dpi <dpi> option in conjunction with all others options.\n$ mons [OPTIONS] --dpi <dpi>\n\nPrimary monitor\nYou might choose one of your monitors as the main one.\nYou can use the --primary <mon_name> option alone or in conjunction with all\nothers options.\n<mon_name> refers to the monitor name that appears in the list of connected\nmonitors (ex: LVDS-1 or VGA-1):\n$ mons\nMonitors: 3\nMode: Primary\n0:* LVDS-1   (enabled)\n5:  VGA-1\n\nThe * character means that the monitor is the primary one:\n$ mons --primary VGA-1\nMonitors: 3\nMode: Primary\n0:  LVDS-1   (enabled)\n5:* VGA-1\n\nDaemon mode\nThis mode is useful for laptops. After unplugging all monitors except the last\none, mons's \"daemon\" mode will reset the display and enable the latter.\nUse case: \"I connect a monitor to my laptop and I only want to work with that\none, so I disable the native one. After a while, I will unplug the\nadditional monitor and I need reset my display to re-activate the native one.\"\n\nRun it as following:\n\n$ nohup mons -a > /dev/null 2>&1 &  (all shells)\n$ mons -a &!                        (zsh)\n$ mons -a &; disown                 (bash)\n\nYou can handle N-monitors on your own by using the -x option. mons will\nexport the ${MONS_NUMBER} environment variable and run the given Shell script\neverytime the number of connected monitors changes:\n\n$ mons -a -x \"<path>/generic-handler.sh\"\n\n# Use it as configuration profiles:\n$ mons -a -x \"<path>/home-profile.sh\"\n$ mons -a -x \"<path>/work-profile.sh\"\n\nExample of script.sh:\n\n#!/bin/sh\n\ncase ${MONS_NUMBER} in\n    1)\n        mons -o\n        feh --no-fehbg --bg-fill \"${HOME}/wallpapers/a.jpg\"\n        ;;\n    2)\n        mons -e top\n        feh --no-fehbg --bg-fill \"${HOME}/wallpapers/a.jpg\" \\\n                       --bg-fill \"${HOME}/wallpapers/b.jpg\"\n        ;;\n    *)\n        # Handle it manually\n        ;;\nesac\n\n\n\n\n\n\n\n\nAbout\n\n      POSIX Shell script to quickly manage monitors on X\n    \nTopics\n\n\n\n  xrandr\n\n\n  manage\n\n\n  monitor\n\n\n  screen\n\n\n  laptop\n\n\n  display\n\n\n  arch-linux\n\n\n  linux\n\n\n  ubuntu\n\n\n  posix\n\n\n  projector\n\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        MIT License\n    \n\n\n\n\n\n\n\n    Releases\n      5\n\n\n\n\n\nv0.8.2\n\n          Latest\n \nJan 9, 2018\n\n \n\n        + 4 releases\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 7\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\nShell\n94.3%\n\n\n\n\n\nMakefile\n5.7%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# mons\n\n> A tool to quickly manage two displays.\n> More information: <https://github.com/Ventto/mons>.\n\n- Enable only the primary monitor:\n\n`mons -o`\n\n- Enable only the secondary monitor:\n\n`mons -s`\n\n- Duplicate the primary monitor onto the secondary monitor, using the resolution of the primary monitor:\n\n`mons -d`\n\n- Mirror the primary monitor onto the secondary monitor, using the resolution of the secondary monitor:\n\n`mons -m`\n"
 },
 {
   "command": "dmidecode",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dmidecode\n\n> Display the DMI (alternatively known as SMBIOS) table contents in a human-readable format.\n> Requires root privileges.\n\n- Show all DMI table contents:\n\n`sudo dmidecode`\n\n- Show the BIOS version:\n\n`sudo dmidecode -s bios-version`\n\n- Show the system's serial number:\n\n`sudo dmidecode -s system-serial-number`\n\n- Show BIOS information:\n\n`sudo dmidecode -t bios`\n\n- Show CPU information:\n\n`sudo dmidecode -t processor`\n\n- Show memory information:\n\n`sudo dmidecode -t memory`\n"
 },
 {
   "command": "apt-cache",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apt-cache\n\n> Debian and Ubuntu package query tool.\n\n- Search for a package in your current sources:\n\n`apt-cache search {{query}}`\n\n- Show information about a package:\n\n`apt-cache show {{package}}`\n\n- Show whether a package is installed and up to date:\n\n`apt-cache policy {{package}}`\n\n- Show dependencies for a package:\n\n`apt-cache depends {{package}}`\n\n- Show packages that depend on a particular package:\n\n`apt-cache rdepends {{package}}`\n"
 },
 {
   "command": "powertop",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# powertop\n\n> Optimize battery power usage.\n\n- Calibrate power usage measurements:\n\n`sudo powertop --calibrate`\n\n- Generate HTML power usage report in the current directory:\n\n`sudo powertop --html={{power_report.html}}`\n\n- Tune to optimal settings:\n\n`sudo powertop --auto-tune`\n"
 },
 {
   "command": "a2query",
   "doc_url": "https://manpages.debian.org/buster/apache2/a2query.1.en.html",
   "doc_text": "\n\n\n\na2query(1) — apache2 — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / apache2\n     \n     \n     \n     / a2query(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXIT CODES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.4.38-3+deb10u3\n\n\nbuster-backports 2.4.46-1~bpo10+1\n\n\ntesting 2.4.46-1\n\n\nunstable 2.4.46-1\n\n\n\n\n\n\nScroll to navigation\n\n\n\nA2QUERY.IN(1)\nUser Contributed Perl Documentation\nA2QUERY.IN(1)\n\n\n\n\n\nNAME¶\na2query - retrieve runtime configuration from a local Apache 2 HTTP server\n\n\nSYNOPSIS¶\na2query [-m [MODULE]] [-s [SITE]] [-c [CONF]] [-a]\n  [-v] [-M] [-d] [-h]\n\n\nDESCRIPTION¶\na2query is a program designed to retrieve configuration values from a\n  locally available Apache 2 HTTP web server. It was designed to be as robust as\n  possible by returning feasible values even if the Apache 2 syntax validator\n  fails.\nThis program is primarily meant to be used from maintainer\n    scripts.\n\n\nOPTIONS¶\n\n-a\nReturns the Apache 2 \"Module Magic Version\" (API version)\n      number, the server was compiled with. The returned version does not\n      contain any minor versions which are known to be compatible with the major\n      version returned.\n-c [CONF]\nChecks whether the configuration CONF is enabled. If no argument\n      was given, all enabled configuration files are being returned. CONF\n      is compared by string comparison by ignoring a leading \"mod_\"\n      prefix and possibly a '.conf' or '.load' suffix.\n-h\nDisplays a brief summary how the program can be called and exits.\n-m [MODULE]\nChecks whether the module MODULE is enabled, The argument is\n      interpreted in the same way, as for configuration files queried by the -c\n      switch.\n-M\nReturns the currently enabled Apache 2 MPM (Multi Processing Module).\n-s [SITE]\nChecks whether the module SITE is enabled, The argument is\n      interpreted in the same way, as for configuration files queried by the -c\n      switch.\n-v\nreturns the currently installed Apache 2 HTTP server version\n-q\nsuppress any output. This is useful to invoke a2query from another script.\n      This is useful if only the return code is of interest.\n\n\n\nEXIT CODES¶\na2query returns with a zero (0) exit status if the requested operation\n  was effectuated successfully and with a non-zero status otherwise. In case of\n  an error it leaves with error code 32 if a requested module, site or\n  configuration was not found and 33 if a module, site or configuration was\n  disabled by a maintainer script. However, exit status 1 is returned if the\n  module was not found at all\n\n\nSEE ALSO¶\napache2ctl(8), apache2(8), perl(1)\n\n\nAUTHOR¶\nThis manual and a2query was written by Arno Toell <debian@toell.net>.\n\n\n\n\n2019-10-15\nperl v5.28.1\n\n\n\n\n\n\n\n\n\nSource file:\n\n\na2query.1.en.gz (from apache2 2.4.38-3+deb10u3)\n\n\n\n\nSource last updated:\n\n\n2019-10-15T19:53:42Z\n\n\n\n\nConverted to HTML:\n\n\n2020-09-01T03:18:55Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# a2query\n\n> Retrieve runtime configuration from Apache on Debian-based OSes.\n> More information: <https://manpages.debian.org/buster/apache2/a2query.1.en.html>.\n\n- List enabled Apache modules:\n\n`sudo a2query -m`\n\n- Check if a specific module is installed:\n\n`sudo a2query -m {{module_name}}`\n\n- List enabled virtual hosts:\n\n`sudo a2query -s`\n\n- Display the currently enabled Multi Processing Module:\n\n`sudo a2query -M`\n\n- Display the Apache version:\n\n`sudo a2query -v`\n"
 },
 {
   "command": "xbps",
   "doc_url": "https://github.com/void-linux/xbps",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - void-linux/xbps: The X Binary Package System\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvoid-linux\n\n/\n\nxbps\n\n\n\n\n\n\n\n    Watch\n \n      29\n    \n\n\n\n\n      Star\n\n\n      285\n    \n\n\n\n\n          Fork\n\n\n        57\n      \n\n\n\n\n\n        The X Binary Package System\n      \n\n\n\nvoidlinux.org/xbps/\n\n\n\n\n\n            View license\n        \n\n\n\n\n285\n        stars\n \n\n57\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n37\n \n\n\n\nPull requests\n27\n \n\n\n\nActions\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n90\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nDuncaen\n\ntests: new test case for updating \"unpacked\" packages\n\n\n\n…\n\n\n\n05ff04a\n\nJul 17, 2020\n\n\n\n\n\ntests: new test case for updating \"unpacked\" packages\n\n\n05ff04a\n\n\n\nGit stats\n\n\n\n\n\n3,618\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github/workflows\n\n\n \n\n\n \n\n\n\n\n\n\n\nbin\n\n\n \n\n\n \n\n\n\n\n\n\n\ndata\n\n\n \n\n\n \n\n\n\n\n\n\n\ndoc\n\n\n \n\n\n \n\n\n\n\n\n\n\ninclude\n\n\n \n\n\n \n\n\n\n\n\n\n\nlib\n\n\n \n\n\n \n\n\n\n\n\n\n\nmk\n\n\n \n\n\n \n\n\n\n\n\n\n\ntests\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\n.travis.yml\n\n\n \n\n\n \n\n\n\n\n\n\n\n3RDPARTY\n\n\n \n\n\n \n\n\n\n\n\n\n\nAUTHORS\n\n\n \n\n\n \n\n\n\n\n\n\n\nLICENSE\n\n\n \n\n\n \n\n\n\n\n\n\n\nLICENSE.3RDPARTY\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile\n\n\n \n\n\n \n\n\n\n\n\n\n\nNEWS\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\nTODO\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfigure\n\n\n \n\n\n \n\n\n\n\n\n\n\nrun-tests\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\nXBPS\nThe X Binary Package System (in short XBPS) is a binary package system\ndesigned and implemented from scratch. Its goal is to be fast, easy to use,\nbug-free, featureful and portable as much as possible.\nThe XBPS code is totally compatible with POSIX/SUSv2/C99 standards, and\nreleased with a Simplified BSD license (2 clause). There is a well\ndocumented API provided by the XBPS Library that is the basis for its frontends\nto handle binary packages and repositories. Some highlights:\n\nSupports multiple local/remote repositories (HTTP/HTTPS/FTP).\nRSA signed remote repositories (NEW in 0.27).\nSupports multiple compression formats for repositories:\ngzip (zlib), bzip2, lz4, xz, zstd (default).\nSupports multiple compression formats for package archives:\ngzip (zlib), bzip2, lz4, xz, zstd (default).\nSHA256 hashes for package metadata, files and binary packages.\nSupports package states (ala dpkg) to mitigate broken package\ninstalls/updates.\nAbility to resume partial package install/updates.\nAbility to unpack only files that have been modified in package updates.\nAbility to use virtual packages.\nAbility to ignore completely any number of packages in dependency resolution.\nAbility to check for incompatible shared libraries in reverse\ndependencies.\nAbility to update reverse dependencies of any number of packages or globally\nin a single transaction.\nAbility to replace packages.\nAbility to put packages on hold (to never update them. NEW in 0.16).\nAbility to preserve/update configuration files.\nAbility to force reinstallation of any installed package.\nAbility to downgrade any installed package.\nAbility to execute pre/post install/remove/update scriptlets.\nAbility to check package integrity: missing files, hashes, missing or\nunresolved (reverse)dependencies, dangling or modified symlinks, etc.\n\nXBPS contains an almost complete test suite, currently with ~200 test cases,\nand its number is growing daily! If you find any issue and you can reproduce it,\nwe will fix it and a new test case will be created. No more regressions!\nXBPS is brought to you by:\n\nJuan Romero Pardines (main author)\nEnno Boland\nDuncan Overbruck\n\nand many other contributors in the free community that have helped improving it.\nSee the AUTHORS file for a complete list of contributors.\nThanks to all who have contributed.\nBuild requirements\nTo build this you'll need:\n\nA C99 compiler (clang, gcc, pcc, tcc)\nA POSIX compatible shell\nGNU make\npkgconf\nzlib\nopenssl or libressl\nlibarchive >= 3.3.3 with lz4 and zstd support.\n\nand optionally:\n\ngraphviz and doxygen\n(--enable-api-docs) to build API documentation.\natf >= 0.15 (--enable-tests) to build the\nKyua test suite.\n\nBuilding and testing for dummies\n$ git clone https://github.com/void-linux/xbps\n$ cd xbps\n$ ./configure --enable-rpath --prefix=/usr --sysconfdir=/etc\n$ make -j$(nproc)\n$ make DESTDIR=~/xbps-git install clean\n$ export PATH=~/xbps-git/usr/bin:$PATH\n$ xbps-query -V\n...\n\nThanks to --enable-rpath you can install it anywhere and it will still use\nthe libxbps shared library at $ORIGIN/../lib, that means that if xbps\nis installed to $HOME/xbps-git/usr, the executables will use\n$HOME/xbps-git/usr/lib to locate libxbps.\nHappy testing!\nTests\nTo run the test suite make sure kyua is installed and run the following:\n$ ./configure --enable-tests\n$ make\n$ make check\n\nBuild instructions\nStandard configure script (not generated by GNU autoconf).\n$ ./configure --prefix=/blah\n$ make -jX\n$ make install\n\nBy default PREFIX is set /usr/local and may be changed by setting --prefix\nin the configure script. The DESTDIR variable is also supported at the\ninstall stage.\nThere are some more options that can be tweaked, see them with\n./configure --help.\nGood luck!\nBinaries\nBinaries for Linux compiled statically with the musl C library are available:\n\naarch64\narmv6hf\ni686\nx86_64\nmips32\n\nThese builds are available on all official void mirrors, along with their\nsha256 checksums.\nUsage instructions\nThe xbps package includes the following utilities (among others, not a complete list):\n\nxbps-create (1)      - XBPS utility to create binary packages\nxbps-dgraph (1)      - XBPS utility to generate dot(1) graphs\nxbps-install (1)     - XBPS utility to install and update packages\nxbps-pkgdb (1)       - XBPS utility to report and fix issues in pkgdb\nxbps-query (1)       - XBPS utility to query for package and repository information\nxbps-reconfigure (1) - XBPS utility to configure installed packages\nxbps-remove (1)      - XBPS utility to remove packages\nxbps-rindex (1)      - XBPS utility to handle local binary package repositories\n\nIn the following sections there will be a brief description of how these utilities currently work.\nPackage expressions\nIn the following examples there will be commands accepting an argument such as <package expression>. A package expression is a form to match a pattern; currently XBPS >= 0.19 supports 3 ways to specify them:\n\n\nby specifying a package name, i.e foo.\n\n\nby specifying the exact package name and version, i.e foo-1.0_1.\n\n\nby specifying a package name and version separated by any of the following version comparators:\n\n< less than\n> greater than\n<= less or equal than\n>= greater or equal than\n\nSuch example would be foo>=2.0 or blah-foo<=1.0.\n\n\nRepositories\nRepositories can be declared in a configuration file of the configuration or system configuration directories:\n\n<sysconfdir>/xbps.d - The configuration directory (set to /etc/xbps.d)\n<sharedir>/xbps.d - The system directory (set to /usr/share/xbps.d)\n\nA configuration file bearing the same filename in /etc/xbps.d overrides the one from <sharedir>/xbps.d.\nBy default the XBPS package provides only the main Void repository in the /usr/share/xbps.d/00-repository-main.conf file.\nAdditional repositories can be added by installing any of the following XBPS packages or creating new configuration files manually:\n$ xbps-query -Rs void-repo\n[*] void-repo-debug-3_1            Void Linux drop-in file for the debug repository\n[*] void-repo-multilib-3_1         Void Linux drop-in file for the multilib repository\n[*] void-repo-multilib-nonfree-3_1 Void Linux drop-in file for the multilib/nonfree repository\n[*] void-repo-nonfree-3_1          Void Linux drop-in file for the nonfree repository\n$\n\n\nRepositories specified in the configuration directory are added to the head of the list, while repositories specified via system configuration directories are appended to the existing list.\n\n\nIf no repositories are found it's possible to declare them manually via the command line option --repository, currently accepted in xbps-install(1) and xbps-query(1).\n\nxbps-query - querying packages and repositories\n\nxbps-query(1) will try to match <package expression> in local packages. This behaviour\ncan be changed by enabling the -R or --repository option to force repository mode.\n\nTo query the list of installed packages:\n$ xbps-query -l\n\nTo query the list of working repositories:\n$ xbps-query -L\n\nTo query the list of installed packages that were installed manually (not as dependencies):\n$ xbps-query -m\n\nTo query the list of packages on hold (won't be upgraded automatically):\n$ xbps-query -H\n\nTo query the list of installed package orphans (packages that were installed as dependencies but there is not any package currently that requires it):\n$ xbps-query -O\n\nTo query a package and show its meta information:\n$ xbps-query <package expression>\n\n\nAdditionally the -p or --property option can be used to only show a specific key of a package:\n\n$ xbps-query --property=pkgver xbps\nxbps-0.19_1\n$\n\n\nMultiple properties can be specified by delimiting them with commas, i.e -p key,key2.\n\nTo query a package and show its file list:\n$ xbps-query -f <package expression>\n\nTo query a package and show required run-time dependencies:\n$ xbps-query -x <package expression>\n\nTo query a package and show required reverse run-time dependencies:\n$ xbps-query -X <package expression>\n\nTo query for packages matching a file with specified pattern(s) (ownedby mode):\n$ xbps-query -o <pattern>\n\n\nWhere <pattern> is a shell wildcard pattern as explained in fnmatch(3); e.g \"*.png\".\n\n\nMultiple <patterns> can be specified as arguments.\n\nTo query for packages matching pkgname/version/description with specified pattern(s) (search mode):\n$ xbps-query -s <pattern>\n\n\nThe same rules explained above in the ownedby mode shall be applied.\n\nxbps-install - installing and updating packages\nTo synchronize remote repository index files:\n$ xbps-install -S\n\n\nThe -S, --sync option can be combined while installing or updating packages, i.e xbps-install -Su.\n\nTo install a package:\n$ xbps-install <package expression>\n\nTo install multiple packages at once:\n$ xbps-install <package expression> <package expressions>\n\nTo update a single package:\n$ xbps-install -u <package expression>\n\nTo update all packages (also known as dist-upgrade in Debian/Ubuntu):\n$ xbps-install -u\n\n\nThe -n, --dry-run option can be used to print what packages will be updated and/or installed and doesn't need permissions in the target rootdir, which can be useful to list updates.\n\nxbps-remove - removing packages\nTo remove a package:\n$ xbps-remove <package name>\n\nTo recursively remove unneeded dependencies that were installed by the target package:\n$ xbps-remove -R <package name>\n\nTo remove package orphans:\n$ xbps-remove -o\n\nTo clean the cache directory and remove outdated packages and/or packages with wrong hash:\n$ xbps-remove -O\n\n\nTo remove package orphans and clean the cache repository both options can be combined, i.e xbps-remove -Oo.\n\nxbps-reconfigure - configure (or force configuration of) a package\nThe xbps-reconfigure(1) utility may be used to configure packages that were not previously\n(perhaps due to a power outage, process killed, etc) or simply to force package\nreconfiguration. By default and unless the -f, --force option is set, only packages that\nwere not configured will be processed.\nIts usage is simple, specify a package name or a, --all for all packages:\n$ xbps-reconfigure [-f] <package name> | -a\n\nxbps-pkgdb - checking for errors in packages and pkgdb\nThe xbps-pkgdb(1) utility may be used to check for errors in packages and in the package database.\nIt is also used to update the package database format (if there have been changes). It works exactly the\nsame way as xbps-reconfigure(1) and expects a package name or -a, --all for all packages.\n$ xbps-pkgdb <package name> | -a\n\nTo put a package on hold mode (won't be upgraded in dist-upgrade mode):\n$ xbps-pkgdb -m hold <package name>\n\nTo remove a package from hold mode:\n$ xbps-pkgdb -m unhold <package name>\n\nTo put a package in automatic mode (as it were installed as a dependency):\n$ xbps-pkgdb -m auto <package name>\n\nTo put a package in manual mode (won't be detected as orphan):\n$ xbps-pkgdb -m manual <package name>\n\nTo update the pkgdb format to the latest one:\n$ xbps-pkgdb -u\n\n\nNOTE: updating the pkgdb format does not happen too frequently, therefore it's only necessary in rare circumstances.\n\nxbps-rindex - Create, update and administer local repositories\nThis command only has 3 operation modes:\n\n\nAdd [-a, --all]: adds the specified packages into the specified repository and removes previous entry if found:\n $ xbps-rindex -a /path/to/repository/*.xbps\n\n\n\n\nThe -f, --force option can be used to forcefully register a package into the repository index, even if the same version is already registered.\n\n\n\nClean [-c, --clean]: cleans the index of the specified repository by removing outdated or invalid entries (nonexistent packages, unmatched hashes, etc):\n $ xbps-rindex -c /path/to/repository\n\n\n\nRemove-obsoletes [-r, --remove-obsoletes]: removes obsolete packages in repository (outdated, broken and unmatched hashes):\n $ xbps-rindex -r /path/to/repository\n\n\n\nExamples\nUpgrade all packages in the system, without asking for an answer:\n# xbps-install -Syu\n\nClean the cache directory and remove package orphans:\n# xbps-remove -Oo\n\nShow information of a package available in repositories:\n$ xbps-query -R xbps\n\nShow filelist of a package available in repositories:\n$ xbps-query -Rf xbps\n\nFind the packages that own the file /bin/ls in repositories:\n$ xbps-query -Ro /bin/ls\n\nMake a package keepable (won't be detected as orphan):\n# xbps-pkgdb -m manual xbps\n\nSearch for packages in repositories matching the xbps pattern in its pkgver and short_desc objects:\n$ xbps-query -Rs xbps\n\nRemove a package and all unnecessary dependencies that were installed:\n# xbps-remove -R xbmc\n\nAppending repositories via command line:\n$ xbps-query --repository=<url> ...\n# xbps-install --repository=<url> ...\n\nSwitch an installed package to on hold mode (won't be updated via xbps-install -u):\n# xbps-pkgdb -m hold <pkgname>\n\nSwitch an installed package to the unhold mode (will be updated if there are updates):\n# xbps-pkgdb -m unhold <pkgname>\n\nCheck for errors on installed packages and in pkgdb:\n# xbps-pkgdb -a\n\nListing all files not managed by xbps:\n#!/bin/sh\n\ntmp=$(mktemp -dt xbps-disownedXXXXXX)\npkg=$tmp/pkg\nfs=$tmp/fs\n\ntrap \"rm -rf $tmp\" EXIT\n\nxbps-query -o \\* | cut -d ' ' -f2 | sort > $pkg\nfind /boot /etc /opt /usr /var -xdev -type f -print | sort > $fs\n\ncomm -23 $fs $pkg\n\n\n\n\n\n\n\n\nAbout\n\n      The X Binary Package System\n    \n\n\n\nvoidlinux.org/xbps/\n\n\nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n\n\n\n90\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 46\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 35 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\nC\n73.8%\n\n\n\n\n\nShell\n19.3%\n\n\n\n\n\nRoff\n5.3%\n\n\n\n\n\nMakefile\n1.4%\n\n\n\n\n\nC++\n0.2%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# xbps\n\n> The X Binary Package System (or xbps) is the binary package system used by Void Linux.\n> More information: <https://github.com/void-linux/xbps>.\n\n- Install packages and synchronize them with the remote repository:\n\n`xbps-install --synchronize {{package_name1}} {{package_name2}}`\n\n- Search for a package in the remote repository:\n\n`xbps-query --repository -s {{package_name}}`\n\n- Remove a package, leaving all of its dependencies installed:\n\n`xbps-remove {{package_name}}`\n\n- Remove a package and all of its dependencies recursively that are not required by other packages:\n\n`xbps-remove --recursive {{package_name}}`\n\n- Synchronize your repository databases and update your system and dependencies:\n\n`xbps-install --synchronize -u`\n\n- Remove packages that were installed as dependencies and aren't currently needed:\n\n`xbps-remove --remove-orphans`\n\n- Remove obsolete packages from the cache:\n\n`xbps-remove --clean-cache`\n"
 },
 {
   "command": "a2enconf",
   "doc_url": "https://manpages.debian.org/buster/apache2/a2enconf.8.en.html",
   "doc_text": "\n\n\n\na2enconf(8) — apache2 — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / apache2\n     \n     \n     \n     / a2enconf(8)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXIT STATUS\n\n\nEXAMPLES\n\n\nFILES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.4.38-3+deb10u3\n\n\nbuster-backports 2.4.46-1~bpo10+1\n\n\ntesting 2.4.46-1\n\n\nunstable 2.4.46-1\n\n\n\n\n\n\nScroll to navigation\n\n\n\nA2ENCONF(8)\nSystem Manager's Manual\nA2ENCONF(8)\n\n\n\n\nNAME¶\na2enconf, a2disconf - enable or disable an apache2 configuration file\n\n\nSYNOPSIS¶\na2enconf [ [-q|--quiet] configuration]\na2disconf [ [-q|--quiet] configuration]\n\n\nDESCRIPTION¶\nThis manual page documents briefly the a2enconf and a2disconf\n  commands.\na2enconf is a script that enables the specified\n    configuration file within the apache2 configuration. It does this by\n    creating symlinks within /etc/apache2/conf-enabled. Likewise,\n    a2disconf disables a specific configuration part by removing those\n    symlinks. It is not an error to enable a configuration which is already\n    enabled, or to disable one which is already disabled.\nNote that many configuration file may have a dependency to\n    specific modules. Unlike module dependencies, these are not resolved\n    automatically. Configuration fragments stored in the conf-available\n    directory are considered non-essential or being installed and manged by\n    reverse dependencies (e.g. web scripts).\n\n\nOPTIONS¶\n\n-q, --quiet\nDon't show informative messages.\n-m, --maintmode\nEnables the maintainer mode, that is the program invocation is effectuated\n      automatically by a maintainer script. This switch should not be used by\n      end users.\n-p, --purge\nWhen disabling a module, purge all traces of the module in the internal\n      state data base.\n\n\n\nEXIT STATUS¶\na2enconf and a2disconf exit with status 0 if all\n  configurations are processed successfully, 1 if errors occur, 2 if an\n  invalid option was used.\n\n\nEXAMPLES¶\na2enconf security\n\na2disconf charset\nEnables Apache security directives stored in the security\n    configuration files, and disables the charset configuration.\n\n\nFILES¶\n\n/etc/apache2/conf-available\nDirectory with files giving information on available configuration\n    files.\n/etc/apache2/conf-enabled\nDirectory with links to the files in conf-available for enabled\n      configuration files.\n\n\n\nSEE ALSO¶\napache2ctl(8), a2enmod(8), a2dismod(8).\n\n\nAUTHOR¶\nThis manual page was written by Arno Toell <debian@toell.net> for the\n  Debian GNU/Linux distribution, as it is a Debian-specific script with the\n  package.\n\n\n\n\n14 February 2012\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\na2enconf.8.en.gz (from apache2 2.4.38-3+deb10u3)\n\n\n\n\nSource last updated:\n\n\n2019-10-15T19:53:42Z\n\n\n\n\nConverted to HTML:\n\n\n2020-09-01T03:18:55Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# a2enconf\n\n> Enable an Apache configuration file on Debian-based OSes.\n> More information: <https://manpages.debian.org/buster/apache2/a2enconf.8.en.html>.\n\n- Enable a configuration file:\n\n`sudo a2enconf {{configuration_file}}`\n\n- Don't show informative messages:\n\n`sudo a2enconf --quiet {{configuration_file}}`\n"
 },
 {
   "command": "netselect",
   "doc_url": "https://github.com/apenwarr/netselect",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - apenwarr/netselect: A parallelizing combination of ping/traceroute\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\napenwarr\n\n/\n\nnetselect\n\n\n\n\n\n\n\n    Watch\n \n      8\n    \n\n\n\n\n      Star\n\n\n      95\n    \n\n\n\n\n          Fork\n\n\n        17\n      \n\n\n\n\n\n        A parallelizing combination of ping/traceroute\n      \n\n\n\n95\n        stars\n \n\n17\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n2\n \n\n\n\nPull requests\n2\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n4\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n \n \nGit stats\n\n\n\n\n\n10\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\nnetinet\n\n\n \n\n\n \n\n\n\n\n\n\n\n.cvsignore\n\n\n \n\n\n \n\n\n\n\n\n\n\n.gitignore\n\n\n \n\n\n \n\n\n\n\n\n\n\nHISTORY\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.OS2\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.traceroute\n\n\n \n\n\n \n\n\n\n\n\n\n\nnetselect-apt\n\n\n \n\n\n \n\n\n\n\n\n\n\nnetselect-apt.1\n\n\n \n\n\n \n\n\n\n\n\n\n\nnetselect.1\n\n\n \n\n\n \n\n\n\n\n\n\n\nnetselect.c\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README\n      \n\n\n\nnetselect 0.3\n=============\n\nThis is netselect, an ultrafast intelligent parallelizing binary-search\nimplementation of \"ping.\"\n\nNow stop laughing and pay attention.\n\nnetselect determines several facts about all of the hosts given on the\ncommand line, much faster you would if you manually tried to use ping and\ntraceroute.  For example, if I type:\n\n\tnetselect -vv ftp.fceia.unr.edu.ar ftp.kulnet.kuleuven.ac.be \\\n\t\t\tftp.cdrom.com ftp.debian.org ftp.de.debian.org\n\t\t\t\nIt tells me this:\n\nftp.fceia.unr.edu.ar                  2792 ms  23 hops  100% ok ( 1/ 1) [ 9213]\nftp.kulnet.kuleuven.ac.be             9999 ms  30 hops    0% ok\nftp.cdrom.com                           94 ms   8 hops  100% ok (10/10) [  169]\nftp.debian.org                          46 ms  15 hops  100% ok (10/10) [  115]\nftp.de.debian.org                     9999 ms  30 hops    0% ok\n  115 ftp.debian.org\n  \nFor each host, it figures out the approximate ping time (though not as\naccurately as \"ping\" does), the number of network \"hops\" to reach the\ntarget, and the percentage of ping requests that got through successfully. \n\nThe value in brackets is the \"score\" of each operational host based on these\nvalues.  A lower score is better.  The last line shows the server with the\nbest score.  If we had not used '-vv' on the command line, only this last\nline would have been printed.\n\nNote that for ftp.kulnet.kuleuven.ac.be and ftp.de.debian.org in this case,\nnothing got through at all.  That indicates that either the host doesn't\nexist, or it is down.\n\nFor a bigger example, try netselect-apt to build your own sources.list for apt\nwith the (possibily) fastest debian mirror.\n\n\nBut Why?\n========\n\nWhy do I want to know about my ping times to computers in Belgium?  Well,\nthe main reason for netselect -- and its name gives you a hint -- is to help\nchoose the \"best\" server for you from among a (possibly very large) list.\n\nStarting with version 0.2, netselect can make these decisions for you using\nits scoring mechanism.  If you want, however, you can still pass the raw\nresults and score the servers as you like.  Try this, for example:\n\n\tnetselect -vv -s 0 $(cat <your_list_of_sites>)\n\t\nThe \"-s 0\" option disables printing of scores at the bottom of the list, and\n\"-vv\" enables printing of the statistics.\n\n\nHow does it work?\n=================\n\nFirst:\n\n - decode each hostname into an IP address, and stores each IP address into\n   a table.  In netselect 0.2, this code was rewritten to resolve hostnames\n   much more quickly than before.\n   \nNow for all hosts at once:\n   \n - start firing UDP packets with \"random-guess\" TTL values, much like\n   traceroute does.  Actually, the code for this is derived from traceroute.\n   \n - if an \"ICMP TTL Expired\" message comes back, then the TTL was too low:\n   the host is farther away than that.  Increase TTL next time.  Otherwise,\n   a \"Port Unreachable\" message comes back, meaning the TTL was large\n   enough.  Try a smaller one.  We do this until we narrow down the TTL. \n   (This is where the \"binary search\" comes in.)\n   \n - Meanwhile, collect timing statistics for all packets that reached the\n   host.  Packets that don't come back are considered lost.\n\nWhen all the hosts have had their TTL values narrowed down, and the \"-t\"\nminimum tries have expired, we're done.  Close the sockets and dump\nthe statistics to stdout.\n\n\n\nCommand-line Options\n====================\n\nNot much right now.  \n\n\t-v\t-- verbose mode.  Displays nameserver resolution messages to\n\t\t   stderr.  You probably want this so that you don't get\n\t\t   bored waiting for a hundred name resolutions to finish.\n\t\t   \n\t-vv\t-- very verbose mode.  Displays nameserver resolution and\n\t\t   statistics (not just scores) to stderr and stdout.\n\t\t   \n\t-vvv\t-- very very verbose mode.  Everything -vv prints, plus\n\t\t   print every packet received as it happens.  Good for\n\t\t   debugging or trying to figure out how it works.\n\t\n\t-vvvv   -- very very very verbose mode. Everything -vvv prints,\n\t\t   plus a trace of all packets sent.\n\t\t   \n\t-m #\t-- maximum ttl.  Don't accept hosts with more hops than\n\t\t   this.\n\t\t   \n\t-t #\t-- make sure at least 50% of the hosts get tested with this\n\t\t   many packets.  The more packets you use, the more\n\t\t   accurate the results... and the longer it takes to run.\n\t\t   The default is 10, which is usually okay.\n\t\n\t-s #\t-- print this many \"top-scoring\" servers at the end of\n\t\t   the list.  \"-s 0\" disables printing of high scores.\n\n\nThe Future\n==========\n\n\nHere are some possible improvements:\n\n\t- try to estimate line bandwidth somehow.  The 'bing' program does\n\t  it using two different ping packet sizes.\n\n\t- try to improve 'ping time' estimate.  It's a problem right now\n\t  because netselect writes a lot of packets in a quick stream (for\n\t  speed reasons).  It's fair to each host, though:  they all put up\n\t  with an equal amount of lag :)\n\nThis program is highly experimental.  Please let me know what you think.\n\n\t- Avery Pennarun\n\t  <apenwarr@gmail.com>\n\n\n\n\n\n\n\n\nAbout\n\n      A parallelizing combination of ping/traceroute\n    \nResources\n\n\n\n      Readme\n \n\n\n\n\n\n\n    Releases\n\n\n\n4\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\nC\n100.0%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# netselect\n\n> Speed test for choosing a fast network server.\n> More information: <https://github.com/apenwarr/netselect> .\n\n- Choose the server with the lowest latency:\n\n`sudo netselect {{host_1}} {{host_2}}`\n\n- Display nameserver resolution and statistics:\n\n`sudo netselect -vv {{host_1}} {{host_2}}`\n\n- Define maximum TTL (time to live):\n\n`sudo netselect -m {{10}} {{host_1}} {{host_2}}`\n\n- Print fastest N servers among the hosts:\n\n`sudo netselect -s {{N}} {{host_1}} {{host_2}} {{host_3}}`\n\n- List available options:\n\n`netselect`\n"
 },
 {
   "command": "mkfs.minix",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs.minix\n\n> Creates a Minix filesystem inside a partition.\n\n- Create a Minix filesystem inside partition 1 on device b (`sdb1`):\n\n`mkfs.minix {{/dev/sdb1}}`\n"
 },
 {
   "command": "debman",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# debman\n\n> Read man pages from uninstalled packages.\n\n- Read a man page for a command that is provided by a specified package name:\n\n`debman -p {{package_name}} {{command_name}}`\n\n- Specify a package version to download:\n\n`debman -p {{package_name}}={{version}} {{command_name}}`\n\n- Read a man page in a .deb file:\n\n`debman -f {{path/to/filename.deb}} {{command_name}}`\n"
 },
 {
   "command": "tlp-stat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# tlp-stat\n\n> A tool to generate TLP status reports. See also `tlp`.\n\n- Generate status report with configuration and all active settings:\n\n`sudo tlp-stat`\n\n- Show battery information:\n\n`sudo tlp-stat -b`\n\n- Show configuration:\n\n`sudo tlp-stat -c`\n"
 },
 {
   "command": "bpytop",
   "doc_url": "https://github.com/aristocratos/bpytop",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - aristocratos/bpytop: Linux/OSX/FreeBSD resource monitor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naristocratos\n\n/\n\nbpytop\n\n\n\n\n\n\n\n\n          Sponsor\n        \n\n\n\n\n\n\n              Sponsor aristocratos/bpytop\n            \n\n\n\n\n\n\n\n\n\n\n\n\n    Watch\n \n      83\n    \n\n\n\n\n      Star\n\n\n      2.7k\n    \n\n\n\n\n          Fork\n\n\n        88\n      \n\n\n\n\n\n        Linux/OSX/FreeBSD resource monitor\n      \n\n\n\n            Apache-2.0 License\n        \n\n\n\n\n2.7k\n        stars\n \n\n88\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n18\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n38\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\naristocratos\n\nv1.0.37 Bug fixes\n\n\n\n…\n\n\n\nc4fa23e\n\nSep 22, 2020\n\n\n\n\n\nv1.0.37 Bug fixes\n\n\nc4fa23e\n\n\n\nGit stats\n\n\n\n\n\n203\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github\n\n\n\nadded psutil verion requirement\n\n\n\nAug 3, 2020\n\n\n\n\n\n\n\nImgs\n\n\n\nv1.0.0 First release\n\n\n\nAug 2, 2020\n\n\n\n\n\n\n\nthemes\n\n\n\nadded email/theme name\n\n\n\nSep 10, 2020\n\n\n\n\n\n\n\n.editorconfig\n\n\n\nnaming...\n\n\n\nAug 2, 2020\n\n\n\n\n\n\n\n.gitignore\n\n\n\nAdded theme install and path detection\n\n\n\nAug 22, 2020\n\n\n\n\n\n\n\nCHANGELOG.md\n\n\n\nv1.0.37 Bug fixes\n\n\n\nSep 22, 2020\n\n\n\n\n\n\n\nCODE_OF_CONDUCT.md\n\n\n\nInit\n\n\n\nJul 1, 2020\n\n\n\n\n\n\n\nCONTRIBUTING.md\n\n\n\nAdded NetBox draw function and added mouse support\n\n\n\nJul 20, 2020\n\n\n\n\n\n\n\nLICENSE\n\n\n\nInit\n\n\n\nJul 1, 2020\n\n\n\n\n\n\n\nMakefile\n\n\n\nv1.0.0 First release\n\n\n\nAug 2, 2020\n\n\n\n\n\n\n\nREADME.md\n\n\n\nAdded mx-linux install instructions\n\n\n\nSep 20, 2020\n\n\n\n\n\n\n\nbpytop-themes\n\n\n\nAdded theme install and path detection\n\n\n\nAug 22, 2020\n\n\n\n\n\n\n\nbpytop.py\n\n\n\nv1.0.37 Bug fixes\n\n\n\nSep 22, 2020\n\n\n\n\n\n\n\npoetry.lock\n\n\n\nAdd psutil 5.7.2 (^5.7.0)\n\n\n\nAug 22, 2020\n\n\n\n\n\n\n\npyproject.toml\n\n\n\nv1.0.37 Bug fixes\n\n\n\nSep 22, 2020\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndex\n\nDocuments\nDescription\nFeatures\nThemes\nSupport and funding\nPrerequisites\nDependencies\nScreenshots\nInstallation\nConfigurability\nTODO\nLicense\n\nDocuments\nCHANGELOG.md\nCONTRIBUTING.md\nCODE_OF_CONDUCT.md\nDescription\nResource monitor that shows usage and stats for processor, memory, disks, network and processes.\nPython port of bashtop.\nFeatures\n\nEasy to use, with a game inspired menu system.\nFull mouse support, all buttons with a highlighted key is clickable and mouse scroll works in process list and menu boxes.\nFast and responsive UI with UP, DOWN keys process selection.\nFunction for showing detailed stats for selected process.\nAbility to filter processes, multiple filters can be entered.\nEasy switching between sorting options.\nSend SIGTERM, SIGKILL, SIGINT to selected process.\nUI menu for changing all config file options.\nAuto scaling graph for network usage.\nShows message in menu if new version is available\nShows current read and write speeds for disks\n\nThemes\nBpytop uses the same theme files as bashtop so any theme made for bashtop will work.\nSee themes folder for available themes.\nThe make install command places the default themes in /usr/local/share/bpytop/themes.\nIf installed with pip3 the themes will be located in a folder called bpytop-themes in the python3 site-packages folder.\nUser created themes should be placed in $HOME/.config/bpytop/themes.\nLet me know if you want to contribute with new themes.\nSupport and funding\nYou can sponsor this project through github, see my sponsors page for options.\nOr donate through paypal or ko-fi.\nAny support is greatly appreciated!\nPrerequisites\nMac Os X\nWill not display correctly in the standard terminal!\nRecommended alternative iTerm2\nWill also need to be run as superuser to display stats for processes not owned by user.\nLinux, Mac Os X and FreeBSD\nFor correct display, a terminal with support for:\n\n24-bit truecolor (See list of terminals with truecolor support)\nWide characters (Are sometimes problematic in web-based terminals)\n\nAlso needs a UTF8 locale and a font that covers:\n\nUnicode Block “Braille Patterns” U+2800 - U+28FF\nUnicode Block “Geometric Shapes” U+25A0 - U+25FF\nUnicode Block \"Box Drawing\" and \"Block Elements\" U+2500 - U+259F\n\nNotice\nIf you are having problems with the characters in the graphs not looking like they do in the screenshots,\nit's likely a problem with your systems configured fallback font not having support for braille characters.\nSee comments by @sgleizes link and @XenHat link in issue #100 for possible solutions.\nNotice\nDropbear seems to not be able to set correct locale. So if accessing bpytop over ssh, OpenSSH is recommended.\nDependencies\nPython3 (v3.6 or later)\npsutil module (v5.7.0 or later)\nOptionals for additional stats\n(Optional OSX) coretemp (recommended), or osx-cpu-temp (less accurate) needed to show CPU temperatures.\nScreenshots\nMain UI showing details for a selected process.\n\nMain UI in mini mode.\n\nMain menu.\n\nOptions menu.\n\nInstallation\nPyPi (will always have latest version)\n\nInstall or update to latest version\n\npip3 install bpytop --upgrade\nArch Linux\nAvailable in the AUR as bpytop\nhttps://aur.archlinux.org/packages/bpytop/\nDebian based\nAvailable for debian/ubuntu from Azlux's repository\nFreeBSD package\nAvailable in FreeBSD ports\n\nInstall pre-built package\n\nsudo pkg install bpytop\nFedora/CentOS 8 package\nAvailable in the Fedora and EPEL-8 repository.\n\nInstallation\n\nsudo dnf install bpytop\nGentoo / Calculate Linux\nAvailable from adrien-overlay\n\nInstallation\n\nsudo emerge -av sys-process/bpytop\nMX Linux\nAvailable in the MX Test Repo as bpytop\nPlease use MX Package Installer MX Test Repo tab to install.\nhttp://mxrepo.com/mx/testrepo/pool/test/b/bpytop/\nSnap package\nby @kz6fittycent\nhttps://github.com/kz6fittycent/bpytop-snap\n\nInstall the package\n\nsudo snap install bpytop\n\nGive permissions\n\nsudo snap connect bpytop:mount-observe\nsudo snap connect bpytop:network-control\nsudo snap connect bpytop:hardware-observe\nsudo snap connect bpytop:system-observe\nsudo snap connect bpytop:process-control\nsudo snap connect bpytop:physical-memory-observe\nThe config folder will be located in ~/snap/bpytop/current/.config/bpytop\nManual installation\nDependencies installation Linux\n\nInstall python3 and git with a package manager of you choice\n\n\nInstall psutil python module (sudo might be required)\n\npython3 -m pip install psutil\nDependencies installation OSX\n\nInstall homebrew if not already installed\n\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n\nInstall python3 if not already installed\n\nbrew install python3 git\n\nInstall psutil python module\n\npython3 -m pip install psutil\n\nInstall optional dependency coretemp (recommended), or osx-cpu-temp (less accurate)\n\nbrew install hacker1024/hacker1024/coretemp\nbrew install osx-cpu-temp\nDependencies installation FreeBSD\n\nInstall with pkg and pip\n\nsudo pkg install git python3 py37-psutil\nManual installation Linux, OSX and FreeBSD\n\nClone and install\n\ngit clone https://github.com/aristocratos/bpytop.git\ncd bpytop\nsudo make install\n\nto uninstall it\n\nsudo make uninstall\nConfigurability\nAll options changeable from within UI.\nConfig files stored in \"$HOME/.config/bpytop\" folder\nbpytop.cfg: (auto generated if not found)\n\"/etc/bpytop.conf\" will be used as default seed for config file creation if it exists.\n#? Config file for bpytop v. 1.0.22\n\n#* Color theme, looks for a .theme file in \"/usr/[local/]share/bpytop/themes\" and \"~/.config/bpytop/themes\", \"Default\" for builtin default theme.\n#* Prefix name by a plus sign (+) for a theme located in user themes folder, i.e. color_theme=\"+monokai\"\ncolor_theme=\"Default\"\n\n#* If the theme set background should be shown, set to False if you want terminal background transparency\ntheme_background=False\n\n#* Set bpytop view mode, \"full\" for everything shown, \"proc\" for cpu stats and processes, \"stat\" for cpu, mem, disks and net stats shown.\nview_mode=full\n\n#* Update time in milliseconds, increases automatically if set below internal loops processing time, recommended 2000 ms or above for better sample times for graphs.\nupdate_ms=2000\n\n#* Processes sorting, \"pid\" \"program\" \"arguments\" \"threads\" \"user\" \"memory\" \"cpu lazy\" \"cpu responsive\",\n#* \"cpu lazy\" updates top process over time, \"cpu responsive\" updates top process directly.\nproc_sorting=\"cpu lazy\"\n\n#* Reverse sorting order, True or False.\nproc_reversed=False\n\n#* Show processes as a tree\nproc_tree=False\n\n#* Use the cpu graph colors in the process list.\nproc_colors=True\n\n#* Use a darkening gradient in the process list.\nproc_gradient=True\n\n#* If process cpu usage should be of the core it's running on or usage of the total available cpu power.\nproc_per_core=True\n\n#* Show process memory as bytes instead of percent\nproc_mem_bytes=True\n\n#* Check cpu temperature, needs \"osx-cpu-temp\" on MacOS X.\ncheck_temp=True\n\n#* Draw a clock at top of screen, formatting according to strftime, empty string to disable.\ndraw_clock=\"%X\"\n\n#* Update main ui in background when menus are showing, set this to false if the menus is flickering too much for comfort.\nbackground_update=True\n\n#* Custom cpu model name, empty string to disable.\ncustom_cpu_name=\"\"\n\n#* Optional filter for shown disks, should be last folder in path of a mountpoint, \"root\" replaces \"/\", separate multiple values with comma.\n#* Begin line with \"exclude=\" to change to exclude filter, oterwise defaults to \"most include\" filter. Example: disks_filter=\"exclude=boot, home\"\ndisks_filter=\"\"\n\n#* Show graphs instead of meters for memory values.\nmem_graphs=True\n\n#* If swap memory should be shown in memory box.\nshow_swap=True\n\n#* Show swap as a disk, ignores show_swap value above, inserts itself after first disk.\nswap_disk=True\n\n#* If mem box should be split to also show disks info.\nshow_disks=True\n\n#* Set fixed values for network graphs, default \"10M\" = 10 Mibibytes, possible units \"K\", \"M\", \"G\", append with \"bit\" for bits instead of bytes, i.e \"100mbit\"\nnet_download=\"100Mbit\"\nnet_upload=\"100Mbit\"\n\n#* Start in network graphs auto rescaling mode, ignores any values set above and rescales down to 10 Kibibytes at the lowest.\nnet_auto=True\n\n#* Sync the scaling for download and upload to whichever currently has the highest scale\nnet_sync=False\n\n#* If the network graphs color gradient should scale to bandwith usage or auto scale, bandwith usage is based on \"net_download\" and \"net_upload\" values\nnet_color_fixed=False\n\n#* Show init screen at startup, the init screen is purely cosmetical\nshow_init=False\n\n#* Enable check for new version from github.com/aristocratos/bpytop at start.\nupdate_check=True\n\n#* Set loglevel for \"~/.config/bpytop/error.log\" levels are: \"ERROR\" \"WARNING\" \"INFO\" \"DEBUG\".\n#* The level set includes all lower levels, i.e. \"DEBUG\" will show all logging info.\nlog_level=WARNING\n\nCommand line options:\nUSAGE: bpytop [argument]\n\nArguments:\n    -f, --full            Start in full mode showing all boxes [default]\n    -p, --proc            Start in minimal mode without memory and net boxes\n    -s, --stat            Start in minimal mode without process box\n    -v, --version         Show version info and exit\n    -h, --help            Show this help message and exit\n    --debug               Start with loglevel set to DEBUG overriding value set in config\n\nTODO\n\n\n Add gpu temp and usage.\n\n\n Add cpu and mem stats for docker containers. (If feasible)\n\n\n Change process list to line scroll instead of page change.\n\n\n Add options for resizing all boxes.\n\n\n Add command line argument parsing.\n\n\n Miscellaneous optimizations and code cleanup.\n\n\nLICENSE\nApache License 2.0\n\n\n\n\n\n\n\n\nAbout\n\n      Linux/OSX/FreeBSD resource monitor\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        Apache-2.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\n\n\n38\ntags\n\n\n\n\n\nSponsor this project\n\n\n\n \n\n\n Sponsor\n        \n\n  Learn more about GitHub Sponsors\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 11\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\nPython\n99.7%\n\n\n\n\n\nMakefile\n0.3%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# bpytop\n\n> Display dynamic real-time information about running processes with graphs. Similar to `gtop` and `htop`.\n> More information: <https://github.com/aristocratos/bpytop>.\n\n- Start bpytop:\n\n`bpytop`\n\n- Start in minimal mode without memory and networking boxes:\n\n`bpytop -m`\n\n- Show version:\n\n`bpytop -v`\n\n- Toggle minimal mode:\n\n`m`\n\n- Search for running programs or processes:\n\n`f`\n\n- Change settings:\n\n`M`\n"
 },
 {
   "command": "losetup",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# losetup\n\n> Set up and control loop devices.\n\n- List loop devices with detailed info:\n\n`losetup -a`\n\n- Attach a file to a given loop device:\n\n`sudo losetup /dev/{{loop}} /{{path/to/file}}`\n\n- Attach a file to a new free loop device and scan the device for partitions:\n\n`sudo losetup --show --partscan -f /{{path/to/file}}`\n\n- Attach a file to a read-only loop device:\n\n`sudo losetup --read-only /dev/{{loop}} /{{path/to/file}}`\n\n- Detach all loop devices:\n\n`sudo losetup -D`\n\n- Detach a given loop device:\n\n`sudo losetup -d /dev/{{loop}}`\n"
 },
 {
   "command": "ldd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ldd\n\n> Display shared library dependencies.\n\n- Display shared library dependencies of a binary:\n\n`ldd {{path/to/binary}}`\n\n- Display unused direct dependencies:\n\n`ldd -u {{path/to/binary}}`\n"
 },
 {
   "command": "zgrep",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nGREP(1) \t\t  BSD General Commands Manual\t\t       GREP(1)\n\nNAME\n     grep, egrep, fgrep, zgrep, zegrep, zfgrep -- file pattern searcher\n\nSYNOPSIS\n     grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]]\n\t  [-e pattern] [-f file] [--binary-files=value] [--color[=when]]\n\t  [--colour[=when]] [--context[=num]] [--label] [--line-buffered]\n\t  [--null] [pattern] [file ...]\n\nDESCRIPTION\n     The grep utility searches any given input files, selecting lines that\n     match one or more patterns.  By default, a pattern matches an input line\n     if the regular expression (RE) in the pattern matches the input line\n     without its trailing newline.  An empty expression matches every line.\n     Each input line that matches at least one of the patterns is written to\n     the standard output.\n\n     grep is used for simple patterns and basic regular expressions (BREs);\n     egrep can handle extended regular expressions (EREs).  See re_format(7)\n     for more information on regular expressions.  fgrep is quicker than both\n     grep and egrep, but can only handle fixed patterns (i.e. it does not\n     interpret regular expressions).  Patterns may consist of one or more\n     lines, allowing any of the pattern lines to match a portion of the input.\n\n     zgrep, zegrep, and zfgrep act like grep, egrep, and fgrep, respectively,\n     but accept input files compressed with the compress(1) or gzip(1) com-\n     pression utilities.\n\n     The following options are available:\n\n     -A num, --after-context=num\n\t     Print num lines of trailing context after each match.  See also\n\t     the -B and -C options.\n\n     -a, --text\n\t     Treat all files as ASCII text.  Normally grep will simply print\n\t     ``Binary file ... matches'' if files contain binary characters.\n\t     Use of this option forces grep to output lines matching the spec-\n\t     ified pattern.\n\n     -B num, --before-context=num\n\t     Print num lines of leading context before each match.  See also\n\t     the -A and -C options.\n\n     -b, --byte-offset\n\t     The offset in bytes of a matched pattern is displayed in front of\n\t     the respective matched line.\n\n     -C[num, --context=num]\n\t     Print num lines of leading and trailing context surrounding each\n\t     match.  The default is 2 and is equivalent to -A 2 -B 2.  Note:\n\t     no whitespace may be given between the option and its argument.\n\n     -c, --count\n\t     Only a count of selected lines is written to standard output.\n\n     --colour=[when, --color=[when]]\n\t     Mark up the matching text with the expression stored in\n\t     GREP_COLOR environment variable.  The possible values of when can\n\t     be `never', `always' or `auto'.\n\n     -D action, --devices=action\n\t     Specify the demanded action for devices, FIFOs and sockets.  The\n\t     default action is `read', which means, that they are read as if\n\t     they were normal files.  If the action is set to `skip', devices\n\t     will be silently skipped.\n\n     -d action, --directories=action\n\t     Specify the demanded action for directories.  It is `read' by\n\t     default, which means that the directories are read in the same\n\t     manner as normal files.  Other possible values are `skip' to\n\t     silently ignore the directories, and `recurse' to read them\n\t     recursively, which has the same effect as the -R and -r option.\n\n     -E, --extended-regexp\n\t     Interpret pattern as an extended regular expression (i.e. force\n\t     grep to behave as egrep).\n\n     -e pattern, --regexp=pattern\n\t     Specify a pattern used during the search of the input: an input\n\t     line is selected if it matches any of the specified patterns.\n\t     This option is most useful when multiple -e options are used to\n\t     specify multiple patterns, or when a pattern begins with a dash\n\t     (`-').\n\n     --exclude\n\t     If specified, it excludes files matching the given filename pat-\n\t     tern from the search.  Note that --exclude patterns take priority\n\t     over --include patterns, and if no --include pattern is speci-\n\t     fied, all files are searched that are not excluded.  Patterns are\n\t     matched to the full path specified, not only to the filename com-\n\t     ponent.\n\n     --exclude-dir\n\t     If -R is specified, it excludes directories matching the given\n\t     filename pattern from the search.\tNote that --exclude-dir pat-\n\t     terns take priority over --include-dir patterns, and if no\n\t     --include-dir pattern is specified, all directories are searched\n\t     that are not excluded.\n\n     -F, --fixed-strings\n\t     Interpret pattern as a set of fixed strings (i.e. force grep to\n\t     behave as fgrep).\n\n     -f file, --file=file\n\t     Read one or more newline separated patterns from file.  Empty\n\t     pattern lines match every input line.  Newlines are not consid-\n\t     ered part of a pattern.  If file is empty, nothing is matched.\n\n     -G, --basic-regexp\n\t     Interpret pattern as a basic regular expression (i.e. force grep\n\t     to behave as traditional grep).\n\n     -H      Always print filename headers with output lines.\n\n     -h, --no-filename\n\t     Never print filename headers (i.e. filenames) with output lines.\n\n     --help  Print a brief help message.\n\n     -I      Ignore binary files.  This option is equivalent to\n\t     --binary-file=without-match option.\n\n     -i, --ignore-case\n\t     Perform case insensitive matching.  By default, grep is case sen-\n\t     sitive.\n\n     --include\n\t     If specified, only files matching the given filename pattern are\n\t     searched.\tNote that --exclude patterns take priority over\n\t     --include patterns.  Patterns are matched to the full path speci-\n\t     fied, not only to the filename component.\n\n     --include-dir\n\t     If -R is specified, only directories matching the given filename\n\t     pattern are searched.  Note that --exclude-dir patterns take pri-\n\t     ority over --include-dir patterns.\n\n     -J, --bz2decompress\n\t     Decompress the bzip2(1) compressed file before looking for the\n\t     text.\n\n     -L, --files-without-match\n\t     Only the names of files not containing selected lines are written\n\t     to standard output.  Pathnames are listed once per file searched.\n\t     If the standard input is searched, the string ``(standard\n\t     input)'' is written.\n\n     -l, --files-with-matches\n\t     Only the names of files containing selected lines are written to\n\t     standard output.  grep will only search a file until a match has\n\t     been found, making searches potentially less expensive.  Path-\n\t     names are listed once per file searched.  If the standard input\n\t     is searched, the string ``(standard input)'' is written.\n\n     --mmap  Use mmap(2) instead of read(2) to read input, which can result in\n\t     better performance under some circumstances but can cause unde-\n\t     fined behaviour.\n\n     -m num, --max-count=num\n\t     Stop reading the file after num matches.\n\n     -n, --line-number\n\t     Each output line is preceded by its relative line number in the\n\t     file, starting at line 1.\tThe line number counter is reset for\n\t     each file processed.  This option is ignored if -c, -L, -l, or -q\n\t     is specified.\n\n     --null  Prints a zero-byte after the file name.\n\n     -O      If -R is specified, follow symbolic links only if they were\n\t     explicitly listed on the command line.  The default is not to\n\t     follow symbolic links.\n\n     -o, --only-matching\n\t     Prints only the matching part of the lines.\n\n     -p      If -R is specified, no symbolic links are followed.  This is the\n\t     default.\n\n     -q, --quiet, --silent\n\t     Quiet mode: suppress normal output.  grep will only search a file\n\t     until a match has been found, making searches potentially less\n\t     expensive.\n\n     -R, -r, --recursive\n\t     Recursively search subdirectories listed.\n\n     -S      If -R is specified, all symbolic links are followed.  The default\n\t     is not to follow symbolic links.\n\n     -s, --no-messages\n\t     Silent mode.  Nonexistent and unreadable files are ignored (i.e.\n\t     their error messages are suppressed).\n\n     -U, --binary\n\t     Search binary files, but do not attempt to print them.\n\n     -V, --version\n\t     Display version information and exit.\n\n     -v, --invert-match\n\t     Selected lines are those not matching any of the specified pat-\n\t     terns.\n\n     -w, --word-regexp\n\t     The expression is searched for as a word (as if surrounded by\n\t     `[[:<:]]' and `[[:>:]]'; see re_format(7)).\n\n     -x, --line-regexp\n\t     Only input lines selected against an entire fixed string or regu-\n\t     lar expression are considered to be matching lines.\n\n     -y      Equivalent to -i.\tObsoleted.\n\n     -Z, -z, --decompress\n\t     Force grep to behave as zgrep.\n\n     --binary-files=value\n\t     Controls searching and printing of binary files.  Options are\n\t     binary, the default: search binary files but do not print them;\n\t     without-match: do not search binary files; and text: treat all\n\t     files as text.\n\n     --context[=num]\n\t     Print num lines of leading and trailing context.  The default is\n\t     2.\n\n     --line-buffered\n\t     Force output to be line buffered.\tBy default, output is line\n\t     buffered when standard output is a terminal and block buffered\n\t     otherwise.\n\n     If no file arguments are specified, the standard input is used.\n\nENVIRONMENT\n     GREP_OPTIONS  May be used to specify default options that will be placed\n\t\t   at the beginning of the argument list.  Backslash-escaping\n\t\t   is not supported, unlike the behavior in GNU grep.\n\nEXIT STATUS\n     The grep utility exits with one of the following values:\n\n     0\t   One or more lines were selected.\n     1\t   No lines were selected.\n     >1    An error occurred.\n\nEXAMPLES\n     To find all occurrences of the word `patricia' in a file:\n\n\t   $ grep 'patricia' myfile\n\n     To find all occurrences of the pattern `.Pp' at the beginning of a line:\n\n\t   $ grep '^\\.Pp' myfile\n\n     The apostrophes ensure the entire expression is evaluated by grep instead\n     of by the user's shell.  The caret `^' matches the null string at the\n     beginning of a line, and the `\\' escapes the `.', which would otherwise\n     match any character.\n\n     To find all lines in a file which do not contain the words `foo' or\n     `bar':\n\n\t   $ grep -v -e 'foo' -e 'bar' myfile\n\n     A simple example of an extended regular expression:\n\n\t   $ egrep '19|20|25' calendar\n\n     Peruses the file `calendar' looking for either 19, 20, or 25.\n\nSEE ALSO\n     ed(1), ex(1), gzip(1), sed(1), re_format(7)\n\nSTANDARDS\n     The grep utility is compliant with the IEEE Std 1003.1-2008 (``POSIX.1'')\n     specification.\n\n     The flags [-AaBbCDdGHhIJLmoPRSUVwZ] are extensions to that specification,\n     and the behaviour of the -f flag when used with an empty pattern file is\n     left undefined.\n\n     All long options are provided for compatibility with GNU versions of this\n     utility.\n\n     Historic versions of the grep utility also supported the flags [-ruy].\n     This implementation supports those options; however, their use is\n     strongly discouraged.\n\nHISTORY\n     The grep command first appeared in Version 6 AT&T UNIX.\n\nBUGS\n     The grep utility does not normalize Unicode input, so a pattern contain-\n     ing composed characters will not match decomposed input, and vice versa.\n\nBSD\t\t\t\t July 28, 2010\t\t\t\t   BSD\n",
   "tldr_summary": "# zgrep\n\n> Grep text patterns from files within compressed file (equivalent to grep -Z).\n\n- Grep a pattern in a compressed file (case-sensitive):\n\n`zgrep {{pattern}} {{path/to/compressed/file}}`\n\n- Grep a pattern in a compressed file (case-insensitive):\n\n`zgrep -i {{pattern}} {{path/to/compressed/file}}`\n\n- Output count of lines containing matched pattern in a compressed file:\n\n`zgrep -c {{pattern}} {{path/to/compressed/file}}`\n\n- Display the lines which don’t have the pattern present (Invert the search function):\n\n`zgrep -v {{pattern}} {{path/to/compressed/file}}`\n\n- Grep a compressed file for multiple patterns:\n\n`zgrep -e \"{{pattern_1}}\" -e \"{{pattern_2}}\" {{path/to/compressed/file}}`\n\n- Use extended regular expressions (supporting `?`, `+`, `{}`, `()` and `|`):\n\n`zgrep -E {{^regex$}} {{path/to/file}}`\n\n- Print 3 lines of [C]ontext around, [B]efore, or [A]fter each match:\n\n`zgrep -{{C|B|A}} {{3}} {{pattern}} {{path/to/compressed/file}}`\n"
 },
 {
   "command": "ksvgtopng5",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ksvgtopng5\n\n> Convert SVG files to PNG format.\n\n- Convert an SVG file (should be an absolute path) to PNG:\n\n`ksvgtopng5 {{width}} {{height}} {{path/to/file.svg}} {{output_filename.png}}`\n"
 },
 {
   "command": "collectd",
   "doc_url": "https://collectd.org/",
   "doc_text": "\n\nStart page – collectd – The system statistics collection daemon\n\n\n\n\n\n\n\n\n\n\n\ncollectd\n\n\nHomepage\nWiki\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigation\n\nStart page\nFeatures\nNews\nDownload\nFAQs\nDocumentation\nDevelopment\nContact\nRelated sites\n\n[an error occurred while processing this directive]\n              \nDownload\n\ncollectd-5.12.0.tar.bz2\ncollectd-5.11.0.tar.bz2\nmore …\n\n\n[an error occurred while processing this directive]\n              \nPlugins\n\nApache\nAPC UPS\nApple Sensors\nAscent\nBattery\nBIND\nConnTrack\nContextSwitch\nCPU\nCPUFreq\nCSV\ncURL\ncURL-JSON\ncURL-XML\nDBI\nDF\nDisk\nDNS\nE-Mail\nEntropy\nExec\nFileCount\nFSCache\nGenericJMX\ngmond\nhddtemp\nInterface\nIPMI\nIP-Tables\nIPVS\nIRQ\nJava\nlibvirt\nLoad\nLogFile\nMadWifi\nMBMon\nmemcachec\nmemcached\nMemory\nModbus\nMonitorus\nMultimeter\nMySQL\nNetApp\nNetlink\nNetwork\nNFS\nnginx\nNotify Desktop\nNotify Email\nNTPd\nNUT\nolsrd\nOneWire\nOpenVPN\nOpenVZ\nOracle\nPerl\nPinba\nPing\nPostgreSQL\nPowerDNS\nProcesses\nProtocols\nPython\nRouterOS\nRRDCacheD\nRRDtool\nSensors\nSerial\nSNMP\nStatsD\nSwap\nSysLog\nTable\nTail\nTape\ntcpconns\nTeamSpeak2\nTED\nthermal\nTokyoTyrant\nUnixSock\nUptime\nUsers\nUUID\nvmem\nVServer\nWireless\nXMMS\nWrite HTTP\nZFS ARC\n\n\n[an error occurred while processing this directive]\n              \nNews\n\n2017-11-21\nVersion 5.8.0 available.\n2017-10-06\nVersion 5.6.3 available.\n2017-06-06\nVersion 5.7.2 available.\n2017-01-23\nVersion 5.7.1 available.\n2016-12-12\nVersion 5.7.0 available.\n\n\n\n\n\ncollectd – The system statistics collection daemon\ncollectd is a\n              daemon which collects system\n              and application performance metrics periodically and provides mechanisms to store the values in a variety\n              of ways, for example in\n              RRD files.\n\n[an error occurred while processing this directive]\n\n              \nCollectd for Windows\nhttp://ssc-serv.com/\nHigh-resolution system metrics. Download free trial version!\nAdvertisement\n\nWhat does collectd do?\ncollectd gathers metrics from various sources, e.g. the operating system,\n              applications, logfiles and external devices, and stores this information or makes it available over the\n              network.\n              Those statistics can be used to monitor systems, find performance bottlenecks (i.e. performance\n                analysis) and predict future system load (i.e. capacity planning). Or if you just want\n              pretty graphs of your private server and are fed up with some homegrown solution you're at the right\n              place, too ;).\nA graph can say more than a thousand words, so here's a graph showing the \n              CPU utilization of a system over the last 60 minutes:\n\nWhy collectd?\nThere are other free, open source projects that are similar to\n              collectd – a few links are listed on the\n              related sites page. So why should you use\n              collectd? There are some key differences we think set\n              collectd apart. For one, it's written in C for performance and portability,\n              allowing it to run on systems without scripting language or cron daemon, such as embedded systems.\n              For example, collectd is popular on OpenWrt, a Linux distribution\n              for home routers.\n              At the same time it includes optimizations and features to handle hundreds of thousands of metrics.\n              The daemon comes with\n              over 100 plugins which range\n              from standard cases to very specialized and advanced topics. It provides powerful networking features and\n              is extensible in numerous ways. Last but not least: collectd is actively\n              developed and supported and well documented. A more complete\n              list of features is available.\nLimitations\nWhile collectd\ncan do a lot for you and your administrative needs,\n              there are limits to what it does:\n\nIt does not generate graphs. It can write to RRD files, but it cannot generate graphs from these\n                files. There's a tiny sample script included\n                in contrib/, though. Take a look at\n                kcollectd, an\n                X frontend, and drraw, a very generic solution, though.\n                More utility programs are listed on the\n                related projects page.\nMonitoring functionality has been added in version 4.3, but is so far limited to simple\n                threshold checking. The document\n                “Notifications and thresholds” describes\n                collectd's monitoring concept and has some details on the limitations,\n                too. Also, there's a plugin for Nagios, so it can use the values\n                collected by collectd.\n\n\nImprint |\n                Facebook |\n                Github |\n                 Google+\n(Community) |\n                identi.ca |\n                Twitter |\n                Xing\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# collectd\n\n> System statistics collection daemon.\n> More information: <https://collectd.org/>.\n\n- Show usage help, including the program version:\n\n`collectd -h`\n\n- Test the configuration file and then exit:\n\n`collectd -t`\n\n- Test plugin data collection functionality and then exit:\n\n`collectd -T`\n\n- Start collectd:\n\n`collectd`\n\n- Specify a custom configuration file location:\n\n`collectd -C {{path/to/file}}`\n\n- Specify a custom PID file location:\n\n`collectd -P {{path/to/file}}`\n\n- Don't fork into the background:\n\n`collectd -f`\n"
 },
 {
   "command": "csplit",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nCSPLIT(1)\t\t  BSD General Commands Manual\t\t     CSPLIT(1)\n\nNAME\n     csplit -- split files based on context\n\nSYNOPSIS\n     csplit [-ks] [-f prefix] [-n number] file args ...\n\nDESCRIPTION\n     The csplit utility splits file into pieces using the patterns args.  If\n     file is a dash (`-'), csplit reads from standard input.\n\n     The options are as follows:\n\n     -f prefix\n\t     Give created files names beginning with prefix.  The default is\n\t     ``xx''.\n\n     -k      Do not remove output files if an error occurs or a HUP, INT or\n\t     TERM signal is received.\n\n     -n number\n\t     Use number of decimal digits after the prefix to form the file\n\t     name.  The default is 2.\n\n     -s      Do not write the size of each output file to standard output as\n\t     it is created.\n\n     The args operands may be a combination of the following patterns:\n\n     /regexp/[[+|-]offset]\n\t     Create a file containing the input from the current line to (but\n\t     not including) the next line matching the given basic regular\n\t     expression.  An optional offset from the line that matched may be\n\t     specified.\n\n     %regexp%[[+|-]offset]\n\t     Same as above but a file is not created for the output.\n\n     line_no\n\t     Create containing the input from the current line to (but not\n\t     including) the specified line number.\n\n     {num}   Repeat the previous pattern the specified number of times.  If it\n\t     follows a line number pattern, a new file will be created for\n\t     each line_no lines, num times.  The first line of the file is\n\t     line number 1 for historic reasons.\n\n     After all the patterns have been processed, the remaining input data (if\n     there is any) will be written to a new file.\n\n     Requesting to split at a line before the current line number or past the\n     end of the file will result in an error.\n\nENVIRONMENT\n     The LANG, LC_ALL, LC_COLLATE and LC_CTYPE environment variables affect\n     the execution of csplit as described in environ(7).\n\nEXIT STATUS\n     The csplit utility exits 0 on success, and >0 if an error occurs.\n\nEXAMPLES\n     Split the mdoc(7) file foo.1 into one file for each section (up to 20):\n\n\t   csplit -k foo.1 '%^\\.Sh%' '/^\\.Sh/' '{20}'\n\n     Split standard input after the first 99 lines and every 100 lines there-\n     after:\n\n\t   csplit -k - 100 '{19}'\n\nSEE ALSO\n     sed(1), split(1), re_format(7)\n\nSTANDARDS\n     The csplit utility conforms to IEEE Std 1003.1-2001 (``POSIX.1'').\n\nHISTORY\n     A csplit command appeared in PWB UNIX.\n\nBUGS\n     Input lines are limited to LINE_MAX (2048) bytes in length.\n\nBSD\t\t\t       January 26, 2005 \t\t\t   BSD\n",
   "tldr_summary": "# csplit\n\n> Split a file into pieces.\n> This generates files named \"xx00\", \"xx01\", and so on.\n\n- Split a file at lines 5 and 23:\n\n`csplit {{file}} {{5}} {{23}}`\n\n- Split a file every 5 lines (this will fail if the total number of lines is not divisible by 5):\n\n`csplit {{file}} {{5}} {*}`\n\n- Split a file every 5 lines, ignoring exact-division error:\n\n`csplit -k {{file}} {{5}} {*}`\n\n- Split a file at line 5 and use a custom prefix for the output files:\n\n`csplit {{file}} {{5}} -f {{prefix}}`\n\n- Split a file at a line matching a regular expression:\n\n`csplit {{file}} /{{regex}}/`\n"
 },
 {
   "command": "unix2dos",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# unix2dos\n\n> Change Unix-style line endings to DOS-style.\n> Replaces CR with CRLF.\n\n- Change the line endings of a file:\n\n`unix2dos {{filename}}`\n\n- Create a copy with DOS-style line endings:\n\n`unix2dos -n {{filename}} {{new_filename}}`\n"
 },
 {
   "command": "xterm",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xterm\n\n> A terminal emulator for the X Window System.\n\n- Open the terminal with a title of `Example`:\n\n`xterm -T {{Example}}`\n\n- Open the terminal in fullscreen mode:\n\n`xterm -fullscreen`\n\n- Open the terminal with a dark blue background and yellow foreground (font color):\n\n`xterm -bg {{darkblue}} -fg {{yellow}}`\n\n- Open the terminal with 100 characters per line and 35 lines, in screen position x=200px, y=20px:\n\n`xterm -geometry {{100}}x{{35}}+{{200}}+{{20}}`\n\n- Open the terminal using a Serif font and a font size equal to 20:\n\n`xterm -fa {{'Serif'}} -fs {{20}}`\n"
 },
 {
   "command": "phpenmod",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# phpenmod\n\n> Enable PHP extensions on Debian-based OSes.\n\n- Enable the json extension for every SAPI of every PHP version:\n\n`sudo phpenmod {{json}}`\n\n- Enable the json extension for PHP 7.3 with the cli SAPI:\n\n`sudo phpenmod -v {{7.3}} -s {{cli}} {{json}}`\n"
 },
 {
   "command": "scriptreplay",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# scriptreplay\n\n> Replay a typescript created by the `script` command to the standard output.\n\n- Replay a typescript at the speed it was recorded:\n\n`scriptreplay {{path/to/timing_file}} {{path/to/typescript}}`\n\n- Replay a typescript at double the original speed:\n\n`scriptreplay {{path/to/timingfile}} {{path/to/typescript}} 2`\n\n- Replay a typescript at half the original speed:\n\n`scriptreplay {{path/to/timingfile}} {{path/to/typescript}} 0.5`\n"
 },
 {
   "command": "disown",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# disown\n\n> Allow sub-processes to live beyond the shell that they are attached to.\n> See also the `jobs` command.\n\n- Disown the current job:\n\n`disown`\n\n- Disown a specific job:\n\n`disown %{{job_number}}`\n\n- Disown all jobs:\n\n`disown -a`\n\n- Keep job (do not disown it), but mark it so that no future SIGHUP is received on shell exit:\n\n`disown -h %{{job_number}}`\n"
 },
 {
   "command": "netselect-apt",
   "doc_url": "https://manpages.debian.org/buster/netselect-apt/netselect-apt.1.en.html",
   "doc_text": "\n\n\n\nnetselect-apt(1) — netselect-apt — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / netselect-apt\n     \n     \n     \n     / netselect-apt(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nENVIRONMENT\n\n\nLIMITATIONS\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 0.3.ds1-28\n\n\ntesting 0.3.ds1-28\n\n\nunstable 0.3.ds1-28\n\n\n\n\n\n\nScroll to navigation\n\n\n\nNETSELECT-APT(1)\nGeneral Commands Manual\nNETSELECT-APT(1)\n\n\n\n\n\nNAME¶\nnetselect-apt - create sources.list for the fastest Debian mirrors\n\n\n\nSYNOPSIS¶\nnetselect-apt [OPTIONS]\n  [stable|testing|unstable|experimental|release_codename|sid]\n\n\n\nDESCRIPTION¶\nnetselect-apt automatically creates a sources.list file for using\n  with apt for the specified distribution by downloading the list of\n  Debian mirrors using wget choosing the fastest servers using\n  netselect, and testing the valid servers using curl (if\n  available). The output file is written to OUTFILE.\nThe list of fastest servers is determined by checking through\n    netselect, which servers responder faster to ICMP queries. In order\n    to determine if the servers are valid a connectiong using the specificied\n    protocol (HTTP or FTP) is done using curl.\nIf netselect is not installed setuid, then\n    netselect-apt needs to run as an administrator user (i.e. root). This\n    is only required because the network probes done by netselect\n    requires these permissions. No changes are done to the system.\nIf -i INFILE is passed netselect-apt uses\n    that rather than downloading another copy to a temporary file. The file will\n    be downloaded from http://www.debian.org/mirror/mirrors_full\n\n\n\nOPTIONS¶\n\nstable|testing|unstable|experimental|release_codename|sid\nSpecify which distribution of Debian to use. By default stable is\n      used.\n-a, --arch ARCH\nUse mirrors containing ARCH. By default the architecture of the\n      current machine is used as reported by dpkg\n-s, --sources\nWhile generating OUTFILE include also deb-src lines to use with\n      ``apt-get source'' to obtain Debian source packages.\n-i, --infile INFILE\nUse INFILE instead of downloading the mirror list to a temporary\n      file. The file must be in the same format as mirrors_full.\n-o, --outfile OUTFILE\nUse OUTFILE instead of sources.list.\n-n, --nonfree\nInclude also non-free section while generating OUTFILE.\n-f, --ftp\nUse FTP mirrors instead of HTTP and generate OUTFILE\n    accordingly.\n-O OPTIONS\nThe OPTIONS provided are added, verbatim, to netselect when\n      it is run. Here you can provide a (quoted) list of options for\n    netselect.\n-t, --tests hosts\nMake a short list with the number of hosts provided and use that list to\n      test for mirror validity. By default 10 hosts are tested.\n-c, --country COUNTRY\nOnly test the sites found under the country COUNTRY (the value can\n      either be an ISO-3166 value or the full name of the language, in English).\n      When this value is set the mirror list or the INFILE will be\n      filtered and only the sites that are listed under the given country will\n      be tested. Note that restricting the search might not give the best\n      results, as the \"fastest\" mirror might not even be in the same\n      country as the system the program is running in.\n    \n\n\n\n\nENVIRONMENT¶\n\nWANT_SOURCES\nsetting this to 1 is equivalent to --sources\nWANT_NONFREE\nsetting this to 1 is equivalent to --nonfree\n    \n\n\n\n\nLIMITATIONS¶\nnetselect-apt is unable to work with restricted environments in which\n  network filtering is implemented as it relies on netselect being able\n  to find a suitable mirror. To do this, the system where the script is run\n  needs to have network visibility of the mirrors, as it will probe them using\n  ICMP probes.\nnetselect-apt is also unable to work in environments where\n    HTTP or FTP network connections have to be done through a proxy host, as it\n    relies on being able to test the validity of the remote mirrors doing direct\n    network connections to them.\nnetselect-apt will not check if the mirror it suggests as\n    the \"fastest\" mirror is either valid or up-to-date. It is\n    recommended that users that use this tool also validate that the mirrors\n    suggested are official mirrors and are also current.\n\n\n\n\nSEE ALSO¶\nnetselect(1), wget(1), curl(1), apt(8),\n  sources.list(5).\nFor Debian GNU/Linux it is recommended that users review the\n    official mirror list at http://www.debian.org/mirror/official as well as the\n    mirror checker tool at http://mirror.debian.org/status.html (which provides\n    information on the up-to-dateness status of mirrors)\n\n\n\nAUTHOR¶\nAvery Pennarun <apenwarr@gmail.com>\nThis manual page and program have been also enhanced by Filippo\n    Giunchedi <filippo@esaurito.net> and Javier Fernandez-Sanguino\n    <jfs@debian.org>\n\n\n\n\n\nMarch 6, 2008\nDEBIAN\n\n\n\n\n\n\n\n\n\nSource file:\n\n\nnetselect-apt.1.en.gz (from netselect-apt 0.3.ds1-28)\n\n\n\n\nSource last updated:\n\n\n2016-06-15T00:19:23Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:03:42Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# netselect-apt\n\n> Create a `sources.list` file for a Debian mirror with the lowest latency.\n> More information: <https://manpages.debian.org/buster/netselect-apt/netselect-apt.1.en.html>.\n\n- Create `sources.list` using the lowest latency server:\n\n`sudo netselect-apt`\n\n- Specify Debian branch, stable is used by default:\n\n`sudo netselect-apt {{testing}}`\n\n- Include non-free section:\n\n`sudo netselect-apt --non-free`\n\n- Specify a country for the mirror list lookup:\n\n`sudo netselect-apt -c {{India}}`\n"
 },
 {
   "command": "iftop",
   "doc_url": "https://linux.die.net/man/8/iftop",
   "doc_text": "\n\niftop(8): bandwidth usage on interface by host - Linux man page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niftop(8) - Linux man page\nName\niftop - display bandwidth usage on an interface by host\nSynopsis\niftop -h | [-nNpblBP] [-i interface] [-f filter code] [-F net/mask] [-G\nnet6/mask6]\nDescription\n\n\n\n\n\niftop listens to network traffic on a named interface, or on the first interface it can find which looks like an external interface if none is\nspecified, and displays a table of current bandwidth usage by pairs of hosts. iftop must be run with sufficient permissions to monitor all network\ntraffic on the interface; see pcap(3) for more information, but on most systems this means that it must be run as root.\nBy default, iftop will look up the hostnames associated with addresses it finds in packets. This can cause substantial traffic of itself, and may\nresult in a confusing display. You may wish to suppress display of DNS traffic by using filter code such as not port domain, or switch it off entirely,\nby using the -n option or by pressing r when the program is running.\nBy default, iftop counts all IP packets that pass through the filter, and the direction of the packet is determined according to the direction the\npacket is moving across the interface. Using the -F option it is possible to get iftop to show packets entering and leaving a given network. For\nexample, iftop -F 10.0.0.0/255.0.0.0 will analyse packets flowing in and out of the 10.* network.\nSome other filter ideas:\n\nnot ether host ff:ff:ff:ff:ff:ff\nIgnore ethernet broadcast packets.\nport http and not host webcache.example.com\nCount web traffic only, unless it is being directed through a local web cache.\nicmp\nHow much bandwidth are users wasting trying to figure out why the network is slow?\n\nOptions\n\n-h\nPrint a summary of usage.\n\n-n\nDon't do hostname lookups.\n\n-N\nDo not resolve port number to service names\n\n-p\nRun in promiscuous mode, so that traffic which does not pass directly through the specified interface is also counted.\n\n-P\nTurn on port display.\n\n-l\nDisplay and count datagrams addressed to or from link-local IPv6 addresses. The default is not to display that address category.\n\n-b\nDon't display bar graphs of traffic.\n\n-B\nDisplay bandwidth rates in bytes/sec rather than bits/sec.\n-i interface\nListen to packets on interface.\n-f filter code\nUse filter code to select the packets to count. Only IP packets are ever counted, so the specified code is evaluated as (filter\ncode) and ip.\n-F net/mask\nSpecifies an IPv4 network for traffic analysis. If specified, iftop will only include packets flowing in to or out of the given network, and packet\ndirection is determined relative to the network boundary, rather than to the interface. You may specify mask as a dotted quad, such as /255.255.255.0,\nor as a single number specifying the number of bits set in the netmask, such as /24.\n-G net6/mask6\nSpecifies an IPv6 network for traffic analysis. The value of mask6 can be given as a prefix length or as a numerical address string for more compound\nbitmasking.\n-c config file\nSpecifies an alternate config file. If not specified, iftop will use ~/.iftoprc if it exists. See below for a description of config\nfiles\n\nDisplay\nWhen running, iftop uses the whole screen to display network usage. At the top of the display is a logarithmic scale for the bar graph which gives a\nvisual indication of traffic.\nThe main part of the display lists, for each pair of hosts, the rate at which data has been sent and received over the preceding 2, 10 and 40 second\nintervals. The direction of data flow is indicated by arrows, <= and =>. For instance,\nfoo.example.com  =>  bar.example.com      1Kb  500b   100b\n                 <=                       2Mb    2Mb    2Mbshows, on the first line, traffic from foo.example.com to bar.example.com; in the preceding 2 seconds, this averaged 1Kbit/s, around half that\namount over the preceding 10s, and a fifth of that over the whole of the last 40s. During each of those intervals, the data sent in the other direction was\nabout 2Mbit/s. On the actual display, part of each line is inverted to give a visual indication of the 10s average of traffic. You might expect to see\nsomething like this where host foo is making repeated HTTP requests to bar, which is sending data back which saturates a 2Mbit/s link.\n\nBy default, the pairs of hosts responsible for the most traffic (10 second average) are displayed at the top of the list.\nAt the bottom of the display, various totals are shown, including peak traffic over the last 40s, total traffic transferred (after filtering), and total\ntransfer rates averaged over 2s, 10s and 40s.\nSOURCE / DEST AGGREGATION\nBy pressing s or d while iftop is running, all traffic for each source or destination will be aggregated together. This is most useful\nwhen iftop is run in promiscuous mode, or is run on a gateway machine.\nPort Display\nS or D toggle the display of source and destination ports respectively. p will toggle port display on/off.\nDisplay Type\nt cycles through the four line display modes; the default 2-line display, with sent and received traffic on separate lines, and 3 1-line displays,\nwith sent, received, or total traffic shown.\nDisplay Order\nBy default, the display is ordered according to the 10s average (2nd column). By pressing 1, 2 or 3 it is possible to sort by the 1st,\n2nd or 3rd column. By pressing < or > the display will be sorted by source or destination hostname respectively.\nDisplay Filtering\nl allows you to enter a POSIX extended regular expression that will be used to filter hostnames shown in the display. This is a good way to quickly\nlimit what is shown on the display. Note that this happens at a much later stage than filter code, and does not affect what is actually captured. Display\nfilters DO NOT affect the totals at the bottom of the screen.\nPAUSE DISPLAY / FREEZE ORDER\nP will pause the current display.\no will freeze the current screen order. This has the side effect that traffic between hosts not shown on the screen at the time will not be shown at\nall, although it will be included in the totals at the bottom of the screen.\nScroll Display\nj and k will scroll the display of hosts. This feature is most useful when the display order is frozen (see above).\nFilter Code\nf allows you to edit the filter code whilst iftop running. This can lead to some unexpected behaviour.\nConfig File\niftop can read its configuration from a config file. If the -c option is not specified, iftop will attempt to read its configuration from\n~/.iftoprc, if it exists. Any command line options specified will override settings in the config file.\nThe config file consists of one configuration directive per line. Each directive is a name value pair, for example:\ninterface: eth0sets the network interface. The following config directives are supported:\n\ninterface: if\nSets the network interface to if.\ndns-resolution: (yes|no)\nControls reverse lookup of IP addresses.\nport-resolution: (yes|no)\nControls conversion of port numbers to service names.\nfilter-code: bpf\nSets the filter code to bpf.\nshow-bars: (yes|no)\nControls display of bar graphs.\npromiscuous: (yes|no)\nPuts the interface into promiscuous mode.\nport-display: (off|source-only|destination-only|on)\nControls display of port numbers.\nlink-local: (yes|no)\nDetermines displaying of link-local IPv6 addresses.\nhide-source: (yes|no)\nHides source host names.\nhide-destination: (yes|no)\nHides destination host names.\nuse-bytes: (yes|no)\nUse bytes for bandwidth display, rather than bits.\nsort: (2s|10s|40s|source|destination)\nSets which column is used to sort the display.\nline-display: (two-line|one-line-both|one-line-sent|one-line-received)\nControls the appearance of each item in the display.\nshow-totals: (yes|no)\nShows cumulative total for each item.\nlog-scale: (yes|no)\nUse a logarithmic scale for bar graphs.\nmax-bandwidth: bw\nFixes the maximum for the bar graph scale to bw, e.g. \"10M\". Note that the value has to always be in bits, regardless if the option to display in\nbytes has been chosen.\nnet-filter: net/mask\nDefines an IP network boundary for determining packet direction.\nnet-filter6: net6/mask6\nDefines an IPv6 network boundary for determining packet direction.\nscreen-filter: regexp\nSets a regular expression to filter screen output.\n\nQUIRKS (aka they're features, not bugs)\nThere are some circumstances in which iftop may not do what you expect. In most cases what it is doing is logical, and we believe it is correct behaviour,\nalthough I'm happy to hear reasoned arguments for alternative behaviour.\nTotals don't add up\nThere are several reasons why the totals may not appear to add up. The most obvious is having a screen filter in effect, or screen ordering frozen. In this\ncase some captured information is not being shown to you, but is included in the totals.\nA more subtle explanation comes about when running in promiscuous mode without specifying a -F option. In this case there is no easy way to assign\nthe direction of traffic between two third parties. For the purposes of the main display this is done in an arbitrary fashion (by ordering of IP addresses),\nbut for the sake of totals all traffic between other hosts is accounted as incoming, because that's what it is from the point of view of your interface. The\n-F option allows you to specify an arbitrary network boundary, and to show traffic flowing across it.\nPeak totals don't add up\nAgain, this is a feature. The peak sent and peak received didn't necessarily happen at the same time. The peak total is the maximum of sent plus received in\neach captured time division.\nChanging the filter code doesn't seem to work\nGive it time. Changing the filter code affects what is captured from the time that you entered it, but most of what is on the display is based on some\nfraction of the last 40s window of capturing. After changing the filter there may be entries on the display that are disallowed by the current filter for up to\n40s. DISPLAY FILTERING has immediate effect and does not affect what is captured.\nFiles\n~/.iftoprc\n\nConfiguration file for iftop.\n\nSee Also\ntcpdump(8), pcap(3), driftnet(1).\nAuthor\nPaul Warren <pdw@ex-parrot.com>\nVersion\n$Id: iftop.8,v 1.27 2010/11/27 11:06:12 pdw Exp $\nCopying\nThis program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software\nFoundation; either version 2 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\nFOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 675 Mass\nAve, Cambridge, MA 02139, USA.\n\n\nReferenced By\ndstat(1)\n\n\n\n\n\n\n\n\nSite Search\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nlinux docs\nlinux man pages\npage load time\n\n\nToys\nworld sunlight\nmoon phase\ntrace explorer\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# iftop\n\n> Show bandwidth usage on an interface by host.\n> More information: <https://linux.die.net/man/8/iftop>.\n\n- Show the bandwidth usage:\n\n`sudo iftop`\n\n- Show the bandwidth usage of a given interface:\n\n`sudo iftop -i {{interface}}`\n\n- Show the bandwidth usage with port information:\n\n`sudo iftop -P`\n\n- Do not show bar graphs of traffic:\n\n`sudo iftop -b`\n\n- Do not look up hostnames:\n\n`sudo iftop -n`\n\n- Get help about interactive commands:\n\n`?`\n"
 },
 {
   "command": "equery",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# equery\n\n> View information about Portage packages.\n\n- List all installed packages:\n\n`equery list '*'`\n\n- Search for installed packages in the Portage tree and in overlays:\n\n`equery list -po {{package_name}}`\n\n- List all packages that depend on a given package:\n\n`equery depends {{package_name}}`\n\n- List all packages that a given package depends on:\n\n`equery depgraph {{package_name}}`\n\n- List all files installed by a package:\n\n`equery files --tree {{package_name}}`\n"
 },
 {
   "command": "fuser",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "FUSER(P)\t\t   POSIX Programmer's Manual\t\t      FUSER(P)\n\n\n\nNAME\n       fuser  -  list process IDs of all processes that have one or more files\n       open\n\nSYNOPSIS\n       fuser [ -cfu ] file ...\n\nDESCRIPTION\n       The fuser utility shall write to standard output  the  process  IDs  of\n       processes running on the local system that have one or more named files\n       open. For block special devices, all processes using any file  on  that\n       device are listed.\n\n       The  fuser utility shall write to standard error additional information\n       about the named files indicating how the file is being used.\n\n       Any output for processes running on remote systems that\thave  a  named\n       file open is unspecified.\n\n       A user may need appropriate privilege to invoke the fuser utility.\n\nOPTIONS\n       The  fuser  utility  shall  conform  to\tthe Base Definitions volume of\n       IEEE Std 1003.1-2001, Section 12.2, Utility Syntax Guidelines.\n\n       The following options shall be supported:\n\n       -c     The file is treated as a\tmount  point  and  the\tutility  shall\n\t      report on any files open in the file system.\n\n       -f     The report shall be only for the named files.\n\n       -u     The  user  name, in parentheses, associated with each process ID\n\t      written to standard output shall be written to standard error.\n\n\nOPERANDS\n       The following operand shall be supported:\n\n       file   A pathname on which the file or file system is to be reported.\n\n\nSTDIN\n       Not used.\n\nINPUT FILES\n       The user database.\n\nENVIRONMENT VARIABLES\n       The following environment  variables  shall  affect  the  execution  of\n       fuser:\n\n       LANG   Provide  a  default value for the internationalization variables\n\t      that are unset or null. (See  the  Base  Definitions  volume  of\n\t      IEEE Std 1003.1-2001,  Section  8.2,  Internationalization Vari-\n\t      ables for the precedence of internationalization variables  used\n\t      to determine the values of locale categories.)\n\n       LC_ALL If  set  to a non-empty string value, override the values of all\n\t      the other internationalization variables.\n\n       LC_CTYPE\n\t      Determine the locale for\tthe  interpretation  of  sequences  of\n\t      bytes  of  text  data as characters (for example, single-byte as\n\t      opposed to multi-byte characters in arguments).\n\n       LC_MESSAGES\n\t      Determine the locale that should be used to  affect  the\tformat\n\t      and contents of diagnostic messages written to standard error.\n\n       NLSPATH\n\t      Determine the location of message catalogs for the processing of\n\t      LC_MESSAGES .\n\n\nASYNCHRONOUS EVENTS\n       Default.\n\nSTDOUT\n       The fuser utility shall write the process ID  for  each\tprocess  using\n       each  file given as an operand to standard output in the following for-\n       mat:\n\n\n\t      \"%d\", <process_id>\n\nSTDERR\n       The fuser utility shall write diagnostic messages to standard error.\n\n       The fuser utility also shall write the following to standard error:\n\n\t* The pathname of each named file is written followed immediately by a\n\t  colon.\n\n\n\t* For  each  process  ID written to standard output, the character 'c'\n\t  shall be written to standard error if the process is using the  file\n\t  as  its  current directory and the character 'r' shall be written to\n\t  standard error if the process is using the file as its  root\tdirec-\n\t  tory. Implementations may write other alphabetic characters to indi-\n\t  cate other uses of files.\n\n\n\t* When the -u option is specified, characters indicating  the  use  of\n\t  the  file  shall be followed immediately by the user name, in paren-\n\t  theses, corresponding to the process' real user  ID.\t If  the  user\n\t  name cannot be resolved from the process' real user ID, the process'\n\t  real user ID shall be written instead of the user name.\n\n\n       When standard output and standard error are directed to the same  file,\n       the  output  shall  be  interleaved so that the filename appears at the\n       start of each line, followed by the process ID and characters  indicat-\n       ing  the use of the file. Then, if the -u option is specified, the user\n       name or user ID for each process using that file shall be written.\n\n       A <newline> shall be written to standard error after  the  last\toutput\n       described above for each file operand.\n\nOUTPUT FILES\n       None.\n\nEXTENDED DESCRIPTION\n       None.\n\nEXIT STATUS\n       The following exit values shall be returned:\n\n\t0     Successful completion.\n\n       >0     An error occurred.\n\n\nCONSEQUENCES OF ERRORS\n       Default.\n\n       The following sections are informative.\n\nAPPLICATION USAGE\n       None.\n\nEXAMPLES\n       The command:\n\n\n\t      fuser -fu .\n\n       writes  to  standard output the process IDs of processes that are using\n       the current directory and writes to standard error an indication of how\n       those  processes  are using the directory and the user names associated\n       with the processes that are using the current directory.\n\nRATIONALE\n       The definition of the fuser utility follows existing practice.\n\nFUTURE DIRECTIONS\n       None.\n\nSEE ALSO\n       None.\n\nCOPYRIGHT\n       Portions of this text are reprinted and reproduced in  electronic  form\n       from IEEE Std 1003.1, 2003 Edition, Standard for Information Technology\n       -- Portable Operating System Interface (POSIX),\tThe  Open  Group  Base\n       Specifications  Issue  6,  Copyright  (C) 2001-2003 by the Institute of\n       Electrical and Electronics Engineers, Inc and The Open  Group.  In  the\n       event of any discrepancy between this version and the original IEEE and\n       The Open Group Standard, the original IEEE and The Open Group  Standard\n       is  the\treferee document. The original Standard can be obtained online\n       at http://www.opengroup.org/unix/online.html .\n\n\n\nIEEE/The Open Group\t\t     2003\t\t\t      FUSER(P)\n",
   "tldr_summary": "# fuser\n\n> Display process IDs currently using files or sockets.\n\n- Find which processes are accessing a file or directory:\n\n`fuser {{path/to/file_or_directory}}`\n\n- Show more fields (`USER`, `PID`, `ACCESS` and `COMMAND`):\n\n`fuser --verbose {{path/to/file_or_directory}}`\n\n- Identify processes using a TCP socket:\n\n`fuser --namespace tcp {{port}}`\n\n- Kill all processes accessing a file or directory (sends the `SIGKILL` signal):\n\n`fuser --kill {{path/to/file_or_directory}}`\n\n- Find which processes are accessing the filesystem containing a specific file or directory:\n\n`fuser --mount {{path/to/file_or_directory}}`\n"
 },
 {
   "command": "fdisk",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nFDISK(8)\t\t  BSD System Manager's Manual\t\t      FDISK(8)\n\nNAME\n     fdisk -- DOS partition maintenance program\n\nSYNOPSIS\n     fdisk [-ieu] [-f mbrname] [-c cylinders] [-h heads] [-s sectors]\n\t   [-S size] [-b size] device\n\nDESCRIPTION\n     In order for the BIOS to boot the kernel, certain conventions must be\n     adhered to.  Sector 0 of a bootable hard disk must contain boot code, an\n     MBR partition table, and a magic number (0xAA55).\tThese MBR partitions\n     (also known as BIOS partitions) can be used to break the disk up into\n     several pieces.\n\n     The BIOS loads sector 0 of the boot disk into memory, verifies the magic\n     number, and begins executing the code at the first byte.  The normal DOS\n     MBR boot code searches the MBR partition table for an ``active'' parti-\n     tion (indicated by a `*' in the first column), and if one is found, the\n     boot block from that partition is loaded and executed in place of the\n     original (MBR) boot block.\n\n     The options are as follows:\n\n     -i      Initialize the MBR sector.\n\n     -a style\n\t     Specify an automatic partitioning style.\n\n     -e      Edit existing MBR sectors.\n\n     -f mbrname\n\t     Specifies an alternate MBR template file.\n\n     -u      Update MBR code, preserving existing partition table.\n\n     -y      Do not ask for confirmation before writing.\n\n     -d      Dump partition table in a format readable by the -r option.\n\n     -r      Read a partition table from the standard input.\n\n     -t      Test if the disk is partitioned.\n\n     -c cylinders, -h heads, -s sectors\n\t     Specifies an alternate BIOS geometry for fdisk to use.\n\n     -S size\n\t     Specify the disk size in blocks.\n\n     -b size\n\t     Specify the number of bytes per disk block.\n\n     The DOS fdisk program can be used to divide space on the disk into parti-\n     tions and set one active.\tThis fdisk program serves a similar purpose to\n     the DOS program.  When called with no special flags, it prints the MBR\n     partition table of the specified device, i.e.,\n\n\t # fdisk fd0\n\t Disk: fd0\t geometry: 80/2/18 [2880 sectors]\n\t Offset: 0\t Signature: 0xAA55\n\t\t  Starting\t  Ending\n\t  #: id  cyl  hd sec -\tcyl  hd sec [\t  start -\tsize]\n\t ----------------------------------------------------------------------\n\t *1: A6    0   0   1 -\t 79   1  18 [\t      0 -\t2880] OpenBSD\n\t  2: 00    0   0   0 -\t  0   0   0 [\t      0 -\t   0] unused\n\t  3: A7    0   0   2 -\t 79   1  18 [\t      1 -\t2879] NEXTSTEP\n\t  4: 00    0   0   0 -\t  0   0   0 [\t      0 -\t   0] unused\n\n     The geometry displayed is a synthetic geometry unless another geometry\n     has been selected using the -c, -h, -s, -S, and -b options.  In the\n     future, fdisk will read the BIOS geometry from the IOKit registry.\n\n     In this example, the disk is divided into two partitions that happen to\n     fill the disk.  The first partition overlaps the third partition.\t(Used\n     for debugging purposes.)\n\n     #\t\t Number of partition table entry.  A ``*'' denotes the\n\t\t bootable partition.\n\n     id \t System identifier.  OpenBSD reserves the magic number 166\n\t\t decimal (A6 in hex).  If no 166 partition is found, it will\n\t\t use an older FreeBSD partition (with a magic number of 165 or\n\t\t A5 in hex).\n\n     cyl/hd/sec  These fields provide the starting and ending address of the\n\t\t partition in BIOS geometry\n\n     start/size  These fields provide the starting sector and size in sectors\n\t\t of the partition in linear block addresses.\n\n     NOTE: The sectors field is ``1 based'', and the start field is ``0\n     based''.  The CHS values may need to be in the BIOS's geometry for older\n     systems to be able to boot and use the drive correctly; most modern sys-\n     tems prefer the starting sector and size in preference to the CHS values.\n\n     The -i flag is used to indicate that the partition data is to be initial-\n     ized.  In this mode, fdisk will completely overwrite the primary MBR and\n     partition table, either using the default MBR template, or the one speci-\n     fied by the -f flag.\n\n     In the default template, partition number 1 will be configured as a Dar-\n     win boot partition spanning from cylinder 0, head 1, sector 1, and\n     extending for 8 megabytes.  Partition number 2 will be configured as a\n     Darwin HFS partition spanning the rest of the disk.  This mode is\n     designed to initialize an MBR the very first time, or when it has been\n     corrupted beyond repair.\n\n     You can specify other default partition styles with the -a flag.  The\n     available styles are:\n\n     boothfs\t Creates an 8Mb boot partition (type AB hex) and makes the\n\t\t rest of the disk a Darwin HFS partition (type AF hex).\n\n     hfs\t Makes the entire disk one HFS+ partition (type AF hex).\n\n     dos\t Makes the entire disk one DOS partition (type 0C hex).\n\n     raid\t Makes the entire disk one type AC hex partition.\n\n     The -u flag is used to update the MBR code on a given drive.  The MBR\n     code extends from offset 0x000 to the start of the partition table at\n     offset 0x1BE.  It is similar to the -i flag, except the existing parti-\n     tion table is preserved. This is useful for writing new MBR code onto an\n     existing drive, and is equivalent to the DOS command ``FDISK /MBR''.\n     Note that this option will overwrite the NT disk signature, if present.\n     The -u and -i flags may not be specified together.\n\n     The flag -e is used to modify a partition table using a interactive edit\n     mode of the fdisk program.  This mode is designed to allow you to change\n     any partition on the drive you choose, including extended partitions.  It\n     is a very powerful mode, but is safe as long as you do not execute the\n     write command, or answer in the negative (the default) when fdisk asks\n     you about writing out changes.\n\nCOMMAND MODE\n     When you first enter this mode, you are presented with a prompt, that\n     looks like so: fdisk: 0>.\tThis prompt has two important pieces of infor-\n     mation for you.  It will tell you if the in-memory copy of the boot block\n     has been modified or not.\tIf it has been modified, the prompt will\n     change to look like: fdisk:*0>.  The second piece of information pertains\n     to the number given in the prompt.  This number specifies the disk offset\n     of the currently selected boot block you are editing.  This number could\n     be something different that zero when you are editing extended parti-\n     tions.  The list of commands and their explanations are given below.\n\n     help    Display a list of commands that fdisk understands in the interac-\n\t     tive edit mode.\n\n     manual  Display this manual page.\n\n     reinit  Initialize the currently selected, in-memory copy of the boot\n\t     block.\n\n     auto    Partition the disk with one of the automatic partition styles.\n\n     disk    Display the current drive geometry that fdisk has probed.\tYou\n\t     are given a chance to edit it if you wish.\n\n     edit    Edit a given table entry in the memory copy of the current boot\n\t     block.  You may edit either in BIOS geometry mode, or in sector\n\t     offsets and sizes.\n\n     setpid  Change the partition identifier of the given partition table\n\t     entry.  This command is particularly useful for reassigning an\n\t     existing partition to OpenBSD.\n\n     flag    Make the given partition table entry bootable.  Only one entry\n\t     can be marked bootable.  If you wish to boot from an extended\n\t     partition, you will need to mark the partition table entry for\n\t     the extended partition as bootable.\n\n     update  Update the machine code in the memory copy of the currently\n\t     selected boot block.  Note that this option will overwrite the NT\n\t     disk signature, if present.\n\n     select  Select and load into memory the boot block pointed to by the\n\t     extended partition table entry in the current boot block.\n\n     print   Print the currently selected in-memory copy of the boot block and\n\t     its MBR table to the terminal.\n\n     write   Write the in-memory copy of the boot block to disk.  You will be\n\t     asked to confirm this operation.\n\n     exit    Exit the current level of fdisk, either returning to the previ-\n\t     ously selected in-memory copy of a boot block, or exiting the\n\t     program if there is none.\n\n     quit    Exit the current level of fdisk, either returning to the previ-\n\t     ously selected in-memory copy of a boot block, or exiting the\n\t     program if there is none.\tUnlike exit it does write the modified\n\t     block out.\n\n     abort   Quit program without saving current changes.\n\nNOTES\n     The automatic calculation of starting cylinder etc. uses a set of figures\n     that represent what the BIOS thinks is the geometry of the drive.\tThese\n     figures are by default taken from the in-core disklabel, or values that\n     /boot has passed to the kernel, but fdisk gives you an opportunity to\n     change them if there is a need to.  This allows the user to create a\n     bootblock that can work with drives that use geometry translation under a\n     potentially different BIOS.\n\n     If you hand craft your disk layout, please make sure that the OpenBSD\n     partition starts on a cylinder boundary.  (This restriction may be\n     changed in the future.)\n\n     Editing an existing partition is risky, and may cause you to lose all the\n     data in that partition.\n\n     You should run this program interactively once or twice to see how it\n     works.  This is completely safe as long as you answer the ``write'' ques-\n     tions in the negative.\n\nFILES\n     /usr/mdec/mbr  default MBR template\n\nSEE ALSO\n     gpt(8), pdisk(8)\n\nBUGS\n     There are subtleties fdisk detects that are not explained in this manual\n     page.  As well, chances are that some of the subtleties it should detect\n     are being steamrolled.  Caveat Emptor.\n\nBSD\t\t\t\tJanuary 3, 2002 \t\t\t   BSD\n",
   "tldr_summary": "# fdisk\n\n> A program for managing partition tables and partitions on a hard disk.\n\n- List partitions:\n\n`fdisk -l`\n\n- Start the partition manipulator:\n\n`fdisk {{/dev/sda}}`\n"
 },
 {
   "command": "edquota",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nEDQUOTA(8)\t\t  BSD System Manager's Manual\t\t    EDQUOTA(8)\n\nNAME\n     edquota -- edit user quotas\n\nSYNOPSIS\n     edquota [-u] [-p proto-username] username ...\n     edquota -g [-p proto-groupname] groupname ...\n     edquota -t [-u]\n     edquota -t -g\n\nDESCRIPTION\n     Edquota is a quota editor.  By default, or if the -u flag is specified,\n     one or more users may be specified on the command line.  For each user a\n     temporary file is created with an ASCII representation of the current\n     disk quotas for that user.  The list of filesystems with user quotas is\n     determined by scanning the mounted filesystems for a .quota.ops.user file\n     located at its root.  An editor is invoked on the ASCII file.  The editor\n     invoked is vi(1) unless the environment variable EDITOR specifies other-\n     wise.\n\n     The quotas may then be modified, new quotas added, etc.  Setting a quota\n     to zero indicates that no quota should be imposed.  Setting a hard limit\n     to one indicates that no allocations should be permitted.\tSetting a soft\n     limit to one with a hard limit of zero indicates that allocations should\n     be permitted on only a temporary basis (see -t below).  The current usage\n     information in the file is for informational purposes; only the hard and\n     soft limits can be changed.\n\n     On leaving the editor, edquota reads the temporary file and modifies the\n     binary quota files to reflect the changes made.  The binary quota file,\n     .quota.user is stored at the root of the filesystem.  The default file-\n     name and root location for the user quotas cannot be overridden.\n\n     If the -p flag is specified, edquota will duplicate the quotas of the\n     prototypical user specified for each user specified.  This is the normal\n     mechanism used to initialize quotas for groups of users.\n\n     If the -g flag is specified, edquota is invoked to edit the quotas of one\n     or more groups specified on the command line.  The list of filesystems\n     with group quotas is determined by scanning the mounted filesystems for a\n     .quota.ops.group file located at its root.  Similarly, the binary quota\n     file, .quota.group is stored at the root of the filesystem.  The default\n     filename and root location for group quotas cannot be overridden.\tThe -p\n     flag can be specified in conjunction with the -g flag to specify a proto-\n     typical group to be duplicated among the listed set of groups.\n\n     Users are permitted to exceed their soft limits for a grace period that\n     may be specified per filesystem.  Once the grace period has expired, the\n     soft limit is enforced as a hard limit.  The default grace period for a\n     filesystem is specified in /usr/include/sys/quota.h.  The -t flag can be\n     used to change the grace period.  By default, or when invoked with the -u\n     flag, the grace period is set for each filesystem with a .quota.ops.user\n     file located at its root.\tWhen invoked with the -g flag, the grace\n     period is set for each filesystem with a .quota.ops.group file located at\n     its root.\tThe grace period may be specified in days, hours, minutes, or\n     seconds.  Setting a grace period to zero indicates that the default grace\n     period should be imposed.\tSetting a grace period to one second indicates\n     that no grace period should be granted.\n\n     Only the super-user may edit quotas.\n\nFILES\n     Each of the following quota files is located at the root of the mounted\n     filesystem.  The mount option files are empty files whose existence indi-\n     cates that quotas are to be enabled for that filesystem.  The binary data\n     files will be created by edquota, if they don't already exist.\n\n     .quota.user       data file containing user quotas\n     .quota.group      data file containing group quotas\n     .quota.ops.user   mount option file used to enable user quotas\n     .quota.ops.group  mount option file used to enable group quotas\n\nSEE ALSO\n     quota(1), quotactl(2), quotacheck(8), quotaon(8), repquota(8)\n\nDIAGNOSTICS\n     Various messages about inaccessible files; self-explanatory.\n\nBSD\t\t\t      September 25, 2020\t\t\t   BSD\n",
   "tldr_summary": "# edquota\n\n> Edit quotas for a user or group. By default it operates on all file systems with quotas.\n> Quota information is stored permanently in the `quota.user` and `quota.group` files in the root of the filesystem.\n\n- Edit quota of the current user:\n\n`edquota --user $(whoami)`\n\n- Edit quota of a specific user:\n\n`sudo edquota --user {{username}}`\n\n- Edit quota for a group:\n\n`sudo edquota --group {{group}}`\n\n- Restrict operations to a given filesystem (by default edquota operates on all filesystems with quotas):\n\n`sudo edquota --file-system {{filesystem}}`\n\n- Edit the default grace period:\n\n`sudo edquota -t`\n\n- Duplicate a quota to other users:\n\n`sudo edquota -p {{reference_user}} {{destination_user1}} {{destination_user2}}`\n"
 },
 {
   "command": "whereis",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nWHEREIS(1)\t\t  BSD General Commands Manual\t\t    WHEREIS(1)\n\nNAME\n     whereis -- locate programs\n\nSYNOPSIS\n     whereis [program ...]\n\nDESCRIPTION\n     The whereis utility checks the standard binary directories for the speci-\n     fied programs, printing out the paths of any it finds.\n\n     The path searched is the string returned by the sysctl(8) utility for the\n     ``user.cs_path'' string.\n\nSEE ALSO\n     find(1), locate(1), man(1), which(1), sysctl(8)\n\nCOMPATIBILITY\n     The historic flags and arguments for the whereis utility are no longer\n     available in this version.\n\nHISTORY\n     The whereis command appeared in 3.0BSD.\n\nBSD\t\t\t\tApril 27, 1995\t\t\t\t   BSD\n",
   "tldr_summary": "# whereis\n\n> Locate the binary, source, and manual page files for a command.\n\n- Locate binary, source and man pages for ssh:\n\n`whereis {{ssh}}`\n\n- Locate binary and man pages for ls:\n\n`whereis -bm {{ls}}`\n\n- Locate source of gcc and man pages for git:\n\n`whereis -s {{gcc}} -m {{git}}`\n\n- Locate binaries for gcc in /usr/bin/ only:\n\n`whereis -b -B {{/usr/bin/}} -f {{gcc}}`\n\n- Locate unusual binaries (those that have more or less than one binary on the system):\n\n`whereis -u *`\n\n- Locate binaries that have unusual manual entries (binaries that have more or less than one manual installed):\n\n`whereis -u -m *`\n"
 },
 {
   "command": "unset",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# unset\n\n> Remove shell variables or functions.\n\n- Remove the variable `foo`, or if the variable doesn't exist, remove the function `foo`:\n\n`unset {{foo}}`\n\n- Remove the variables foo and bar:\n\n`unset -v {{foo}} {{bar}}`\n\n- Remove the function my_func:\n\n`unset -f {{my_func}}`\n"
 },
 {
   "command": "swapon",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# swapon\n\n> Enables device or file for swapping.\n\n- Get swap information:\n\n`swapon -s`\n\n- Enable a given swap partition:\n\n`swapon {{/dev/sdb7}}`\n\n- Enable a given swap file:\n\n`swapon {{path/to/file}}`\n\n- Enable all swap areas:\n\n`swapon -a`\n\n- Enable swap by label of a device or file:\n\n`swapon -L {{swap1}}`\n"
 },
 {
   "command": "faketime",
   "doc_url": "https://manpages.ubuntu.com/manpages/trusty/man1/faketime.1.html",
   "doc_text": "\n\n\n\n\n\n\nUbuntu Manpage:\n\n       faketime - manipulate the system time for a given command\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMenu\nClose menu\n\n\n\n\n\n\n\n\n\n\n\n\nJump to main content\n\n\n\n\n\n\n\n\n\n\n\n\n\nProvided by: faketime_0.9.5-2_amd64 \nNAME\n       faketime - manipulate the system time for a given command\n\nSYNOPSIS\n       faketime [options] timestamp program [arguments...]\n\nDESCRIPTION\n       The  given  command will be tricked into believing that the current system time is the one\n       specified in the timestamp. The wall clock will continue to run from this  date  and  time\n       unless  specified otherwise (see advanced options). Actually, faketime is a simple wrapper\n       for libfaketime, which uses the  LD_PRELOAD  mechanism  to  load  a  small  library  which\n       intercepts  system  calls  to functions such as time(2) and fstat(2). This wrapper exposes\n       only a subset of libfaketime's functionality; please refer to the README  file  that  came\n       with   faketime   for   more   details   and   advanced   options,   or  have  a  look  at\n       http://github.com/wolfcw/libfaketime\n\nOPTIONS\n       --help show usage information and quit.\n\n       --version\n              show version information and quit.\n\n       -m     use the multi-threading variant of libfaketime.\n\n       -f     use the advanced timestamp specification format.\n\nEXAMPLES\n       faketime 'last Friday 5 pm' /bin/date\n       faketime '2008-12-24 08:15:42' /bin/date\n       faketime -f '+2,5y x10,0' /bin/bash -c 'date; while true; do echo $SECONDS ; sleep 1 ; done'\n       faketime -f '+2,5y x0,50' /bin/bash -c 'date; while true; do echo $SECONDS ; sleep 1 ; done'\n       faketime -f '+2,5y i2,0' /bin/bash -c 'while true; do date ; sleep 1 ; done'\n       In this single case all spawned processes will use the same global clock without restaring it at the start of each process.\n\n       (Please note that it depends on your locale settings whether . or , has to be used for fractional offsets)\n\nADVANCED TIMESTAMP FORMAT\n       The simple timestamp format used by default applies the  /bin/date  -d  command  to  parse\n       user-friendly specifications such as 'last friday'. When using the faketime option -f, the\n       timestamp specified on the command line is directly passed to libfaketime, which enables a\n       couple  of  additional  features  such as speeding the clock up or slowing it down for the\n       target program. It is strongly recommended  that  you  have  a  look  at  the  libfaketime\n       documentation. Summary:\n\n       Freeze clock at absolute timestamp: \"YYYY-MM-DD hh:mm:ss\"\n              If you want to specify an absolute point in time, exactly this format must be used.\n              Please note that freezing the clock is usually not what you want and may break  the\n              application. Only use if you know what you're doing!\n\n       Relative time offset: \"[+/-]123[m/h/d/y], e.g. \"+60m\", \"+2y\"\n              This  is  the most often used format and specifies the faked time relatively to the\n              current real time. The first character of the format string must be a + or a -. The\n              numeric  value  by default represents seconds, but the modifiers m, h, d, and y can\n              be used to specify minutes, hours, days, or years, respectively. For example, \"-2y\"\n              means  \"two  years  ago\".  Fractional time offsets can be used, e.g. \"+2,5y\", which\n              means \"two and a half years in the future\". Please note that the fraction delimiter\n              depends on your locale settings, so if \"+2,5y\" does not work, you might want to try\n              \"+2.5y\".\n\n       Start-at timestamps: \"@YYYY-MM-DD hh:mm:ss\"\n              The wall clock will start counting at the given timestamp for the program. This can\n              be used for specifying absolute timestamps without freezing the clock.\n\nADVANCED USAGE\n       When  using  relative  time  offsets or start-at timestamps (see ADVANCED TIMESTAMP FORMAT\n       above and option -f), the clock speed can be adjusted, i.e. time may run faster or  slower\n       for  the executed program. For example, \"+5y x10\" will set the faked time 5 years into the\n       future and make the time pass 10 times as fast (one real second equals 10 seconds measured\n       by  the  program). Similarly, the flow of time can be slowed, e.g. using \"-7d x0,2\", which\n       will set the faked time 7 days in the past and set the clock speed to 20 percent, i.e.  it\n       takes  five real world seconds for one second measured by the program. Again, depending on\n       your locale, either \"x2.0\" or \"x2,0\" may be required regarding the delimiter. You can also\n       make  faketime  to  advance  the  reported time by a preset interval upon each time() call\n       independently from the system's time using \"-7d  i2,0\",  where  \"i\"  is  followed  by  the\n       increase interval in seconds.\n\n       Faking  times  for  multiple  programs  or  even  system-wide  can  be simplified by using\n       ~/.faketimerc files and /etc/faketimerc.  Please  refer  to  the  README  that  came  with\n       faketime for warnings and details.\n\nAUTHOR\n       Please see the README and NEWS files for contributers.\n\nBUGS\n       Due  to  limitations of the LD_PRELOAD mechanism, faketime will not work with suidroot and\n       statically linked programs.  While  timestamps  and  time  offsets  will  work  for  child\n       processes,  speeding  the  clock  up or slowing it down might not work for child processes\n       spawned by the executed program as expected; a new instance of  libfaketime  is  used  for\n       each  child  process,  which means that the libfaketime start time, which is used in speed\n       adjustments, will also be  re-initialized.  Some  programs  may  dynamically  load  system\n       libraries,  such  as  librt,  at run-time and therefore bypass libfaketime. You may report\n       programs that do not work with libfaketime, but only if they are available as open source.\n\nREPORTING BUGS\n       Please use https://github.com/wolfcw/libfaketime/issues\n\nCOPYRIGHT\n       Copyright Â© 2003-2013 by the libfaketime authors.\n\n       There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR  A  PARTICULAR  PURPOSE.\n       You may redistribute copies of faketime under the terms of the GNU General Public License.\n       For more information about these matters, see the file named COPYING.\n\nSEE ALSO\n       ld.so(1), time(2), fstat(2)\n\n\n\n\n\nPowered by the Ubuntu Manpage Repository, file bugs in Launchpad\n© 2019 Canonical Ltd. Ubuntu and Canonical are registered trademarks of Canonical Ltd.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# faketime\n\n> Fake the system time for a given command.\n> More information: <https://manpages.ubuntu.com/manpages/trusty/man1/faketime.1.html>.\n\n- Fake the time to this evening, before printing the result of `date`:\n\n`faketime '{{today 23:30}}' {{date}}`\n\n- Open a new `bash` shell, which uses yesterday as the current date:\n\n`faketime '{{yesterday}}' {{bash}}`\n\n- Simulate how any program would act next friday night:\n\n`faketime '{{next Friday 1 am}}' {{path/to/any/program}}`\n"
 },
 {
   "command": "diff3",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "DIFF3(1)\t\t\t User Commands\t\t\t      DIFF3(1)\n\n\n\nNAME\n       diff3 - compare three files line by line\n\nSYNOPSIS\n       diff3 [OPTION]... MYFILE OLDFILE YOURFILE\n\nDESCRIPTION\n       Compare three files line by line.\n\n       -e  --ed\n\t      Output unmerged changes from OLDFILE to YOURFILE into MYFILE.\n\n       -E  --show-overlap\n\t      Output unmerged changes, bracketing conflicts.\n\n       -A  --show-all\n\t      Output all changes, bracketing conflicts.\n\n       -x  --overlap-only\n\t      Output overlapping changes.\n\n       -X     Output overlapping changes, bracketing them.\n\n       -3  --easy-only\n\t      Output unmerged nonoverlapping changes.\n\n       -m  --merge\n\t      Output merged file instead of ed script (default -A).\n\n       -L LABEL  --label=LABEL\n\t      Use LABEL instead of file name.\n\n       -i     Append `w' and `q' commands to ed scripts.\n\n       -a  --text\n\t      Treat all files as text.\n\n       -T  --initial-tab\n\t      Make tabs line up by prepending a tab.\n\n       --diff-program=PROGRAM\n\t      Use PROGRAM to compare files.\n\n       -v  --version\n\t      Output version info.\n\n       --help Output this help.\n\n       If a FILE is `-', read standard input.\n\nAUTHOR\n       Written by Randy Smith.\n\nREPORTING BUGS\n       Report bugs to <bug-gnu-utils@gnu.org>.\n\nCOPYRIGHT\n       Copyright (C) 2002 Free Software Foundation, Inc.\n\n       This  program  comes  with NO WARRANTY, to the extent permitted by law.\n       You may redistribute copies of this program under the terms of the  GNU\n       General\tPublic License.  For more information about these matters, see\n       the file named COPYING.\n\nSEE ALSO\n       The full documentation for diff3 is maintained as a Texinfo manual.  If\n       the  info  and  diff3 programs are properly installed at your site, the\n       command\n\n\t      info diff\n\n       should give you access to the complete manual.\n\n\n\ndiffutils 2.8.1 \t\t  April 2002\t\t\t      DIFF3(1)\n",
   "tldr_summary": "# diff3\n\n> Compare three files line by line.\n\n- Compare files:\n\n`diff3 {{file1}} {{file2}} {{file3}}`\n\n- Show all changes, outlining conflicts:\n\n`diff3 --show-all {{file1}} {{file2}} {{file3}}`\n"
 },
 {
   "command": "tshark",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# tshark\n\n> Packet analysis tool, CLI version of wireshark.\n\n- Monitor everything on localhost:\n\n`tshark`\n\n- Only capture packets matching a specific capture filter:\n\n`tshark -f '{{udp port 53}}'`\n\n- Only show packets matching a specific output filter:\n\n`tshark -Y '{{http.request.method == \"GET\"}}'`\n\n- Decode a TCP port using a specific protocol (e.g. HTTP):\n\n`tshark -d tcp.port=={{8888}},{{http}}`\n\n- Specify the format of captured output:\n\n`tshark -T {{json|text|ps|…}}`\n\n- Select specific fields to output:\n\n`tshark -T {{fields|ek|json|pdml}} -e {{http.request.method}} -e {{ip.src}}`\n\n- Write captured packet to a file:\n\n`tshark -w {{path/to/file}}`\n\n- Analyze packets from a file:\n\n`tshark -r {{filename}}.pcap`\n"
 },
 {
   "command": "expect",
   "doc_url": "https://linux.die.net/man/1/expect",
   "doc_text": "\n\nexpect(1) - Linux man page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpect(1) - Linux man page\nName\nexpect - programmed dialogue with interactive programs, Version 5\nSynopsis\nexpect [ -dDinN ] [ -c cmds ] [ [ -[f|b] ]\ncmdfile ] [ args ]\nIntroduction\n\n\n\n\n\nExpect is a program that \"talks\" to other interactive programs according to a script.\nFollowing the script, Expect knows what can be expected from a program and what the correct response should be. An interpreted language provides\nbranching and high-level control structures to direct the dialogue. In addition, the user can take control and interact directly when desired, afterward\nreturning control to the script.\nExpectk is a mixture of Expect and Tk. It behaves just like Expect and Tk's wish. Expect can also be used\ndirectly in C or C++ (that is, without Tcl). See libexpect(3).\nThe name \"Expect\" comes from the idea of send/expect sequences popularized by uucp, kermit and other modem control programs. However unlike uucp,\nExpect is generalized so that it can be run as a user-level command with any program and task in mind. Expect can actually talk to several\nprograms at the same time.\nFor example, here are some things Expect can do:\n\n\nCause your computer to dial you back, so that you can login without paying for the call.\nStart a game (e.g., rogue) and if the optimal configuration doesn't appear, restart it (again and again) until it does, then hand over control to you.\nRun fsck, and in response to its questions, answer \"yes\", \"no\" or give control back to you, based on predetermined criteria.\nConnect to another network or BBS (e.g., MCI Mail, CompuServe) and automatically retrieve your mail so that it appears as if it was originally sent to your\nlocal system.\nCarry environment variables, current directory, or any kind of information across rlogin, telnet, tip, su, chgrp, etc.\nThere are a variety of reasons why the shell cannot perform these tasks. (Try, you'll see.) All are possible with Expect.\nIn general, Expect is useful for running any program which requires interaction between the program and the user. All that is necessary is that the\ninteraction can be characterized programmatically. Expect can also give the user back control (without halting the program being controlled) if desired.\nSimilarly, the user can return control to the script at any time.\nUsage\nExpect reads cmdfile for a list of commands to execute. Expect may also be\ninvoked implicitly on systems which support the #! notation by marking the script executable, and making the first line in your script:\n#!/usr/local/bin/expect -fOf course, the path must accurately describe where Expect lives. /usr/local/bin is just an example.\nThe -c flag prefaces a command to be executed before any in the script. The command should be quoted to prevent being broken up by the shell. This\noption may be used multiple times. Multiple commands may be executed with a single -c by separating them with semicolons. Commands are executed in the\norder they appear. (When using Expectk, this option is specified as -command.)\nThe -d flag enables some diagnostic output, which primarily reports internal activity of commands such as expect and interact. This\nflag has the same effect as \"exp_internal 1\" at the beginning of an Expect script, plus the version of Expect is printed. (The strace command is\nuseful for tracing statements, and the trace command is useful for tracing variable assignments.) (When using Expectk, this option is specified as\n-diag.)\nThe -D flag enables an interactive debugger. An integer value should follow. The debugger will take control before the next Tcl procedure if the\nvalue is non-zero or if a ^C is pressed (or a breakpoint is hit, or other appropriate debugger command appears in the script). See the README file or SEE ALSO\n(below) for more information on the debugger. (When using Expectk, this option is specified as -Debug.)\nThe -f flag prefaces a file from which to read commands from. The flag itself is optional as it is only useful when using the #! notation (see\nabove), so that other arguments may be supplied on the command line. (When using Expectk, this option is specified as -file.)\nBy default, the command file is read into memory and executed in its entirety. It is occasionally desirable to read files one line at a time. For example,\nstdin is read this way. In order to force arbitrary files to be handled this way, use the -b flag. (When using Expectk, this option is specified as\n-buffer.) Note that stdio-buffering may still take place however this shouldn't cause problems when reading from a fifo or stdin.\nIf the string \"-\" is supplied as a filename, standard input is read instead. (Use \"./-\" to read from a file actually named \"-\".)\nThe -i flag causes Expect to interactively prompt for commands instead of reading them from a file. Prompting is terminated via the\nexit command or upon EOF. See interpreter (below) for more information. -i is assumed if neither a command file nor -c is used.\n(When using Expectk, this option is specified as -interactive.)\n-- may be used to delimit the end of the options. This is useful if you want to pass an option-like argument to your script without it being\ninterpreted by Expect. This can usefully be placed in the #! line to prevent any flag-like interpretation by Expect. For example, the following will\nleave the original arguments (including the script name) in the variable argv.\n#!/usr/local/bin/expect --Note that the usual getopt(3) and execve(2) conventions must be observed when adding arguments to the #! line.\nThe file $exp_library/expect.rc is sourced automatically if present, unless the -N flag is used. (When using Expectk, this option is specified as\n-NORC.) Immediately after this, the file ~/.expect.rc is sourced automatically, unless the -n flag is used. If the environment variable DOTDIR is\ndefined, it is treated as a directory and .expect.rc is read from there. (When using Expectk, this option is specified as -norc.) This sourcing occurs\nonly after executing any -c flags.\n-v causes Expect to print its version number and exit. (The corresponding flag in Expectk, which uses long flag names, is -version.)\nOptional args are constructed into a list and stored in the variable named argv. argc is initialized to the length of argv.\nargv0 is defined to be the name of the script (or binary if no script is used). For example, the following prints out the name of the script and the\nfirst three arguments:send_user \"$argv0 [lrange $argv 0 2]\\n\"\nCommands\nExpect uses Tcl (Tool Command Language). Tcl provides control flow (e.g., if, for,\nbreak), expression evaluation and several other features such as recursion, procedure definition, etc. Commands used here but not defined (e.g., set,\nif, exec) are Tcl commands (see tcl(3)). Expect supports additional commands, described below. Unless otherwise specified, commands\nreturn the empty string.\nCommands are listed alphabetically so that they can be quickly located. However, new users may find it easier to start by reading the descriptions of\nspawn, send, expect, and interact, in that order.\nNote that the best introduction to the language (both Expect and Tcl) is provided in the book \"Exploring Expect\" (see SEE ALSO below). Examples are included\nin this man page but they are very limited since this man page is meant primarily as reference material.\nNote that in the text of this man page, \"Expect\" with an uppercase \"E\" refers to the Expect program while \"expect\" with a lower-case \"e\" refers to\nthe expect command within the Expect program.)\n\nclose [-slave] [-onexec 0|1] [-i spawn_id]\ncloses the connection to the current process. Most interactive programs will detect EOF on their stdin and exit; thus close usually suffices to kill\nthe process as well. The -i flag declares the process to close corresponding to the named spawn_id.\nBoth expect and interact will detect when the current process exits and implicitly do a close. But if you kill the process by, say,\n\"exec kill $pid\", you will need to explicitly call close.\nThe -onexec flag determines whether the spawn id will be closed in any new spawned processes or if the process is overlayed. To leave a spawn id\nopen, use the value 0. A non-zero integer value will force the spawn closed (the default) in any new processes.\nThe -slave flag closes the slave associated with the spawn id. (See \"spawn -pty\".) When the connection is closed, the slave is automatically closed\nas well if still open.\nNo matter whether the connection is closed implicitly or explicitly, you should call wait to clear up the corresponding kernel process slot.\nclose does not call wait since there is no guarantee that closing a process connection will cause it to exit. See wait below for more\ninfo.\ndebug [[-now] 0|1]\ncontrols a Tcl debugger allowing you to step through statements, set breakpoints, etc.\nWith no arguments, a 1 is returned if the debugger is not running, otherwise a 0 is returned.\nWith a 1 argument, the debugger is started. With a 0 argument, the debugger is stopped. If a 1 argument is preceded by the -now flag, the debugger is\nstarted immediately (i.e., in the middle of the debug command itself). Otherwise, the debugger is started with the next Tcl statement.\nThe debug command does not change any traps. Compare this to starting Expect with the -D flag (see above).\nSee the README file or SEE ALSO (below) for more information on the debugger.\ndisconnect\ndisconnects a forked process from the terminal. It continues running in the background. The process is given its own process group (if possible). Standard\nI/O is redirected to /dev/null.\nThe following fragment uses\ndisconnect to continue running the script in the background.if {[fork]!=0} exit\ndisconnect\n. . .\nThe following script reads a password, and then runs a program every hour that demands a password each time it is run. The script supplies the password so that\nyou only have to type it once. (See the stty command which demonstrates how to turn off password echoing.)send_user \"password?\\ \"\nexpect_user -re \"(.*)\\n\"\nfor {} 1 {} {\n    if {[fork]!=0} {sleep 3600;continue}\n    disconnect\n    spawn priv_prog\n    expect Password:\n    send \"$expect_out(1,string)\\r\"\n    . . .\n    exit\n}\nAn advantage to using disconnect over the shell asynchronous process feature (&) is that Expect can save the terminal parameters prior to\ndisconnection, and then later apply them to new ptys. With &, Expect does not have a chance to read the terminal's parameters since the terminal is\nalready disconnected by the time Expect receives control.\nexit [-opts] [status]\ncauses Expect to exit or otherwise prepare to do so.\nThe -onexit flag causes the next argument to be used as an exit handler. Without an argument, the current exit handler is returned.\nThe -noexit flag causes Expect to prepare to exit but stop short of actually returning control to the operating system. The user-defined exit\nhandler is run as well as Expect's own internal handlers. No further Expect commands should be executed. This is useful if you are running Expect with other\nTcl extensions. The current interpreter (and main window if in the Tk environment) remain so that other Tcl extensions can clean up. If Expect's exit is\ncalled again (however this might occur), the handlers are not rerun.\nUpon exiting, all connections to spawned processes are closed. Closure will be detected as an EOF by spawned processes. exit takes no other actions\nbeyond what the normal _exit(2) procedure does. Thus, spawned processes that do not check for EOF may continue to run. (A variety of conditions are important\nto determining, for example, what signals a spawned process will be sent, but these are system-dependent, typically documented under exit(3).) Spawned\nprocesses that continue to run will be inherited by init.\nstatus (or 0 if not specified) is returned as the exit status of Expect. exit is implicitly executed if the end of the script is\nreached.\nexp_continue [-continue_timer]\nThe command exp_continue allows expect itself to continue executing rather than returning as it normally would. By default\nexp_continue resets the timeout timer. The -continue_timer flag prevents timer from being restarted. (See expect for more information.)\nexp_internal[-f file] value\ncauses further commands to send diagnostic information internal to Expect to stderr if value is non-zero. This output is disabled if\nvalue is 0. The diagnostic information includes every character received, and every attempt made to match the current output against the patterns.\nIf the optional\nfile is supplied, all normal and debugging output is written to that file (regardless of the value of value). Any previous diagnostic output\nfile is closed.\nThe -info flag causes exp_internal to return a description of the most recent non-info arguments given.\nexp_open [args] [-i spawn_id]\nreturns a Tcl file identifier that corresponds to the original spawn id. The file identifier can then be used as if it were opened by Tcl's open\ncommand. (The spawn id should no longer be used. A wait should not be executed.\nThe -leaveopen flag leaves the spawn id open for access through Expect commands. A wait must be executed on the spawn id.\nexp_pid [-i spawn_id]\nreturns the process id corresponding to the currently spawned process. If the -i flag is used, the pid returned corresponds to that of the given\nspawn id.\nexp_send\nis an alias for send.\nexp_send_error\nis an alias for send_error.\nexp_send_log\nis an alias for send_log.\nexp_send_tty\nis an alias for send_tty.\nexp_send_user\nis an alias for send_user.\nexp_version [[-exit] version]\nis useful for assuring that the script is compatible with the current version of Expect.\nWith no arguments, the current version of\nExpect is returned. This version may then be encoded in your script. If you actually know that you are not using features of recent versions, you\ncan specify an earlier version.\nVersions consist of three numbers separated by dots. First\nis the major number. Scripts written for versions of Expect with a different major number will almost certainly not work. exp_version returns\nan error if the major numbers do not match.\nSecond is the minor number. Scripts written for a version with a\ngreater minor number than the current version may depend upon some new feature and might not run. exp_version returns an error if the major numbers\nmatch, but the script minor number is greater than that of the running Expect.\nThird is a number that plays no part in the version comparison.\nHowever, it is incremented when the Expect software distribution is changed in any way, such as by additional documentation or optimization. It is\nreset to 0 upon each new minor version.\nWith the\n-exit flag, Expect prints an error and exits if the version is out of date.\nexpect [[-opts] pat1 body1] ... [-opts] patn [bodyn]\nwaits until one of the patterns matches the output of a spawned process, a specified time period has passed, or an end-of-file is seen. If the final body\nis empty, it may be omitted.\nPatterns from the most recent\nexpect_before command are implicitly used before any other patterns. Patterns from the most recent expect_after command are implicitly used\nafter any other patterns.\nIf the arguments to the entire\nexpect statement require more than one line, all the arguments may be \"braced\" into one so as to avoid terminating each line with a backslash. In\nthis one case, the usual Tcl substitutions will occur despite the braces.\nIf a pattern is the keyword\neof, the corresponding body is executed upon end-of-file. If a pattern is the keyword timeout, the corresponding body is executed upon\ntimeout. If no timeout keyword is used, an implicit null action is executed upon timeout. The default timeout period is 10 seconds but may be set, for example\nto 30, by the command \"set timeout 30\". An infinite timeout may be designated by the value -1. If a pattern is the keyword default, the corresponding\nbody is executed upon either timeout or end-of-file.\nIf a pattern matches, then the corresponding body is executed.\nexpect returns the result of the body (or the empty string if no pattern matched). In the event that multiple patterns match, the one appearing\nfirst is used to select a body.\nEach time new output arrives, it is compared to each pattern in the order\nthey are listed. Thus, you may test for absence of a match by making the last pattern something guaranteed to appear, such as a prompt. In situations where\nthere is no prompt, you must use timeout (just like you would if you were interacting manually).\nPatterns are specified in three ways. By default,\npatterns are specified as with Tcl's string match command. (Such patterns are also similar to C-shell regular expressions usually referred to as\n\"glob\" patterns). The -gl flag may may be used to protect patterns that might otherwise match expect flags from doing so. Any pattern beginning\nwith a \"-\" should be protected this way. (All strings starting with \"-\" are reserved for future options.)\nFor example, the following fragment looks for a successful login.\n(Note that abort is presumed to be a procedure defined elsewhere in the script.)expect {\n    busy               {puts busy\\n ; exp_continue}\n    failed             abort\n    \"invalid password\" abort\n    timeout            abort\n    connected\n}\nQuotes are necessary on the fourth pattern since it contains a space, which would otherwise separate the pattern from the action. Patterns with the same action\n(such as the 3rd and 4th) require listing the actions again. This can be avoid by using regexp-style patterns (see below). More information on forming\nglob-style patterns can be found in the Tcl manual.\nRegexp-style patterns follow the syntax defined by Tcl's\nregexp (short for \"regular expression\") command. regexp patterns are introduced with the flag -re. The previous example can be rewritten\nusing a regexp as:expect {\n    busy       {puts busy\\n ; exp_continue}\n    -re \"failed|invalid password\" abort\n    timeout    abort\n    connected\n}\nBoth types of patterns are \"unanchored\". This means that patterns do not have to match the entire string, but can begin and end the match anywhere in the\nstring (as long as everything else matches). Use ^ to match the beginning of a string, and $ to match the end. Note that if you do not wait for the end of a\nstring, your responses can easily end up in the middle of the string as they are echoed from the spawned process. While still producing correct results, the\noutput can look unnatural. Thus, use of $ is encouraged if you can exactly describe the characters at the end of a string.\nNote that in many editors, the ^ and $ match the beginning and end of lines respectively. However, because expect is not line oriented, these characters\nmatch the beginning and end of the data (as opposed to lines) currently in the expect matching buffer. (Also, see the note below on \"system indigestion.\")\nThe -ex flag causes the pattern to be matched as an \"exact\" string. No interpretation of *, ^, etc is made (although the usual Tcl conventions must\nstill be observed). Exact patterns are always unanchored.\nThe\n-nocase flag causes uppercase characters of the output to compare as if they were lowercase characters. The pattern is not affected.\nWhile reading output,\nmore than 2000 bytes can force earlier bytes to be \"forgotten\". This may be changed with the function match_max. (Note that excessively large values\ncan slow down the pattern matcher.) If patlist is full_buffer, the corresponding body is executed if match_max bytes have been received\nand no other patterns have matched. Whether or not the full_buffer keyword is used, the forgotten characters are written to expect_out(buffer).\nIf patlist is the keyword null, and nulls are allowed (via the remove_nulls command), the corresponding body is executed if a single\nASCII 0 is matched. It is not possible to match 0 bytes via glob or regexp patterns.\nUpon matching a pattern (or eof or full_buffer), any matching and previously unmatched output is saved in the variable expect_out(buffer). Up to 9\nregexp substring matches are saved in the variables expect_out(1,string) through expect_out(9,string). If the -indices flag is used before\na pattern, the starting and ending indices (in a form suitable for lrange) of the 10 strings are stored in the variables expect_out(X,start) and\nexpect_out(X,end) where X is a digit, corresponds to the substring position in the buffer. 0 refers to strings which matched the entire pattern and is\ngenerated for glob patterns as well as regexp patterns. For example, if a process has produced output of \"abcdefgh\\n\", the result of:expect \"cd\"\nis as if the following statements had executed:set expect_out(0,string) cd\nset expect_out(buffer) abcd\nand \"efgh\\n\" is left in the output buffer. If a process produced the output \"abbbcabkkkka\\n\", the result of:expect -indices -re \"b(b*).*(k+)\"\nis as if the following statements had executed:set expect_out(0,start) 1\nset expect_out(0,end) 10\nset expect_out(0,string) bbbcabkkkk\nset expect_out(1,start) 2\nset expect_out(1,end) 3\nset expect_out(1,string) bb\nset expect_out(2,start) 10\nset expect_out(2,end) 10\nset expect_out(2,string) k\nset expect_out(buffer) abbbcabkkkk\nand \"a\\n\" is left in the output buffer. The pattern \"*\" (and -re \".*\") will flush the output buffer without reading any more output from the process.\nNormally, the matched output is discarded from Expect's internal buffers.\nThis may be prevented by prefixing a pattern with the -notransfer flag. This flag is especially useful in experimenting (and can be abbreviated to\n\"-not\" for convenience while experimenting).\nThe spawn id associated with the matching output (or eof or full_buffer) is stored in expect_out(spawn_id).\nThe -timeout flag causes the current expect command to use the following value as a timeout instead of using the value of the timeout variable.\nBy default, patterns are matched against output from the current process, however the -i flag declares the output from the named spawn_id list be\nmatched against any following patterns (up to the next -i). The spawn_id list should either be a whitespace separated list of spawn_ids or a variable\nreferring to such a list of spawn_ids.\nFor example, the following example waits for \"connected\" from the current process, or \"busy\", \"failed\" or \"invalid password\" from the spawn_id named by\n$proc2.expect {\n    -i $proc2 busy {puts busy\\n ; exp_continue}\n    -re \"failed|invalid password\" abort\n    timeout abort\n    connected\n}\nThe value of the global variable any_spawn_id may be used to match patterns to any spawn_ids that are named with all other -i flags in the\ncurrent expect command. The spawn_id from a -i flag with no associated pattern (i.e., followed immediately by another -i) is made\navailable to any other patterns in the same expect command associated with any_spawn_id.\nThe -i flag may also name a global variable in which case the variable is read for a list of spawn ids. The variable is reread whenever it changes.\nThis provides a way of changing the I/O source while the command is in execution. Spawn ids provided this way are called \"indirect\" spawn ids.\nActions such as break and continue cause control structures (i.e., for, proc) to behave in the usual way. The command\nexp_continue allows expect itself to continue executing rather than returning as it normally would.\nThis is useful for avoiding explicit loops or repeated expect statements.\nThe following example is part of a fragment to automate rlogin. The exp_continue avoids having to write a second expect statement (to look\nfor the prompt again) if the rlogin prompts for a password.expect {\n    Password: {\n        stty -echo\n        send_user \"password (for $user) on $host: \"\n        expect_user -re \"(.*)\\n\"\n        send_user \"\\n\"\n        send \"$expect_out(1,string)\\r\"\n        stty echo\n        exp_continue\n    } incorrect {\n        send_user \"invalid password or account\\n\"\n        exit\n    } timeout {\n        send_user \"connection to $host timed out\\n\"\n        exit\n    } eof {\n        send_user \\\n            \"connection to host failed: $expect_out(buffer)\"\n        exit\n    } -re $prompt\n}\nFor example, the following fragment might help a user guide an interaction that is already totally automated. In this case, the terminal is put into raw mode.\nIf the user presses \"+\", a variable is incremented. If \"p\" is pressed, several returns are sent to the process, perhaps to poke it in some way, and \"i\" lets\nthe user interact with the process, effectively stealing away control from the script. In each case, the exp_continue allows the current expect\nto continue pattern matching after executing the current action.stty raw -echo\nexpect_after {\n    -i $user_spawn_id\n    \"p\" {send \"\\r\\r\\r\"; exp_continue}\n    \"+\" {incr foo; exp_continue}\n    \"i\" {interact; exp_continue}\n    \"quit\" exit\n}\nBy default,\nexp_continue resets the timeout timer. The timer is not restarted, if exp_continue is called with the -continue_timer flag.\nexpect_after [expect_args]\nworks identically to the expect_before except that if patterns from both expect and expect_after can match, the expect pattern\nis used. See the expect_before command for more information.\nexpect_background [expect_args]\ntakes the same arguments as expect, however it returns immediately. Patterns are tested whenever new input arrives. The pattern timeout and\ndefault are meaningless to expect_background and are silently discarded. Otherwise, the expect_background command uses\nexpect_before and expect_after patterns just like expect does.\nWhen expect_background actions are being evaluated, background processing for the same spawn id is blocked. Background processing is unblocked when\nthe action completes. While background processing is blocked, it is possible to do a (foreground) expect on the same spawn id.\nIt is not possible to execute an expect while an expect_background is unblocked. expect_background for a particular spawn id is deleted\nby declaring a new expect_background with the same spawn id. Declaring expect_background with no pattern removes the given spawn id from the ability to\nmatch patterns in the background.\nexpect_before [expect_args]\ntakes the same arguments as expect, however it returns immediately. Pattern-action pairs from the most recent expect_before with the same\nspawn id are implicitly added to any following expect commands. If a pattern matches, it is treated as if it had been specified in the expect\ncommand itself, and the associated body is executed in the context of the expect command. If patterns from both expect_before and expect\ncan match, the expect_before pattern is used.\nIf no pattern is specified, the spawn id is not checked for any patterns.\nUnless overridden by a -i flag, expect_before patterns match against the spawn id defined at the time that the expect_before command\nwas executed (not when its pattern is matched).\nThe -info flag causes expect_before to return the current specifications of what patterns it will match. By default, it reports on the current spawn\nid. An optional spawn id specification may be given for information on that spawn id. For exampleexpect_before -info -i $proc\nAt most one spawn id specification may be given. The flag -indirect suppresses direct spawn ids that come only from indirect specifications.\nInstead of a spawn id specification, the flag \"-all\" will cause \"-info\" to report on all spawn ids.\nThe output of the -info flag can be reused as the argument to expect_before.\nexpect_tty [expect_args]\nis like expect but it reads characters from /dev/tty (i.e. keystrokes from the user). By default, reading is performed in cooked mode. Thus, lines\nmust end with a return in order for expect to see them. This may be changed via stty (see the stty command below).\nexpect_user[expect_args]\nis like expect but it reads characters from stdin (i.e. keystrokes from the user). By default, reading is performed in cooked mode. Thus, lines must\nend with a return in order for expect to see them. This may be changed via stty (see the stty command below).\nfork\ncreates a new process. The new process is an exact copy of the current Expect process. On success, fork returns 0 to the new (child) process\nand returns the process ID of the child process to the parent process. On failure (invariably due to lack of resources, e.g., swap space, memory), fork\nreturns -1 to the parent process, and no child process is created.\nForked processes exit via the\nexit command, just like the original process. Forked processes are allowed to write to the log files. If you do not disable debugging or logging in\nmost of the processes, the result can be confusing.\nSome pty implementations may be confused by multiple readers and writers,\neven momentarily. Thus, it is safest to fork before spawning processes.\ninteract [string1 body1] ... [stringn [bodyn]]\ngives control of the current process to the user, so that keystrokes are sent to the current process, and the stdout and stderr of the current process are\nreturned.\nString-body pairs may be specified as arguments, in which case the\nbody is executed when the corresponding string is entered. (By default, the string is not sent to the current process.) The interpreter command is\nassumed, if the final body is missing.\nIf the arguments to the entire\ninteract statement require more than one line, all the arguments may be \"braced\" into one so as to avoid terminating each line with a backslash. In\nthis one case, the usual Tcl substitutions will occur despite the braces.\nFor example, the following command runs interact with the following\nstring-body pairs defined: When ^Z is pressed, Expect is suspended. (The -reset flag restores the terminal modes.) When ^A is pressed, the\nuser sees \"you typed a control-A\" and the process is sent a ^A. When $ is pressed, the user sees the date. When ^C is pressed, Expect exits. If \"foo\" is\nentered, the user sees \"bar\". When ~~ is pressed, the Expect interpreter runs interactively.set CTRLZ \\032\ninteract {\n    -reset $CTRLZ {exec kill -STOP [pid]}\n    \\001   {send_user \"you typed a control-A\\n\";\n            send \"\\001\"\n           }\n    $      {send_user \"The date is [clock format [clock seconds]].\"}\n    \\003   exit\n    foo    {send_user \"bar\"}\n    ~~\n}\nIn string-body pairs, strings are matched in the order they are listed\nas arguments. Strings that partially match are not sent to the current process in anticipation of the remainder coming. If characters are then entered such\nthat there can no longer possibly be a match, only the part of the string will be sent to the process that cannot possibly begin another match. Thus, strings\nthat are substrings of partial matches can match later, if the original strings that was attempting to be match ultimately fails.\nBy default, string matching is exact with no wild cards. (In contrast,\nthe expect command uses glob-style patterns by default.) The -ex flag may be used to protect patterns that might otherwise match\ninteract flags from doing so. Any pattern beginning with a \"-\" should be protected this way. (All strings starting with \"-\" are reserved for future\noptions.)\nThe -re flag forces the string to be interpreted as a regexp-style pattern. In this case, matching substrings are stored in the variable\ninteract_out similarly to the way expect stores its output in the variable expect_out. The -indices flag is similarly supported.\nThe pattern eof introduces an action that is executed upon end-of-file. A separate eof pattern may also follow the -output flag in\nwhich case it is matched if an eof is detected while writing output. The default eof action is \"return\", so that interact simply returns upon any\nEOF.\nThe pattern timeout introduces a timeout (in seconds) and action that is executed after no characters have been read for a given time. The\ntimeout pattern applies to the most recently specified process. There is no default timeout. The special variable \"timeout\" (used by the expect\ncommand) has no affect on this timeout.\nFor example, the following statement could be used to autologout users who have not typed anything for an hour but who still get frequent system\nmessages:interact -input $user_spawn_id timeout 3600 return -output \\\n    $spawn_idIf the pattern is the keyword null, and nulls are allowed (via the remove_nulls command), the corresponding body is executed if a single ASCII\n0 is matched. It is not possible to match 0 bytes via glob or regexp patterns.\nPrefacing a pattern with the flag -iwrite causes the variable interact_out(spawn_id) to be set to the spawn_id which matched the pattern (or\neof).\nActions such as break and continue cause control structures (i.e., for, proc) to behave in the usual way. However return\ncauses interact to return to its caller, while inter_return causes interact to cause a return in its caller. For example, if \"proc foo\" called\ninteract which then executed the action inter_return, proc foo would return. (This means that if interact calls interpreter\ninteractively typing return will cause the interact to continue, while inter_return will cause the interact to return to its caller.)\nDuring\ninteract, raw mode is used so that all characters may be passed to the current process. If the current process does not catch job control signals,\nit will stop if sent a stop signal (by default ^Z). To restart it, send a continue signal (such as by \"kill -CONT <pid>\"). If you really want to send a\nSIGSTOP to such a process (by ^Z), consider spawning csh first and then running your program. On the other hand, if you want to send a SIGSTOP to Expect\nitself, first call interpreter (perhaps by using an escape character), and then press ^Z.\nString-body pairs can be used as a shorthand for avoiding having\nto enter the interpreter and execute commands interactively. The previous terminal mode is used while the body of a string-body pair is being executed.\nFor speed, actions execute in raw mode by default. The\n-reset flag resets the terminal to the mode it had before interact was executed (invariably, cooked mode). Note that characters entered when\nthe mode is being switched may be lost (an unfortunate feature of the terminal driver on some systems). The only reason to use -reset is if your action\ndepends on running in cooked mode.\nThe\n-echo flag sends characters that match the following pattern back to the process that generated them as each character is read. This may be useful\nwhen the user needs to see feedback from partially typed patterns.\nIf a pattern is being echoed but eventually fails to match,\nthe characters are sent to the spawned process. If the spawned process then echoes them, the user will see the characters twice. -echo is probably\nonly appropriate in situations where the user is unlikely to not complete the pattern. For example, the following excerpt is from rftp, the recursive-ftp\nscript, where the user is prompted to enter ~g, ~p, or ~l, to get, put, or list the current directory recursively. These are so far away from the normal ftp\ncommands, that the user is unlikely to type ~ followed by anything else, except mistakenly, in which case, they'll probably just ignore the result anyway.interact {\n    -echo ~g {getcurdirectory 1}\n    -echo ~l {getcurdirectory 0}\n    -echo ~p {putcurdirectory}\n}\nThe -nobuffer flag sends characters that match the following pattern on to the output process as characters are read.\nThis is useful when you wish to let a program echo back the pattern. For example, the following might be used to monitor where a person is dialing (a\nHayes-style modem). Each time \"atd\" is seen the script logs the rest of the line.proc lognumber {} {\n    interact -nobuffer -re \"(.*)\\r\" return\n    puts $log \"[clock format [clock seconds]]: dialed $interact_out(1,string)\"\n}\ninteract -nobuffer \"atd\" lognumber\nDuring\ninteract, previous use of log_user is ignored. In particular, interact will force its output to be logged (sent to the standard\noutput) since it is presumed the user doesn't wish to interact blindly.\nThe\n-o flag causes any following key-body pairs to be applied to the output of the current process. This can be useful, for example, when dealing with\nhosts that send unwanted characters during a telnet session.\nBy default,\ninteract expects the user to be writing stdin and reading stdout of the Expect process itself. The -u flag (for \"user\") makes\ninteract look for the user as the process named by its argument (which must be a spawned id).\nThis allows two unrelated processes to be joined\ntogether without using an explicit loop. To aid in debugging, Expect diagnostics always go to stderr (or stdout for certain logging and debugging\ninformation). For the same reason, the interpreter command will read interactively from stdin.\nFor example, the following fragment creates a login process.\nThen it dials the user (not shown), and finally connects the two together. Of course, any process may be substituted for login. A shell, for example, would\nallow the user to work without supplying an account and password.spawn login\nset login $spawn_id\nspawn tip modem\n# dial back out to user\n# connect user to login\ninteract -u $login\nTo send output to multiple processes, list each spawn id list prefaced by a -output flag. Input for a group of output spawn ids may be determined by a\nspawn id list prefaced by a -input flag. (Both -input and -output may take lists in the same form as the -i flag in the\nexpect command, except that any_spawn_id is not meaningful in interact.) All following flags and strings (or patterns) apply to this input until\nanother -input flag appears. If no -input appears, -output implies \"-input $user_spawn_id -output\". (Similarly, with patterns that do not have\n-input.) If one -input is specified, it overrides $user_spawn_id. If a second -input is specified, it overrides $spawn_id. Additional\n-input flags may be specified.\nThe two implied input processes default to having their outputs specified as $spawn_id and $user_spawn_id (in reverse). If a -input flag appears with\nno -output flag, characters from that process are discarded.\nThe -i flag introduces a replacement for the current spawn_id when no other -input or -output flags are used. A -i flag implies a -o\nflag.\nIt is possible to change the processes that are being interacted with by using indirect spawn ids. (Indirect spawn ids are described in the section on the\nexpect command.) Indirect spawn ids may be specified with the -i, -u, -input, or -output flags.\ninterpreter \" [args]\"\ncauses the user to be interactively prompted for Expect and Tcl commands. The result of each command is printed.\nActions such as\nbreak and continue cause control structures (i.e., for, proc) to behave in the usual way. However return causes\ninterpreter to return to its caller, while inter_return causes interpreter to cause a return in its caller. For example, if \"proc foo\" called\ninterpreter which then executed the action inter_return, proc foo would return. Any other command causes interpreter to continue\nprompting for new commands.\nBy default, the prompt contains two integers.\nThe first integer describes the depth of the evaluation stack (i.e., how many times Tcl_Eval has been called). The second integer is the Tcl history\nidentifier. The prompt can be set by defining a procedure called \"prompt1\" whose return value becomes the next prompt. If a statement has open quotes, parens,\nbraces, or brackets, a secondary prompt (by default \"+> \") is issued upon newline. The secondary prompt may be set by defining a procedure called \"prompt2\".\nDuring\ninterpreter, cooked mode is used, even if the its caller was using raw mode.\nIf stdin is closed,\ninterpreter will return unless the -eof flag is used, in which case the subsequent argument is invoked.\nlog_file[args] [[-a] file]\nIf a filename is provided, log_file will record a transcript of the session (beginning at that point) in the file. log_file will stop\nrecording if no argument is given. Any previous log file is closed.\nInstead of a filename, a Tcl file identifier may be provided by using the -open or -leaveopen flags. This is similar to the spawn\ncommand. (See spawn for more info.)\nThe -a flag forces output to be logged that was suppressed by the log_user command.\nBy default, the log_file command appends to old files rather than truncating them, for the convenience of being able to turn logging off and\non multiple times in one session. To truncate files, use the -noappend flag.\nThe -info flag causes log_file to return a description of the most recent non-info arguments given.\nlog_user -info|0|1\nBy default, the send/expect dialogue is logged to stdout (and a logfile if open). The logging to stdout is disabled by the command \"log_user 0\" and\nreenabled by \"log_user 1\". Logging to the logfile is unchanged.\nThe -info flag causes log_user to return a description of the most recent non-info arguments given.\nmatch_max [-d] [-i spawn_id] [size]\ndefines the size of the buffer (in bytes) used internally by expect. With no size argument, the current size is returned.\nWith the\n-d flag, the default size is set. (The initial default is 2000.) With the -i flag, the size is set for the named spawn id, otherwise it is\nset for the current process.\noverlay [-# spawn_id] [-# spawn_id] [...] program [args]\nexecutes program args in place of the current Expect program, which terminates. A bare hyphen argument forces a hyphen in front of the\ncommand name as if it was a login shell. All spawn_ids are closed except for those named as arguments. These are mapped onto the named file identifiers.\nSpawn_ids are mapped to file identifiers for the new program to inherit.\nFor example, the following line runs chess and allows it to be controlled by the current process - say, a chess master.overlay -0 $spawn_id -1 $spawn_id -2 $spawn_id chess\nThis is more efficient than \"interact -u\", however, it sacrifices the ability to do programmed interaction since the Expect process is no longer in\ncontrol.\nNote that no controlling terminal is provided. Thus, if you\ndisconnect or remap standard input, programs that do job control (shells, login, etc) will not function properly.\nparity [-d] [-i spawn_id] [value]\ndefines whether parity should be retained or stripped from the output of spawned processes. If value is zero, parity is stripped, otherwise it is\nnot stripped. With no value argument, the current value is returned.\nWith the\n-d flag, the default parity value is set. (The initial default is 1, i.e., parity is not stripped.) With the -i flag, the parity value is set\nfor the named spawn id, otherwise it is set for the current process.\nremove_nulls [-d] [-i spawn_id] [value]\ndefines whether nulls are retained or removed from the output of spawned processes before pattern matching or storing in the variable expect_out or\ninteract_out. If value is 1, nulls are removed. If value is 0, nulls are not removed. With no value argument, the current value is\nreturned.\nWith the\n-d flag, the default value is set. (The initial default is 1, i.e., nulls are removed.) With the -i flag, the value is set for the named\nspawn id, otherwise it is set for the current process.\nWhether or not nulls are removed, Expect will record null bytes to the log and stdout.\nsend [-flags] string\nSends string to the current process. For example, the commandsend \"hello world\\r\"\nsends the characters, h e l l o <blank> w o r l d <return> to the current process. (Tcl includes a printf-like command (called format) which\ncan build arbitrarily complex strings.)\nCharacters are sent immediately although programs with line-buffered input\nwill not read the characters until a return character is sent. A return character is denoted \"\\r\".\nThe -- flag forces the next argument to be interpreted as a string rather than a flag. Any string can be preceded by \"--\" whether or not it actually\nlooks like a flag. This provides a reliable mechanism to specify variable strings without being tripped up by those that accidentally look like flags. (All\nstrings starting with \"-\" are reserved for future options.)\nThe -i flag declares that the string be sent to the named spawn_id. If the spawn_id is user_spawn_id, and the terminal is in raw mode,\nnewlines in the string are translated to return-newline sequences so that they appear as if the terminal was in cooked mode. The -raw flag disables this\ntranslation.\nThe -null flag sends null characters (0 bytes). By default, one null is sent. An integer may follow the -null to indicate how many nulls to\nsend.\nThe -break flag generates a break condition. This only makes sense if the spawn id refers to a tty device opened via \"spawn -open\". If you have\nspawned a process such as tip, you should use tip's convention for generating a break.\nThe -s flag forces output to be sent \"slowly\", thus avoid the common situation where a computer outtypes an input buffer that was designed for a\nhuman who would never outtype the same buffer. This output is controlled by the value of the variable \"send_slow\" which takes a two element list. The first\nelement is an integer that describes the number of bytes to send atomically. The second element is a real number that describes the number of seconds by which\nthe atomic sends must be separated. For example, \"set send_slow {10 .001}\" would force \"send -s\" to send strings with 1 millisecond in between each 10\ncharacters sent.\nThe -h flag forces output to be sent (somewhat) like a human actually typing. Human-like delays appear between the characters. (The algorithm is\nbased upon a Weibull distribution, with modifications to suit this particular application.) This output is controlled by the value of the variable \"send_human\"\nwhich takes a five element list. The first two elements are average interarrival time of characters in seconds. The first is used by default. The second is\nused at word endings, to simulate the subtle pauses that occasionally occur at such transitions. The third parameter is a measure of variability where .1 is\nquite variable, 1 is reasonably variable, and 10 is quite invariable. The extremes are 0 to infinity. The last two parameters are, respectively, a minimum and\nmaximum interarrival time. The minimum and maximum are used last and \"clip\" the final time. The ultimate average can be quite different from the given average\nif the minimum and maximum clip enough values.\nAs an example, the following command emulates a fast and consistent typist:set send_human {.1 .3 1 .05 2}\nsend -h \"I'm hungry.  Let's do lunch.\"\nwhile the following might be more suitable after a hangover:set send_human {.4 .4 .2 .5 100}\nsend -h \"Goodd party lash night!\"\nNote that errors are not simulated, although you can set up error correction situations yourself by embedding mistakes and corrections in a send argument.\nThe flags for sending null characters, for sending breaks, for forcing slow output and for human-style output are mutually exclusive. Only the one specified\nlast will be used. Furthermore, no string argument can be specified with the flags for sending null characters or breaks.\nIt is a good idea to precede the first send to a process by an expect. expect will wait for the process to start, while send\ncannot. In particular, if the first send completes before the process starts running, you run the risk of having your data ignored. In situations where\ninteractive programs offer no initial prompt, you can precede send by a delay as in:# To avoid giving hackers hints on how to break in,\n# this system does not prompt for an external password.\n# Wait for 5 seconds for exec to complete\nspawn telnet very.secure.gov\nsleep 5\nsend password\\r\nexp_send is an alias for send. If you are using Expectk or some other variant of Expect in the Tk environment, send is defined by\nTk for an entirely different purpose. exp_send is provided for compatibility between environments. Similar aliases are provided for other Expect's other\nsend commands.\nsend_error[-flags] string\nis like send, except that the output is sent to stderr rather than the current process.\nsend_log [--] string\nis like send, except that the string is only sent to the log file (see log_file.) The arguments are ignored if no log file is open.\nsend_tty [-flags] string\nis like send, except that the output is sent to /dev/tty rather than the current process.\nsend_user[-flags] string\nis like send, except that the output is sent to stdout rather than the current process.\nsleep seconds\ncauses the script to sleep for the given number of seconds. Seconds may be a decimal number. Interrupts (and Tk events if you are using Expectk) are\nprocessed while Expect sleeps.\nspawn[args] program [args]\ncreates a new process running program args. Its stdin, stdout and stderr are connected to Expect, so that they may be read and written by other\nExpect commands. The connection is broken by close or if the process itself closes any of the file identifiers.\nWhen a process is started by\nspawn, the variable spawn_id is set to a descriptor referring to that process. The process described by spawn_id is considered the\ncurrent process. spawn_id may be read or written, in effect providing job control.\nuser_spawn_id\nis a global variable containing a descriptor which refers to the user. For example, when spawn_id is set to this value, expect behaves like\nexpect_user.\nerror_spawn_id is a global variable containing a descriptor which refers to the standard error. For example, when spawn_id is set to this\nvalue, send behaves like send_error.\ntty_spawn_id\nis a global variable containing a descriptor which refers to /dev/tty. If /dev/tty does not exist (such as in a cron, at, or batch script), then\ntty_spawn_id is not defined. This may be tested as:if {[info vars tty_spawn_id]} {\n    # /dev/tty exists\n} else {\n    # /dev/tty doesn't exist\n    # probably in cron, batch, or at script\n}\nspawn\nreturns the UNIX process id. If no process is spawned, 0 is returned. The variable spawn_out(slave,name) is set to the name of the pty slave device.\nBy default,\nspawn echoes the command name and arguments. The -noecho flag stops spawn from doing this.\nThe\n-console flag causes console output to be redirected to the spawned process. This is not supported on all systems.\nInternally, spawn uses a pty, initialized the same way as the user's tty. This is further initialized so that all settings are \"sane\" (according to\nstty(1)). If the variable stty_init is defined, it is interpreted in the style of stty arguments as further configuration. For example, \"set\nstty_init raw\" will cause further spawned processes's terminals to start in raw mode. -nottycopy skips the initialization based on the user's tty.\n-nottyinit skips the \"sane\" initialization.\nNormally,\nspawn takes little time to execute. If you notice spawn taking a significant amount of time, it is probably encountering ptys that are wedged. A\nnumber of tests are run on ptys to avoid entanglements with errant processes. (These take 10 seconds per wedged pty.) Running Expect with the -d option\nwill show if Expect is encountering many ptys in odd states. If you cannot kill the processes to which these ptys are attached, your only recourse may\nbe to reboot.\nIf program cannot be spawned successfully because exec(2) fails (e.g. when program doesn't exist), an error message will be returned by\nthe next interact or expect command as if program had run and produced the error message as output. This behavior is a natural consequence\nof the implementation of spawn. Internally, spawn forks, after which the spawned process has no way to communicate with the original Expect\nprocess except by communication via the spawn_id.\nThe -open flag causes the next argument to be interpreted as a Tcl file identifier (i.e., returned by open.) The spawn id can then be used as\nif it were a spawned process. (The file identifier should no longer be used.) This lets you treat raw devices, files, and pipelines as spawned processes\nwithout using a pty. 0 is returned to indicate there is no associated process. When the connection to the spawned process is closed, so is the Tcl file\nidentifier. The -leaveopen flag is similar to -open except that -leaveopen causes the file identifier to be left open even after the spawn\nid is closed.\nThe -pty flag causes a pty to be opened but no process spawned. 0 is returned to indicate there is no associated process. Spawn_id is set as usual.\nThe variable spawn_out(slave,fd) is set to a file identifier corresponding to the pty slave. It can be closed using \"close -slave\".\nThe -ignore flag names a signal to be ignored in the spawned process. Otherwise, signals get the default behavior. Signals are named as in the\ntrap command, except that each signal requires a separate flag.\nstrace level\ncauses following statements to be printed before being executed. (Tcl's trace command traces variables.) level indicates how far down in the call\nstack to trace. For example, the following command runs Expect while tracing the first 4 levels of calls, but none below that.expect -c \"strace 4\" script.expThe -info flag causes strace to return a description of the most recent non-info arguments given.\nstty args\nchanges terminal modes similarly to the external stty command.\nBy default, the controlling terminal is accessed. Other terminals can be accessed by appending \"< /dev/tty...\" to the command. (Note that the arguments\nshould not be grouped into a single argument.)\nRequests for status return it as the result of the command. If no status is requested and the controlling terminal is accessed, the previous status of the\nraw and echo attributes are returned in a form which can later be used by the command.\nFor example, the arguments raw or -cooked put the terminal into raw mode. The arguments -raw or cooked put the terminal into\ncooked mode. The arguments echo and -echo put the terminal into echo and noecho mode respectively.\nThe following example illustrates how to temporarily disable echoing.\nThis could be used in otherwise-automatic scripts to avoid embedding passwords in them. (See more discussion on this under EXPECT HINTS below.)stty -echo\nsend_user \"Password: \"\nexpect_user -re \"(.*)\\n\"\nset password $expect_out(1,string)\nstty echo\nsystem args\ngives args to sh(1) as input, just as if it had been typed as a command from a terminal. Expect waits until the shell terminates. The\nreturn status from sh is handled the same way that exec handles its return status.\nIn contrast to\nexec which redirects stdin and stdout to the script, system performs no redirection (other than that indicated by the string itself). Thus,\nit is possible to use programs which must talk directly to /dev/tty. For the same reason, the results of system are not recorded in the log.\ntimestamp [args]\nreturns a timestamp. With no arguments, the number of seconds since the epoch is returned.\nThe -format flag introduces a string which is returned but with substitutions made according to the POSIX rules for strftime. For example %a is\nreplaced by an abbreviated weekday name (i.e., Sat). Others are:%a      abbreviated weekday name\n%A      full weekday name\n%b      abbreviated month name\n%B      full month name\n%c      date-time as in: Wed Oct  6 11:45:56 1993\n%d      day of the month (01-31)\n%H      hour (00-23)\n%I      hour (01-12)\n%j      day (001-366)\n%m      month (01-12)\n%M      minute (00-59)\n%p      am or pm\n%S      second (00-61)\n%u      day (1-7, Monday is first day of week)\n%U      week (00-53, first Sunday is first day of week one)\n%V      week (01-53, ISO 8601 style)\n%w      day (0-6)\n%W      week (00-53, first Monday is first day of week one)\n%x      date-time as in: Wed Oct  6 1993\n%X      time as in: 23:59:59\n%y      year (00-99)\n%Y      year as in: 1993\n%Z      timezone (or nothing if not determinable)\n%%      a bare percent sign\nOther % specifications are undefined. Other characters will be passed through untouched. Only the C locale is supported.\nThe -seconds flag introduces a number of seconds since the epoch to be used as a source from which to format. Otherwise, the current time is used.\nThe -gmt flag forces timestamp output to use the GMT timezone. With no flag, the local timezone is used.\ntrap [[command] signals]\ncauses the given command to be executed upon future receipt of any of the given signals. The command is executed in the global scope. If\ncommand is absent, the signal action is returned. If command is the string SIG_IGN, the signals are ignored. If command is the string\nSIG_DFL, the signals are result to the system default. signals is either a single signal or a list of signals. Signals may be specified numerically or\nsymbolically as per signal(3). The \"SIG\" prefix may be omitted.\nWith no arguments (or the argument -number), trap returns the signal number of the trap command currently being executed.\nThe -code flag uses the return code of the command in place of whatever code Tcl was about to return when the command originally started running.\nThe -interp flag causes the command to be evaluated using the interpreter active at the time the command started running rather than when the trap\nwas declared.\nThe -name flag causes the trap command to return the signal name of the trap command currently being executed.\nThe -max flag causes the trap command to return the largest signal number that can be set.\nFor example, the command \"trap {send_user \"Ouch!\"} SIGINT\" will print \"Ouch!\" each time the user presses ^C.\nBy default, SIGINT (which can usually be generated by pressing ^C) and SIGTERM cause Expect to exit. This is due to the following trap, created by default\nwhen Expect starts.trap exit {SIGINT SIGTERM}\nIf you use the -D flag to start the debugger, SIGINT is redefined to start the interactive debugger. This is due to the following trap:trap {exp_debug 1} SIGINT\nThe debugger trap can be changed by setting the environment variable EXPECT_DEBUG_INIT to a new trap command.\nYou can, of course, override both of these just by adding trap commands to your script. In particular, if you have your own \"trap exit SIGINT\", this will\noverride the debugger trap. This is useful if you want to prevent users from getting to the debugger at all.\nIf you want to define your own trap on SIGINT but still trap to the debugger when it is running, use:if {![exp_debug]} {trap mystuff SIGINT}\nAlternatively, you can trap to the debugger using some other signal.\ntrap will not let you override the action for SIGALRM as this is used internally to Expect. The disconnect command sets SIGALRM to SIG_IGN\n(ignore). You can reenable this as long as you disable it during subsequent spawn commands.\nSee signal(3) for more info.\nwait [args]\ndelays until a spawned process (or the current process if none is named) terminates.\nwait\nnormally returns a list of four integers. The first integer is the pid of the process that was waited upon. The second integer is the corresponding spawn\nid. The third integer is -1 if an operating system error occurred, or 0 otherwise. If the third integer was 0, the fourth integer is the status returned by the\nspawned process. If the third integer was -1, the fourth integer is the value of errno set by the operating system. The global variable errorCode is also set.\nAdditional elements may appear at the end of the return value from wait. An optional fifth element identifies a class of information. Currently, the\nonly possible value for this element is CHILDKILLED in which case the next two values are the C-style signal name and a short textual description.\nThe\n-i flag declares the process to wait corresponding to the named spawn_id (NOT the process id). Inside a SIGCHLD handler, it is possible to wait for\nany spawned process by using the spawn id -1.\nThe -nowait flag causes the wait to return immediately with the indication of a successful wait. When the process exits (later), it will\nautomatically disappear without the need for an explicit wait.\nThe wait command may also be used wait for a forked process using the arguments \"-i -1\". Unlike its use with spawned processes, this command can be\nexecuted at any time. There is no control over which process is reaped. However, the return value can be checked for the process id.\nLibraries\nExpect automatically knows about two built-in libraries for Expect scripts. These are defined by\nthe directories named in the variables exp_library and exp_exec_library. Both are meant to contain utility files that can be used by other scripts.\nexp_library contains architecture-independent files. exp_exec_library contains architecture-dependent files. Depending on your system, both directories may\nbe totally empty. The existence of the file $exp_exec_library/cat-buffers describes whether your /bin/cat buffers by default.\nPretty-printing\nA vgrind definition is available for pretty-printing Expect scripts. Assuming the\nvgrind definition supplied with the Expect distribution is correctly installed, you can use it as:vgrind -lexpect file\nExamples\nIt many not be apparent how to put everything together that the man page describes. I encourage\nyou to read and try out the examples in the example directory of the Expect distribution. Some of them are real programs. Others are simply illustrative\nof certain techniques, and of course, a couple are just quick hacks. The INSTALL file has a quick overview of these programs.\nThe Expect papers (see SEE ALSO) are also useful. While some papers use syntax corresponding to earlier versions of Expect, the accompanying\nrationales are still valid and go into a lot more detail than this man page.\nCaveats\nExtensions may collide with Expect's command names. For example, send is defined by Tk for\nan entirely different purpose. For this reason, most of the Expect commands are also available as \"exp_XXXX\". Commands and variables beginning with\n\"exp\", \"inter\", \"spawn\", and \"timeout\" do not have aliases. Use the extended command names if you need this compatibility between environments.\nExpect takes a rather liberal view of scoping. In particular, variables read by commands specific to the Expect program will be sought first\nfrom the local scope, and if not found, in the global scope. For example, this obviates the need to place \"global timeout\" in every procedure you write that\nuses expect. On the other hand, variables written are always in the local scope (unless a \"global\" command has been issued). The most common problem\nthis causes is when spawn is executed in a procedure. Outside the procedure, spawn_id no longer exists, so the spawned process is no longer accessible\nsimply because of scoping. Add a \"global spawn_id\" to such a procedure.\nIf you cannot enable the multispawning capability (i.e., your system supports neither select (BSD *.*), poll (SVR>2), nor something equivalent),\nExpect will only be able to control a single process at a time. In this case, do not attempt to set spawn_id, nor should you execute processes\nvia exec while a spawned process is running. Furthermore, you will not be able to expect from multiple processes (including the user as one) at the same\ntime.\nTerminal parameters can have a big effect on scripts. For example, if a script is written to look for echoing, it will misbehave if echoing is turned off.\nFor this reason, Expect forces sane terminal parameters by default. Unfortunately, this can make things unpleasant for other programs. As an example, the emacs\nshell wants to change the \"usual\" mappings: newlines get mapped to newlines instead of carriage-return newlines, and echoing is disabled. This allows one to\nuse emacs to edit the input line. Unfortunately, Expect cannot possibly guess this.\nYou can request that Expect not override its default setting of terminal parameters, but you must then be very careful when writing scripts for such\nenvironments. In the case of emacs, avoid depending upon things like echoing and end-of-line mappings.\nThe commands that accepted arguments braced into a single list (the expect variants and interact) use a heuristic to decide if the list is\nactually one argument or many. The heuristic can fail only in the case when the list actually does represent a single argument which has multiple embedded \\n's\nwith non-whitespace characters between them. This seems sufficiently improbable, however the argument \"-nobrace\" can be used to force a single argument to be\nhandled as a single argument. This could conceivably be used with machine-generated Expect code. Similarly, -brace forces a single argument to be handle as\nmultiple patterns/actions.\nBugs\nIt was really tempting to name the program \"sex\" (for either \"Smart EXec\" or \"Send-EXpect\"), but good\nsense (or perhaps just Puritanism) prevailed.\nOn some systems, when a shell is spawned, it complains about not being able to access the tty but runs anyway. This means your system has a mechanism for\ngaining the controlling tty that Expect doesn't know about. Please find out what it is, and send this information back to me.\nUltrix 4.1 (at least the latest versions around here) considers timeouts of above 1000000 to be equivalent to 0.\nDigital UNIX 4.0A (and probably other versions) refuses to allocate ptys if you define a SIGCHLD handler. See grantpt page for more info.\nIRIX 6.0 does not handle pty permissions correctly so that if Expect attempts to allocate a pty previously used by someone else, it fails. Upgrade to IRIX\n6.1.\nTelnet (verified only under SunOS 4.1.2) hangs if TERM is not set. This is a problem under cron, at and in cgi scripts, which do not define TERM. Thus, you\nmust set it explicitly - to what type is usually irrelevant. It just has to be set to something! The following probably suffices for most cases.set env(TERM) vt100Tip (verified only under BSDI BSD/OS 3.1 i386) hangs if SHELL and HOME are not set. This is a problem under cron, at and in cgi scripts, which do not define\nthese environment variables. Thus, you must set them explicitly - to what type is usually irrelevant. It just has to be set to something! The following\nprobably suffices for most cases.set env(SHELL) /bin/sh\nset env(HOME) /usr/local/binSome implementations of ptys are designed so that the kernel throws away any unread output after 10 to 15 seconds (actual number is\nimplementation-dependent) after the process has closed the file descriptor. Thus Expect programs such asspawn date\nsleep 20\nexpect\nwill fail. To avoid this, invoke non-interactive programs with exec rather than spawn. While such situations are conceivable, in practice I have\nnever encountered a situation in which the final output of a truly interactive program would be lost due to this behavior.\nOn the other hand, Cray UNICOS ptys throw away any unread output immediately after the process has closed the file descriptor. I have reported this to Cray\nand they are working on a fix.\nSometimes a delay is required between a prompt and a response, such as when a tty interface is changing UART settings or matching baud rates by looking for\nstart/stop bits. Usually, all this is require is to sleep for a second or two. A more robust technique is to retry until the hardware is ready to receive\ninput. The following example uses both strategies:send \"speed 9600\\r\";\nsleep 1\nexpect {\n    timeout {send \"\\r\"; exp_continue}\n    $prompt\n}trap -code will not work with any command that sits in Tcl's event loop, such as sleep. The problem is that in the event loop, Tcl discards the return codes\nfrom async event handlers. A workaround is to set a flag in the trap code. Then check the flag immediately after the command (i.e., sleep).\nThe expect_background command ignores -timeout arguments and has no concept of timeouts in general.\nExpect Hints\nThere are a couple of things about Expect that may be non-intuitive. This section\nattempts to address some of these things with a couple of suggestions.\nA common expect problem is how to recognize shell prompts. Since these are customized differently by differently people and different shells, portably\nautomating rlogin can be difficult without knowing the prompt. A reasonable convention is to have users store a regular expression describing their prompt (in\nparticular, the end of it) in the environment variable EXPECT_PROMPT. Code like the following can be used. If EXPECT_PROMPT doesn't exist, the code still has a\ngood chance of functioning correctly.set prompt \"(%|#|\\\\$) $\"          ;# default prompt\ncatch {set prompt $env(EXPECT_PROMPT)}\nexpect -re $prompt\nI encourage you to write expect patterns that include the end of whatever you expect to see. This avoids the possibility of answering a question before\nseeing the entire thing. In addition, while you may well be able to answer questions before seeing them entirely, if you answer early, your answer may appear\nechoed back in the middle of the question. In other words, the resulting dialogue will be correct but look scrambled.\nMost prompts include a space character at the end. For example, the prompt from ftp is 'f', 't', 'p', '>' and <blank>. To match this prompt, you\nmust account for each of these characters. It is a common mistake not to include the blank. Put the blank in explicitly.\nIf you use a pattern of the form X*, the * will match all the output received from the end of X to the last thing received. This sounds intuitive but can be\nsomewhat confusing because the phrase \"last thing received\" can vary depending upon the speed of the computer and the processing of I/O both by the kernel and\nthe device driver.\nIn particular, humans tend to see program output arriving in huge chunks (atomically) when in reality most programs produce output one line at a time.\nAssuming this is the case, the * in the pattern of the previous paragraph may only match the end of the current line even though there seems to be more,\nbecause at the time of the match that was all the output that had been received.\nexpect has no way of knowing that further output is coming unless your pattern specifically accounts for it.\nEven depending on line-oriented buffering is unwise. Not only do programs rarely make promises about the type of buffering they do, but system indigestion\ncan break output lines up so that lines break at seemingly random places. Thus, if you can express the last few characters of a prompt when writing patterns,\nit is wise to do so.\nIf you are waiting for a pattern in the last output of a program and the program emits something else instead, you will not be able to detect that with the\ntimeout keyword. The reason is that expect will not timeout - instead it will get an eof indication. Use that instead. Even better, use\nboth. That way if that line is ever moved around, you won't have to edit the line itself.\nNewlines are usually converted to carriage return, linefeed sequences when output by the terminal driver. Thus, if you want a pattern that explicitly\nmatches the two lines, from, say, printf(\"foo\\nbar\"), you should use the pattern \"foo\\r\\nbar\".\nA similar translation occurs when reading from the user, via expect_user. In this case, when you press return, it will be translated to a newline. If\nExpect then passes that to a program which sets its terminal to raw mode (like telnet), there is going to be a problem, as the program expects a true\nreturn. (Some programs are actually forgiving in that they will automatically translate newlines to returns, but most don't.) Unfortunately, there is no way to\nfind out that a program put its terminal into raw mode.\nRather than manually replacing newlines with returns, the solution is to use the command \"stty raw\", which will stop the translation. Note, however, that\nthis means that you will no longer get the cooked line-editing features.\ninteract implicitly sets your terminal to raw mode so this problem will not arise then.\nIt is often useful to store passwords (or other private information) in Expect scripts. This is not recommended since anything that is stored on a\ncomputer is susceptible to being accessed by anyone. Thus, interactively prompting for passwords from a script is a smarter idea than embedding them literally.\nNonetheless, sometimes such embedding is the only possibility.\nUnfortunately, the UNIX file system has no direct way of creating scripts which are executable but unreadable. Systems which support setgid shell scripts\nmay indirectly simulate this as follows:\nCreate the Expect script (that contains the secret data) as usual. Make its permissions be 750 (-rwxr-x---) and owned by a trusted group, i.e., a\ngroup which is allowed to read it. If necessary, create a new group for this purpose. Next, create a /bin/sh script with permissions 2751 (-rwxr-s--x) owned by\nthe same group as before.\nThe result is a script which may be executed (and read) by anyone. When invoked, it runs the Expect script.\nSee Also\nTcl(3), libexpect(3)\n\"Exploring Expect: A Tcl-Based Toolkit for Automating Interactive Programs\" by Don Libes, pp. 602, ISBN 1-56592-090-2, O'Reilly and Associates, 1995.\n\"expect: Curing Those Uncontrollable Fits of Interactivity\" by Don Libes, Proceedings of the Summer 1990 USENIX Conference, Anaheim, California, June 11-15,\n1990.\n\"Using expect to Automate System Administration Tasks\" by Don Libes, Proceedings of the 1990 USENIX Large Installation Systems Administration\nConference, Colorado Springs, Colorado, October 17-19, 1990.\n\"Tcl: An Embeddable Command Language\" by John Ousterhout, Proceedings of the Winter 1990 USENIX Conference, Washington, D.C., January 22-26, 1990.\n\"expect: Scripts for Controlling Interactive Programs\" by Don Libes, Computing Systems, Vol. 4, No. 2, University of California Press Journals, November\n1991.\n\"Regression Testing and Conformance Testing Interactive Programs\", by Don Libes, Proceedings of the Summer 1992 USENIX Conference, pp. 135-144, San Antonio,\nTX, June 12-15, 1992.\n\"Kibitz - Connecting Multiple Interactive Programs Together\", by Don Libes, Software - Practice & Experience, John Wiley & Sons, West Sussex, England,\nVol. 23, No. 5, May, 1993.\n\"A Debugger for Tcl Applications\", by Don Libes, Proceedings of the 1993 Tcl/Tk Workshop, Berkeley, CA, June 10-11, 1993.\nAuthor\nDon Libes, National Institute of Standards and Technology\nAcknowledgments\nThanks to John Ousterhout for Tcl, and Scott Paisley for inspiration. Thanks to Rob\nSavoye for Expect's autoconfiguration code.\nThe HISTORY file documents much of the evolution of expect. It makes interesting reading and might give you further insight to this software. Thanks\nto the people mentioned in it who sent me bug fixes and gave other assistance.\nDesign and implementation of Expect was paid for in part by the U.S. government and is therefore in the public domain. However the author and NIST\nwould like credit if this program and documentation or portions of them are used.\n\n\nReferenced By\nclogin(1),\nkibitz(1),\npty(7),\nshellout(3),\nx3270-script(1),\nx3270if(1),\nxkibitz(1)\n\n\n\n\n\n\n\n\nSite Search\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nlinux docs\nlinux man pages\npage load time\n\n\nToys\nworld sunlight\nmoon phase\ntrace explorer\n\n\n\n\n\n\n\n",
   "man_entry": "EXPECT(1)\t\t\t\t\t\t\t     EXPECT(1)\n\n\n\nNAME\n       expect - programmed dialogue with interactive programs, Version 5\n\nSYNOPSIS\n       expect [ -dDinN ] [ -c cmds ] [ [ -[f|b] ] cmdfile ] [ args ]\n\nINTRODUCTION\n       Expect  is a program that \"talks\" to other interactive programs accord-\n       ing to a script.  Following  the  script,  Expect  knows  what  can  be\n       expected  from  a  program and what the correct response should be.  An\n       interpreted language provides branching and high-level  control\tstruc-\n       tures  to  direct the dialogue.\tIn addition, the user can take control\n       and interact directly when desired, afterward returning control to  the\n       script.\n\n       Expectk is a mixture of Expect and Tk.  It behaves just like Expect and\n       Tk's wish.  Expect can also be used directly in\tC  or  C++  (that  is,\n       without Tcl).  See libexpect(3).\n\n       The name \"Expect\" comes from the idea of send/expect sequences popular-\n       ized by uucp, kermit and other modem control programs.  However\tunlike\n       uucp,  Expect is generalized so that it can be run as a user-level com-\n       mand with any program and task in mind.\tExpect can  actually  talk  to\n       several programs at the same time.\n\n       For example, here are some things Expect can do:\n\n\t      o   Cause  your computer to dial you back, so that you can login\n\t\t  without paying for the call.\n\n\t      o   Start a game (e.g., rogue) and if the optimal  configuration\n\t\t  doesn't  appear, restart it (again and again) until it does,\n\t\t  then hand over control to you.\n\n\t      o   Run fsck, and in response to its  questions,\tanswer\t\"yes\",\n\t\t  \"no\"\tor  give  control  back to you, based on predetermined\n\t\t  criteria.\n\n\t      o   Connect to another network or  BBS  (e.g.,  MCI  Mail,  Com-\n\t\t  puServe)  and  automatically\tretrieve  your mail so that it\n\t\t  appears as if it was originally sent to your local system.\n\n\t      o   Carry environment variables, current directory, or any  kind\n\t\t  of information across rlogin, telnet, tip, su, chgrp, etc.\n\n       There  are  a  variety  of  reasons  why the shell cannot perform these\n       tasks.  (Try, you'll see.)  All are possible with Expect.\n\n       In general, Expect is useful for running  any  program  which  requires\n       interaction between the program and the user.  All that is necessary is\n       that the interaction can be characterized programmatically.  Expect can\n       also give the user back control (without halting the program being con-\n       trolled) if desired.  Similarly, the user can  return  control  to  the\n       script at any time.\n\nUSAGE\n       Expect  reads  cmdfile  for  a list of commands to execute.  Expect may\n       also be invoked implicitly on systems which support the #! notation  by\n       marking\tthe  script  executable,  and  making  the  first line in your\n       script:\n\n\t   #!/usr/local/bin/expect -f\n\n       Of course, the  path  must  accurately  describe  where\tExpect\tlives.\n       /usr/local/bin is just an example.\n\n       The -c flag prefaces a command to be executed before any in the script.\n       The command should be quoted to prevent being broken up by  the\tshell.\n       This  option may be used multiple times.  Multiple commands may be exe-\n       cuted with a single -c by separating them  with\tsemicolons.   Commands\n       are  executed  in  the  order  they  appear.  (When using Expectk, this\n       option is specified as -command.)\n\n       The -d flag enables some diagnostic  output,  which  primarily  reports\n       internal  activity  of commands such as expect and interact.  This flag\n       has the same effect as \"exp_internal 1\" at the beginning of  an\tExpect\n       script,\tplus the version of Expect is printed.\t(The strace command is\n       useful for tracing statements, and the  trace  command  is  useful  for\n       tracing\tvariable  assignments.)   (When  using Expectk, this option is\n       specified as -diag.)\n\n       The -D flag enables an interactive debugger.  An integer  value\tshould\n       follow.\t The  debugger will take control before the next Tcl procedure\n       if the value is non-zero or if a ^C is pressed (or a breakpoint is hit,\n       or  other appropriate debugger command appears in the script).  See the\n       README file or SEE ALSO (below) for more information on\tthe  debugger.\n       (When using Expectk, this option is specified as -Debug.)\n\n       The -f flag prefaces a file from which to read commands from.  The flag\n       itself is optional as it is only useful when using the #! notation (see\n       above),\tso  that  other arguments may be supplied on the command line.\n       (When using Expectk, this option is specified as -file.)\n\n       By default, the command file is read into memory and  executed  in  its\n       entirety.   It  is  occasionally  desirable to read files one line at a\n       time.  For example, stdin is read this way.  In order  to  force  arbi-\n       trary  files  to  be  handled  this  way, use the -b flag.  (When using\n       Expectk, this option is specified as  -buffer.)Notethatstdio-buffering-\n       maystilltakeplacehoweverthisshouldn'tcauseproblemswhenreadingfromafi-\n       foorstdin.\n\n       If the string \"-\" is supplied as a filename,  standard  input  is  read\n       instead.  (Use \"./-\" to read from a file actually named \"-\".)\n\n       The  -i flag causes Expect to interactively prompt for commands instead\n       of reading them from a file.  Prompting is terminated via the exit com-\n       mand or upon EOF.  See interpreter (below) for more information.  -i is\n       assumed if neither a command file nor -c is used.  (When using Expectk,\n       this option is specified as -interactive.)\n\n       --  may\tbe  used to delimit the end of the options.  This is useful if\n       you want to pass an option-like argument  to  your  script  without  it\n       being  interpreted  by  Expect.\t This can usefully be placed in the #!\n       line to prevent any flag-like interpretation by Expect.\t For  example,\n       the  following  will leave the original arguments (including the script\n       name) in the variable argv.\n\n\t   #!/usr/local/bin/expect --\n\n       Note that  the  usual  getopt(3)  and  execve(2)  conventions  must  be\n       observed when adding arguments to the #! line.\n\n       The  file  $exp_library/expect.rc  is sourced automatically if present,\n       unless the -N flag is used.  (When using Expectk, this option is speci-\n       fied  as  -NORC.)   Immediately\tafter  this,  the file ~/.expect.rc is\n       sourced automatically, unless the -n flag is used.  If the  environment\n       variable DOTDIR is defined, it is treated as a directory and .expect.rc\n       is read from there.  (When using Expectk, this option is  specified  as\n       -norc.)\tThis sourcing occurs only after executing any -c flags.\n\n       -v  causes  Expect  to  print its version number and exit.  (The corre-\n       sponding flag in Expectk, which uses long flag names, is -version.)\n\n       Optional args are constructed into a list and stored  in  the  variable\n       named argv.  argc is initialized to the length of argv.\n\n       argv0  is  defined to be the name of the script (or binary if no script\n       is used).  For example, the following prints out the name of the script\n       and the first three arguments:\n\n\t   send_user \"$argv0 [lrange $argv 0 2]\\n\"\n\n\nCOMMANDS\n       Expect  uses  Tcl  (Tool  Command Language).  Tcl provides control flow\n       (e.g., if, for, break), expression evaluation and  several  other  fea-\n       tures such as recursion, procedure definition, etc.  Commands used here\n       but not defined (e.g., set, if, exec) are Tcl  commands\t(see  tcl(3)).\n       Expect supports additional commands, described below.  Unless otherwise\n       specified, commands return the empty string.\n\n       Commands are listed alphabetically so that they can be quickly located.\n       However,  new users may find it easier to start by reading the descrip-\n       tions of spawn, send, expect, and interact, in that order.\n\n       Note that the best introduction to the language (both Expect  and  Tcl)\n       is provided in the book \"Exploring Expect\" (see SEE ALSO below).  Exam-\n       ples are included in this man page but they are very limited since this\n       man page is meant primarily as reference material.\n\n       Note  that in the text of this man page, \"Expect\" with an uppercase \"E\"\n       refers to the Expect program  while  \"expect\"  with  a  lower-case  \"e\"\n       refers to the expect command within the Expect program.)\n\n       close [-slave] [-onexec 0|1] [-i spawn_id]\n\t     closes  the  connection to the current process.  Most interactive\n\t     programs will detect EOF on their stdin and exit; thus close usu-\n\t     ally  suffices to kill the process as well.  The -i flag declares\n\t     the process to close corresponding to the named spawn_id.\n\n\t     Both expect and interact will detect  when  the  current  process\n\t     exits and implicitly do a close.  But if you kill the process by,\n\t     say, \"exec kill $pid\", you will need to explicitly call close.\n\n\t     The -onexec flag determines whether the spawn id will  be\tclosed\n\t     in  any new spawned processes or if the process is overlayed.  To\n\t     leave a spawn id open, use the value 0.  A non-zero integer value\n\t     will force the spawn closed (the default) in any new processes.\n\n\t     The  -slave  flag\tcloses the slave associated with the spawn id.\n\t     (See \"spawn -pty\".)  When the connection is closed, the slave  is\n\t     automatically closed as well if still open.\n\n\t     No  matter whether the connection is closed implicitly or explic-\n\t     itly, you should call wait to clear up the  corresponding\tkernel\n\t     process slot.  close does not call wait since there is no guaran-\n\t     tee that closing a process connection will cause it to exit.  See\n\t     wait below for more info.\n\n       debug [[-now] 0|1]\n\t     controls  a Tcl debugger allowing you to step through statements,\n\t     set breakpoints, etc.\n\n\t     With no arguments, a 1 is returned if the debugger  is  not  run-\n\t     ning, otherwise a 0 is returned.\n\n\t     With  a  1 argument, the debugger is started.  With a 0 argument,\n\t     the debugger is stopped.  If a 1 argument is preceded by the -now\n\t     flag, the debugger is started immediately (i.e., in the middle of\n\t     the debug command itself).  Otherwise, the  debugger  is  started\n\t     with the next Tcl statement.\n\n\t     The  debug  command  does\tnot change any traps.  Compare this to\n\t     starting Expect with the -D flag (see above).\n\n\t     See the README file or SEE ALSO (below) for more  information  on\n\t     the debugger.\n\n       disconnect\n\t     disconnects  a  forked  process  from the terminal.  It continues\n\t     running in the background.  The process is given its own  process\n\t     group (if possible).  Standard I/O is redirected to /dev/null.\n\n\t     The  following  fragment  uses disconnect to continue running the\n\t     script in the background.\n\n\t\t if {[fork]!=0} exit\n\t\t disconnect\n\t\t . . .\n\n\t     The following script reads a password, and then  runs  a  program\n\t     every  hour  that\tdemands  a  password each time it is run.  The\n\t     script supplies the password so that you only  have  to  type  it\n\t     once.   (See  the stty command which demonstrates how to turn off\n\t     password echoing.)\n\n\t\t send_user \"password?\\ \"\n\t\t expect_user -re \"(.*)\\n\"\n\t\t for {} 1 {} {\n\t\t     if {[fork]!=0} {sleep 3600;continue}\n\t\t     disconnect\n\t\t     spawn priv_prog\n\t\t     expect Password:\n\t\t     send \"$expect_out(1,string)\\r\"\n\t\t     . . .\n\t\t     exit\n\t\t }\n\n\t     An advantage to using  disconnect\tover  the  shell  asynchronous\n\t     process  feature (&) is that Expect can save the terminal parame-\n\t     ters prior to disconnection, and then later  apply  them  to  new\n\t     ptys.   With  &, Expect does not have a chance to read the termi-\n\t     nal's parameters since the terminal is  already  disconnected  by\n\t     the time Expect receives control.\n\n       exit [-opts] [status]\n\t     causes Expect to exit or otherwise prepare to do so.\n\n\t     The  -onexit  flag causes the next argument to be used as an exit\n\t     handler.  Without\tan  argument,  the  current  exit  handler  is\n\t     returned.\n\n\t     The  -noexit flag causes Expect to prepare to exit but stop short\n\t     of actually returning control to the operating system.  The user-\n\t     defined exit handler is run as well as Expect's own internal han-\n\t     dlers.  No further Expect commands should be executed.   This  is\n\t     useful  if you are running Expect with other Tcl extensions.  The\n\t     current interpreter (and main window if in  the  Tk  environment)\n\t     remain  so  that  other Tcl extensions can clean up.  If Expect's\n\t     exit is called again (however this might occur), the handlers are\n\t     not rerun.\n\n\t     Upon  exiting,  all  connections to spawned processes are closed.\n\t     Closure will be detected as an EOF by  spawned  processes.   exit\n\t     takes  no other actions beyond what the normal _exit(2) procedure\n\t     does.  Thus, spawned processes that do not check for EOF may con-\n\t     tinue  to\trun.  (A variety of conditions are important to deter-\n\t     mining, for example, what signals a spawned process will be sent,\n\t     but   these  are  system-dependent,  typically  documented  under\n\t     exit(3).)\tSpawned processes that continue to run will be\tinher-\n\t     ited by init.\n\n\t     status  (or 0 if not specified) is returned as the exit status of\n\t     Expect.  exit is implicitly executed if the end of the script  is\n\t     reached.\n\n       exp_continue [-continue_timer]\n\t     The command exp_continue allows expect itself to continue execut-\n\t     ing rather than  returning  as  it  normally  would.  By  default\n\t     exp_continue  resets  the timeout timer. The -continue_timer flag\n\t     prevents timer from being restarted. (See expect for more\tinfor-\n\t     mation.)\n\n       exp_internal [-f file] value\n\t     causes  further  commands to send diagnostic information internal\n\t     to Expect to stderr if value is non-zero.\tThis  output  is  dis-\n\t     abled  if\tvalue is 0.  The diagnostic information includes every\n\t     character received, and every attempt made to match  the  current\n\t     output against the patterns.\n\n\t     If the optional file is supplied, all normal and debugging output\n\t     is written to that file (regardless of the value of value).   Any\n\t     previous diagnostic output file is closed.\n\n\t     The -info flag causes exp_internal to return a description of the\n\t     most recent non-info arguments given.\n\n       exp_open [args] [-i spawn_id]\n\t     returns a Tcl file identifier that corresponds  to  the  original\n\t     spawn  id.   The  file  identifier can then be used as if it were\n\t     opened by Tcl's open command.  (The spawn id should no longer  be\n\t     used.  A wait should not be executed.\n\n\t     The  -leaveopen  flag leaves the spawn id open for access through\n\t     Expect commands.  A wait must be executed on the spawn id.\n\n       exp_pid [-i spawn_id]\n\t     returns the process id corresponding  to  the  currently  spawned\n\t     process.  If the -i flag is used, the pid returned corresponds to\n\t     that of the given spawn id.\n\n       exp_send\n\t     is an alias for send.\n\n       exp_send_error\n\t     is an alias for send_error.\n\n       exp_send_log\n\t     is an alias for send_log.\n\n       exp_send_tty\n\t     is an alias for send_tty.\n\n       exp_send_user\n\t     is an alias for send_user.\n\n       exp_version [[-exit] version]\n\t     is useful for assuring that the script  is  compatible  with  the\n\t     current version of Expect.\n\n\t     With  no  arguments,  the\tcurrent version of Expect is returned.\n\t     This version may then be encoded in your script.  If you actually\n\t     know  that you are not using features of recent versions, you can\n\t     specify an earlier version.\n\n\t     Versions consist of three numbers separated by  dots.   First  is\n\t     the  major number.  Scripts written for versions of Expect with a\n\t     different major number will almost certainly not work.   exp_ver-\n\t     sion returns an error if the major numbers do not match.\n\n\t     Second is the minor number.  Scripts written for a version with a\n\t     greater minor number than the current  version  may  depend  upon\n\t     some new feature and might not run.  exp_version returns an error\n\t     if the major numbers  match,  but\tthe  script  minor  number  is\n\t     greater than that of the running Expect.\n\n\t     Third  is\ta number that plays no part in the version comparison.\n\t     However, it is incremented when the Expect software  distribution\n\t     is  changed  in  any  way, such as by additional documentation or\n\t     optimization.  It is reset to 0 upon each new minor version.\n\n\t     With the -exit flag, Expect prints an error and exits if the ver-\n\t     sion is out of date.\n\n       expect [[-opts] pat1 body1] ... [-opts] patn [bodyn]\n\t     waits  until  one of the patterns matches the output of a spawned\n\t     process, a specified time period has passed, or an end-of-file is\n\t     seen.  If the final body is empty, it may be omitted.\n\n\t     Patterns  from  the most recent expect_before command are implic-\n\t     itly used before any other  patterns.   Patterns  from  the  most\n\t     recent  expect_after  command are implicitly used after any other\n\t     patterns.\n\n\t     If the arguments to the entire expect statement require more than\n\t     one  line,  all  the  arguments may be \"braced\" into one so as to\n\t     avoid terminating each line with a backslash.  In this one  case,\n\t     the usual Tcl substitutions will occur despite the braces.\n\n\t     If  a  pattern is the keyword eof, the corresponding body is exe-\n\t     cuted upon end-of-file.  If a pattern is the keyword timeout, the\n\t     corresponding  body is executed upon timeout.  If no timeout key-\n\t     word is used, an implicit null action is executed\tupon  timeout.\n\t     The  default  timeout  period  is\t10 seconds but may be set, for\n\t     example to 30, by the command  \"set  timeout  30\".   An  infinite\n\t     timeout  may  be designated by the value -1.  If a pattern is the\n\t     keyword default, the corresponding body is executed  upon\teither\n\t     timeout or end-of-file.\n\n\t     If  a  pattern  matches, then the corresponding body is executed.\n\t     expect returns the result of the body (or the empty string if  no\n\t     pattern matched).\tIn the event that multiple patterns match, the\n\t     one appearing first is used to select a body.\n\n\t     Each time new output arrives, it is compared to each  pattern  in\n\t     the  order  they are listed.  Thus, you may test for absence of a\n\t     match by making the last pattern something guaranteed to  appear,\n\t     such  as  a  prompt.  In situations where there is no prompt, you\n\t     must use timeout (just like you would  if\tyou  were  interacting\n\t     manually).\n\n\t     Patterns  are  specified in three ways.  By default, patterns are\n\t     specified as with Tcl's string match command.  (Such patterns are\n\t     also  similar  to C-shell regular expressions usually referred to\n\t     as \"glob\" patterns).  The -gl flag may may  be  used  to  protect\n\t     patterns  that  might otherwise match expect flags from doing so.\n\t     Any pattern beginning with a \"-\" should be  protected  this  way.\n\t     (All  strings starting with \"-\" are reserved for future options.)\n\n\n\t     For example, the following fragment looks for a successful login.\n\t     (Note  that abort is presumed to be a procedure defined elsewhere\n\t     in the script.)\n\n\t\t expect {\n\t\t     busy\t\t{puts busy\\n ; exp_continue}\n\t\t     failed\t\tabort\n\t\t     \"invalid password\" abort\n\t\t     timeout\t\tabort\n\t\t     connected\n\t\t }\n\n\t     Quotes are necessary on the fourth pattern since  it  contains  a\n\t     space,  which  would  otherwise  separate\tthe  pattern  from the\n\t     action.  Patterns with the same action (such as the 3rd and  4th)\n\t     require  listing  the  actions again.  This can be avoid by using\n\t     regexp-style patterns (see below).  More information  on  forming\n\t     glob-style patterns can be found in the Tcl manual.\n\n\t     Regexp-style  patterns  follow the syntax defined by Tcl's regexp\n\t     (short for \"regular expression\") command.\t regexp  patterns  are\n\t     introduced  with  the  flag  -re.\t The  previous\texample can be\n\t     rewritten using a regexp as:\n\n\t\t expect {\n\t\t     busy\t{puts busy\\n ; exp_continue}\n\t\t     -re \"failed|invalid password\" abort\n\t\t     timeout\tabort\n\t\t     connected\n\t\t }\n\n\t     Both types of patterns are \"unanchored\".  This  means  that  pat-\n\t     terns  do\tnot have to match the entire string, but can begin and\n\t     end the match anywhere in the string (as long as everything  else\n\t     matches).\t Use  ^  to  match the beginning of a string, and $ to\n\t     match the end.  Note that if you do not wait for  the  end  of  a\n\t     string,  your  responses  can  easily end up in the middle of the\n\t     string as they are echoed from the spawned process.  While  still\n\t     producing\tcorrect results, the output can look unnatural.  Thus,\n\t     use of $ is encouraged if you can exactly describe the characters\n\t     at the end of a string.\n\n\t     Note  that  in  many editors, the ^ and $ match the beginning and\n\t     end of lines respectively. However, because expect  is  not  line\n\t     oriented,\tthese  characters  match  the beginning and end of the\n\t     data (as opposed to  lines)  currently  in  the  expect  matching\n\t     buffer.  (Also, see the note below on \"system indigestion.\")\n\n\t     The  -ex  flag  causes  the  pattern  to be matched as an \"exact\"\n\t     string.  No interpretation of *, ^, etc  is  made\t(although  the\n\t     usual  Tcl  conventions  must still be observed).\tExact patterns\n\t     are always unanchored.\n\n\n\t     The -nocase flag causes uppercase characters  of  the  output  to\n\t     compare as if they were lowercase characters.  The pattern is not\n\t     affected.\n\n\t     While reading output, more than  2000  bytes  can\tforce  earlier\n\t     bytes  to\tbe \"forgotten\".  This may be changed with the function\n\t     match_max.  (Note that excessively large values can slow down the\n\t     pattern  matcher.)   If patlist is full_buffer, the corresponding\n\t     body is executed if match_max bytes have  been  received  and  no\n\t     other patterns have matched.  Whether or not the full_buffer key-\n\t     word  is  used,  the  forgotten   characters   are   written   to\n\t     expect_out(buffer).\n\n\t     If  patlist  is  the keyword null, and nulls are allowed (via the\n\t     remove_nulls command), the corresponding body is  executed  if  a\n\t     single  ASCII  0 is matched.  It is not possible to match 0 bytes\n\t     via glob or regexp patterns.\n\n\t     Upon matching a pattern (or eof or full_buffer), any matching and\n\t     previously   unmatched   output   is   saved   in\t the  variable\n\t     expect_out(buffer).  Up to 9 regexp substring matches  are  saved\n\t     in      the      variables      expect_out(1,string)      through\n\t     expect_out(9,string).  If the -indices flag is used before a pat-\n\t     tern,  the  starting  and\tending indices (in a form suitable for\n\t     lrange)  of  the  10  strings  are  stored   in   the   variables\n\t     expect_out(X,start)  and  expect_out(X,end)  where  X is a digit,\n\t     corresponds to the substring position in the buffer.  0 refers to\n\t     strings  which  matched  the  entire pattern and is generated for\n\t     glob patterns as well as regexp  patterns.   For  example,  if  a\n\t     process has produced output of \"abcdefgh\\n\", the result of:\n\n\t\t expect \"cd\"\n\n\t     is as if the following statements had executed:\n\n\t\t set expect_out(0,string) cd\n\t\t set expect_out(buffer) abcd\n\n\t     and \"efgh\\n\" is left in the output buffer.  If a process produced\n\t     the output \"abbbcabkkkka\\n\", the result of:\n\n\t\t expect -indices -re \"b(b*).*(k+)\"\n\n\t     is as if the following statements had executed:\n\n\t\t set expect_out(0,start) 1\n\t\t set expect_out(0,end) 10\n\t\t set expect_out(0,string) bbbcabkkkk\n\t\t set expect_out(1,start) 2\n\t\t set expect_out(1,end) 3\n\t\t set expect_out(1,string) bb\n\t\t set expect_out(2,start) 10\n\t\t set expect_out(2,end) 10\n\t\t set expect_out(2,string) k\n\t\t set expect_out(buffer) abbbcabkkkk\n\n\t     and \"a\\n\" is left in the output buffer.  The pattern \"*\" (and -re\n\t     \".*\")  will flush the output buffer without reading any more out-\n\t     put from the process.\n\n\t     Normally, the matched output is discarded from Expect's  internal\n\t     buffers.\tThis  may be prevented by prefixing a pattern with the\n\t     -notransfer flag.\tThis flag is especially useful in  experiment-\n\t     ing  (and\tcan  be  abbreviated  to  \"-not\" for convenience while\n\t     experimenting).\n\n\t     The spawn id associated with  the\tmatching  output  (or  eof  or\n\t     full_buffer) is stored in expect_out(spawn_id).\n\n\t     The  -timeout  flag  causes the current expect command to use the\n\t     following value as a timeout instead of using the\tvalue  of  the\n\t     timeout variable.\n\n\t     By  default, patterns are matched against output from the current\n\t     process, however the -i flag declares the output from  the  named\n\t     spawn_id  list  be  matched against any following patterns (up to\n\t     the next -i).  The spawn_id list should either  be  a  whitespace\n\t     separated\tlist  of  spawn_ids  or a variable referring to such a\n\t     list of spawn_ids.\n\n\t     For example, the following example waits for \"connected\" from the\n\t     current  process,\tor \"busy\", \"failed\" or \"invalid password\" from\n\t     the spawn_id named by $proc2.\n\n\t\t expect {\n\t\t     -i $proc2 busy {puts busy\\n ; exp_continue}\n\t\t     -re \"failed|invalid password\" abort\n\t\t     timeout abort\n\t\t     connected\n\t\t }\n\n\t     The value of the global variable  any_spawn_id  may  be  used  to\n\t     match  patterns to any spawn_ids that are named with all other -i\n\t     flags in the current expect command.  The spawn_id from a -i flag\n\t     with no associated pattern (i.e., followed immediately by another\n\t     -i) is made available to any other patterns in  the  same\texpect\n\t     command associated with any_spawn_id.\n\n\t     The  -i  flag  may  also name a global variable in which case the\n\t     variable is read for a list of spawn ids.\tThe variable is reread\n\t     whenever  it  changes.   This  provides a way of changing the I/O\n\t     source while the command is in  execution.   Spawn  ids  provided\n\t     this way are called \"indirect\" spawn ids.\n\n\t     Actions  such  as\tbreak  and  continue  cause control structures\n\t     (i.e., for, proc) to  behave  in  the  usual  way.   The  command\n\t     exp_continue  allows  expect  itself to continue executing rather\n\t     than returning as it normally would.\n\n\t     This is useful for avoiding explicit  loops  or  repeated\texpect\n\t     statements.  The following example is part of a fragment to auto-\n\t     mate rlogin.  The exp_continue avoids having to  write  a\tsecond\n\t     expect  statement\t(to  look  for the prompt again) if the rlogin\n\t     prompts for a password.\n\n\t\t expect {\n\t\t     Password: {\n\t\t\t stty -echo\n\t\t\t send_user \"password (for $user) on $host: \"\n\t\t\t expect_user -re \"(.*)\\n\"\n\t\t\t send_user \"\\n\"\n\t\t\t send \"$expect_out(1,string)\\r\"\n\t\t\t stty echo\n\t\t\t exp_continue\n\t\t     } incorrect {\n\t\t\t send_user \"invalid password or account\\n\"\n\t\t\t exit\n\t\t     } timeout {\n\t\t\t send_user \"connection to $host timed out\\n\"\n\t\t\t exit\n\t\t     } eof {\n\t\t\t send_user \\\n\t\t\t     \"connection to host failed: $expect_out(buffer)\"\n\t\t\t exit\n\t\t     } -re $prompt\n\t\t }\n\n\t     For example, the following fragment might help a  user  guide  an\n\t     interaction that is already totally automated.  In this case, the\n\t     terminal is put into raw mode.  If the user presses \"+\", a  vari-\n\t     able is incremented.  If \"p\" is pressed, several returns are sent\n\t     to the process, perhaps to poke it in some way, and \"i\" lets  the\n\t     user interact with the process, effectively stealing away control\n\t     from the script.  In each case, the exp_continue allows the  cur-\n\t     rent expect to continue pattern matching after executing the cur-\n\t     rent action.\n\n\t\t stty raw -echo\n\t\t expect_after {\n\t\t     -i $user_spawn_id\n\t\t     \"p\" {send \"\\r\\r\\r\"; exp_continue}\n\t\t     \"+\" {incr foo; exp_continue}\n\t\t     \"i\" {interact; exp_continue}\n\t\t     \"quit\" exit\n\t\t }\n\n\n\t     By default, exp_continue resets the timeout timer.  The timer  is\n\t     not restarted, if exp_continue is called with the -continue_timer\n\t     flag.\n\n       expect_after [expect_args]\n\t     works identically to the expect_before except  that  if  patterns\n\t     from  both  expect and expect_after can match, the expect pattern\n\t     is used.  See the expect_before command for more information.\n\n       expect_background [expect_args]\n\t     takes the same arguments as expect, however  it  returns  immedi-\n\t     ately.  Patterns are tested whenever new input arrives.  The pat-\n\t     tern timeout and default are meaningless to expect_background and\n\t     are silently discarded.  Otherwise, the expect_background command\n\t     uses expect_before and expect_after  patterns  just  like\texpect\n\t     does.\n\n\t     When  expect_background  actions  are being evaluated, background\n\t     processing for the same spawn id is blocked.  Background process-\n\t     ing  is  unblocked  when  the action completes.  While background\n\t     processing is blocked, it is possible to do a (foreground) expect\n\t     on the same spawn id.\n\n\t     It  is  not  possible  to execute an expect while an expect_back-\n\t     ground is unblocked.  expect_background for a particular spawn id\n\t     is  deleted  by  declaring  a new expect_background with the same\n\t     spawn id.\tDeclaring expect_background with  no  pattern  removes\n\t     the  given  spawn\tid  from  the ability to match patterns in the\n\t     background.\n\n       expect_before [expect_args]\n\t     takes the same arguments as expect, however  it  returns  immedi-\n\t     ately.   Pattern-action  pairs from the most recent expect_before\n\t     with the same spawn id are  implicitly  added  to\tany  following\n\t     expect  commands.\t If  a pattern matches, it is treated as if it\n\t     had been specified in the expect command itself, and the  associ-\n\t     ated  body  is executed in the context of the expect command.  If\n\t     patterns from  both  expect_before  and  expect  can  match,  the\n\t     expect_before pattern is used.\n\n\t     If  no  pattern is specified, the spawn id is not checked for any\n\t     patterns.\n\n\t     Unless overridden by a  -i  flag,\texpect_before  patterns  match\n\t     against  the  spawn id defined at the time that the expect_before\n\t     command was executed (not when its pattern is matched).\n\n\t     The -info flag causes expect_before to return the current\tspeci-\n\t     fications of what patterns it will match.\tBy default, it reports\n\t     on the current spawn id.  An optional spawn id specification  may\n\t     be given for information on that spawn id.  For example\n\n\t\t expect_before -info -i $proc\n\n\t     At most one spawn id specification may be given.  The flag -indi-\n\t     rect suppresses direct spawn ids that  come  only\tfrom  indirect\n\t     specifications.\n\n\t     Instead  of  a spawn id specification, the flag \"-all\" will cause\n\t     \"-info\" to report on all spawn ids.\n\n\t     The output of the -info flag can be reused  as  the  argument  to\n\t     expect_before.\n\n       expect_tty [expect_args]\n\t     is  like  expect but it reads characters from /dev/tty (i.e. key-\n\t     strokes from the user).  By  default,  reading  is  performed  in\n\t     cooked  mode.   Thus,  lines  must end with a return in order for\n\t     expect to see them.  This may be changed via stty (see  the  stty\n\t     command below).\n\n       expect_user [expect_args]\n\t     is  like  expect  but  it\treads characters from stdin (i.e. key-\n\t     strokes from the user).  By  default,  reading  is  performed  in\n\t     cooked  mode.   Thus,  lines  must end with a return in order for\n\t     expect to see them.  This may be changed via stty (see  the  stty\n\t     command below).\n\n       fork  creates  a  new process.  The new process is an exact copy of the\n\t     current Expect process.  On success, fork returns 0  to  the  new\n\t     (child)  process  and returns the process ID of the child process\n\t     to the parent process.  On failure (invariably  due  to  lack  of\n\t     resources, e.g., swap space, memory), fork returns -1 to the par-\n\t     ent process, and no child process is created.\n\n\t     Forked processes exit via the exit command, just like the\torigi-\n\t     nal  process.   Forked  processes are allowed to write to the log\n\t     files.  If you do not disable debugging or logging in most of the\n\t     processes, the result can be confusing.\n\n\t     Some  pty implementations may be confused by multiple readers and\n\t     writers, even momentarily.  Thus, it is  safest  to  fork\tbefore\n\t     spawning processes.\n\n       interact [string1 body1] ... [stringn [bodyn]]\n\t     gives  control  of  the current process to the user, so that key-\n\t     strokes are sent to the  current  process,  and  the  stdout  and\n\t     stderr of the current process are returned.\n\n\t     String-body  pairs  may  be specified as arguments, in which case\n\t     the body is executed when the corresponding  string  is  entered.\n\t     (By  default,  the  string  is  not sent to the current process.)\n\t     The interpreter command is assumed, if the final body is missing.\n\n\t     If  the  arguments  to the entire interact statement require more\n\t     than one line, all the arguments may be \"braced\" into one\tso  as\n\t     to  avoid\tterminating  each  line with a backslash.  In this one\n\t     case, the usual Tcl substitutions will occur despite the  braces.\n\n\t     For example, the following command runs interact with the follow-\n\t     ing string-body pairs defined:  When ^Z  is  pressed,  Expect  is\n\t     suspended.   (The -reset flag restores the terminal modes.)  When\n\t     ^A is pressed, the user sees \"you\ttyped  a  control-A\"  and  the\n\t     process is sent a ^A.  When $ is pressed, the user sees the date.\n\t     When ^C is pressed, Expect exits.\tIf \"foo\" is entered, the  user\n\t     sees  \"bar\".   When  ~~  is  pressed, the Expect interpreter runs\n\t     interactively.\n\n\t\t set CTRLZ \\032\n\t\t interact {\n\t\t     -reset $CTRLZ {exec kill -STOP [pid]}\n\t\t     \\001   {send_user \"you typed a control-A\\n\";\n\t\t\t     send \"\\001\"\n\t\t\t    }\n\t\t     $\t    {send_user \"The date is [clock format [clock seconds]].\"}\n\t\t     \\003   exit\n\t\t     foo    {send_user \"bar\"}\n\t\t     ~~\n\t\t }\n\n\n\t     In string-body pairs, strings are matched in the order  they  are\n\t     listed  as  arguments.  Strings that partially match are not sent\n\t     to the current process in anticipation of the  remainder  coming.\n\t     If characters are then entered such that there can no longer pos-\n\t     sibly be a match, only the part of the string will be sent to the\n\t     process  that cannot possibly begin another match.  Thus, strings\n\t     that are substrings of partial matches can match  later,  if  the\n\t     original  strings\tthat  was  attempting  to  be match ultimately\n\t     fails.\n\n\t     By default, string matching is exact with\tno  wild  cards.   (In\n\t     contrast,\t the   expect  command\tuses  glob-style  patterns  by\n\t     default.)\tThe -ex flag may be  used  to  protect\tpatterns  that\n\t     might  otherwise match interact flags from doing so.  Any pattern\n\t     beginning with a  \"-\"  should  be\tprotected  this  way.\t  (All\n\t     strings starting with \"-\" are reserved for future options.)\n\n\t     The  -re  flag  forces  the string to be interpreted as a regexp-\n\t     style pattern.  In this case, matching substrings are  stored  in\n\t     the  variable interact_out similarly to the way expect stores its\n\t     output in the variable expect_out.  The -indices  flag  is  simi-\n\t     larly supported.\n\n\t     The  pattern  eof introduces an action that is executed upon end-\n\t     of-file.  A separate eof pattern may also follow the -output flag\n\t     in  which\tcase it is matched if an eof is detected while writing\n\t     output.  The default eof action is  \"return\",  so\tthat  interact\n\t     simply returns upon any EOF.\n\n\t     The  pattern timeout introduces a timeout (in seconds) and action\n\t     that is executed after no characters have been read for  a  given\n\t     time.  The timeout pattern applies to the most recently specified\n\t     process.  There is no  default  timeout.\tThe  special  variable\n\t     \"timeout\"\t(used  by  the\texpect\tcommand) has no affect on this\n\t     timeout.\n\n\t     For example, the following statement could be used to  autologout\n\t     users  who  have not typed anything for an hour but who still get\n\t     frequent system messages:\n\n\t\t interact -input $user_spawn_id timeout 3600 return -output \\\n\t\t     $spawn_id\n\n\n\t     If the pattern is the keyword null, and nulls  are  allowed  (via\n\t     the  remove_nulls command), the corresponding body is executed if\n\t     a single ASCII 0 is matched.  It is not possible to match 0 bytes\n\t     via glob or regexp patterns.\n\n\t     Prefacing\ta  pattern  with  the flag -iwrite causes the variable\n\t     interact_out(spawn_id) to be set to the  spawn_id\twhich  matched\n\t     the pattern (or eof).\n\n\t     Actions  such  as\tbreak  and  continue  cause control structures\n\t     (i.e., for, proc) to behave in the  usual\tway.   However\treturn\n\t     causes  interact  to  return  to  its  caller, while inter_return\n\t     causes interact to cause a return in its caller.  For example, if\n\t     \"proc  foo\"  called  interact  which  then  executed  the\taction\n\t     inter_return, proc foo would return.  (This means that if\tinter-\n\t     act  calls interpreter interactively typing return will cause the\n\t     interact to continue, while inter_return will cause the  interact\n\t     to return to its caller.)\n\n\t     During  interact,\traw mode is used so that all characters may be\n\t     passed to the current process.  If the current process  does  not\n\t     catch job control signals, it will stop if sent a stop signal (by\n\t     default ^Z).  To restart it, send a continue signal (such\tas  by\n\t     \"kill  -CONT  <pid>\").   If  you really want to send a SIGSTOP to\n\t     such a process (by ^Z), consider spawning csh first and then run-\n\t     ning  your  program.   On\tthe  other hand, if you want to send a\n\t     SIGSTOP to Expect itself,\tfirst  call  interpreter  (perhaps  by\n\t     using an escape character), and then press ^Z.\n\n\t     String-body  pairs can be used as a shorthand for avoiding having\n\t     to enter the interpreter and execute commands interactively.  The\n\t     previous  terminal  mode  is used while the body of a string-body\n\t     pair is being executed.\n\n\t     For speed, actions execute in raw mode by\tdefault.   The\t-reset\n\t     flag  resets  the terminal to the mode it had before interact was\n\t     executed (invariably, cooked mode).  Note that characters entered\n\t     when  the mode is being switched may be lost (an unfortunate fea-\n\t     ture of the terminal driver on some systems).  The only reason to\n\t     use -reset is if your action depends on running in cooked mode.\n\n\t     The  -echo flag sends characters that match the following pattern\n\t     back to the process that generated  them  as  each  character  is\n\t     read.   This  may\tbe  useful when the user needs to see feedback\n\t     from partially typed patterns.\n\n\t     If a pattern is being echoed but eventually fails to  match,  the\n\t     characters  are  sent  to\tthe  spawned  process.\tIf the spawned\n\t     process then echoes them, the user will see the characters twice.\n\t     -echo  is\tprobably only appropriate in situations where the user\n\t     is unlikely to not complete the pattern.  For example,  the  fol-\n\t     lowing  excerpt is from rftp, the recursive-ftp script, where the\n\t     user is prompted to enter ~g, ~p, or ~l, to get, put, or list the\n\t     current  directory  recursively.\tThese are so far away from the\n\t     normal ftp commands, that the user is unlikely to type ~ followed\n\t     by anything else, except mistakenly, in which case, they'll prob-\n\t     ably just ignore the result anyway.\n\n\t\t interact {\n\t\t     -echo ~g {getcurdirectory 1}\n\t\t     -echo ~l {getcurdirectory 0}\n\t\t     -echo ~p {putcurdirectory}\n\t\t }\n\n\t     The -nobuffer flag sends characters that match the following pat-\n\t     tern on to the output process as characters are read.\n\n\t     This  is useful when you wish to let a program echo back the pat-\n\t     tern.  For example, the following might be used to monitor  where\n\t     a\tperson\tis  dialing (a Hayes-style modem).  Each time \"atd\" is\n\t     seen the script logs the rest of the line.\n\n\t\t proc lognumber {} {\n\t\t     interact -nobuffer -re \"(.*)\\r\" return\n\t\t     puts $log \"[clock format [clock seconds]]: dialed $interact_out(1,string)\"\n\t\t }\n\n\t\t interact -nobuffer \"atd\" lognumber\n\n\n\t     During interact, previous use of log_user is ignored.  In partic-\n\t     ular,  interact  will  force its output to be logged (sent to the\n\t     standard output) since it is presumed the user  doesn't  wish  to\n\t     interact blindly.\n\n\t     The  -o flag causes any following key-body pairs to be applied to\n\t     the output of the current process.  This can be useful, for exam-\n\t     ple, when dealing with hosts that send unwanted characters during\n\t     a telnet session.\n\n\t     By default, interact expects the user to  be  writing  stdin  and\n\t     reading  stdout  of  the Expect process itself.  The -u flag (for\n\t     \"user\") makes interact look for the user as the process named  by\n\t     its argument (which must be a spawned id).\n\n\t     This allows two unrelated processes to be joined together without\n\t     using an explicit loop.  To aid in debugging, Expect  diagnostics\n\t     always  go to stderr (or stdout for certain logging and debugging\n\t     information).  For the same reason, the interpreter command  will\n\t     read interactively from stdin.\n\n\t     For  example,  the  following  fragment  creates a login process.\n\t     Then it dials the user (not shown), and finally connects the  two\n\t     together.\t Of  course, any process may be substituted for login.\n\t     A shell, for example, would allow the user to work  without  sup-\n\t     plying an account and password.\n\n\t\t spawn login\n\t\t set login $spawn_id\n\t\t spawn tip modem\n\t\t # dial back out to user\n\t\t # connect user to login\n\t\t interact -u $login\n\n\t     To  send  output  to  multiple processes, list each spawn id list\n\t     prefaced by a -output flag.  Input for a group  of  output  spawn\n\t     ids  may  be  determined  by a spawn id list prefaced by a -input\n\t     flag.  (Both -input and -output may take lists in the  same  form\n\t     as the -i flag in the expect command, except that any_spawn_id is\n\t     not meaningful in interact.)  All following flags and strings (or\n\t     patterns)\tapply to this input until another -input flag appears.\n\t     If no -input  appears,  -output  implies  \"-input\t$user_spawn_id\n\t     -output\".\t (Similarly,  with  patterns that do not have -input.)\n\t     If one -input is specified, it overrides  $user_spawn_id.\t If  a\n\t     second  -input  is specified, it overrides $spawn_id.  Additional\n\t     -input flags may be specified.\n\n\t     The two implied input processes default to having\ttheir  outputs\n\t     specified\tas  $spawn_id  and  $user_spawn_id (in reverse).  If a\n\t     -input flag appears with no -output flag,\tcharacters  from  that\n\t     process are discarded.\n\n\t     The  -i  flag  introduces\ta replacement for the current spawn_id\n\t     when no other -input or  -output  flags  are  used.   A  -i  flag\n\t     implies a -o flag.\n\n\t     It  is possible to change the processes that are being interacted\n\t     with by using  indirect  spawn  ids.   (Indirect  spawn  ids  are\n\t     described\tin the section on the expect command.)\tIndirect spawn\n\t     ids may be specified with the -i, -u, -input, or -output flags.\n\n       interpreter  [args]\n\t     causes the user to be interactively prompted for Expect  and  Tcl\n\t     commands.\tThe result of each command is printed.\n\n\t     Actions  such  as\tbreak  and  continue  cause control structures\n\t     (i.e., for, proc) to behave in the  usual\tway.   However\treturn\n\t     causes  interpreter  to  return to its caller, while inter_return\n\t     causes interpreter to cause a return in its caller.  For example,\n\t     if  \"proc\tfoo\" called interpreter which then executed the action\n\t     inter_return, proc foo would return.  Any\tother  command\tcauses\n\t     interpreter to continue prompting for new commands.\n\n\t     By  default, the prompt contains two integers.  The first integer\n\t     describes the depth of the evaluation stack (i.e., how many times\n\t     Tcl_Eval has been called).  The second integer is the Tcl history\n\t     identifier.  The prompt can be set by defining a procedure called\n\t     \"prompt1\"\twhose  return  value  becomes  the  next prompt.  If a\n\t     statement has open quotes, parens, braces, or  brackets,  a  sec-\n\t     ondary  prompt  (by  default  \"+> \") is issued upon newline.  The\n\t     secondary prompt may  be  set  by\tdefining  a  procedure\tcalled\n\t     \"prompt2\".\n\n\t     During  interpreter,  cooked mode is used, even if the its caller\n\t     was using raw mode.\n\n\t     If stdin is closed, interpreter will return unless the -eof  flag\n\t     is used, in which case the subsequent argument is invoked.\n\n       log_file [args] [[-a] file]\n\t     If  a  filename is provided, log_file will record a transcript of\n\t     the session (beginning at that point) in the file.  log_file will\n\t     stop recording if no argument is given.  Any previous log file is\n\t     closed.\n\n\t     Instead of a filename, a Tcl file identifier may be  provided  by\n\t     using  the  -open\tor  -leaveopen\tflags.\tThis is similar to the\n\t     spawn command.  (See spawn for more info.)\n\n\t     The -a flag forces output to be logged that was suppressed by the\n\t     log_user command.\n\n\t     By default, the log_file command appends to old files rather than\n\t     truncating them, for the convenience of being able to  turn  log-\n\t     ging  off\tand  on  multiple  times  in one session.  To truncate\n\t     files, use the -noappend flag.\n\n\t     The -info flag causes log_file to return  a  description  of  the\n\t     most recent non-info arguments given.\n\n       log_user -info|0|1\n\t     By  default,  the send/expect dialogue is logged to stdout (and a\n\t     logfile if open).\tThe logging to stdout is disabled by the  com-\n\t     mand  \"log_user 0\" and reenabled by \"log_user 1\".\tLogging to the\n\t     logfile is unchanged.\n\n\t     The -info flag causes log_user to return  a  description  of  the\n\t     most recent non-info arguments given.\n\n       match_max [-d] [-i spawn_id] [size]\n\t     defines  the  size  of  the  buffer (in bytes) used internally by\n\t     expect.  With no size argument, the current size is returned.\n\n\t     With the -d flag, the default size is set.  (The initial  default\n\t     is  2000.)  With the -i flag, the size is set for the named spawn\n\t     id, otherwise it is set for the current process.\n\n       overlay [-# spawn_id] [-# spawn_id] [...] program [args]\n\t     executes program args in place of\tthe  current  Expect  program,\n\t     which  terminates.   A  bare  hyphen  argument forces a hyphen in\n\t     front of the command name as  if  it  was\ta  login  shell.   All\n\t     spawn_ids\tare closed except for those named as arguments.  These\n\t     are mapped onto the named file identifiers.\n\n\t     Spawn_ids are mapped to file identifiers for the new  program  to\n\t     inherit.\tFor  example, the following line runs chess and allows\n\t     it to be controlled by the current process - say, a chess master.\n\n\t\t overlay -0 $spawn_id -1 $spawn_id -2 $spawn_id chess\n\n\t     This is more efficient than \"interact -u\", however, it sacrifices\n\t     the ability to do programmed interaction since the Expect process\n\t     is no longer in control.\n\n\t     Note that no controlling terminal is provided.  Thus, if you dis-\n\t     connect or remap standard input, programs\tthat  do  job  control\n\t     (shells, login, etc) will not function properly.\n\n       parity [-d] [-i spawn_id] [value]\n\t     defines  whether  parity  should be retained or stripped from the\n\t     output of\tspawned  processes.   If  value  is  zero,  parity  is\n\t     stripped,\totherwise it is not stripped.  With no value argument,\n\t     the current value is returned.\n\n\t     With the -d flag, the default parity value is set.  (The  initial\n\t     default  is  1, i.e., parity is not stripped.)  With the -i flag,\n\t     the parity value is set for the named spawn id, otherwise\tit  is\n\t     set for the current process.\n\n       remove_nulls [-d] [-i spawn_id] [value]\n\t     defines  whether nulls are retained or removed from the output of\n\t     spawned processes before pattern matching or storing in the vari-\n\t     able  expect_out  or  interact_out.   If  value  is  1, nulls are\n\t     removed.  If value is 0, nulls are not removed.   With  no  value\n\t     argument, the current value is returned.\n\n\t     With the -d flag, the default value is set.  (The initial default\n\t     is 1, i.e., nulls are removed.)  With the -i flag, the  value  is\n\t     set  for  the named spawn id, otherwise it is set for the current\n\t     process.\n\n\t     Whether or not nulls are removed, Expect will record  null  bytes\n\t     to the log and stdout.\n\n       send [-flags] string\n\t     Sends string to the current process.  For example, the command\n\n\t\t send \"hello world\\r\"\n\n\t     sends the characters, h e l l o <blank> w o r l d <return> to the\n\t     current process.  (Tcl includes  a  printf-like  command  (called\n\t     format) which can build arbitrarily complex strings.)\n\n\t     Characters  are  sent  immediately  although  programs with line-\n\t     buffered input will not read the characters until a return  char-\n\t     acter is sent.  A return character is denoted \"\\r\".\n\n\t     The  --  flag  forces  the  next  argument to be interpreted as a\n\t     string rather than a flag.  Any string can be  preceded  by  \"--\"\n\t     whether  or  not  it actually looks like a flag.  This provides a\n\t     reliable mechanism to  specify  variable  strings\twithout  being\n\t     tripped  up  by  those  that  accidentally look like flags.  (All\n\t     strings starting with \"-\" are reserved for future options.)\n\n\t     The -i flag declares  that  the  string  be  sent\tto  the  named\n\t     spawn_id.\t If the spawn_id is user_spawn_id, and the terminal is\n\t     in raw mode, newlines in the string are translated to return-new-\n\t     line  sequences  so  that\tthey  appear as if the terminal was in\n\t     cooked mode.  The -raw flag disables this translation.\n\n\t     The -null flag sends null characters (0 bytes).  By default,  one\n\t     null  is  sent.   An integer may follow the -null to indicate how\n\t     many nulls to send.\n\n\t     The -break flag generates a break\tcondition.   This  only  makes\n\t     sense  if\tthe  spawn id refers to a tty device opened via \"spawn\n\t     -open\".  If you have spawned a process such as  tip,  you\tshould\n\t     use tip's convention for generating a break.\n\n\t     The  -s  flag  forces  output to be sent \"slowly\", thus avoid the\n\t     common situation where a computer outtypes an input  buffer  that\n\t     was designed for a human who would never outtype the same buffer.\n\t     This  output  is  controlled  by  the  value  of\tthe   variable\n\t     \"send_slow\" which takes a two element list.  The first element is\n\t     an integer that describes the number of bytes to send atomically.\n\t     The  second element is a real number that describes the number of\n\t     seconds by which the atomic sends must be separated.   For  exam-\n\t     ple,  \"set  send_slow  {10  .001}\"  would force \"send -s\" to send\n\t     strings with 1 millisecond in between each 10 characters sent.\n\n\t     The -h flag forces output to be  sent  (somewhat)\tlike  a  human\n\t     actually  typing.\t Human-like  delays appear between the charac-\n\t     ters.  (The algorithm is based upon a Weibull distribution,  with\n\t     modifications  to suit this particular application.)  This output\n\t     is controlled by the value of  the  variable  \"send_human\"  which\n\t     takes  a  five  element list.  The first two elements are average\n\t     interarrival time of characters in seconds.  The first is used by\n\t     default.\tThe  second  is  used at word endings, to simulate the\n\t     subtle pauses that occasionally occur at such  transitions.   The\n\t     third  parameter  is  a  measure of variability where .1 is quite\n\t     variable, 1 is reasonably variable, and 10 is  quite  invariable.\n\t     The  extremes  are  0  to infinity.  The last two parameters are,\n\t     respectively, a minimum and maximum interarrival time.  The mini-\n\t     mum  and  maximum\tare  used last and \"clip\" the final time.  The\n\t     ultimate average can be quite different from the given average if\n\t     the minimum and maximum clip enough values.\n\n\t     As  an example, the following command emulates a fast and consis-\n\t     tent typist:\n\n\t\t set send_human {.1 .3 1 .05 2}\n\t\t send -h \"I'm hungry.  Let's do lunch.\"\n\n\t     while the following might be more suitable after a hangover:\n\n\t\t set send_human {.4 .4 .2 .5 100}\n\t\t send -h \"Goodd party lash night!\"\n\n\t     Note that errors are not simulated, although you can set up error\n\t     correction  situations yourself by embedding mistakes and correc-\n\t     tions in a send argument.\n\n\t     The flags for sending null characters, for  sending  breaks,  for\n\t     forcing  slow  output  and  for  human-style  output are mutually\n\t     exclusive. Only the one specified last will be used. Furthermore,\n\t     no  string  argument  can be specified with the flags for sending\n\t     null characters or breaks.\n\n\t     It is a good idea to precede the first send to a  process\tby  an\n\t     expect.   expect  will  wait for the process to start, while send\n\t     cannot.  In particular, if the first send\tcompletes  before  the\n\t     process  starts  running,\tyou  run  the risk of having your data\n\t     ignored.  In situations where interactive programs offer no  ini-\n\t     tial prompt, you can precede send by a delay as in:\n\n\t\t # To avoid giving hackers hints on how to break in,\n\t\t # this system does not prompt for an external password.\n\t\t # Wait for 5 seconds for exec to complete\n\t\t spawn telnet very.secure.gov\n\t\t sleep 5\n\t\t send password\\r\n\n\t     exp_send  is an alias for send.  If you are using Expectk or some\n\t     other variant of Expect in the Tk environment, send is defined by\n\t     Tk  for  an entirely different purpose.  exp_send is provided for\n\t     compatibility between environments.  Similar aliases are provided\n\t     for other Expect's other send commands.\n\n       send_error [-flags] string\n\t     is  like  send,  except  that the output is sent to stderr rather\n\t     than the current process.\n\n       send_log [--] string\n\t     is like send, except that the string is only sent to the log file\n\t     (see  log_file.)\tThe  arguments\tare  ignored if no log file is\n\t     open.\n\n       send_tty [-flags] string\n\t     is like send, except that the output is sent to  /dev/tty\trather\n\t     than the current process.\n\n       send_user [-flags] string\n\t     is  like  send,  except  that the output is sent to stdout rather\n\t     than the current process.\n\n       sleep seconds\n\t     causes the script to sleep for the given number of seconds.  Sec-\n\t     onds  may\tbe a decimal number.  Interrupts (and Tk events if you\n\t     are using Expectk) are processed while Expect sleeps.\n\n       spawn [args] program [args]\n\t     creates a new process running program args.   Its\tstdin,\tstdout\n\t     and  stderr are connected to Expect, so that they may be read and\n\t     written by other Expect commands.\tThe connection\tis  broken  by\n\t     close  or\tif  the  process itself closes any of the file identi-\n\t     fiers.\n\n\t     When a process is started by spawn, the variable spawn_id is  set\n\t     to a descriptor referring to that process.  The process described\n\t     by spawn_id is considered the current process.  spawn_id  may  be\n\t     read or written, in effect providing job control.\n\n\t     user_spawn_id  is a global variable containing a descriptor which\n\t     refers to the user.  For example, when spawn_id is  set  to  this\n\t     value, expect behaves like expect_user.\n\n\t     error_spawn_id is a global variable containing a descriptor which\n\t     refers to the standard error.  For example, when spawn_id is  set\n\t     to this value, send behaves like send_error.\n\n\t     tty_spawn_id  is  a global variable containing a descriptor which\n\t     refers to /dev/tty.  If /dev/tty does not exist  (such  as  in  a\n\t     cron,  at,  or  batch  script), then tty_spawn_id is not defined.\n\t     This may be tested as:\n\n\t\t if {[info vars tty_spawn_id]} {\n\t\t     # /dev/tty exists\n\t\t } else {\n\t\t     # /dev/tty doesn't exist\n\t\t     # probably in cron, batch, or at script\n\t\t }\n\n\n\t     spawn returns the UNIX process id.  If no process is  spawned,  0\n\t     is  returned.   The  variable spawn_out(slave,name) is set to the\n\t     name of the pty slave device.\n\n\t     By default, spawn echoes the command  name  and  arguments.   The\n\t     -noecho flag stops spawn from doing this.\n\n\t     The  -console  flag causes console output to be redirected to the\n\t     spawned process.  This is not supported on all systems.\n\n\t     Internally, spawn uses a pty, initialized the  same  way  as  the\n\t     user's tty.  This is further initialized so that all settings are\n\t     \"sane\" (according to stty(1)).   If  the  variable  stty_init  is\n\t     defined, it is interpreted in the style of stty arguments as fur-\n\t     ther configuration.  For example, \"set stty_init raw\" will  cause\n\t     further  spawned  processes's  terminals  to  start  in raw mode.\n\t     -nottycopy skips the initialization  based  on  the  user's  tty.\n\t     -nottyinit skips the \"sane\" initialization.\n\n\t     Normally,\tspawn  takes  little  time  to execute.  If you notice\n\t     spawn taking a significant amount of time, it is probably encoun-\n\t     tering  ptys  that are wedged.  A number of tests are run on ptys\n\t     to avoid entanglements with errant  processes.   (These  take  10\n\t     seconds  per wedged pty.)\tRunning Expect with the -d option will\n\t     show if Expect is encountering many ptys in odd states.   If  you\n\t     cannot  kill the processes to which these ptys are attached, your\n\t     only recourse may be to reboot.\n\n\t     If program cannot be spawned successfully because\texec(2)  fails\n\t     (e.g.  when  program  doesn't  exist),  an  error message will be\n\t     returned by the next interact or expect command as if program had\n\t     run and produced the error message as output.  This behavior is a\n\t     natural consequence of the implementation of spawn.   Internally,\n\t     spawn forks, after which the spawned process has no way to commu-\n\t     nicate with the original Expect process except  by  communication\n\t     via the spawn_id.\n\n\t     The  -open  flag  causes the next argument to be interpreted as a\n\t     Tcl file identifier (i.e., returned by open.)  The spawn  id  can\n\t     then  be used as if it were a spawned process.  (The file identi-\n\t     fier should no longer be used.)  This lets you treat raw devices,\n\t     files, and pipelines as spawned processes without using a pty.  0\n\t     is returned to indicate there is no associated process.  When the\n\t     connection  to  the spawned process is closed, so is the Tcl file\n\t     identifier.  The -leaveopen flag is similar to -open except  that\n\t     -leaveopen  causes the file identifier to be left open even after\n\t     the spawn id is closed.\n\n\t     The -pty flag causes a pty to be opened but no  process  spawned.\n\t     0\tis  returned  to  indicate  there  is  no  associated process.\n\t     Spawn_id is set as usual.\n\n\t     The variable spawn_out(slave,fd) is set to a file identifier cor-\n\t     responding  to  the  pty  slave.\tIt  can be closed using \"close\n\t     -slave\".\n\n\t     The -ignore flag names a signal to  be  ignored  in  the  spawned\n\t     process.\tOtherwise,  signals get the default behavior.  Signals\n\t     are named as  in  the  trap  command,  except  that  each\tsignal\n\t     requires a separate flag.\n\n       strace level\n\t     causes  following statements to be printed before being executed.\n\t     (Tcl's trace command traces variables.)  level indicates how  far\n\t     down in the call stack to trace.  For example, the following com-\n\t     mand runs Expect while tracing the first 4 levels of  calls,  but\n\t     none below that.\n\n\t\t expect -c \"strace 4\" script.exp\n\n\n\t     The  -info flag causes strace to return a description of the most\n\t     recent non-info arguments given.\n\n       stty args\n\t     changes terminal modes similarly to the external stty command.\n\n\t     By default, the controlling terminal is accessed.\t Other\ttermi-\n\t     nals can be accessed by appending \"< /dev/tty...\" to the command.\n\t     (Note that the arguments should not  be  grouped  into  a\tsingle\n\t     argument.)\n\n\t     Requests  for  status return it as the result of the command.  If\n\t     no status is requested and the controlling terminal is  accessed,\n\t     the  previous  status of the raw and echo attributes are returned\n\t     in a form which can later be used by the command.\n\n\t     For example, the arguments raw or -cooked put the\tterminal  into\n\t     raw  mode.   The  arguments  -raw or cooked put the terminal into\n\t     cooked mode.  The arguments echo and -echo put the terminal  into\n\t     echo and noecho mode respectively.\n\n\t     The  following  example  illustrates  how\tto temporarily disable\n\t     echoing.  This could be used in  otherwise-automatic  scripts  to\n\t     avoid  embedding passwords in them.  (See more discussion on this\n\t     under EXPECT HINTS below.)\n\n\t\t stty -echo\n\t\t send_user \"Password: \"\n\t\t expect_user -re \"(.*)\\n\"\n\t\t set password $expect_out(1,string)\n\t\t stty echo\n\n\n       system args\n\t     gives args to sh(1) as input, just as if it had been typed  as  a\n\t     command  from  a  terminal.   Expect waits until the shell termi-\n\t     nates.  The return status from sh is handled the  same  way  that\n\t     exec handles its return status.\n\n\t     In  contrast  to  exec  which  redirects  stdin and stdout to the\n\t     script, system performs no redirection (other than that indicated\n\t     by  the  string  itself).\t Thus,\tit is possible to use programs\n\t     which must talk directly to /dev/tty.  For the same  reason,  the\n\t     results of system are not recorded in the log.\n\n       timestamp [args]\n\t     returns  a  timestamp.   With no arguments, the number of seconds\n\t     since the epoch is returned.\n\n\t     The -format flag introduces a string which is returned  but  with\n\t     substitutions  made  according  to  the POSIX rules for strftime.\n\t     For example %a is replaced by an abbreviated weekday name\t(i.e.,\n\t     Sat).  Others are:\n\t\t %a\t abbreviated weekday name\n\t\t %A\t full weekday name\n\t\t %b\t abbreviated month name\n\t\t %B\t full month name\n\t\t %c\t date-time as in: Wed Oct  6 11:45:56 1993\n\t\t %d\t day of the month (01-31)\n\t\t %H\t hour (00-23)\n\t\t %I\t hour (01-12)\n\t\t %j\t day (001-366)\n\t\t %m\t month (01-12)\n\t\t %M\t minute (00-59)\n\t\t %p\t am or pm\n\t\t %S\t second (00-61)\n\t\t %u\t day (1-7, Monday is first day of week)\n\t\t %U\t week (00-53, first Sunday is first day of week one)\n\t\t %V\t week (01-53, ISO 8601 style)\n\t\t %w\t day (0-6)\n\t\t %W\t week (00-53, first Monday is first day of week one)\n\t\t %x\t date-time as in: Wed Oct  6 1993\n\t\t %X\t time as in: 23:59:59\n\t\t %y\t year (00-99)\n\t\t %Y\t year as in: 1993\n\t\t %Z\t timezone (or nothing if not determinable)\n\t\t %%\t a bare percent sign\n\n\t     Other  %  specifications are undefined.  Other characters will be\n\t     passed through untouched.\tOnly the C locale is supported.\n\n\t     The -seconds flag introduces a number of seconds since the  epoch\n\t     to be used as a source from which to format.  Otherwise, the cur-\n\t     rent time is used.\n\n\t     The -gmt flag forces timestamp output to use  the\tGMT  timezone.\n\t     With no flag, the local timezone is used.\n\n       trap [[command] signals]\n\t     causes  the  given  command to be executed upon future receipt of\n\t     any of the given signals.\tThe command is executed in the\tglobal\n\t     scope.   If command is absent, the signal action is returned.  If\n\t     command is the string SIG_IGN, the signals are ignored.  If  com-\n\t     mand  is the string SIG_DFL, the signals are result to the system\n\t     default.  signals is either a single signal or a list of signals.\n\t     Signals  may be specified numerically or symbolically as per sig-\n\t     nal(3).  The \"SIG\" prefix may be omitted.\n\n\t     With no arguments (or the argument  -number),  trap  returns  the\n\t     signal number of the trap command currently being executed.\n\n\t     The  -code  flag  uses the return code of the command in place of\n\t     whatever code Tcl was about to return when the command originally\n\t     started running.\n\n\t     The  -interp  flag  causes  the command to be evaluated using the\n\t     interpreter active at the time the command started running rather\n\t     than when the trap was declared.\n\n\t     The  -name flag causes the trap command to return the signal name\n\t     of the trap command currently being executed.\n\n\t     The -max flag causes the trap command to return the largest  sig-\n\t     nal number that can be set.\n\n\t     For  example,  the command \"trap {send_user \"Ouch!\"} SIGINT\" will\n\t     print \"Ouch!\"  each time the user presses ^C.\n\n\t     By default, SIGINT (which can usually be  generated  by  pressing\n\t     ^C) and SIGTERM cause Expect to exit.  This is due to the follow-\n\t     ing trap, created by default when Expect starts.\n\n\t\t trap exit {SIGINT SIGTERM}\n\n\t     If you use the -D flag to start the debugger, SIGINT is redefined\n\t     to  start the interactive debugger.  This is due to the following\n\t     trap:\n\n\t\t trap {exp_debug 1} SIGINT\n\n\t     The debugger trap can be changed by setting the environment vari-\n\t     able EXPECT_DEBUG_INIT to a new trap command.\n\n\t     You  can,\tof  course, override both of these just by adding trap\n\t     commands to your script.  In particular, if  you  have  your  own\n\t     \"trap  exit  SIGINT\", this will override the debugger trap.  This\n\t     is useful if you want to prevent users from getting to the debug-\n\t     ger at all.\n\n\t     If  you  want to define your own trap on SIGINT but still trap to\n\t     the debugger when it is running, use:\n\n\t\t if {![exp_debug]} {trap mystuff SIGINT}\n\n\t     Alternatively, you can trap to the debugger using some other sig-\n\t     nal.\n\n\t     trap  will not let you override the action for SIGALRM as this is\n\t     used internally to Expect.  The disconnect command  sets  SIGALRM\n\t     to  SIG_IGN  (ignore).  You can reenable this as long as you dis-\n\t     able it during subsequent spawn commands.\n\n\t     See signal(3) for more info.\n\n       wait [args]\n\t     delays until a spawned process (or the current process if none is\n\t     named) terminates.\n\n\t     wait normally returns a list of four integers.  The first integer\n\t     is the pid of the process that was waited upon.  The second inte-\n\t     ger is the corresponding spawn id.  The third integer is -1 if an\n\t     operating system error occurred, or 0 otherwise.\tIf  the  third\n\t     integer  was  0, the fourth integer is the status returned by the\n\t     spawned process.  If the third integer was -1, the fourth integer\n\t     is  the  value  of errno set by the operating system.  The global\n\t     variable errorCode is also set.\n\n\t     Additional elements may appear at the end\tof  the  return  value\n\t     from  wait.   An  optional  fifth\telement  identifies a class of\n\t     information.  Currently, the only possible value for this element\n\t     is  CHILDKILLED in which case the next two values are the C-style\n\t     signal name and a short textual description.\n\n\t     The -i flag declares the process to  wait\tcorresponding  to  the\n\t     named  spawn_id  (NOT the process id).  Inside a SIGCHLD handler,\n\t     it is possible to wait for any spawned process by using the spawn\n\t     id -1.\n\n\t     The  -nowait  flag causes the wait to return immediately with the\n\t     indication of a successful wait.  When the process exits (later),\n\t     it  will automatically disappear without the need for an explicit\n\t     wait.\n\n\t     The wait command may also be used wait for a forked process using\n\t     the  arguments  \"-i  -1\".\tUnlike its use with spawned processes,\n\t     this command can be executed at any time.\tThere  is  no  control\n\t     over  which  process is reaped.  However, the return value can be\n\t     checked for the process id.\n\n\nLIBRARIES\n       Expect automatically knows about  two  built-in\tlibraries  for\tExpect\n       scripts.   These  are defined by the directories named in the variables\n       exp_library and exp_exec_library.  Both are meant  to  contain  utility\n       files that can be used by other scripts.\n\n       exp_library  contains architecture-independent files.  exp_exec_library\n       contains architecture-dependent files.  Depending on your system,  both\n       directories   may   be  totally\tempty.\t The  existence  of  the  file\n       $exp_exec_library/cat-buffers describes whether your  /bin/cat  buffers\n       by default.\n\nPRETTY-PRINTING\n       A  vgrind  definition  is available for pretty-printing Expect scripts.\n       Assuming the vgrind definition supplied with the Expect distribution is\n       correctly installed, you can use it as:\n\n\t   vgrind -lexpect file\n\n\nEXAMPLES\n       It  many  not  be  apparent how to put everything together that the man\n       page describes.\tI encourage you to read and try out  the  examples  in\n       the  example  directory\tof  the Expect distribution.  Some of them are\n       real programs.  Others are simply illustrative of  certain  techniques,\n       and  of\tcourse, a couple are just quick hacks.\tThe INSTALL file has a\n       quick overview of these programs.\n\n       The Expect papers (see SEE ALSO) are also useful.   While  some\tpapers\n       use  syntax corresponding to earlier versions of Expect, the accompany-\n       ing rationales are still valid and go into a lot more detail than  this\n       man page.\n\nCAVEATS\n       Extensions  may collide with Expect's command names.  For example, send\n       is defined by Tk for an entirely different purpose.  For  this  reason,\n       most of the Expect commands are also available as \"exp_XXXX\".  Commands\n       and variables beginning with \"exp\", \"inter\", \"spawn\", and \"timeout\"  do\n       not have aliases.  Use the extended command names if you need this com-\n       patibility between environments.\n\n       Expect takes a rather liberal view of scoping.\tIn  particular,  vari-\n       ables  read  by\tcommands specific to the Expect program will be sought\n       first from the local scope, and if not found, in the global scope.  For\n       example, this obviates the need to place \"global timeout\" in every pro-\n       cedure you write that uses expect.  On the other hand, variables  writ-\n       ten  are  always in the local scope (unless a \"global\" command has been\n       issued).  The most common problem this causes is when spawn is executed\n       in  a  procedure.  Outside the procedure, spawn_id no longer exists, so\n       the spawned process is no longer accessible simply because of  scoping.\n       Add a \"global spawn_id\" to such a procedure.\n\n       If  you\tcannot\tenable the multispawning capability (i.e., your system\n       supports neither select (BSD *.*), poll (SVR>2), nor something  equiva-\n       lent),  Expect will only be able to control a single process at a time.\n       In this case, do not attempt to set spawn_id, nor  should  you  execute\n       processes  via  exec  while a spawned process is running.  Furthermore,\n       you will not be able to expect from multiple processes  (including  the\n       user as one) at the same time.\n\n       Terminal  parameters can have a big effect on scripts.  For example, if\n       a script is written to look for echoing, it will misbehave  if  echoing\n       is turned off.  For this reason, Expect forces sane terminal parameters\n       by default.  Unfortunately, this can make things unpleasant  for  other\n       programs.   As  an example, the emacs shell wants to change the \"usual\"\n       mappings: newlines get mapped to newlines  instead  of  carriage-return\n       newlines,  and  echoing\tis  disabled.  This allows one to use emacs to\n       edit the input line.  Unfortunately, Expect cannot possibly guess this.\n\n       You  can request that Expect not override its default setting of termi-\n       nal parameters, but you must then be very careful when writing  scripts\n       for  such  environments.   In  the  case of emacs, avoid depending upon\n       things like echoing and end-of-line mappings.\n\n       The commands that accepted arguments braced into  a  single  list  (the\n       expect  variants and interact) use a heuristic to decide if the list is\n       actually one argument or many.  The heuristic can fail only in the case\n       when  the list actually does represent a single argument which has mul-\n       tiple embedded \\n's with non-whitespace characters between them.   This\n       seems  sufficiently  improbable, however the argument \"-nobrace\" can be\n       used to force a single argument to be handled  as  a  single  argument.\n       This  could  conceivably  be  used  with machine-generated Expect code.\n       Similarly, -brace forces a single argument to  be  handle  as  multiple\n       patterns/actions.\n\n\nBUGS\n       It  was\treally\ttempting  to name the program \"sex\" (for either \"Smart\n       EXec\" or \"Send-EXpect\"), but good sense (or  perhaps  just  Puritanism)\n       prevailed.\n\n       On  some systems, when a shell is spawned, it complains about not being\n       able to access the tty but runs anyway.\tThis means your system\thas  a\n       mechanism  for  gaining\tthe  controlling  tty that Expect doesn't know\n       about.  Please find out what it is, and send this information  back  to\n       me.\n\n       Ultrix  4.1  (at least the latest versions around here) considers time-\n       outs of above 1000000 to be equivalent to 0.\n\n       Digital UNIX 4.0A (and probably other  versions)  refuses  to  allocate\n       ptys  if you define a SIGCHLD handler.  See grantpt page for more info.\n\n       IRIX 6.0 does not handle pty permissions correctly so  that  if\tExpect\n       attempts  to  allocate a pty previously used by someone else, it fails.\n       Upgrade to IRIX 6.1.\n\n       Telnet (verified only under SunOS 4.1.2) hangs  if  TERM  is  not  set.\n       This  is  a  problem  under  cron,  at and in cgi scripts, which do not\n       define TERM.  Thus, you must set it explicitly - to what type  is  usu-\n       ally  irrelevant.   It  just has to be set to something!  The following\n       probably suffices for most cases.\n\n\t   set env(TERM) vt100\n\n\n       Tip (verified only under BSDI BSD/OS 3.1 i386) hangs if SHELL and  HOME\n       are  not  set.\tThis  is  a problem under cron, at and in cgi scripts,\n       which do not define these environment variables.  Thus,\tyou  must  set\n       them  explicitly  - to what type is usually irrelevant.\tIt just has to\n       be set to something!  The following probably suffices for most cases.\n\n\t   set env(SHELL) /bin/sh\n\t   set env(HOME) /usr/local/bin\n\n\n\n       Some implementations of ptys are designed so  that  the\tkernel\tthrows\n       away  any unread output after 10 to 15 seconds (actual number is imple-\n       mentation-dependent) after the process has closed the file  descriptor.\n       Thus Expect programs such as\n\n\t   spawn date\n\t   sleep 20\n\t   expect\n\n       will  fail.   To  avoid this, invoke non-interactive programs with exec\n       rather than spawn.  While such situations are conceivable, in  practice\n       I  have\tnever  encountered  a situation in which the final output of a\n       truly interactive program would be lost due to this behavior.\n\n       On the other hand, Cray UNICOS ptys throw away any unread output  imme-\n       diately\tafter  the  process  has  closed  the file descriptor.\tI have\n       reported this to Cray and they are working on a fix.\n\n       Sometimes a delay is required between a prompt and a response, such  as\n       when  a\ttty interface is changing UART settings or matching baud rates\n       by looking for start/stop bits.\tUsually, all this  is  require\tis  to\n       sleep  for  a second or two.  A more robust technique is to retry until\n       the hardware is ready to receive input.\t The  following  example  uses\n       both strategies:\n\n\t   send \"speed 9600\\r\";\n\t   sleep 1\n\t   expect {\n\t       timeout {send \"\\r\"; exp_continue}\n\t       $prompt\n\t   }\n\n\n       trap  -code  will  not  work  with any command that sits in Tcl's event\n       loop, such as sleep.  The problem is that in the event loop,  Tcl  dis-\n       cards  the  return codes from async event handlers.  A workaround is to\n       set a flag in the trap code.  Then check the flag immediately after the\n       command (i.e., sleep).\n\n       The  expect_background  command\tignores  -timeout arguments and has no\n       concept of timeouts in general.\n\n\nEXPECT HINTS\n       There are a couple of things about Expect that  may  be\tnon-intuitive.\n       This  section attempts to address some of these things with a couple of\n       suggestions.\n\n       A common expect problem is how to recognize shell prompts.  Since these\n       are  customized differently by differently people and different shells,\n       portably automating rlogin can be difficult without knowing the prompt.\n       A  reasonable  convention  is  to have users store a regular expression\n       describing their prompt (in particular, the end of it) in the  environ-\n       ment  variable EXPECT_PROMPT.  Code like the following can be used.  If\n       EXPECT_PROMPT doesn't exist, the code still has a good chance of  func-\n       tioning correctly.\n\n\t   set prompt \"(%|#|\\\\$) $\"\t     ;# default prompt\n\t   catch {set prompt $env(EXPECT_PROMPT)}\n\n\t   expect -re $prompt\n\n       I  encourage you to write expect patterns that include the end of what-\n       ever you expect to see.\tThis avoids the  possibility  of  answering  a\n       question  before  seeing  the entire thing.  In addition, while you may\n       well be able to answer questions before seeing them  entirely,  if  you\n       answer  early,  your answer may appear echoed back in the middle of the\n       question.  In other words, the resulting dialogue will be  correct  but\n       look scrambled.\n\n       Most  prompts  include  a space character at the end.  For example, the\n       prompt from ftp is 'f', 't', 'p',  '>'  and  <blank>.   To  match  this\n       prompt,\tyou must account for each of these characters.\tIt is a common\n       mistake not to include the blank.  Put the blank in explicitly.\n\n       If you use a pattern of the form X*, the * will match  all  the\toutput\n       received  from  the  end  of X to the last thing received.  This sounds\n       intuitive but can be somewhat confusing because the phrase \"last  thing\n       received\"  can  vary  depending\tupon the speed of the computer and the\n       processing of I/O both by the kernel and the device driver.\n\n       In particular, humans tend to  see  program  output  arriving  in  huge\n       chunks  (atomically)  when  in reality most programs produce output one\n       line at a time.\tAssuming this is the case, the * in the pattern of the\n       previous  paragraph  may  only  match  the end of the current line even\n       though there seems to be more, because at the time of  the  match  that\n       was all the output that had been received.\n\n       expect  has no way of knowing that further output is coming unless your\n       pattern specifically accounts for it.\n\n       Even depending on line-oriented buffering is unwise.  Not only do  pro-\n       grams  rarely  make  promises  about the type of buffering they do, but\n       system indigestion can break output lines up so\tthat  lines  break  at\n       seemingly random places.  Thus, if you can express the last few charac-\n       ters of a prompt when writing patterns, it is wise to do so.\n\n       If you are waiting for a pattern in the last output of  a  program  and\n       the  program  emits  something  else  instead,  you will not be able to\n       detect that with the timeout keyword.  The reason is that  expect  will\n       not timeout - instead it will get an eof indication.  Use that instead.\n       Even better, use both.  That way if that line is ever moved around, you\n       won't have to edit the line itself.\n\n       Newlines  are  usually converted to carriage return, linefeed sequences\n       when output by the terminal driver.  Thus, if you want a  pattern  that\n       explicitly  matches  the  two lines, from, say, printf(\"foo\\nbar\"), you\n       should use the pattern \"foo\\r\\nbar\".\n\n       A  similar  translation\toccurs\twhen  reading  from  the   user,   via\n       expect_user.   In  this\tcase, when you press return, it will be trans-\n       lated to a newline.  If Expect then passes that to a program which sets\n       its terminal to raw mode (like telnet), there is going to be a problem,\n       as the program expects a true return.  (Some programs are actually for-\n       giving  in  that they will automatically translate newlines to returns,\n       but most don't.)  Unfortunately, there is no way to  find  out  that  a\n       program put its terminal into raw mode.\n\n       Rather  than  manually replacing newlines with returns, the solution is\n       to use the command \"stty raw\", which will stop the translation.\t Note,\n       however,  that  this means that you will no longer get the cooked line-\n       editing features.\n\n       interact implicitly sets your terminal to raw mode so this problem will\n       not arise then.\n\n       It is often useful to store passwords (or other private information) in\n       Expect scripts.\tThis is not recommended since anything that is\tstored\n       on a computer is susceptible to being accessed by anyone.  Thus, inter-\n       actively prompting for passwords from a script is a smarter  idea  than\n       embedding them literally.  Nonetheless, sometimes such embedding is the\n       only possibility.\n\n       Unfortunately, the UNIX file system  has  no  direct  way  of  creating\n       scripts\twhich  are  executable\tbut unreadable.  Systems which support\n       setgid shell scripts may indirectly simulate this as follows:\n\n       Create the Expect script (that contains\tthe  secret  data)  as\tusual.\n       Make  its permissions be 750 (-rwxr-x---) and owned by a trusted group,\n       i.e., a group which is allowed to read it.  If necessary, create a  new\n       group for this purpose.\tNext, create a /bin/sh script with permissions\n       2751 (-rwxr-s--x) owned by the same group as before.\n\n       The result is a script which may be  executed  (and  read)  by  anyone.\n       When invoked, it runs the Expect script.\n\nSEE ALSO\n       Tcl(3), libexpect(3)\n       \"Exploring  Expect: A Tcl-Based Toolkit for Automating Interactive Pro-\n       grams\" by Don Libes, pp. 602, ISBN 1-56592-090-2,  O'Reilly  and  Asso-\n       ciates, 1995.\n       \"expect:  Curing  Those\tUncontrollable\tFits  of Interactivity\" by Don\n       Libes, Proceedings of the Summer 1990 USENIX Conference, Anaheim, Cali-\n       fornia, June 11-15, 1990.\n       \"Using  expect  to  Automate System Administration Tasks\" by Don Libes,\n       Proceedings of the 1990 USENIX Large Installation  Systems  Administra-\n       tion Conference, Colorado Springs, Colorado, October 17-19, 1990.\n       \"Tcl:  An  Embeddable Command Language\" by John Ousterhout, Proceedings\n       of the Winter 1990 USENIX Conference, Washington, D.C., January\t22-26,\n       1990.\n       \"expect:  Scripts  for  Controlling Interactive Programs\" by Don Libes,\n       Computing Systems, Vol. 4, No. 2, University of California Press  Jour-\n       nals, November 1991.\n       \"Regression  Testing  and Conformance Testing Interactive Programs\", by\n       Don Libes, Proceedings  of  the\tSummer\t1992  USENIX  Conference,  pp.\n       135-144, San Antonio, TX, June 12-15, 1992.\n       \"Kibitz\t-  Connecting  Multiple Interactive Programs Together\", by Don\n       Libes, Software - Practice & Experience, John Wiley & Sons,  West  Sus-\n       sex, England, Vol. 23, No. 5, May, 1993.\n       \"A  Debugger  for  Tcl  Applications\", by Don Libes, Proceedings of the\n       1993 Tcl/Tk Workshop, Berkeley, CA, June 10-11, 1993.\n\nAUTHOR\n       Don Libes, National Institute of Standards and Technology\n\nACKNOWLEDGMENTS\n       Thanks to John Ousterhout for Tcl, and Scott Paisley  for  inspiration.\n       Thanks to Rob Savoye for Expect's autoconfiguration code.\n\n       The  HISTORY  file documents much of the evolution of expect.  It makes\n       interesting reading and might give you further insight  to  this  soft-\n       ware.   Thanks  to the people mentioned in it who sent me bug fixes and\n       gave other assistance.\n\n       Design and implementation of Expect was paid for in part  by  the  U.S.\n       government  and\tis therefore in the public domain.  However the author\n       and NIST would like credit if this program and  documentation  or  por-\n       tions of them are used.\n\n\n\n\t\t\t       29 December 1994 \t\t     EXPECT(1)\n",
   "tldr_summary": "# expect\n\n> Script executor that interacts with other programs that require user input.\n> More information: <https://linux.die.net/man/1/expect>.\n\n- Execute an expect script from a file:\n\n`expect {{path/to/file}}`\n\n- Execute a specified expect script:\n\n`expect -c \"{{commands}}\"`\n\n- Enter an interactive REPL (use `exit` or Ctrl + D to exit):\n\n`expect -i`\n"
 },
 {
   "command": "dockerd",
   "doc_url": "https://docs.docker.com/engine/reference/commandline/dockerd/",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndockerd | Docker Documentation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToggle navigation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndockerd\n\nEstimated reading time: \n  \n  \n    55 minutes\n  \n\n\ndaemon\nUsage: dockerd COMMAND\n\nA self-sufficient runtime for containers.\n\nOptions:\n      --add-runtime runtime                   Register an additional OCI compatible runtime (default [])\n      --allow-nondistributable-artifacts list Allow push of nondistributable artifacts to registry\n      --api-cors-header string                Set CORS headers in the Engine API\n      --authorization-plugin list             Authorization plugins to load\n      --bip string                            Specify network bridge IP\n  -b, --bridge string                         Attach containers to a network bridge\n      --cgroup-parent string                  Set parent cgroup for all containers\n      --cluster-advertise string              Address or interface name to advertise\n      --cluster-store string                  URL of the distributed storage backend\n      --cluster-store-opt map                 Set cluster store options (default map[])\n      --config-file string                    Daemon configuration file (default \"/etc/docker/daemon.json\")\n      --containerd string                     containerd grpc address\n      --cpu-rt-period int                     Limit the CPU real-time period in microseconds\n      --cpu-rt-runtime int                    Limit the CPU real-time runtime in microseconds\n      --cri-containerd                        start containerd with cri\n      --data-root string                      Root directory of persistent Docker state (default \"/var/lib/docker\")\n  -D, --debug                                 Enable debug mode\n      --default-address-pool pool-options     Default address pools for node specific local networks\n      --default-gateway ip                    Container default gateway IPv4 address\n      --default-gateway-v6 ip                 Container default gateway IPv6 address\n      --default-ipc-mode string               Default mode for containers ipc (\"shareable\" | \"private\") (default \"private\")\n      --default-runtime string                Default OCI runtime for containers (default \"runc\")\n      --default-shm-size bytes                Default shm size for containers (default 64MiB)\n      --default-ulimit ulimit                 Default ulimits for containers (default [])\n      --dns list                              DNS server to use\n      --dns-opt list                          DNS options to use\n      --dns-search list                       DNS search domains to use\n      --exec-opt list                         Runtime execution options\n      --exec-root string                      Root directory for execution state files (default \"/var/run/docker\")\n      --experimental                          Enable experimental features\n      --fixed-cidr string                     IPv4 subnet for fixed IPs\n      --fixed-cidr-v6 string                  IPv6 subnet for fixed IPs\n  -G, --group string                          Group for the unix socket (default \"docker\")\n      --help                                  Print usage\n  -H, --host list                             Daemon socket(s) to connect to\n      --icc                                   Enable inter-container communication (default true)\n      --init                                  Run an init in the container to forward signals and reap processes\n      --init-path string                      Path to the docker-init binary\n      --insecure-registry list                Enable insecure registry communication\n      --ip ip                                 Default IP when binding container ports (default 0.0.0.0)\n      --ip-forward                            Enable net.ipv4.ip_forward (default true)\n      --ip-masq                               Enable IP masquerading (default true)\n      --iptables                              Enable addition of iptables rules (default true)\n      --ipv6                                  Enable IPv6 networking\n      --label list                            Set key=value labels to the daemon\n      --live-restore                          Enable live restore of docker when containers are still running\n      --log-driver string                     Default driver for container logs (default \"json-file\")\n  -l, --log-level string                      Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\")\n      --log-opt map                           Default log driver options for containers (default map[])\n      --max-concurrent-downloads int          Set the max concurrent downloads for each pull (default 3)\n      --max-concurrent-uploads int            Set the max concurrent uploads for each push (default 5)\n      --metrics-addr string                   Set default address and port to serve the metrics api on\n      --mtu int                               Set the containers network MTU\n      --network-control-plane-mtu int         Network Control plane MTU (default 1500)\n      --no-new-privileges                     Set no-new-privileges by default for new containers\n      --node-generic-resource list            Advertise user-defined resource\n      --oom-score-adjust int                  Set the oom_score_adj for the daemon (default -500)\n  -p, --pidfile string                        Path to use for daemon PID file (default \"/var/run/docker.pid\")\n      --raw-logs                              Full timestamps without ANSI coloring\n      --registry-mirror list                  Preferred Docker registry mirror\n      --rootless                              Enable rootless mode; typically used with RootlessKit (experimental)\n      --seccomp-profile string                Path to seccomp profile\n      --selinux-enabled                       Enable selinux support\n      --shutdown-timeout int                  Set the default shutdown timeout (default 15)\n  -s, --storage-driver string                 Storage driver to use\n      --storage-opt list                      Storage driver options\n      --swarm-default-advertise-addr string   Set default address or interface for swarm advertised address\n      --tls                                   Use TLS; implied by --tlsverify\n      --tlscacert string                      Trust certs signed only by this CA (default \"~/.docker/ca.pem\")\n      --tlscert string                        Path to TLS certificate file (default \"~/.docker/cert.pem\")\n      --tlskey string                         Path to TLS key file (default \"~/.docker/key.pem\")\n      --tlsverify                             Use TLS and verify the remote\n      --userland-proxy                        Use userland proxy for loopback traffic (default true)\n      --userland-proxy-path string            Path to the userland proxy binary\n      --userns-remap string                   User/Group setting for user namespaces\n  -v, --version                               Print version information and quit\n\nOptions with [] may be specified multiple times.\nDescription\ndockerd is the persistent process that manages containers. Docker\nuses different binaries for the daemon and client. To run the daemon you\ntype dockerd.\nTo run the daemon with debug output, use dockerd -D or add \"debug\": true to\nthe daemon.json file.\n\nEnabling experimental features\nEnable experimental features by starting dockerd with the --experimental\nflag or adding \"experimental\": true to the daemon.json file.\n\nEnvironment variables\nFor easy reference, the following list of environment variables are supported\nby the dockerd command line:\n\nDOCKER_DRIVER The graph driver to use.\nDOCKER_NOWARN_KERNEL_VERSION Prevent warnings that your Linux kernel is\nunsuitable for Docker.\nDOCKER_RAMDISK If set this will disable âpivot_rootâ.\nDOCKER_TMPDIR Location for temporary Docker files.\nMOBY_DISABLE_PIGZ Do not use unpigz to\ndecompress layers in parallel when pulling images, even if it is installed.\n\nExamples\nDaemon socket option\nThe Docker daemon can listen for Docker Engine API\nrequests via three different types of Socket: unix, tcp, and fd.\nBy default, a unix domain socket (or IPC socket) is created at\n/var/run/docker.sock, requiring either root permission, or docker group\nmembership.\nIf you need to access the Docker daemon remotely, you need to enable the tcp\nSocket. Beware that the default setup provides un-encrypted and\nun-authenticated direct access to the Docker daemon - and should be secured\neither using the built in HTTPS encrypted socket, or by\nputting a secure web proxy in front of it. You can listen on port 2375 on all\nnetwork interfaces with -H tcp://0.0.0.0:2375, or on a particular network\ninterface using its IP address: -H tcp://192.168.59.103:2375. It is\nconventional to use port 2375 for un-encrypted, and port 2376 for encrypted\ncommunication with the daemon.\n\nNote\nIf youâre using an HTTPS encrypted socket, keep in mind that only\nTLS1.0 and greater are supported. Protocols SSLv3 and under are not\nsupported anymore for security reasons.\n\nOn Systemd based systems, you can communicate with the daemon via\nSystemd socket activation,\nuse dockerd -H fd://. Using fd:// will work perfectly for most setups but\nyou can also specify individual sockets: dockerd -H fd://3. If the\nspecified socket activated files arenât found, then Docker will exit. You can\nfind examples of using Systemd socket activation with Docker and Systemd in the\nDocker source tree.\nYou can configure the Docker daemon to listen to multiple sockets at the same\ntime using multiple -H options:\n# listen using the default unix socket, and on 2 specific IP addresses on this host.\n\n$ sudo dockerd -H unix:///var/run/docker.sock -H tcp://192.168.59.106 -H tcp://10.10.10.2\n\nThe Docker client will honor the DOCKER_HOST environment variable to set the\n-H flag for the client. Use one of the following commands:\n$ docker -H tcp://0.0.0.0:2375 ps\n\n$ export DOCKER_HOST=\"tcp://0.0.0.0:2375\"\n\n$ docker ps\n\nSetting the DOCKER_TLS_VERIFY environment variable to any value other than\nthe empty string is equivalent to setting the --tlsverify flag. The following\nare equivalent:\n$ docker --tlsverify ps\n# or\n$ export DOCKER_TLS_VERIFY=1\n$ docker ps\n\nThe Docker client will honor the HTTP_PROXY, HTTPS_PROXY, and NO_PROXY\nenvironment variables (or the lowercase versions thereof). HTTPS_PROXY takes\nprecedence over HTTP_PROXY.\nStarting with Docker 18.09, the Docker client supports connecting to a remote\ndaemon via SSH:\n$ docker -H ssh://me@example.com:22 ps\n$ docker -H ssh://me@example.com ps\n$ docker -H ssh://example.com ps\n\nTo use SSH connection, you need to set up ssh so that it can reach the\nremote host with public key authentication. Password authentication is not\nsupported. If your key is protected with passphrase, you need to set up\nssh-agent.\nAlso, you need to have docker binary 18.09 or later on the daemon host.\nBind Docker to another host/port or a Unix socket\n\nWarning:\nChanging the default docker daemon binding to a\nTCP port or Unix docker user group will increase your security risks\nby allowing non-root users to gain root access on the host. Make sure\nyou control access to docker. If you are binding\nto a TCP port, anyone with access to that port has full Docker access;\nso it is not advisable on an open network.\n\nWith -H it is possible to make the Docker daemon to listen on a\nspecific IP and port. By default, it will listen on\nunix:///var/run/docker.sock to allow only local connections by the\nroot user. You could set it to 0.0.0.0:2375 or a specific host IP\nto give access to everybody, but that is not recommended because\nthen it is trivial for someone to gain root access to the host where the\ndaemon is running.\nSimilarly, the Docker client can use -H to connect to a custom port.\nThe Docker client will default to connecting to unix:///var/run/docker.sock\non Linux, and tcp://127.0.0.1:2376 on Windows.\n-H accepts host and port assignment in the following format:\ntcp://[host]:[port][path] or unix://path\n\nFor example:\n\ntcp:// -> TCP connection to 127.0.0.1 on either port 2376 when TLS encryption\nis on, or port 2375 when communication is in plain text.\ntcp://host:2375 -> TCP connection on\nhost:2375\ntcp://host:2375/path -> TCP connection on\nhost:2375 and prepend path to all requests\nunix://path/to/socket -> Unix socket located\nat path/to/socket\n\n-H, when empty, will default to the same value as\nwhen no -H was passed in.\n-H also accepts short form for TCP bindings: host: or host:port or :port\nRun Docker in daemon mode:\n$ sudo <path to>/dockerd -H 0.0.0.0:5555 &\n\nDownload an ubuntu image:\n$ docker -H :5555 pull ubuntu\n\nYou can use multiple -H, for example, if you want to listen on both\nTCP and a Unix socket\n# Run docker in daemon mode\n$ sudo <path to>/dockerd -H tcp://127.0.0.1:2375 -H unix:///var/run/docker.sock &\n# Download an ubuntu image, use default Unix socket\n$ docker pull ubuntu\n# OR use the TCP port\n$ docker -H tcp://127.0.0.1:2375 pull ubuntu\n\nDaemon storage-driver\nOn Linux, the Docker daemon has support for several different image layer storage\ndrivers: aufs, devicemapper, btrfs, zfs, overlay and overlay2.\nThe aufs driver is the oldest, but is based on a Linux kernel patch-set that\nis unlikely to be merged into the main kernel. These are also known to cause\nsome serious kernel crashes. However aufs allows containers to share\nexecutable and shared library memory, so is a useful choice when running\nthousands of containers with the same program or libraries.\nThe devicemapper driver uses thin provisioning and Copy on Write (CoW)\nsnapshots. For each devicemapper graph location â typically\n/var/lib/docker/devicemapper â a thin pool is created based on two block\ndevices, one for data and one for metadata. By default, these block devices\nare created automatically by using loopback mounts of automatically created\nsparse files. Refer to Devicemapper options below\nfor a way how to customize this setup.\n~jpetazzo/Resizing Docker containers with the Device Mapper plugin\narticle explains how to tune your existing setup without the use of options.\nThe btrfs driver is very fast for docker build - but like devicemapper\ndoes not share executable memory between devices. Use\ndockerd -s btrfs -g /mnt/btrfs_partition.\nThe zfs driver is probably not as fast as btrfs but has a longer track record\non stability. Thanks to Single Copy ARC shared blocks between clones will be\ncached only once. Use dockerd -s zfs. To select a different zfs filesystem\nset zfs.fsname option as described in ZFS options.\nThe overlay is a very fast union filesystem. It is now merged in the main\nLinux kernel as of 3.18.0. overlay\nalso supports page cache sharing, this means multiple containers accessing\nthe same file can share a single page cache entry (or entries), it makes\noverlay as efficient with memory as aufs driver. Call dockerd -s overlay\nto use it.\nThe overlay2 uses the same fast union filesystem but takes advantage of\nadditional features added in Linux\nkernel 4.0 to avoid excessive inode consumption. Call dockerd -s overlay2\nto use it.\n\nNote\nThe overlay storage driver can cause excessive inode consumption (especially\nas the number of images grows). We recommend using the overlay2 storage\ndriver instead.\n\n\nNote\nBoth overlay and overlay2 are currently unsupported on btrfs\nor any Copy on Write filesystem and should only be used over ext4 partitions.\n\nOn Windows, the Docker daemon supports a single image layer storage driver\ndepending on the image platform: windowsfilter for Windows images, and\nlcow for Linux containers on Windows.\nOptions per storage driver\nParticular storage-driver can be configured with options specified with\n--storage-opt flags. Options for devicemapper are prefixed with dm,\noptions for zfs start with zfs, options for btrfs start with btrfs\nand options for lcow start with lcow.\nDevicemapper options\nThis is an example of the configuration file for devicemapper on Linux:\n{\n  \"storage-driver\": \"devicemapper\",\n  \"storage-opts\": [\n    \"dm.thinpooldev=/dev/mapper/thin-pool\",\n    \"dm.use_deferred_deletion=true\",\n    \"dm.use_deferred_removal=true\"\n  ]\n}\n\ndm.thinpooldev\nSpecifies a custom block storage device to use for the thin pool.\nIf using a block device for device mapper storage, it is best to use lvm\nto create and manage the thin-pool volume. This volume is then handed to Docker\nto exclusively create snapshot volumes needed for images and containers.\nManaging the thin-pool outside of Engine makes for the most feature-rich\nmethod of having Docker utilize device mapper thin provisioning as the\nbacking storage for Docker containers. The highlights of the lvm-based\nthin-pool management feature include: automatic or interactive thin-pool\nresize support, dynamically changing thin-pool features, automatic thinp\nmetadata checking when lvm activates the thin-pool, etc.\nAs a fallback if no thin pool is provided, loopback files are\ncreated. Loopback is very slow, but can be used without any\npre-configuration of storage. It is strongly recommended that you do\nnot use loopback in production. Ensure your Engine daemon has a\n--storage-opt dm.thinpooldev argument provided.\nExample:\n$ sudo dockerd --storage-opt dm.thinpooldev=/dev/mapper/thin-pool\n\ndm.directlvm_device\nAs an alternative to providing a thin pool as above, Docker can setup a block\ndevice for you.\nExample:\n$ sudo dockerd --storage-opt dm.directlvm_device=/dev/xvdf\n\ndm.thinp_percent\nSets the percentage of passed in block device to use for storage.\nExample:\n$ sudo dockerd --storage-opt dm.thinp_percent=95\n\ndm.thinp_metapercent\nSets the percentage of the passed in block device to use for metadata storage.\nExample:\n$ sudo dockerd --storage-opt dm.thinp_metapercent=1\n\ndm.thinp_autoextend_threshold\nSets the value of the percentage of space used before lvm attempts to\nautoextend the available space [100 = disabled]\nExample:\n$ sudo dockerd --storage-opt dm.thinp_autoextend_threshold=80\n\ndm.thinp_autoextend_percent\nSets the value percentage value to increase the thin pool by when lvm\nattempts to autoextend the available space [100 = disabled]\nExample:\n$ sudo dockerd --storage-opt dm.thinp_autoextend_percent=20\n\ndm.basesize\nSpecifies the size to use when creating the base device, which limits the\nsize of images and containers. The default value is 10G. Note, thin devices\nare inherently âsparseâ, so a 10G device which is mostly empty doesnât use\n10 GB of space on the pool. However, the filesystem will use more space for\nthe empty case the larger the device is.\nThe base device size can be increased at daemon restart which will allow\nall future images and containers (based on those new images) to be of the\nnew base device size.\nExamples\n$ sudo dockerd --storage-opt dm.basesize=50G\n\nThis will increase the base device size to 50G. The Docker daemon will throw an\nerror if existing base device size is larger than 50G. A user can use\nthis option to expand the base device size however shrinking is not permitted.\nThis value affects the system-wide âbaseâ empty filesystem\nthat may already be initialized and inherited by pulled images. Typically,\na change to this value requires additional steps to take effect:\n$ sudo service docker stop\n\n$ sudo rm -rf /var/lib/docker\n\n$ sudo service docker start\n\ndm.loopdatasize\n\nNote\nThis option configures devicemapper loopback, which should not\nbe used in production.\n\nSpecifies the size to use when creating the loopback file for the\nâdataâ device which is used for the thin pool. The default size is\n100G. The file is sparse, so it will not initially take up this\nmuch space.\nExample\n$ sudo dockerd --storage-opt dm.loopdatasize=200G\n\ndm.loopmetadatasize\n\nNote\nThis option configures devicemapper loopback, which should not\nbe used in production.\n\nSpecifies the size to use when creating the loopback file for the\nâmetadataâ device which is used for the thin pool. The default size\nis 2G. The file is sparse, so it will not initially take up\nthis much space.\nExample\n$ sudo dockerd --storage-opt dm.loopmetadatasize=4G\n\ndm.fs\nSpecifies the filesystem type to use for the base device. The supported\noptions are âext4â and âxfsâ. The default is âxfsâ\nExample\n$ sudo dockerd --storage-opt dm.fs=ext4\n\ndm.mkfsarg\nSpecifies extra mkfs arguments to be used when creating the base device.\nExample\n$ sudo dockerd --storage-opt \"dm.mkfsarg=-O ^has_journal\"\n\ndm.mountopt\nSpecifies extra mount options used when mounting the thin devices.\nExample\n$ sudo dockerd --storage-opt dm.mountopt=nodiscard\n\ndm.datadev\n(Deprecated, use dm.thinpooldev)\nSpecifies a custom blockdevice to use for data for the thin pool.\nIf using a block device for device mapper storage, ideally both datadev and\nmetadatadev should be specified to completely avoid using the loopback\ndevice.\nExample\n$ sudo dockerd \\\n      --storage-opt dm.datadev=/dev/sdb1 \\\n      --storage-opt dm.metadatadev=/dev/sdc1\n\ndm.metadatadev\n(Deprecated, use dm.thinpooldev)\nSpecifies a custom blockdevice to use for metadata for the thin pool.\nFor best performance the metadata should be on a different spindle than the\ndata, or even better on an SSD.\nIf setting up a new metadata pool it is required to be valid. This can be\nachieved by zeroing the first 4k to indicate empty metadata, like this:\n$ dd if=/dev/zero of=$metadata_dev bs=4096 count=1\n\nExample\n$ sudo dockerd \\\n      --storage-opt dm.datadev=/dev/sdb1 \\\n      --storage-opt dm.metadatadev=/dev/sdc1\n\ndm.blocksize\nSpecifies a custom blocksize to use for the thin pool. The default\nblocksize is 64K.\nExample\n$ sudo dockerd --storage-opt dm.blocksize=512K\n\ndm.blkdiscard\nEnables or disables the use of blkdiscard when removing devicemapper\ndevices. This is enabled by default (only) if using loopback devices and is\nrequired to resparsify the loopback file on image/container removal.\nDisabling this on loopback can lead to much faster container removal\ntimes, but will make the space used in /var/lib/docker directory not be\nreturned to the system for other use when containers are removed.\nExamples\n$ sudo dockerd --storage-opt dm.blkdiscard=false\n\ndm.override_udev_sync_check\nOverrides the udev synchronization checks between devicemapper and udev.\nudev is the device manager for the Linux kernel.\nTo view the udev sync support of a Docker daemon that is using the\ndevicemapper driver, run:\n$ docker info\n[...]\nUdev Sync Supported: true\n[...]\n\nWhen udev sync support is true, then devicemapper and udev can\ncoordinate the activation and deactivation of devices for containers.\nWhen udev sync support is false, a race condition occurs between\nthedevicemapper and udev during create and cleanup. The race condition\nresults in errors and failures. (For information on these failures, see\ndocker#4036)\nTo allow the docker daemon to start, regardless of udev sync not being\nsupported, set dm.override_udev_sync_check to true:\n$ sudo dockerd --storage-opt dm.override_udev_sync_check=true\n\nWhen this value is true, the  devicemapper continues and simply warns\nyou the errors are happening.\n\nNote\nThe ideal is to pursue a docker daemon and environment that does\nsupport synchronizing with udev. For further discussion on this\ntopic, see docker#4036.\nOtherwise, set this flag for migrating existing Docker daemons to\na daemon with a supported environment.\n\ndm.use_deferred_removal\nEnables use of deferred device removal if libdm and the kernel driver\nsupport the mechanism.\nDeferred device removal means that if device is busy when devices are\nbeing removed/deactivated, then a deferred removal is scheduled on\ndevice. And devices automatically go away when last user of the device\nexits.\nFor example, when a container exits, its associated thin device is removed.\nIf that device has leaked into some other mount namespace and canât be\nremoved, the container exit still succeeds and this option causes the\nsystem to schedule the device for deferred removal. It does not wait in a\nloop trying to remove a busy device.\nExample\n$ sudo dockerd --storage-opt dm.use_deferred_removal=true\n\ndm.use_deferred_deletion\nEnables use of deferred device deletion for thin pool devices. By default,\nthin pool device deletion is synchronous. Before a container is deleted,\nthe Docker daemon removes any associated devices. If the storage driver\ncan not remove a device, the container deletion fails and daemon returns.\nError deleting container: Error response from daemon: Cannot destroy container\n\nTo avoid this failure, enable both deferred device deletion and deferred\ndevice removal on the daemon.\n$ sudo dockerd \\\n      --storage-opt dm.use_deferred_deletion=true \\\n      --storage-opt dm.use_deferred_removal=true\n\nWith these two options enabled, if a device is busy when the driver is\ndeleting a container, the driver marks the device as deleted. Later, when\nthe device isnât in use, the driver deletes it.\nIn general it should be safe to enable this option by default. It will help\nwhen unintentional leaking of mount point happens across multiple mount\nnamespaces.\ndm.min_free_space\nSpecifies the min free space percent in a thin pool require for new device\ncreation to succeed. This check applies to both free data space as well\nas free metadata space. Valid values are from 0% - 99%. Value 0% disables\nfree space checking logic. If user does not specify a value for this option,\nthe Engine uses a default value of 10%.\nWhenever a new a thin pool device is created (during docker pull or during\ncontainer creation), the Engine checks if the minimum free space is\navailable. If sufficient space is unavailable, then device creation fails\nand any relevant docker operation fails.\nTo recover from this error, you must create more free space in the thin pool\nto recover from the error. You can create free space by deleting some images\nand containers from the thin pool. You can also add more storage to the thin\npool.\nTo add more space to a LVM (logical volume management) thin pool, just add\nmore storage to the volume group container thin pool; this should automatically\nresolve any errors. If your configuration uses loop devices, then stop the\nEngine daemon, grow the size of loop files and restart the daemon to resolve\nthe issue.\nExample\n$ sudo dockerd --storage-opt dm.min_free_space=10%\n\ndm.xfs_nospace_max_retries\nSpecifies the maximum number of retries XFS should attempt to complete\nIO when ENOSPC (no space) error is returned by underlying storage device.\nBy default XFS retries infinitely for IO to finish and this can result\nin unkillable process. To change this behavior one can set\nxfs_nospace_max_retries to say 0 and XFS will not retry IO after getting\nENOSPC and will shutdown filesystem.\nExample\n$ sudo dockerd --storage-opt dm.xfs_nospace_max_retries=0\n\ndm.libdm_log_level\nSpecifies the maxmimum libdm log level that will be forwarded to the\ndockerd log (as specified by --log-level). This option is primarily\nintended for debugging problems involving libdm. Using values other than the\ndefaults may cause false-positive warnings to be logged.\nValues specified must fall within the range of valid libdm log levels. At the\ntime of writing, the following is the list of libdm log levels as well as\ntheir corresponding levels when output by dockerd.\n\n\n\nlibdm Level\nValue\n--log-level\n\n\n\n\n_LOG_FATAL\n2\nerror\n\n\n_LOG_ERR\n3\nerror\n\n\n_LOG_WARN\n4\nwarn\n\n\n_LOG_NOTICE\n5\ninfo\n\n\n_LOG_INFO\n6\ninfo\n\n\n_LOG_DEBUG\n7\ndebug\n\n\n\nExample\n$ sudo dockerd \\\n      --log-level debug \\\n      --storage-opt dm.libdm_log_level=7\n\nZFS options\nzfs.fsname\nSet zfs filesystem under which docker will create its own datasets.\nBy default docker will pick up the zfs filesystem where docker graph\n(/var/lib/docker) is located.\nExample\n$ sudo dockerd -s zfs --storage-opt zfs.fsname=zroot/docker\n\nBtrfs options\nbtrfs.min_space\nSpecifies the minimum size to use when creating the subvolume which is used\nfor containers. If user uses disk quota for btrfs when creating or running\na container with --storage-opt size option, docker should ensure the\nsize cannot be smaller than btrfs.min_space.\nExample\n$ sudo dockerd -s btrfs --storage-opt btrfs.min_space=10G\n\nOverlay2 options\noverlay2.override_kernel_check\nOverrides the Linux kernel version check allowing overlay2. Support for\nspecifying multiple lower directories needed by overlay2 was added to the\nLinux kernel in 4.0.0. However, some older kernel versions may be patched\nto add multiple lower directory support for OverlayFS. This option should\nonly be used after verifying this support exists in the kernel. Applying\nthis option on a kernel without this support will cause failures on mount.\noverlay2.size\nSets the default max size of the container. It is supported only when the\nbacking fs is xfs and mounted with pquota mount option. Under these\nconditions the user can pass any size less then the backing fs size.\nExample\n$ sudo dockerd -s overlay2 --storage-opt overlay2.size=1G\n\nWindowsfilter options\nsize\nSpecifies the size to use when creating the sandbox which is used for containers.\nDefaults to 20G.\nExample\nC:\\> dockerd --storage-opt size=40G\n\nLCOW (Linux Containers on Windows) options\nlcow.globalmode\nSpecifies whether the daemon instantiates utility VM instances as required\n(recommended and default if omitted), or uses single global utility VM (better\nperformance, but has security implications and not recommended for production\ndeployments).\nExample\nC:\\> dockerd --storage-opt lcow.globalmode=false\n\nlcow.kirdpath\nSpecifies the folder path to the location of a pair of kernel and initrd files\nused for booting a utility VM. Defaults to %ProgramFiles%\\Linux Containers.\nExample\nC:\\> dockerd --storage-opt lcow.kirdpath=c:\\path\\to\\files\n\nlcow.kernel\nSpecifies the filename of a kernel file located in the lcow.kirdpath path.\nDefaults to bootx64.efi.\nExample\nC:\\> dockerd --storage-opt lcow.kernel=kernel.efi\n\nlcow.initrd\nSpecifies the filename of an initrd file located in the lcow.kirdpath path.\nDefaults to initrd.img.\nExample\nC:\\> dockerd --storage-opt lcow.initrd=myinitrd.img\n\nlcow.bootparameters\nSpecifies additional boot parameters for booting utility VMs when in kernel/\ninitrd mode. Ignored if the utility VM is booting from VHD. These settings\nare kernel specific.\nExample\nC:\\> dockerd --storage-opt \"lcow.bootparameters='option=value'\"\n\nlcow.vhdx\nSpecifies a custom VHDX to boot a utility VM, as an alternate to kernel\nand initrd booting. Defaults to uvm.vhdx under lcow.kirdpath.\nExample\nC:\\> dockerd --storage-opt lcow.vhdx=custom.vhdx\n\nlcow.timeout\nSpecifies the timeout for utility VM operations in seconds. Defaults\nto 300.\nExample\nC:\\> dockerd --storage-opt lcow.timeout=240\n\nlcow.sandboxsize\nSpecifies the size in GB to use when creating the sandbox which is used for\ncontainers. Defaults to 20. Cannot be less than 20.\nExample\nC:\\> dockerd --storage-opt lcow.sandboxsize=40\n\nDocker runtime execution options\nThe Docker daemon relies on a\nOCI compliant runtime\n(invoked via the containerd daemon) as its interface to the Linux\nkernel namespaces, cgroups, and SELinux.\nBy default, the Docker daemon automatically starts containerd. If you want to\ncontrol containerd startup, manually start containerd and pass the path to\nthe containerd socket using the --containerd flag. For example:\n$ sudo dockerd --containerd /var/run/dev/docker-containerd.sock\n\nRuntimes can be registered with the daemon either via the\nconfiguration file or using the --add-runtime command line argument.\nThe following is an example adding 2 runtimes via the configuration:\n{\n\t\"default-runtime\": \"runc\",\n\t\"runtimes\": {\n\t\t\"runc\": {\n\t\t\t\"path\": \"runc\"\n\t\t},\n\t\t\"custom\": {\n\t\t\t\"path\": \"/usr/local/bin/my-runc-replacement\",\n\t\t\t\"runtimeArgs\": [\n\t\t\t\t\"--debug\"\n\t\t\t]\n\t\t}\n\t}\n}\n\nThis is the same example via the command line:\n$ sudo dockerd --add-runtime runc=runc --add-runtime custom=/usr/local/bin/my-runc-replacement\n\n\nNote\nDefining runtime arguments via the command line is not supported.\n\nOptions for the runtime\nYou can configure the runtime using options specified\nwith the --exec-opt flag. All the flagâs options have the native prefix. A\nsingle native.cgroupdriver option is available.\nThe native.cgroupdriver option specifies the management of the containerâs\ncgroups. You can only specify cgroupfs or systemd. If you specify\nsystemd and it is not available, the system errors out. If you omit the\nnative.cgroupdriver option, cgroupfs is used.\nThis example sets the cgroupdriver to systemd:\n$ sudo dockerd --exec-opt native.cgroupdriver=systemd\n\nSetting this option applies to all containers the daemon launches.\nAlso Windows Container makes use of --exec-opt for special purpose. Docker user\ncan specify default container isolation technology with this, for example:\n> dockerd --exec-opt isolation=hyperv\n\nWill make hyperv the default isolation technology on Windows. If no isolation\nvalue is specified on daemon start, on Windows client, the default is\nhyperv, and on Windows server, the default is process.\nDaemon DNS options\nTo set the DNS server for all Docker containers, use:\n$ sudo dockerd --dns 8.8.8.8\n\nTo set the DNS search domain for all Docker containers, use:\n$ sudo dockerd --dns-search example.com\n\nAllow push of nondistributable artifacts\nSome images (e.g., Windows base images) contain artifacts whose distribution is\nrestricted by license. When these images are pushed to a registry, restricted\nartifacts are not included.\nTo override this behavior for specific registries, use the\n--allow-nondistributable-artifacts option in one of the following forms:\n\n--allow-nondistributable-artifacts myregistry:5000 tells the Docker daemon\nto push nondistributable artifacts to myregistry:5000.\n--allow-nondistributable-artifacts 10.1.0.0/16 tells the Docker daemon to\npush nondistributable artifacts to all registries whose resolved IP address\nis within the subnet described by the CIDR syntax.\n\nThis option can be used multiple times.\nThis option is useful when pushing images containing nondistributable artifacts\nto a registry on an air-gapped network so hosts on that network can pull the\nimages without connecting to another server.\n\nWarning: Nondistributable artifacts typically have restrictions on how\nand where they can be distributed and shared. Only use this feature to push\nartifacts to private registries and ensure that you are in compliance with\nany terms that cover redistributing nondistributable artifacts.\n\nInsecure registries\nDocker considers a private registry either secure or insecure. In the rest of\nthis section, registry is used for private registry, and myregistry:5000\nis a placeholder example for a private registry.\nA secure registry uses TLS and a copy of its CA certificate is placed on the\nDocker host at /etc/docker/certs.d/myregistry:5000/ca.crt. An insecure\nregistry is either not using TLS (i.e., listening on plain text HTTP), or is\nusing TLS with a CA certificate not known by the Docker daemon. The latter can\nhappen when the certificate was not found under\n/etc/docker/certs.d/myregistry:5000/, or if the certificate verification\nfailed (i.e., wrong CA).\nBy default, Docker assumes all, but local (see local registries below),\nregistries are secure. Communicating with an insecure registry is not possible\nif Docker assumes that registry is secure. In order to communicate with an\ninsecure registry, the Docker daemon requires --insecure-registry in one of\nthe following two forms:\n\n--insecure-registry myregistry:5000 tells the Docker daemon that\nmyregistry:5000 should be considered insecure.\n--insecure-registry 10.1.0.0/16 tells the Docker daemon that all registries\nwhose domain resolve to an IP address is part of the subnet described by the\nCIDR syntax, should be considered insecure.\n\nThe flag can be used multiple times to allow multiple registries to be marked\nas insecure.\nIf an insecure registry is not marked as insecure, docker pull,\ndocker push, and docker search will result in an error message prompting\nthe user to either secure or pass the --insecure-registry flag to the Docker\ndaemon as described above.\nLocal registries, whose IP address falls in the 127.0.0.0/8 range, are\nautomatically marked as insecure as of Docker 1.3.2. It is not recommended to\nrely on this, as it may change in the future.\nEnabling --insecure-registry, i.e., allowing un-encrypted and/or untrusted\ncommunication, can be useful when running a local registry.  However,\nbecause its use creates security vulnerabilities it should ONLY be enabled for\ntesting purposes.  For increased security, users should add their CA to their\nsystemâs list of trusted CAs instead of enabling --insecure-registry.\nLegacy Registries\nStarting with Docker 17.12, operations against registries supporting only the\nlegacy v1 protocol are no longer supported. Specifically, the daemon will not\nattempt push, pull and login to v1 registries. The exception to this is\nsearch which can still be performed on v1 registries.\nThe disable-legacy-registry configuration option has been removed and, when\nused, will produce an error on daemon startup.\nRunning a Docker daemon behind an HTTPS_PROXY\nWhen running inside a LAN that uses an HTTPS proxy, the Docker Hub\ncertificates will be replaced by the proxyâs certificates. These certificates\nneed to be added to your Docker hostâs configuration:\n\nInstall the ca-certificates package for your distribution\nAsk your network admin for the proxyâs CA certificate and append them to\n/etc/pki/tls/certs/ca-bundle.crt\nThen start your Docker daemon with HTTPS_PROXY=http://username:password@proxy:port/ dockerd.\nThe username: and password@ are optional - and are only needed if your\nproxy is set up to require authentication.\n\nThis will only add the proxy and authentication to the Docker daemonâs requests -\nyour docker builds and running containers will need extra configuration to\nuse the proxy\nDefault ulimit settings\n--default-ulimit allows you to set the default ulimit options to use for\nall containers. It takes the same options as --ulimit for docker run. If\nthese defaults are not set, ulimit settings will be inherited, if not set on\ndocker run, from the Docker daemon. Any --ulimit options passed to\ndocker run will overwrite these defaults.\nBe careful setting nproc with the ulimit flag as nproc is designed by Linux to\nset the maximum number of processes available to a user, not to a container. For details\nplease check the run reference.\nNode discovery\nThe --cluster-advertise option specifies the host:port or interface:port\ncombination that this particular daemon instance should use when advertising\nitself to the cluster. The daemon is reached by remote hosts through this value.\nIf you  specify an interface, make sure it includes the IP address of the actual\nDocker host. For Engine installation created through docker-machine, the\ninterface is typically eth1.\nThe daemon uses libkv to advertise\nthe node within the cluster. Some key-value backends support mutual\nTLS. To configure the client TLS settings used by the daemon can be configured\nusing the --cluster-store-opt flag, specifying the paths to PEM encoded\nfiles. For example:\n$ sudo dockerd \\\n    --cluster-advertise 192.168.1.2:2376 \\\n    --cluster-store etcd://192.168.1.2:2379 \\\n    --cluster-store-opt kv.cacertfile=/path/to/ca.pem \\\n    --cluster-store-opt kv.certfile=/path/to/cert.pem \\\n    --cluster-store-opt kv.keyfile=/path/to/key.pem\n\nThe currently supported cluster store options are:\n\n\n\nOption\nDescription\n\n\n\n\ndiscovery.heartbeat\nSpecifies the heartbeat timer in seconds which is used by the daemon as a keepalive mechanism to make sure discovery module treats the node as alive in the cluster. If not configured, the default value is 20 seconds.\n\n\ndiscovery.ttl\nSpecifies the TTL (time-to-live) in seconds which is used by the discovery module to timeout a node if a valid heartbeat is not received within the configured ttl value. If not configured, the default value is 60 seconds.\n\n\nkv.cacertfile\nSpecifies the path to a local file with PEM encoded CA certificates to trust.\n\n\nkv.certfile\nSpecifies the path to a local file with a PEM encoded certificate. This certificate is used as the client cert for communication with the Key/Value store.\n\n\nkv.keyfile\nSpecifies the path to a local file with a PEM encoded private key. This private key is used as the client key for communication with the Key/Value store.\n\n\nkv.path\nSpecifies the path in the Key/Value store. If not configured, the default value is âdocker/nodesâ.\n\n\n\nAccess authorization\nDockerâs access authorization can be extended by authorization plugins that your\norganization can purchase or build themselves. You can install one or more\nauthorization plugins when you start the Docker daemon using the\n--authorization-plugin=PLUGIN_ID option.\n$ sudo dockerd --authorization-plugin=plugin1 --authorization-plugin=plugin2,...\n\nThe PLUGIN_ID value is either the pluginâs name or a path to its specification\nfile. The pluginâs implementation determines whether you can specify a name or\npath. Consult with your Docker administrator to get information about the\nplugins available to you.\nOnce a plugin is installed, requests made to the daemon through the\ncommand line or Dockerâs Engine API are allowed or denied by the plugin.\nIf you have multiple plugins installed, each plugin, in order, must\nallow the request for it to complete.\nFor information about how to create an authorization plugin, see authorization\nplugin section in the Docker extend section of this documentation.\nDaemon user namespace options\nThe Linux kernel\nuser namespace support\nprovides additional security by enabling a process, and therefore a container,\nto have a unique range of user and group IDs which are outside the traditional\nuser and group range utilized by the host system. Potentially the most important\nsecurity improvement is that, by default, container processes running as the\nroot user will have expected administrative privilege (with some restrictions)\ninside the container but will effectively be mapped to an unprivileged uid on\nthe host.\nFor details about how to use this feature, as well as limitations, see\nIsolate containers with a user namespace.\nMiscellaneous options\nIP masquerading uses address translation to allow containers without a public\nIP to talk to other machines on the Internet. This may interfere with some\nnetwork topologies and can be disabled with --ip-masq=false.\nDocker supports softlinks for the Docker data directory (/var/lib/docker) and\nfor /var/lib/docker/tmp. The DOCKER_TMPDIR and the data directory can be\nset like this:\nDOCKER_TMPDIR=/mnt/disk2/tmp /usr/local/bin/dockerd -D -g /var/lib/docker -H unix:// > /var/lib/docker-machine/docker.log 2>&1\n# or\nexport DOCKER_TMPDIR=/mnt/disk2/tmp\n/usr/local/bin/dockerd -D -g /var/lib/docker -H unix:// > /var/lib/docker-machine/docker.log 2>&1\n\nDefault cgroup parent\nThe --cgroup-parent option allows you to set the default cgroup parent\nto use for containers. If this option is not set, it defaults to /docker for\nfs cgroup driver and system.slice for systemd cgroup driver.\nIf the cgroup has a leading forward slash (/), the cgroup is created\nunder the root cgroup, otherwise the cgroup is created under the daemon\ncgroup.\nAssuming the daemon is running in cgroup daemoncgroup,\n--cgroup-parent=/foobar creates a cgroup in\n/sys/fs/cgroup/memory/foobar, whereas using --cgroup-parent=foobar\ncreates the cgroup in /sys/fs/cgroup/memory/daemoncgroup/foobar\nThe systemd cgroup driver has different rules for --cgroup-parent. Systemd\nrepresents hierarchy by slice and the name of the slice encodes the location in\nthe tree. So --cgroup-parent for systemd cgroups should be a slice name. A\nname can consist of a dash-separated series of names, which describes the path\nto the slice from the root slice. For example, --cgroup-parent=user-a-b.slice\nmeans the memory cgroup for the container is created in\n/sys/fs/cgroup/memory/user.slice/user-a.slice/user-a-b.slice/docker-<id>.scope.\nThis setting can also be set per container, using the --cgroup-parent\noption on docker create and docker run, and takes precedence over\nthe --cgroup-parent option on the daemon.\nDaemon metrics\nThe --metrics-addr option takes a tcp address to serve the metrics API.\nThis feature is still experimental, therefore, the daemon must be running in experimental\nmode for this feature to work.\nTo serve the metrics API on localhost:9323 you would specify --metrics-addr 127.0.0.1:9323,\nallowing you to make requests on the API at 127.0.0.1:9323/metrics to receive metrics in the\nprometheus format.\nPort 9323 is the default port associated with Docker\nmetrics\nto avoid collisions with other prometheus exporters and services.\nIf you are running a prometheus server you can add this address to your scrape configs\nto have prometheus collect metrics on Docker.  For more information\non prometheus refer to the prometheus website.\nscrape_configs:\n  - job_name: 'docker'\n    static_configs:\n      - targets: ['127.0.0.1:9323']\n\nPlease note that this feature is still marked as experimental as metrics and metric\nnames could change while this feature is still in experimental.  Please provide\nfeedback on what you would like to see collected in the API.\nNode Generic Resources\nThe --node-generic-resources option takes a list of key-value\npair (key=value) that allows you to advertise user defined resources\nin a swarm cluster.\nThe current expected use case is to advertise NVIDIA GPUs so that services\nrequesting NVIDIA-GPU=[0-16] can land on a node that has enough GPUs for\nthe task to run.\nExample of usage:\n{\n  \"node-generic-resources\": [\"NVIDIA-GPU=UUID1\", \"NVIDIA-GPU=UUID2\"]\n}\n\nDaemon configuration file\nThe --config-file option allows you to set any configuration option\nfor the daemon in a JSON format. This file uses the same flag names as keys,\nexcept for flags that allow several entries, where it uses the plural\nof the flag name, e.g., labels for the label flag.\nThe options set in the configuration file must not conflict with options set\nvia flags. The docker daemon fails to start if an option is duplicated between\nthe file and the flags, regardless their value. We do this to avoid\nsilently ignore changes introduced in configuration reloads.\nFor example, the daemon fails to start if you set daemon labels\nin the configuration file and also set daemon labels via the --label flag.\nOptions that are not present in the file are ignored when the daemon starts.\nOn Linux\nThe default location of the configuration file on Linux is\n/etc/docker/daemon.json. The --config-file flag can be used to specify a\n non-default location.\nThis is a full example of the allowed configuration options on Linux:\n{\n  \"authorization-plugins\": [],\n  \"data-root\": \"\",\n  \"dns\": [],\n  \"dns-opts\": [],\n  \"dns-search\": [],\n  \"exec-opts\": [],\n  \"exec-root\": \"\",\n  \"experimental\": false,\n  \"features\": {},\n  \"storage-driver\": \"\",\n  \"storage-opts\": [],\n  \"labels\": [],\n  \"live-restore\": true,\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\":\"5\",\n    \"labels\": \"somelabel\",\n    \"env\": \"os,customer\"\n  },\n  \"mtu\": 0,\n  \"pidfile\": \"\",\n  \"cluster-store\": \"\",\n  \"cluster-store-opts\": {},\n  \"cluster-advertise\": \"\",\n  \"max-concurrent-downloads\": 3,\n  \"max-concurrent-uploads\": 5,\n  \"default-shm-size\": \"64M\",\n  \"shutdown-timeout\": 15,\n  \"debug\": true,\n  \"hosts\": [],\n  \"log-level\": \"\",\n  \"tls\": true,\n  \"tlsverify\": true,\n  \"tlscacert\": \"\",\n  \"tlscert\": \"\",\n  \"tlskey\": \"\",\n  \"swarm-default-advertise-addr\": \"\",\n  \"api-cors-header\": \"\",\n  \"selinux-enabled\": false,\n  \"userns-remap\": \"\",\n  \"group\": \"\",\n  \"cgroup-parent\": \"\",\n  \"default-ulimits\": {\n    \"nofile\": {\n      \"Name\": \"nofile\",\n      \"Hard\": 64000,\n      \"Soft\": 64000\n    }\n  },\n  \"init\": false,\n  \"init-path\": \"/usr/libexec/docker-init\",\n  \"ipv6\": false,\n  \"iptables\": false,\n  \"ip-forward\": false,\n  \"ip-masq\": false,\n  \"userland-proxy\": false,\n  \"userland-proxy-path\": \"/usr/libexec/docker-proxy\",\n  \"ip\": \"0.0.0.0\",\n  \"bridge\": \"\",\n  \"bip\": \"\",\n  \"fixed-cidr\": \"\",\n  \"fixed-cidr-v6\": \"\",\n  \"default-gateway\": \"\",\n  \"default-gateway-v6\": \"\",\n  \"icc\": false,\n  \"raw-logs\": false,\n  \"allow-nondistributable-artifacts\": [],\n  \"registry-mirrors\": [],\n  \"seccomp-profile\": \"\",\n  \"insecure-registries\": [],\n  \"no-new-privileges\": false,\n  \"default-runtime\": \"runc\",\n  \"oom-score-adjust\": -500,\n  \"node-generic-resources\": [\"NVIDIA-GPU=UUID1\", \"NVIDIA-GPU=UUID2\"],\n  \"runtimes\": {\n    \"cc-runtime\": {\n      \"path\": \"/usr/bin/cc-runtime\"\n    },\n    \"custom\": {\n      \"path\": \"/usr/local/bin/my-runc-replacement\",\n      \"runtimeArgs\": [\n        \"--debug\"\n      ]\n    }\n  },\n  \"default-address-pools\":[\n    {\"base\":\"172.80.0.0/16\",\"size\":24},\n    {\"base\":\"172.90.0.0/16\",\"size\":24}\n  ]\n}\n\n\nNote:\nYou cannot set options in daemon.json that have already been set on\ndaemon startup as a flag.\nOn systems that use systemd to start the Docker daemon, -H is already set, so\nyou cannot use the hosts key in daemon.json to add listening addresses.\nSee https://docs.docker.com/engine/admin/systemd/#custom-docker-daemon-options for how\nto accomplish this task with a systemd drop-in file.\n\nOn Windows\nThe default location of the configuration file on Windows is\n %programdata%\\docker\\config\\daemon.json. The --config-file flag can be\n used to specify a non-default location.\nThis is a full example of the allowed configuration options on Windows:\n{\n  \"authorization-plugins\": [],\n  \"data-root\": \"\",\n  \"dns\": [],\n  \"dns-opts\": [],\n  \"dns-search\": [],\n  \"exec-opts\": [],\n  \"experimental\": false,\n  \"features\":{},\n  \"storage-driver\": \"\",\n  \"storage-opts\": [],\n  \"labels\": [],\n  \"log-driver\": \"\",\n  \"mtu\": 0,\n  \"pidfile\": \"\",\n  \"cluster-store\": \"\",\n  \"cluster-advertise\": \"\",\n  \"max-concurrent-downloads\": 3,\n  \"max-concurrent-uploads\": 5,\n  \"shutdown-timeout\": 15,\n  \"debug\": true,\n  \"hosts\": [],\n  \"log-level\": \"\",\n  \"tlsverify\": true,\n  \"tlscacert\": \"\",\n  \"tlscert\": \"\",\n  \"tlskey\": \"\",\n  \"swarm-default-advertise-addr\": \"\",\n  \"group\": \"\",\n  \"default-ulimits\": {},\n  \"bridge\": \"\",\n  \"fixed-cidr\": \"\",\n  \"raw-logs\": false,\n  \"allow-nondistributable-artifacts\": [],\n  \"registry-mirrors\": [],\n  \"insecure-registries\": []\n}\n\nFeature options\nThe optional field features in daemon.json allows users to enable or disable specific\ndaemon features. For example, {\"features\":{\"buildkit\": true}} enables buildkit as the\ndefault docker image builder.\nThe list of currently supported feature options:\n\nbuildkit: It enables buildkit as default builder when set to true or disables it by\nfalse. Note that if this option is not explicitly set in the daemon config file, then it\nis up to the cli to determine which builder to invoke.\n\nConfiguration reload behavior\nSome options can be reconfigured when the daemon is running without requiring\nto restart the process. We use the SIGHUP signal in Linux to reload, and a global event\nin Windows with the key Global\\docker-daemon-config-$PID. The options can\nbe modified in the configuration file but still will check for conflicts with\nthe provided flags. The daemon fails to reconfigure itself\nif there are conflicts, but it wonât stop execution.\nThe list of currently supported options that can be reconfigured is this:\n\ndebug: it changes the daemon to debug mode when set to true.\ncluster-store: it reloads the discovery store with the new address.\ncluster-store-opts: it uses the new options to reload the discovery store.\ncluster-advertise: it modifies the address advertised after reloading.\nlabels: it replaces the daemon labels with a new set of labels.\nlive-restore: Enables keeping containers alive during daemon downtime.\nmax-concurrent-downloads: it updates the max concurrent downloads for each pull.\nmax-concurrent-uploads: it updates the max concurrent uploads for each push.\ndefault-runtime: it updates the runtime to be used if not is\nspecified at container creation. It defaults to âdefaultâ which is\nthe runtime shipped with the official docker packages.\nruntimes: it updates the list of available OCI runtimes that can\nbe used to run containers.\nauthorization-plugin: it specifies the authorization plugins to use.\nallow-nondistributable-artifacts: Replaces the set of registries to which the daemon will push nondistributable artifacts with a new set of registries.\ninsecure-registries: it replaces the daemon insecure registries with a new set of insecure registries. If some existing insecure registries in daemonâs configuration are not in newly reloaded insecure resgitries, these existing ones will be removed from daemonâs config.\nregistry-mirrors: it replaces the daemon registry mirrors with a new set of registry mirrors. If some existing registry mirrors in daemonâs configuration are not in newly reloaded registry mirrors, these existing ones will be removed from daemonâs config.\nshutdown-timeout: it replaces the daemonâs existing configuration timeout with a new timeout for shutting down all containers.\nfeatures: it explicitly enables or disables specific features.\n\nUpdating and reloading the cluster configurations such as --cluster-store,\n--cluster-advertise and --cluster-store-opts will take effect only if\nthese configurations were not previously configured. If --cluster-store\nhas been provided in flags and cluster-advertise not, cluster-advertise\ncan be added in the configuration file without accompanied by --cluster-store.\nConfiguration reload will log a warning message if it detects a change in\npreviously configured cluster configurations.\nRun multiple daemons\n\nNote: Running multiple daemons on a single host is considered as âexperimentalâ. The user should be aware of\nunsolved problems. This solution may not work properly in some cases. Solutions are currently under development\nand will be delivered in the near future.\n\nThis section describes how to run multiple Docker daemons on a single host. To\nrun multiple daemons, you must configure each daemon so that it does not\nconflict with other daemons on the same host. You can set these options either\nby providing them as flags, or by using a daemon configuration file.\nThe following daemon options must be configured for each daemon:\n-b, --bridge=                          Attach containers to a network bridge\n--exec-root=/var/run/docker            Root of the Docker execdriver\n--data-root=/var/lib/docker            Root of persisted Docker data\n-p, --pidfile=/var/run/docker.pid      Path to use for daemon PID file\n-H, --host=[]                          Daemon socket(s) to connect to\n--iptables=true                        Enable addition of iptables rules\n--config-file=/etc/docker/daemon.json  Daemon configuration file\n--tlscacert=\"~/.docker/ca.pem\"         Trust certs signed only by this CA\n--tlscert=\"~/.docker/cert.pem\"         Path to TLS certificate file\n--tlskey=\"~/.docker/key.pem\"           Path to TLS key file\n\nWhen your daemons use different values for these flags, you can run them on the same host without any problems.\nIt is very important to properly understand the meaning of those options and to use them correctly.\n\nThe -b, --bridge= flag is set to docker0 as default bridge network. It is created automatically when you install Docker.\nIf you are not using the default, you must create and configure the bridge manually or just set it to ânoneâ: --bridge=none\n--exec-root is the path where the container state is stored. The default value is /var/run/docker. Specify the path for\nyour running daemon here.\n--data-root is the path where persisted data such as images, volumes, and\ncluster state are stored. The default value is /var/lib/docker. To avoid any\nconflict with other daemons, set this parameter separately for each daemon.\n-p, --pidfile=/var/run/docker.pid is the path where the process ID of the daemon is stored. Specify the path for your\npid file here.\n--host=[] specifies where the Docker daemon will listen for client connections. If unspecified, it defaults to /var/run/docker.sock.\n--iptables=false prevents the Docker daemon from adding iptables rules. If\nmultiple daemons manage iptables rules, they may overwrite rules set by another\ndaemon. Be aware that disabling this option requires you to manually add\niptables rules to expose container ports. If you prevent Docker from adding\niptables rules, Docker will also not add IP masquerading rules, even if you set\n--ip-masq to true. Without IP masquerading rules, Docker containers will not be\nable to connect to external hosts or the internet when using network other than\ndefault bridge.\n--config-file=/etc/docker/daemon.json is the path where configuration file is stored. You can use it instead of\ndaemon flags. Specify the path for each daemon.\n--tls* Docker daemon supports --tlsverify mode that enforces encrypted and authenticated remote connections.\nThe --tls* options enable use of specific certificates for individual daemons.\n\nExample script for a separate âbootstrapâ instance of the Docker daemon without network:\n$ sudo dockerd \\\n        -H unix:///var/run/docker-bootstrap.sock \\\n        -p /var/run/docker-bootstrap.pid \\\n        --iptables=false \\\n        --ip-masq=false \\\n        --bridge=none \\\n        --data-root=/var/lib/docker-bootstrap \\\n        --exec-root=/var/run/docker-bootstrap\n\n\ncontainer, daemon, runtime\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Edit this\n                                                page\n Request\n                                                docs changes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn this page:\n\nDescription\n\nEnvironment variables\n\n\nExamples\n\nDaemon socket option\nDaemon storage-driver\nOptions per storage driver\nDocker runtime execution options\nDaemon DNS options\nAllow push of nondistributable artifacts\nInsecure registries\nRunning a Docker daemon behind an HTTPS_PROXY\nDefault ulimit settings\nNode discovery\nAccess authorization\nDaemon user namespace options\nMiscellaneous options\nDaemon configuration file\nRun multiple daemons\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Docker?\nWhat is a Container?\n\n\n\n\nProducts\nDocker Desktop\nDocker Hub\nFeatures\nContainer Runtime\nDeveloper Tools\nKubernetes\n\n\n\n\nDevelopers\nUse Cases\nPlay with Docker\nCommunity\nOpen Source\nDocker Captains\n\n\n\n\nCompany\nAbout Us\nBlog\nCustomers\nPartners\nNewsroom\nCareers\nContact Us\n\n\n\n\n\n\nStatus\nSecurity\nLegal\nContact\n\n\n\n\n\n\n\n                    Copyright © 2013-2020 Docker Inc. All rights reserved. \n\n\n\nTwitter\nYoutube\nGitHub\nLinkedin\nFacebook\nSlideshare\nReddit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# dockerd\n\n> A persistent process to start and manage docker containers.\n> More information: <https://docs.docker.com/engine/reference/commandline/dockerd/>.\n\n- Run docker daemon:\n\n`dockerd`\n\n- Run docker daemon and config it to listen to specific sockets(unix,tcp):\n\n`dockerd --host unix://{{path/to/tmp.sock}} --host tcp://{{ip}}`\n\n- Run with specific daemon PID file:\n\n`dockerd --pidfile {{path/to/pid_file}}`\n\n- Run in debug mode:\n\n`dockerd --debug`\n\n- Run and set a specific log level:\n\n`dockerd --log-level={{debug|info|warn|error|fatal}}`\n"
 },
 {
   "command": "mkfs.cramfs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs.cramfs\n\n> Creates a ROM filesystem inside a partition.\n\n- Create a ROM filesystem inside partition 1 on device b (`sdb1`):\n\n`mkfs.cramfs {{/dev/sdb1}}`\n\n- Create a ROM filesystem with a volume-name:\n\n`mkfs.cramfs -n {{volume_name}} {{/dev/sdb1}}`\n"
 },
 {
   "command": "smbclient",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# smbclient\n\n> FTP-like client to access SMB/CIFS resources on servers.\n\n- Connect to a share (user will be prompted for password; `exit` to quit the session):\n\n`smbclient {{//server/share}}`\n\n- Connect with a different username:\n\n`smbclient {{//server/share}} --user {{username}}`\n\n- Connect with a different workgroup:\n\n`smbclient {{//server/share}} --workgroup {{domain}} --user {{username}}`\n\n- Connect with a username and password:\n\n`smbclient {{//server/share}} --user {{username%password}}`\n\n- Download a file from the server:\n\n`smbclient {{//server/share}} --directory {{path/to/directory}} --command \"get {{file.txt}}\"`\n\n- Upload a file to the server:\n\n`smbclient {{//server/share}} --directory {{path/to/directory}} --command \"put {{file.txt}}\"`\n"
 },
 {
   "command": "cryptsetup",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# cryptsetup\n\n> Manage plain dm-crypt and LUKS (Linux Unified Key Setup) encrypted volumes.\n\n- Initialize a LUKS volume (overwrites all data on the partition):\n\n`cryptsetup luksFormat {{/dev/sda1}}`\n\n- Open a LUKS volume and create a decrypted mapping at /dev/mapper/{{target}}:\n\n`cryptsetup luksOpen {{/dev/sda1}} {{target}}`\n\n- Remove an existing mapping:\n\n`cryptsetup luksClose {{target}}`\n\n- Change the LUKS volume's passphrase:\n\n`cryptsetup luksChangeKey {{/dev/sda1}}`\n"
 },
 {
   "command": "userdel",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# userdel\n\n> Remove a user.\n\n- Remove a user and their home directory:\n\n`userdel -r {{name}}`\n"
 },
 {
   "command": "logcat",
   "doc_url": "https://developer.android.com/studio/command-line/logcat",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogcat command-line tool  |  Android Developers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  Platform\n\n\n\n\n  Android Studio\n\n\n\n\n  Google Play\n\n\n\n\n  Jetpack\n\n\n\n\n  Kotlin\n\n\n\n\n  Docs\n\n\n\n\n  News\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage\n\n        English\n      \n\n        Bahasa Indonesia\n      \n\n        Deutsch\n      \n\n        Español\n      \n\n        Español – América Latina\n      \n\n        Français\n      \n\n        Português – Brasil\n      \n\n        Tiếng Việt\n      \n\n        Türkçe\n      \n\n        Русский\n      \n\n        ภาษาไทย\n      \n\n        中文 – 简体\n      \n\n        中文 – 繁體\n      \n\n        日本語\n      \n\n        한국어\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n        Android Studio\n      \n  \n\n\n\n\n\n\n\n\n\n  Download\n\n\n\n\n  What's new\n\n\n\n\n  User guide\n\n\n\n\n  Preview\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      Platform\n   \n\n\n\n\n\n      Android Studio\n   \n\n\n\n\n\n      Download\n   \n\n\n\n\n\n      What's new\n   \n\n\n\n\n\n\n\n      User guide\n   \n\n\n\n\n\n\n\n      Preview\n   \n\n\n\n\n\n\n\n\n\n      Google Play\n   \n\n\n\n\n\n      Jetpack\n   \n\n\n\n\n\n      Kotlin\n   \n\n\n\n\n\n      Docs\n   \n\n\n\n\n\n      News\n   \n\n\n\n\n\n\n\nMeet Android StudioOverviewInstall Android StudioMigrate to Android StudioConfigure the IDEKeyboard shortcutsAccessibility featuresUpdate the IDE and tools\nWorkflow basics\n\nManage your projectOverviewCreate a projectAbout Play Feature Delivery\nAdd C and C++ codeOverviewInstall NDK and CMakeConfigure the NDK for AGPConfigure CMakeLink GradleCreate an Android librarySet up continuous integration\n\nWrite your appOverviewAdd code from a templateFind sample codeAdd a module for a new deviceCreate a Java class or typeUse Java 8 language featuresJava 8 language support tableAdd app resourcesBuild a UI with Layout EditorBuild animation with Motion EditorManage your app's UI resourcesDesign app themesAdd multi-density vector graphicsCreate icons with Image Asset StudioCreate resizable bitmaps (9-Patch)Create WebP imagesLocalize the UIAdd Android app linksConnect to FirebaseImprove your code with lint checksImprove code inspection with annotationsTools attributes reference\n\nBuild and run your appOverview\nRun apps on the emulatorOverviewCreate and manage virtual devicesStart the emulator from the command lineSend emulator console commandsSet up emulator networkingConfigure hardware accelerationEmulator feature comparisonTroubleshoot emulator\nRun apps on a hardware deviceOverviewInstall OEM USB driversGet the Google USB driverCreate run/debug configurationsBuild your app from the command line\n\nConfigure your buildOverviewSet the application IDAdd build dependenciesUsing native dependenciesOptimize your build speedTroubleshoot build performanceUse the build cacheConfigure build variantsBuild multiple APKsMerge multiple manifestsInject build variables into the manifestShrink your appEnable multidexInspect artifacts with APK AnalyzerUse the Maven Publish pluginGradle tips and recipes\n\nDebug your appOverviewConfigure developer optionsWrite and view logsAnalyze a stack traceDebug your layout with Layout InspectorView on-device filesDebug pre-built APKsTake a screenshotRecord a videoCapture and read bug reports\n\nTest your appOverviewTest from the command lineCreate UI tests with Espresso Test RecorderUI/App Exerciser Monkey\nmonkeyrunner referenceOverviewMonkeyDeviceMonkeyImageMonkeyRunner\n\nProfile your appOverviewMeasure app performance\nBenchmark your appOverviewBuild benchmarks without GradleRun benchmarks in Continuous IntegrationProfile pre-built APKs\nInspect CPU activityOverviewGenerate trace logs by instrumenting your appView the heap and memory allocationsInspect network activityInspect energy use\n\nPublish your appOverviewPrepare for releaseVersion your appSign your appUpload your app\n\nCommand line toolsOverviewaapt2adbapkanalyzerapksigneravdmanagerbmgrbundletoold8dmtracedumpdumpsysetc1tooljobbjetifier-standalonelogcatmksdcardsdkmanagersystraceperfettozipalignEnvironment variables\nTroubleshoot\nKnown issues\nReport a bug\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Google is committed to advancing racial equity for Black communities. See how.\n\n\n\n\n\n\n\n    \n        Android Developers\n      \n  \n\n\n\n\n    \n        Android Studio\n      \n  \n\n\n\n\n    \n        User guide\n      \n  \n\n\n\n\n\nLogcat command-line tool\n\n\n\nLogcat is a command-line tool that dumps a log of system messages, including stack traces when the\ndevice throws an error and messages that you have written from your app with the\nLog class.\nThis page is about the command-line logcat tool, but you can also view log\nmessages from the Logcat window in Android Studio. For\ninformation about viewing and filtering logs from Android Studio,\nsee Write and View Logs with\nLogcat.\nLogging system overview\n\n    The Android logging system is a set of structured circular buffers maintained by the system\n    process logd. The set of available buffers is fixed and defined by the\n    system. The most relevant ones are: main, which stores most application logs,\n    system, which stores messages originating from the Android OS, and\n    crash, which stores crash logs. Each log entry has a priority\n    (one of VERBOSE, DEBUG, INFO, WARNING,\n    ERROR or FATAL), a tag that identifies the origin of the log,\n    and the actual log message.\n  \n\n    The primary interface to the logging system is the shared library liblog\n    and its header <android/log.h>.\n    All language-specific logging facilities eventually call the function\n    __android_log_write. By default, it calls the function\n    __android_log_logd_logger, which sends the log entry to logd\n    using a socket. Starting with API level 30, the logging function can be changed by calling\n    __android_set_log_writer. More information is available in the\n    NDK documentation.\n  \n\n    Logs displayed by adb logcat undergo four levels of filtering:\n  \n\nCompile-time filtering: depending on compilation settings, some logs may be completely\n      removed from the binary. For example, Proguard can be configured to remove calls to\n      Log.d from Java code.\nSystem property filtering: liblog queries a set of system properties to\n      determine the minimum severity level to be sent to logd. If your logs have\n      the tag MyApp, the following properties are checked, and are expected to contain\n      the first letter of the minimum severity (V, D, I,\n      W, E, or S to disable all logs):\n\nlog.tag.MyApp\npersist.log.tag.MyApp\nlog.tag\npersist.log.tag\n\nApplication filtering: If none of the properties are set, liblog uses\n      the minimum priority set by __android_log_set_minimum_priority.\n      The default setting is INFO.\nDisplay filtering: adb logcat supports additional filters that can reduce\n      the amount of logs shown from logd.\n      See below for details.\nCommand-line syntax\n\n    To run logcat through the adb shell, the general usage is:\n  \n\n[adb] logcat [<option>] ... [<filter-spec>] ...\n\nYou can run logcat as an adb command or directly in a shell prompt\n  of your emulator or connected device. To view log output using adb, navigate to your SDK\n  platform-tools/ directory and execute:\n\nadb logcat\n\n\nFor logcat online help, start a device and then execute:\n\n\nadb logcat --help\n\nYou can create a shell connection to a device and execute:\n\n$ adb shell\n# logcat\n\nOptions\nThe following table describes the command line options of logcat.\n\n\nOption\nDescription\n\n\n-b <buffer>\nLoad an alternate log buffer for viewing, such as events or\n        radio. The main, system, and crash buffer\n        set is used by default. See Viewing Alternative Log Buffers.\n\n\n-c, --clear\nClear (flush) the selected buffers and exit. The default buffer set is main,\n        system and crash. To clear all of the buffers, use\n        -b all -c.\n      \n\n\n-e <expr>, --regex=<expr>\nOnly print lines where the log message matches <expr>\n          where <expr> is a regular expression.\n\n\n-m <count>, --max-count=<count>\nQuit after printing <count> number of lines. This is meant to be\n        paired with --regex, but will work on its own.\n\n\n--print\nPaired with --regex and --max-count\n        to let content bypass the regex filter, but still stop at the\n        right number of matches.\n\n\n-d\nDump the log to the screen and exits.\n\n\n-f <filename>\nWrite log message output to <filename>. The default is\n      stdout.\n\n\n-g, --buffer-size\nPrint the size of the specified log buffer and exits.\n\n\n-n <count>\nSet the maximum number of rotated logs to <count>. The default value\n      is 4. Requires the -r option.\n\n\n-r <kbytes>\nRotate the log file every <kbytes> of output. The default value is\n      16. Requires the -f option.\n\n\n-s\nEquivalent to the filter expression '*:S', which sets priority for all tags\n      to silent, and is used to precede a list of filter expressions that add content. To learn more,\n      go to the section about filtering log output.\n      \n\n\n-v <format>\nSet the output format for log messages. The default is threadtime format. For a\n      list of supported formats, go to the section about the Control log\n      output format.\n      \n\n\n-D, --dividers\nPrint dividers between each log buffer.\n\n\n-c\nFlush (clear) the entire log and exit.\n\n\n-t <count> \nPrint only the most recent number of lines. This option includes -d\n        functionality.\n\n\n-t '<time>' \nPrint the most recent lines since the specified time. This option includes\n        -d functionality. See the -P option for\n        information about quoting parameters with embedded spaces.\n\n        adb logcat -t '01-26 20:52:41.820'\n\n\n\n-T <count> \nPrint the most recent number of lines since the specified time. This option does not\n        include -d functionality \n\n\n-T '<time>' \nPrint the most recent lines since the specified time. This option does not include\n        include -d functionality. See the -P option for\n      information about quoting parameters with embedded spaces.\n\n        adb logcat -t '01-26 20:52:41.820'\n\n\n\n-L, -last\nDump the logs prior to the last reboot.\n\n\n-B, --binary\nOutput the log in binary.\n\n\n-S, --statistics\nInclude statistics in the output to help you identify and target log spammers.\n\n\n-G <size> \nSet the size of the log ring buffer. Can add\n        K or M at the end to indicate\n        kilobytes or megabytes.\n\n\n-p, --prune\n\n         Print (read) the current allow (white) and deny (black) lists and\n         takes no arguments, as follows:\n\n\nadb logcat -p\n\n\n\n\n\n-P '<list> ...'\n          --prune '<list> ...'\n          -P '<white_and_black_list>'\n\n\n        Write (set) the allow (white) and deny (black) lists to adjust the\n        logging content for a specific purpose. You provide a mixed content of allowed\n        (<white>) and denied (~<black>) list entries, where\n        <white> or <black> can be a UID, UID/PID or /PID. With\n        guidance from the logcat statistics (logcat -S), one can consider adjustments\n        to the allow (white) and deny (black) lists for purposes such as:\n\nGive the highest longevity to specific logging content through UID selections.\nPrevent someone (UID) or something (PID) from consuming these resources to help increase the\n    logspan so you can have more visibility into the problems you are diagnosing.\n\n\n  By default the logging system automatically prevents the worst offender in the log statistics\n  dynamically to make space for new log messages. Once it has exhausted the heuristics, the system\n  prunes the oldest entries to make space for the new messages.\n\n\n    Adding an allowlist (whitelist) protects your Android Identification number (AID),\n    which becomes the processes' AID and GID from being declared an offender, and adding a denylist\n    helps free up space before the worst offenders are considered. You can choose how active the\n    pruning is, and you can turn pruning off so it only removes content from the oldest entries in\n    each log buffer.\n  \nQuotes\n\nadb logcat does not preserve the quotes, so the syntax for specifying allow\n  (white) and deny (black) lists is as follows:\n\n\n$ adb logcat -P '\"<white_and_blacklist>\"'\n\nor\n\nadb shell\n$ logcat -P '<white_and_blacklist>'\n\n\n  The following example specifies an allow (white) list with PID 32676 and UID 675, and\n  a deny (black) list with PID 32677 and UID 897. PID 32677 on the denylist is\n  weighted for faster pruning.\n\n\nadb logcat -P '\"/32676 675 ~/32677 897\"'\n\n\n  Other allow (white) and deny (black) list command variations you can use\n  are as follows:\n  \n\n~! worst uid blacklist\n~1000/! worst pid in system (1000)\n\n\n\n\n--pid=<pid> ...\nOnly print logs from the given PID.\n\n\n--wrap\nSleep for 2 hours or when the buffer is about to wrap whichever\n          comes first. Improves efficiency of polling by providing\n          an about-to-wrap wakeup.\n\n\nFiltering log output\n\nThe tag of a log message is a short string indicating the system component from which the\n    message originates (for example, \"View\" for the view system).\nThe priority is one of the following character values, ordered from lowest to highest\n    priority:\n\n\nV: Verbose (lowest priority)\nD: Debug\nI: Info\nW: Warning\nE: Error\nF: Fatal\nS: Silent (highest priority, on which nothing is ever printed)\n\n\n\nYou can obtain a list of tags used in the system, with priorities, by running\n  logcat and observing the first two columns of each message, given as\n  <priority>/<tag>.\n\n    The following is an example of brief logcat output obtained with the\n    logcat -v brief output command. It shows that the message relates to priority\n    level \"I\" and tag \"ActivityManager\":\n  \n\nI/ActivityManager(  585): Starting activity: Intent { action=android.intent.action...}\n\nTo reduce the log output to a manageable level, you can restrict log output using filter\n  expressions. Filter expressions let you indicate to the system the tags-priority\n  combinations that you are interested in — the system suppresses other messages for the\n  specified tags.\nA filter expression follows this format tag:priority ..., where tag\n  indicates the tag of interest and priority indicates the minimum level of\n  priority to report for that tag. Messages for that tag at or above the specified priority are\n  written to the log. You can supply any number of tag:priority specifications in a\n  single filter expression. The series of specifications is whitespace-delimited.\nHere's an example of a filter expression that suppresses all log messages except those with\n  the tag \"ActivityManager\", at priority \"Info\" or above, and all log messages with tag \"MyApp\",\n  with priority \"Debug\" or above:\n\nadb logcat ActivityManager:I MyApp:D *:S\n\nThe final element in the above expression, *:S, sets the priority level for all\n  tags to \"silent\", thus ensuring only log messages with \"ActivityManager\" and \"MyApp\" are displayed. Using\n  *:S is an excellent way to ensure that log output is restricted to the filters that\n  you have explicitly specified — it lets your filters serve as an allowlist for log\n  output.\nThe following filter expression displays all log messages with priority level \"warning\" and higher, on all tags:\n\nadb logcat *:W\n\nIf you're running logcat from your development computer (versus running it on a\n  remote adb shell), you can also set a default filter expression by exporting a value for the\n  environment variable ANDROID_LOG_TAGS:\n\nexport ANDROID_LOG_TAGS=\"ActivityManager:I MyApp:D *:S\"\n\nNote that ANDROID_LOG_TAGS filter is not exported to the emulator/device\n  instance, if you are running logcat from a remote shell or using adb shell\n  logcat.\nControl log output format\nLog messages contain a number of metadata fields, in addition to the tag and priority. You can\n  modify the output format for messages so that they display a specific metadata field. To do so,\n  you use the -v option and specify one of the supported output formats listed\n    below.\n\n  \nbrief: Display priority, tag, and PID of the process issuing the\n    message.\nlong: Display all metadata fields and separate messages with blank\n    lines.\nprocess: Display PID only.\nraw: Display the raw log message with no other metadata fields.\ntag: Display the priority and tag only.\nthread: A legacy format that shows priority, PID, and TID of the\n      thread issuing the message.\nthreadtime (default): Display the date, invocation time, priority,\n        tag, PID, and TID of the thread issuing the message.\ntime: Display the date, invocation time, priority, tag, and PID of the\n    process issuing the message.\n\nWhen starting logcat, you can specify the output format you want by using the\n  -v option:\n\n[adb] logcat [-v <format>]\n\nHere's an example that shows how to generate messages in thread output\n  format:\n\nadb logcat -v thread\n\nNote that you can only specify one output format with the -v option, but you\n    can specify as many modifiers that make sense. Logcat ignores modifiers that do not make sense.\nFormat modifiers\n\n    Format modifiers change the logcat output in terms of any combination of one or more of\n    the following modifiers. To specify a format modifier, use the -v option, as\n    follows:\n  \n\nadb logcat -b all -v color -d\n\nEvery Android log message has a tag and a priority associated with it.\n  You can combine any format modifier with any one of the following format options: brief,\n      long, process, raw, tag,\n      thread, threadtime, and time.\n\n\n  You can get the format modifier details by typing logcat -v --help at the command line.\n  \n\ncolor: Show each priority level with a different color.\ndescriptive: Show log buffer event descriptions. This modifier affects event\n      log buffer messages only, and has no effect on the other non-binary buffers. The event\n      descriptions come from the event-log-tags database.\nepoch: Display time in seconds starting from Jan 1, 1970.\nmonotonic: Display time in CPU seconds starting from the last boot.\nprintable: Ensure that any binary logging content is escaped.\nuid: If permitted by access controls, display the UID or Android ID of the\n      logged process.\nusec: Display the time with precision down to microseconds.\nUTC: Display time as UTC.\nyear:  Add the year to the displayed time.\nzone: Add the local time zone to the displayed time.\n\nViewing alternative log buffers\nThe Android logging system keeps multiple circular buffers for log messages, and not all of\n  the log messages are sent to the default circular buffer. To see additional log messages, you can\n  run the logcat command with the -b option, to request viewing of an\n  alternate circular buffer. You can view any of these alternate buffers:\n\nradio: View the buffer that contains radio/telephony related\n    messages.\nevents: View the interpreted binary system event buffer messages.\nmain: View the main log buffer (default) does not contain\n      system and crash log messages.\nsystem: View the system log buffer (default).\ncrash: View the crash log buffer (default).\nall: View all buffers.\ndefault: Reports main, system, and\n      crash buffers.\n  \n\n      The usage of the -b option is:\n\n[adb] logcat [-b <buffer>]\n\n\n    Here is an example of how to view a log buffer containing radio and telephony messages:\n  \n\nadb logcat -b radio\n\n\n    You can also specify multiple -b flags for all of the buffers you want to print,\n    as follows:\n  \n\nlogcat -b main -b radio -b events\n\n\n    You can specify a single -b flag with a comma-separated list of buffers,\n    for example:\n  \n\nlogcat -b main,radio,events\n\nLogging from code\nThe Log class allows you to create log entries in your code that display\n  in the logcat tool. Common logging methods include:\n\nLog.v(String, String) (verbose)\nLog.d(String, String) (debug)\nLog.i(String, String) (information)\nLog.w(String, String) (warning)\nLog.e(String, String) (error)\n\nFor example, using the following call:\n\nKotlin\n\nLog.i(\"MyActivity\", \"MyClass.getView() — get item number $position\")\n\nJava\n\nLog.i(\"MyActivity\", \"MyClass.getView() — get item number \" + position);\n\n\n\nThe logcat outputs something like:\n\nI/MyActivity( 1557): MyClass.getView() — get item number 1\n\n\n\n\n\n\n\nContent and code samples on this page are subject to the licenses described in the Content License. Java is a registered trademark of Oracle and/or its affiliates.\nLast updated 2020-08-25 UTC.\n\n\n\n\n\n\n\n\n\n        \n        Twitter\n      \nFollow @AndroidDev on Twitter\n\n\n\n\n        \n        YouTube\n      \nCheck out Android Developers on YouTube\n\n\n\n\n\n\n\n\nMore Android\n\n\n\n          \n            Android\n          \n          \n\n\n\n          \n            Enterprise\n          \n          \n\n\n\n          \n            Security\n          \n          \n\n\n\n          \n            Source\n          \n          \n\n\n\n\nSupport\n\n\n\n          \n            Report platform bug\n          \n          \n\n\n\n          \n            Report documentation bug\n          \n          \n\n\n\n          \n            Google Play support\n          \n          \n\n\n\n          \n            Join research studies\n          \n          \n\n\n\n\nDocumentation\n\n\n\n          \n            Developer guides\n          \n          \n\n\n\n          \n            Design guides\n          \n          \n\n\n\n          \n            API reference\n          \n          \n\n\n\n          \n            Samples\n          \n          \n\n\n\n          \n            Android Studio\n          \n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Android\n        \n\n\n\n          Chrome\n        \n\n\n\n          Firebase\n        \n\n\n\n          Google Cloud Platform\n        \n\n\n\n          All products\n        \n\n\n\n\n\n\n\n          Privacy\n        \n\n\n\n          License\n        \n\n\n\n          Brand guidelines\n        \n\n\nGet news and tips by email\n\n          Subscribe\n        \n\n\n\n\n\nLanguage\n\n        English\n      \n\n        Bahasa Indonesia\n      \n\n        Deutsch\n      \n\n        Español\n      \n\n        Español – América Latina\n      \n\n        Français\n      \n\n        Português – Brasil\n      \n\n        Tiếng Việt\n      \n\n        Türkçe\n      \n\n        Русский\n      \n\n        ภาษาไทย\n      \n\n        中文 – 简体\n      \n\n        中文 – 繁體\n      \n\n        日本語\n      \n\n        한국어\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# logcat\n\n> Dump a log of system messages.\n> Native Android CLI tool.\n> More information: <https://developer.android.com/studio/command-line/logcat>.\n\n- Display system logs:\n\n`logcat`\n\n- Write system logs to a file:\n\n`logcat -f {{path/to/file}}`\n\n- Display lines that match a regex:\n\n`logcat --regex {{regex}}`\n"
 },
 {
   "command": "resize2fs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# resize2fs\n\n> Resize an ext2, ext3 or ext4 filesystem.\n> Does not resize the underlying partition, and the filesystem must be unmounted.\n\n- Automatically resize a filesystem:\n\n`resize2fs {{/dev/sdXN}}`\n\n- Resize the filesystem to a size of 40G, displaying a progress bar:\n\n`resize2fs -p {{/dev/sdXN}} {{40G}}`\n\n- Shrink the filesystem to its minimum possible size:\n\n`resize2fs -M {{/dev/sdXN}}`\n"
 },
 {
   "command": "service",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# service\n\n> Manage services by running init scripts.\n> The full script path should be omitted (/etc/init.d/ is assumed).\n\n- Start/Stop/Restart/Reload service (start/stop should always be available):\n\n`service {{init_script}} {{start|stop|restart|reload}}`\n\n- Do a full restart (runs script twice with start and stop):\n\n`service {{init_script}} --full-restart`\n\n- Show the current status of a service:\n\n`service {{init_script}} status`\n\n- List the status of all services:\n\n`service --status-all`\n"
 },
 {
   "command": "ac",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nAC(8)\t\t\t  BSD System Manager's Manual\t\t\t AC(8)\n\nNAME\n     ac -- display connect-time accounting\n\nSYNOPSIS\n     ac [-d] [-p] [-w file] [users ...]\n\nDESCRIPTION\n     A record of individual login and logout times are written to the system\n     log by login(8) and launchd(8), respectively.  The program ac examines\n     these records and writes the accumulated connect time (in decimal hours)\n     for all logins to the standard output.\n\n     Options available:\n\n     -d      Display the connect times in 24 hour chunks.\n\n     -p      Display individual user totals.\n\n     -w file\n\t     Read raw connect time data from file, instead of the system log.\n\n     users ...\n\t     Display totals for the given individuals only.\n\n     If no arguments are given, ac displays the total amount of login time for\n     all active accounts on the system.\n\nSEE ALSO\n     login(1), utmpx(5), launchd(8), sa(8)\n\nHISTORY\n     An ac command appeared in Version 6 AT&T UNIX.\n\n4th Berkeley Distribution\tApril 19, 1994\t     4th Berkeley Distribution\n",
   "tldr_summary": "# ac\n\n> Print statistics on how long users have been connected.\n\n- Print how long the current user has been connected in hours:\n\n`ac`\n\n- Print how long users have been connected in hours:\n\n`ac --individual-totals`\n\n- Print how long a particular user has been connected in hours:\n\n`ac --individual-totals {{username}}`\n\n- Print how long a particular user has been connected in hours per day (with total):\n\n`ac --daily-totals --individual-totals {{username}}`\n"
 },
 {
   "command": "pacaur",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pacaur\n\n> A utility for Arch Linux to build and install packages from the Arch User Repository.\n\n- Synchronize and update all packages (includes AUR):\n\n`pacaur -Syu`\n\n- Synchronize and update only AUR packages:\n\n`pacaur -Syua`\n\n- Install a new package (includes AUR):\n\n`pacaur -S {{package_name}}`\n\n- Remove a package and its dependencies (includes AUR packages):\n\n`pacaur -Rs {{package_name}}`\n\n- Search the package database for a keyword (includes AUR):\n\n`pacaur -Ss {{keyword}}`\n\n- List all currently installed packages (includes AUR packages):\n\n`pacaur -Qs`\n"
 },
 {
   "command": "yay",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# yay\n\n> Yet Another Yogurt: A utility for Arch Linux to build and install packages from the Arch User Repository.\n> Also see `pacman`.\n\n- Interactively search and install packages from the repos and AUR:\n\n`yay {{package_name|search_term}}`\n\n- Synchronize and update all packages from the repos and AUR:\n\n`yay`\n\n- Synchronize and update only AUR packages:\n\n`yay -Sua`\n\n- Install a new package from the repos and AUR:\n\n`yay -S {{package_name}}`\n\n- Search the package database for a keyword from the repos and AUR:\n\n`yay -Ss {{keyword}}`\n\n- Show statistics for installed packages and system health:\n\n`yay -Ps`\n"
 },
 {
   "command": "pwgen",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pwgen\n\n> Generate pronounceable passwords.\n\n- Generate random password with s[y]mbols:\n\n`pwgen -y {{length}}`\n\n- Generate secure, hard-to-memorize passwords:\n\n`pwgen -s {{length}}`\n\n- Generate password with at least one capital letter in them:\n\n`pwgen -c {{length}}`\n"
 },
 {
   "command": "newgrp",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nNEWGRP(1)\t\t  BSD General Commands Manual\t\t     NEWGRP(1)\n\nNAME\n     newgrp -- change to a new group\n\nSYNOPSIS\n     newgrp [-l] [group]\n\nDESCRIPTION\n     The newgrp utility creates a new shell execution environment with modi-\n     fied real and effective group IDs.\n\n     The options are as follows:\n\n     -l      Simulate a full login.  The environment and umask are set to what\n\t     would be expected if the user actually logged in again.\n\n     If the group operand is present, a new shell is started with the speci-\n     fied effective and real group IDs.  The user will be prompted for a pass-\n     word if they are not a member of the specified group.\n\n     Otherwise, the real, effective and supplementary group IDs are restored\n     to those from the current user's password database entry.\n\nEXIT STATUS\n     The newgrp utility attempts to start the shell regardless of whether\n     group IDs were successfully changed.\n\n     If an error occurs and the shell cannot be started, newgrp exits >0.\n     Otherwise, the exit status of newgrp is the exit status of the shell.\n\nSEE ALSO\n     csh(1), groups(1), login(1), sh(1), su(1), umask(1), group(5), passwd(5),\n     environ(7)\n\nSTANDARDS\n     The newgrp utility conforms to IEEE Std 1003.1-2001 (``POSIX.1'').\n\nHISTORY\n     A newgrp utility appeared in Version 6 AT&T UNIX.\n\nBUGS\n     Group passwords are inherently insecure as there is no way to stop users\n     obtaining the crypted passwords from the group database.  Their use is\n     discouraged.\n\nBSD\t\t\t\t May 23, 2002\t\t\t\t   BSD\n",
   "tldr_summary": "# newgrp\n\n> Switch primary group membership.\n\n- Change user's primary group membership:\n\n`newgrp {{group_name}}`\n\n- Reset primary group membership to user's default group in /etc/passwd:\n\n`newgrp`\n"
 },
 {
   "command": "genie",
   "doc_url": "https://github.com/arkane-systems/genie",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - arkane-systems/genie: A quick way into a systemd \"bottle\" for WSL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\narkane-systems\n\n/\n\ngenie\n\n\n\n\n\n\n\n\n          Sponsor\n        \n\n\n\n\n\n\n              Sponsor arkane-systems/genie\n            \n\n\n\n\n\n\n\n\n\n\n\n\n    Watch\n \n      17\n    \n\n\n\n\n      Star\n\n\n      493\n    \n\n\n\n\n          Fork\n\n\n        29\n      \n\n\n\n\n\n        A quick way into a systemd \"bottle\" for WSL\n      \n\n\n\n            View license\n        \n\n\n\n\n493\n        stars\n \n\n29\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n5\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nbranches\n\n\n\n18\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\ncerebrate\n\nMerge branch 'master' of https://github.com/arkane-systems/genie into…\n\n\n\n…\n\n\n\n97f89c0\n\nSep 21, 2020\n\n\n\n\n\nMerge branch 'master' of https://github.com/arkane-systems/genie into…\n\n… master\n\n* 'master' of https://github.com/arkane-systems/genie:\n  Update readme.md\n\n97f89c0\n\n\n\nGit stats\n\n\n\n\n\n188\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\n.github\n\n\n\nUpdate stale.yml\n\n\n\nJun 21, 2020\n\n\n\n\n\n\n\narch\n\n\n\nReady to add arch build.\n\n\n\nSep 21, 2020\n\n\n\n\n\n\n\ngenie\n\n\n\nMerge branch 'master' of https://github.com/arkane-systems/genie into…\n\n\n\nSep 21, 2020\n\n\n\n\n\n\n\n.gitignore\n\n\n\nHack shlibs for buster compat.\n\n\n\nSep 2, 2020\n\n\n\n\n\n\n\nCONTENTS\n\n\n\nAdded contents file.\n\n\n\nAug 13, 2020\n\n\n\n\n\n\n\nLICENSE\n\n\n\nRemade source tree and makefile for debuild.\n\n\n\nAug 12, 2020\n\n\n\n\n\n\n\nMakefile\n\n\n\nReady to add arch build.\n\n\n\nSep 21, 2020\n\n\n\n\n\n\n\nPBUILDER.md\n\n\n\nAdded description of pbuilder environment.\n\n\n\nAug 19, 2020\n\n\n\n\n\n\n\nREADME.md\n\n\n\nRemade source tree and makefile for debuild.\n\n\n\nAug 12, 2020\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\ngenie\n\nA quick way into a systemd \"bottle\" for WSL\nWhat does that even mean?\nWell, this gives you a way to run systemd as pid 1, with all the trimmings, inside WSL 2. It does this by creating a pid namespace, the eponymous poor-man's-container \"bottle\", starting up systemd in there, and entering it, and providing some helpful shortcuts to do so.\nIf you want to try it, please read this entire document first, especially the BUGS section.\nNOTE: WSL 2 ONLY\nNote: it is only possible to run systemd (and thus genie ) under WSL 2; WSL 1 does not support the system calls required to do so. If you are running inside a distro configured as WSL 1, even if your system supports WSL 2, genie will fail to operate properly.\nINSTALLATION\nIf there is a package available for your distribution, this is the recommended method of installing genie.\nDebian\nDependent packages on Debian are daemonize, dbus, dotnet-runtime-3.1, policykit-1, and systemd . For the most part, these are either already installed or in the distro and able to be installed automatically. You need debhelper and dotnet-sdk-3.1 (and optionally pbuilder) to build the Debian package, but not to simply build genie or install locally.\nThe chief exception is dotnet-runtime-3.1 , for which you will need to follow the installation instructions here:\nhttps://dotnet.microsoft.com/download/\nTo install, add the wsl-translinux repository here by issueing the following command, or by following the instructions here (https://packagecloud.io/arkane-systems/wsl-translinux):\ncurl -s https://packagecloud.io/install/repositories/arkane-systems/wsl-translinux/script.deb.sh | sudo bash\nthen install genie using the command:\nsudo apt install -y systemd-genie\nPLEASE NOTE\nThe wsl-translinux repository is hosted by packagecloud.io, whose free plan allows for 250 MB of downloads per month. Due to the unexpected popularity of genie, we are currently skating right at the edge of this level of usage, and my poor indie developer budget does not stretch to the $75/mo. required for a \"Small\" plan. As such, if it won't download for you, you may need to either download the .deb file from the Releases page and install manually using dpkg -i, or wait for the usage counter to reset on the 12th of the month.\nWe apologize for the inconvenience. Anyone wishing to be this project's sugar daddy is welcome to apply.\nOther Distros\nDebian is the \"native\" distribution for genie , for which read, \"what the author uses\". Specifically, Debian stretch+, with usrmerge installed. If you're using anything else, you may need to tweak the configuration file (see below) accordingly.\nOther\nWe're actively looking for maintainers for everything else. If you can use .deb packages (especially if your distro is a Debian derivative), the Debian package may work for you. Otherwise, manually installing from the .tar.gz is probably the best I can suggest.\nI am unable to support distributions which there are not prebuilt packages for. I am actively seeking maintainers for these packages.\n...OR BUILD IT YOURSELF\nIt is possible to build your own version of genie and install it locally. To do so, you will require build-essential and dotnet-sdk-3.1 in addition to the other dependencies, all of which must be installed manually.\nAfter cloning the repository, run\nsudo make local\n\nThis will build genie and install it under /usr/local .\nCONFIGURATION FILE\nThat would be the file /etc/genie.ini. This defines the secure path (i.e., those directories in which genie will look for the utilities it depends on), and also the explicit path to unshare(1), required by daemonize(1). Normally, it looks like this:\n[genie]\nsecure-path=/lib/systemd:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nunshare=/usr/bin/unshare\nupdate-hostname=true\n\nThe secure-path setting should be generic enough to cover all but the weirdest Linux filesystem layouts, but on the off-chance that yours stores binaries somewhere particularly idiosyncratic, you can change it here. Meanwhile, the unshare setting is much more likely to be system-dependent; if you are getting errors running genie, please replace this with the output of which unshare before trying anything else.\nThe update-hostname setting controls whether or not genie updates the WSL hostname when creating the bottle. By default, genie updates a hostname foo to foo-wsl, to prevent hostname clashes between the host Windows machine and the WSL distribution, especially when communicating back and forth between the two. However, as recent Insider builds allow the hostname of the WSL distributions to be set in _.wslconfig, this option has been provided to disable genie's intervention and keep the original hostname.\nUSAGE\ngenie:\n  Handles transitions to the \"bottle\" namespace for systemd under WSL.\n\nUsage:\n  genie [options] [command]\n\nOptions:\n  -v, --verbose <VERBOSE>    Display verbose progress messages\n  --version                  Display version information\n\nCommands:\n  -i, --initialize           Initialize the bottle (if necessary) only.\n  -s, --shell                Initialize the bottle (if necessary), and run a shell in it.\n  -c, --command <COMMAND>    Initialize the bottle (if necessary), and run the specified command in it.\n  --shutdown, -u             Shut down systemd and exit the bottle.\n\nSo, it has three modes, all of which will set up the bottle and run systemd in it if it isn't already running for simplicity of use.\ngenie -i will set up the bottle - including changing the WSL hostname by suffixing -wsl, to distinguish it from the Windows host -  run systemd, and then exit. This is intended for use if you want services running all the time in the background, or to preinitialize things so you needn't worry about startup time later on, and for this purpose is ideally run from Task Scheduler on logon.\ngenie -s runs your login shell inside the bottle; basically, Windows-side, wsl genie -s is your substitute for just wsl to get started, or for the shortcut you get to start a shell in the distro. It follows login semantics, and as such does not preserve the current working directory.\ngenie -c [command] runs command inside the bottle, then exits. The return code is the return code of the command. It follows sudo semantics, and so does preserve the cwd.\nMeanwhile, genie -u , run from outside the bottle, will shut down systemd cleanly and exit the bottle. This uses the systemctl poweroff command to simulate a normal Linux system shutting down. It is suggested that this be used before shutting down Windows or restarting the Linux distribution to ensure a clean shutdown of systemd services.\nWhile not compulsory, it is recommended that you shut down and restart the WSL distro before using genie again after you have used genie -u. See BUGS, below, for more details.\nRECOMMENDATIONS\nOnce you have this up and running, I suggest disabling via systemctl the getty@tty1 service (since logging on and using WSL is done via ptsen, not ttys).\nFurther tips on usage from other genie users can be found on the wiki for this repo.\nBUGS\n\n\nThis breaks pstree and other /proc-walking tools that count on everything being a child of pid 1, because entering the namespace with a shell or other process leaves that process with a ppid of 0. To the best of my knowledge, I can't set the ppid of a process, and if I'm wrong about that, please send edification and pull requests to be gratefully accepted.\n\n\nIt is considerably clunkier than I'd like it to be, inasmuch as you have to invoke genie every time to get inside the bottle, either manually (replacing, for example, wsl [command] with wsl genie -c [command]), or by using your own shortcut in place of the one WSL gives you for the distro, using which will put you outside the bottle. Pull requests, etc.\n\n\nThere is a race condition that means that if you start a genie session too quickly after initializing the bottle (very likely if you use genie -c or genie -s without having running genie -i first, meaning that they will auto-initialize the bottle on first run), you may not get a systemd-logind login session or the functionality supplied by that, such as a systemd user instance. Using genie -i is strongly recommended to avoid this issue. Please see https://github.com/arkane-systems/genie/issues/70 for more details.\n\n\ngenie is not idempotent; i.e., it is possible that changes made by genie or by systemd inside the bottle will not be perftectly reverted when the genie bottle is shut down with genie -u . As such, it is recommended that you terminate the entire wsl session with wsl -t  or wsl --shutdown in between stopping and restarting the bottle, or errors may occur.\n\n\n\n\n\n\n\n\n\n\nAbout\n\n      A quick way into a systemd \"bottle\" for WSL\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n      18\n\n\n\n\n\n1.28 - bug fixes and hostname updateless edition\n\n          Latest\n \nSep 5, 2020\n\n \n\n        + 17 releases\n\n\n\n\n\nSponsor this project\n\n\n\n \n\n\n\n\n\nko-fi.com/arkanesystems\n\n\n\n\n  Learn more about GitHub Sponsors\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 9\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\nC#\n61.8%\n\n\n\n\n\nMakefile\n19.5%\n\n\n\n\n\nRoff\n17.5%\n\n\n\n\n\nShell\n1.2%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# genie\n\n> Set up and use a \"bottle\" namespace to run systemd under WSL (Windows Subsystem for Linux).\n> To run these from Windows rather than an already-running distribution, precede them with `wsl`.\n> More information: <https://github.com/arkane-systems/genie>.\n\n- Initialize the bottle (run once, at start):\n\n`genie -i`\n\n- Run a login shell inside the bottle:\n\n`genie -s`\n\n- Run a specified command inside the bottle:\n\n`genie -c {{command}}`\n"
 },
 {
   "command": "apport-bug",
   "doc_url": "https://wiki.ubuntu.com/Apport",
   "doc_text": "\n\n\n\nApport - Ubuntu Wiki\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Partners \n Support \n Community \n Ubuntu.com \n\n\n Ubuntu Wiki \n\n\n\n\n\nSearch:\n\n\n\n\n\n\n\n\n\n\nImmutable PageInfoAttachments\n\n\nMore Actions:\n\nRaw Text\nPrint View\nRender as Docbook\nDelete Cache\n------------------------\nCheck Spelling\nLike Pages\nLocal Site Map\n------------------------\nRename Page\nCopy Page\nDelete Page\n------------------------\nSubscribe User\n------------------------\nRemove Spam\nRevert to this revision\nPackage Pages\nSync Pages\n------------------------\nLoad\nSave\nSlideShow\n\n\n\n\n\n\n\nUbuntu Wiki\nLogin\nHelp\n\n\n\n\n\n\n\nApport\n\n\n\n\nAvailable languages:Italiano,  Contents\nWhat is this all about?\nWhat does it look like for users?\nWhy is apport disabled by default?\nHow to enable apport\nI'm a developer. How do I use these crash reports?\nReport format\nFields\nTools\nHow does it work internally?\nCrash interception\nExample\nBackend\nFrontend invocation\nLaunchpad-based auto-retracer\nPer-package Apport Hooks\nUse the source, Luke!\nFuture plans\nFurther links\n\n\nWhat is this all about?\nDebugging program crashes without any automated tools has been pretty time consuming and hard for both developers and users. Many program crashes remain unreported or unfixed because: Many crashes are not easily reproducible. End users do not know how to prepare a report that is really useful for developers, like building a package with debug symbols, operating gdb, etc. A considerable part of bug triage is spent with collecting relevant information about the crash itself, package versions, hardware architecture, operating system version, etc. There is no easy frontend which allow users to submit detailed problem reports. Existing solutions like bug-buddy or krash are specific to a particular desktop environment, are nontrivial to adapt to the needs of a distribution developer, do not work for crashes of background servers (like a database or an email server), and do not integrate well with existing debug packages that a distribution might provide. Apport is a system which: intercepts crashes right when they happen the first time, gathers potentially useful information about the crash and the OS environment, can be automatically invoked for unhandled exceptions in other programming languages (e. g. in Ubuntu this is done for Python), can be automatically invoked for other problems that can be automatically detected (e. g. Ubuntu automatically detects and reports package installation/upgrade failures from update-manager), presents a UI that informs the user about the crash and instructs them on how to proceed, and is able to file non-crash bug reports about software, so that developers still get information about package versions, OS version etc. We are sure that this will lead to a much better level of quality assurance in the future. If you want to make crash reports of your software even more useful when being reported through apport, please see /DeveloperHowTo. \nWhat does it look like for users?\nThe user side of apport is designed to be extremely simple and as unannoying as possible. If any process in the system dies due to a signal that is commonly referred to as a 'crash' (segmentation violation, bus error, floating point exception, etc.), or e. g. a packaged Python application raises an uncaught exception, the apport backend is automatically invoked. It produces an initial crash report in a file in /var/crash/ (the file name is composed from the name of the crashed executable and the user id). If the crashed process belongs to the user who is currently logged in, or it belongs to a system process and the user is an administrator, apport informs the user about the crash and offers to report the problem:  You can click on \"Show Details...\" to see what data it collected:  If the user leaves the \"Send error report\" checkbox enabled, Apport uploads the collected information to the bug tracking system. After that it opens the packages' bug filing page with a sensible default bug title and leaves the rest of bug filing process to the web UI. \nWhy is apport disabled by default?\nApport is not enabled by default in stable releases, even if it is installed. The automatic crash interception component of apport is disabled by default in stable releases for a number of reasons: Apport collects potentially sensitive data, such as core dumps, stack traces, and log files. They can contain passwords, credit card numbers, serial numbers, and other private material. This is mitigated by the fact that it presents you what will be sent to the bug tracker, and that all crash report bugs are private by default, limited to the Ubuntu bug triaging team. We can reasonably expect developers and technically savvy users, who run the development release, to be aware of this and judge whether it is appropriate to file a crash report. But we shouldn't assume that every Ubuntu user of stable releases is able to do so. In 12.04 and up this is transparently handled by whoopsie, see ErrorTracker. During the development release we already collect thousands of crash reports, much more than we can ever fix. Continuing to collect those for stable releases is not really useful, since The most important crashes have already been discovered in the development release. The less important ones are not suitable for getting fixed in stable releases (see https://wiki.ubuntu.com/StableReleaseUpdates Asking users to send crash reports to us is insincere, since we can't possibly answer and deal with all of them. Data collection from apport takes a nontrivial amount of CPU and I/O resources, which slow down the computer and don't allow you to restart the crashed program for several seconds. Note apport does not trap SIGABRT signals. If you are getting such a signal, then please see DebuggingProgramCrash. \nHow to enable apport\nApport itself is running at all times because it collects crash data for whoopsie (see ErrorTracker). However, the crash interception component is still disabled. To enable it permanently, do: sudo nano /etc/apport/crashdb.conf... and add a hash symbol # in the beginning of the following line:         'problem_types': ['Bug', 'Package'],To disable crash reporting just remove the hash symbol. \nI'm a developer. How do I use these crash reports?\n\nReport format\napport internally uses the standard Debian control syntax for reports, i. e. keeps everything in a flat file that looks like this: DistroRelease: Ubuntu 12.04\nExecutablePath: /usr/bin/gcalctool\nPackage: gcalctool 5.8.24-0ubuntu2\nProcCmdline: gcalctool\nProcEnviron:\n SHELL=/bin/bash\n PATH=/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11:/usr/games\n LANG=de_DE.UTF-8\nStackTrace:\n [...]\n #0  0x00002ae577bb37bf in poll () from /lib/libc.so.6\n No symbol table info available.\n #1  0x00002ae57786991e in g_main_context_check () from /usr/lib64/libglib-2.0.so.0\n No symbol table info available.\n [...]\nCoreDump: base64\n eJzsXQmcFMXV7+XGA0dBREVoDxSPXQYEB...Only a tiny subset of the available fields are shown here. Apport reports include a core dump in a compressed and encoded format, which is useful for post-mortem debugging and post-mortem generation of a symbolic stack trace. However, when uploading the data to a bug tracking system, a different format can be used. e. g. when using Launchpad, the data is uploaded in Multipart/MIME format so that the small parts land directly in the bug summary and the big parts become separate bug attachments. \nFields\nSome fields warrant further details: SegvAnalysis: when examining a Segmentation Fault (signal 11), Apport attempts to review the exact machine instruction that caused the fault, and checks the program counter, source, and destination addresses, looking for any virtual memory address (VMA) that is outside an allocated range (as reported in the ProcMaps attachment). SegvReason: a VMA can be read from, written to, or executed.  On a SegFault, one of these 3 CPU actions has taken place at a given VMA that either not allocated, or lacks permissions to perform the action.  For example: SegvReason: reading NULL VMA would mean that a NULL pointer was most likely dereferenced while reading a value. SegvReason: writing unknown VMA would mean that something was attempting to write to the destination of a pointer aimed outside of allocated memory.  (This is sometimes a security issue.) SegvReason: executing writable VMA [stack] would mean that something was causing code on the stack to be executed, but the stack (correctly) lacked execute permissions.  (This is almost always a security issue.)  \nTools\nThere are several tools available for working with a crash report: Ubuntu Bug Patterns: These are patterns for packages (writable by Ubuntu Bug Control) that prevent bugs from being filed by apport.  Complete details are found in the README. apport-unpack: Unpack a report into single files (one per attribute). This is most useful for extracting the core dump. Please see the manpage for further details. This tool is not necessary when working with Launchpad, since it already splits the parts into separate attachments. apport-retrace: Regenerate stack traces of a report. If you supply the -g option, this tool will automatically download available debug symbol packages and use them to generate a symbolic stack trace. The manpage explains the functionality and all available options in detail. python-problem-report: This package ships a Python module problem_report which provides general dictionary access to a crash report and loading/saving methods (not specific to apport reports). python-apport: This ships a Python package apport which encapsulates core functionality of apport and is specific to crash and bug reports. You can use it to implement your own frontends and backends. apport-collect: This checks the source package(s) of an existing Launchpad bug, runs apport hooks for them, and uploads their collected information back to the bug report. \nHow does it work internally?\n\nCrash interception\nApport uses /proc/sys/kernel/core_pattern to directly pipe the core dump into apport: $ cat /proc/sys/kernel/core_pattern\n|/usr/share/apport/apport %p %s %c\n$ Note that even if ulimit is set to disabled core files (by specyfing a core file size of zero using ulimit -c 0), apport will still capture the crash. For intercepting Python crashes it installs a /etc/python*/sitecustomize.py to call apport on unhandled exceptions. \nExample\nApport is even able to capture core files if PID 1 (Upstart) dies: If Upstart detects an internal inconsistency, it raises the SIGABRT signal. The Upstart crash handler is called on SIGABRT. Upstart crash handler forks a child process. The Upstart child process re-raises the signal which results in the child exiting abnormally. The kernel detects the child process has exited abnormally and calls apport, piping the core file to apports standard input (due to /proc/sys/kernel/core_pattern). apport writes the core file to disk in /var/crash/. PID 1 waits for its child to terminate (which only happens once apport has finished writing the core file). PID 1 exits. kernel panics. On next boot, Whoopsie will detect the crash file and process it. \nBackend\nIn order to keep the delay and CPU/IO impact as low as possible, /usr/share/apport/apport only collects data which has to be acquired while the crashed process still exists: information from /proc/pid, the core dump, the executable path, and the signal number. The report is written to /var/crash/executable_path.uid.crash. \nFrontend invocation\nIn Gnome, update-notifier keeps an inotify watch on /var/crash. Whenever there is something new, it calls /usr/share/apport/apport-checkreports. If there are new reports, it calls /usr/share/apport/apport-gtk, which is the frontend shown in the screenshots above. The frontend then collects additional information like package versions, package file checksums, or OS version, and calls all matching package hooks. To disable this, you can run gsettings set com.ubuntu.update-notifier show-apport-crashes false (as your ordinary desktop user). \nLaunchpad-based auto-retracer\nThe Canonical data center runs a service which automatically retrace bugs with apport. By tagging the bugs according to architecture in Launchpad, a retrace will be done and the tag will be removed. Tags that are used are need-i386-retrace or need-amd64-retrace. See the announcement. \nPer-package Apport Hooks\nIt is possible for packages to specify information gathered from the system and included in the bug report.  These are done by apport hooks contained in packages.  For some useful examples see: source_xorg.py - adds additional log files and hardware details to bug reports usplash - ignores crashes in specific code paths source_totem.py - asks the reporter questions and gathers different information based on responses in /usr/share/apport/package-hooks.  There is also a list of packages providing apport hooks. Please see /DeveloperHowTo for further information. If a crash or bug report is submitted through apport, the relevant hooks will be run automatically. If you have an already reported bug that was filed without apport, and you are interested in the information from those hooks, you can ask the bug reporter to use apport-collect bugnumber (see #Tools). \nUse the source, Luke!\nYou can download the upstream tarball from the Launchpad project page, or the Ubuntu source tarball from the Ubuntu archive. apport is developed with the bazaar RCS on Launchpad. If you want to contribute to it or develop your own system based on it, you can get your own branch with bzr branch lp:apport for trunk, or debcheckout -a apport for the Ubuntu packaging branch. You can also browse it online. \nFuture plans\nVarious improvements to performance, better tools to work with reports, and integration of more languages (Mono/Python stack traces, assertion messages, etc.) See the relevant specification. \nFurther links\nThe report file data format specification. Original specifications: apport design, User interface Ubuntu apport bug patterns Whoopsie is a newer Ubuntu crash submission system that doesn't require any input from the user and integrates with Apport Please do not hesitate to report bugs and feature requests to the bug tracker. See Bugs/ApportRetraces for additional documentation for those triaging Apport-generated bug reports in LaunchPad, based on a MOTU/School session by EmmetHikory . Brian Murray gave a class at Ubuntu Developer week regarding writing package hooks. Integration using LaunchpadIntegration: https://wiki.ubuntu.com/UbuntuDevelopment/Internationalisation/Coding#LPI  \n\n\n\n\nApport  (last edited 2017-05-25 20:03:48 by penalvch)\n\n\n\n\n\n\n\n\n\n\n The material on this wiki is available under a free license, see \n\tCopyright / License for details.\n        \n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# apport-bug\n\n> File a bug report on Ubuntu.\n> More information: <https://wiki.ubuntu.com/Apport>.\n\n- Report a bug about the whole system:\n\n`apport-bug`\n\n- Report a bug about a specific package:\n\n`apport-bug {{package}}`\n\n- Report a bug about a specific executable:\n\n`apport-bug {{path/to/executable}}`\n\n- Report a bug about a specific process:\n\n`apport-bug {{PID}}`\n"
 },
 {
   "command": "uvcdynctrl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# uvcdynctrl\n\n> A libwebcam command line tool to manage dynamic controls in uvcvideo.\n\n- List all available cameras:\n\n`uvcdynctrl -l`\n\n- Specify the device to use (defaults to `video0`):\n\n`uvcdynctrl -d {{device_name}}`\n\n- List available controls:\n\n`uvcdynctrl -c`\n\n- Set a new control value (for negative values, add -- before {{-value}}):\n\n`uvcdynctrl -s {{control_name}} {{value}}`\n\n- Get the current control value:\n\n`uvcdynctrl -g {{control_name}}`\n\n- Save the state of the current controls to a file:\n\n`uvcdynctrl -W {{filename}}`\n\n- Load the state of the controls from a file:\n\n`uvcdynctrl -L {{filename}}`\n"
 },
 {
   "command": "tree",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "TREE(1) \t\t\t\t\t\t\t       TREE(1)\n\n\n\nNAME\n       tree - list contents of directories in a tree-like format.\n\nSYNOPSIS\n       tree  [-acdfghilnpqrstuvxACDFQNSUX]  [-L  level [-R]] [-H baseHREF] [-T\n       title] [-o filename] [--nolinks] [-P pattern] [-I  pattern]  [--inodes]\n       [--device] [--noreport] [--dirsfirst] [--version] [--help] [--filelimit\n       #] [--si] [--prune] [--du] [--timefmt  format]  [--matchdirs]  [--from-\n       file] [--] [directory ...]\n\n\nDESCRIPTION\n       Tree  is  a  recursive  directory listing program that produces a depth\n       indented listing of files, which is  colorized  ala  dircolors  if  the\n       LS_COLORS  environment  variable  is set and output is to tty.  With no\n       arguments, tree lists the files in the current directory.  When\tdirec-\n       tory  arguments\tare given, tree lists all the files and/or directories\n       found in the given directories each in turn.  Upon completion of  list-\n       ing all files/directories found, tree returns the total number of files\n       and/or directories listed.\n\n       By default, when a symbolic link is encountered, the path that the sym-\n       bolic  link refers to is printed after the name of the link in the for-\n       mat:\n\n\t   name -> real-path\n\n       If the `-l' option is given and the symbolic link refers to  an\tactual\n       directory, then tree will follow the path of the symbolic link as if it\n       were a real directory.\n\n\nOPTIONS\n       Tree understands the following command line switches:\n\n\nLISTING OPTIONS\n       -a     All files are printed.  By default tree does  not  print\thidden\n\t      files  (those  beginning with a dot `.').  In no event does tree\n\t      print the file system constructs\t`.'  (current  directory)  and\n\t      `..' (previous directory).\n\n\n       -d     List directories only.\n\n\n       -l     Follows  symbolic links if they point to directories, as if they\n\t      were directories. Symbolic links that will result  in  recursion\n\t      are avoided when detected.\n\n\n       -f     Prints the full path prefix for each file.\n\n\n       -x     Stay on the current file-system only.  Ala find -xdev.\n\n\n       -L level\n\t      Max display depth of the directory tree.\n\n\n       -R     Recursively  cross  down the tree each level directories (see -L\n\t      option), and at each of  them  execute  tree  again  adding  `-o\n\t      00Tree.html' as a new option.\n\n\n       -P pattern\n\t      List  only  those files that match the wild-card pattern.  Note:\n\t      you must use the -a option to also consider those  files\tbegin-\n\t      ning with a dot `.'  for matching.  Valid wildcard operators are\n\t      `*' (any zero or more characters), `?' (any  single  character),\n\t      `[...]'  (any single character listed between brackets (optional\n\t      - (dash) for character  range  may  be  used:  ex:  [A-Z]),  and\n\t      `[^...]'\t(any  single character not listed in brackets) and `|'\n\t      separates alternate patterns.\n\n\n       -I pattern\n\t      Do not list those files that match the wild-card pattern.\n\n\n       --ignore-case\n\t      If a match pattern is specified by the -P  or  -I  option,  this\n\t      will  cause  the pattern to match without regards to the case of\n\t      each letter.\n\n\n       --matchdirs\n\t      If a match pattern is specified by  the  -P  option,  this  will\n\t      cause  the pattern to be applied to directory names (in addition\n\t      to filenames).  In the event of a match on the  directory  name,\n\t      matching\tis  disabled  for  the\tdirectory's  contents.\tIf the\n\t      --prune option is used, empty folders  that  match  the  pattern\n\t      will not be pruned.\n\n\n       --prune\n\t      Makes  tree prune empty directories from the output, useful when\n\t      used in conjunction with -P or -I.  See BUGS AND NOTES below for\n\t      more information on this option.\n\n\n       --noreport\n\t      Omits  printing  of  the file and directory report at the end of\n\t      the tree listing.\n\n\n       --charset charset\n\t      Set the character set to use when outputting HTML and  for  line\n\t      drawing.\n\n\n       --filelimit #\n\t      Do not descend directories that contain more than # entries.\n\n\n       --timefmt format\n\t      Prints (implies -D) and formats the date according to the format\n\t      string which uses the strftime(3) syntax.\n\n\n       -o filename\n\t      Send output to filename.\n\n\n\nFILE OPTIONS\n       -q     Print non-printable characters in filenames  as  question  marks\n\t      instead of the default.\n\n\n       -N     Print non-printable characters as is instead of as escaped octal\n\t      numbers.\n\n\n       -Q     Quote the names of files in double quotes.\n\n\n       -p     Print the file type and permissions for each  file  (as  per  ls\n\t      -l).\n\n\n       -u     Print the username, or UID # if no username is available, of the\n\t      file.\n\n\n       -g     Print the group name, or GID # if no group name is available, of\n\t      the file.\n\n\n       -s     Print the size of each file in bytes along with the name.\n\n\n       -h     Print  the  size\tof each file but in a more human readable way,\n\t      e.g. appending a size letter for kilobytes (K),  megabytes  (M),\n\t      gigabytes (G), terabytes (T), petabytes (P) and exabytes (E).\n\n\n       --si   Like -h but use SI units (powers of 1000) instead.\n\n\n       --du   For  each directory report its size as the accumulation of sizes\n\t      of all its files and sub-directories (and their  files,  and  so\n\t      on).   The total amount of used space is also given in the final\n\t      report (like the 'du -c' command.) This option requires tree  to\n\t      read  the entire directory tree before emitting it, see BUGS AND\n\t      NOTES below.  Implies -s.\n\n\n       -D     Print the date of the last modification time or if -c  is  used,\n\t      the last status change time for the file listed.\n\n\n       -F     Append  a `/' for directories, a `=' for socket files, a `*' for\n\t      executable files, a `>'  for  doors  (Solaris)  and  a  `|'  for\n\t      FIFO's, as per ls -F\n\n\n       --inodes\n\t      Prints the inode number of the file or directory\n\n\n       --device\n\t      Prints the device number to which the file or directory belongs\n\n\n\nSORTING OPTIONS\n       -v     Sort the output by version.\n\n\n       -t     Sort  the output by last modification time instead of alphabeti-\n\t      cally.\n\n\n       -c     Sort the output by last status change instead of alphabetically.\n\t      Modifies the -D option (if used) to print the last status change\n\t      instead of modification time.\n\n\n       -U     Do not sort.  Lists files in directory order.  Disables  --dirs-\n\t      first.\n\n\n       -r     Sort  the  output  in  reverse  order.  This is a meta-sort that\n\t      alter the above sorts.  This option is disabled when -U is used.\n\n\n       --dirsfirst\n\t      List  directories  before files. This is a meta-sort that alters\n\t      the above sorts.\tThis option is disabled when -U is used.\n\n\n       --sort[=]type\n\t      Sort the output by type instead of name.\tPossible  values  are:\n\t      ctime (-c), mtime (-t), size, or version (-v).\n\n\nGRAPHICS OPTIONS\n       -i     Makes  tree not print the indentation lines, useful when used in\n\t      conjunction with the -f option.  Also removes as much whitespace\n\t      as possible when used with the -J or -x options.\n\n\n       -A     Turn  on\tANSI  line graphics hack when printing the indentation\n\t      lines.\n\n\n       -S     Turn on CP437 line graphics (useful  when  using\tLinux  console\n\t      mode fonts). This option is now equivalent to `--charset=IBM437'\n\t      and may eventually be depreciated.\n\n\n       -n     Turn colorization off always, over-ridden by the -C option.\n\n\n       -C     Turn colorization on always, using built-in  color  defaults  if\n\t      the  LS_COLORS or TREE_COLORS environment variables are not set.\n\t      Useful to colorize output to a pipe.\n\n\n\nXML/JSON/HTML OPTIONS\n       -X     Turn on XML output. Outputs the directory tree as an XML format-\n\t      ted file.\n\n\n       -J     Turn  on JSON output. Outputs the directory tree as an JSON for-\n\t      matted array.\n\n\n       -H baseHREF\n\t      Turn on HTML output, including HTTP references. Useful  for  ftp\n\t      sites.   baseHREF  gives\tthe  base ftp location when using HTML\n\t      output. That is, the local directory  may  be  `/local/ftp/pub',\n\t      but   it\t must\tbe   referenced  as  `ftp://hostname.organiza-\n\t      tion.domain/pub' (baseHREF should  be  `ftp://hostname.organiza-\n\t      tion.domain').  Hint: don't use ANSI lines with this option, and\n\t      don't give more than one directory in the directory list. If you\n\t      wish  to\tuse  colors  via CSS style-sheet, use the -C option in\n\t      addition to this option to force color output.\n\n\n       -T title\n\t      Sets the title and H1 header string in HTML output mode.\n\n\n       --nolinks\n\t      Turns off hyperlinks in HTML output.\n\n\n\nINPUT OPTIONS\n       --fromfile Reads a directory listing from a file rather than the  file-\n       system.\t Paths\tprovided  on  the  command line are files to read from\n       rather than directories to search.  The\tdot  (.)  directory  indicates\n       that tree should read paths from standard input.\n\n\nMISC OPTIONS\n       --help Outputs a verbose usage listing.\n\n\n       --version\n\t      Outputs the version of tree.\n\n\n       --     Option  processing  terminator.  No further options will be pro-\n\t      cessed after this.\n\n\n\nFILES\n       /etc/DIR_COLORS\t\tSystem color database.\n       ~/.dircolors\t   Users color database.\n\n\nENVIRONMENT\n       LS_COLORS      Color information created by dircolors\n       TREE_COLORS    Uses this for color information over LS_COLORS if it  is\n       set.\n       TREE_CHARSET   Character set for tree to use in HTML mode.\n       CLICOLOR       Enables colorization even if TREE_COLORS or LS_COLORS is\n       not set.\n       CLICOLOR_FORCE Always enables colorization (effectively -C)\n       LC_CTYPE       Locale for filename output.\n       LC_TIME\t      Locale for timefmt output, see strftime(3).\n       TZ\t Timezone for timefmt output, see strftime(3).\n\n\nAUTHOR\n       Steve Baker (ice@mama.indstate.edu)\n       HTML output hacked by Francesc Rocher (rocher@econ.udg.es)\n       Charsets and OS/2 support by Kyosuke Tokoro (NBG01720@nifty.ne.jp)\n\n\nBUGS AND NOTES\n       Tree does not prune \"empty\" directories when the -P and -I options  are\n       used by default. Use the --prune option.\n\n       The -h and --si options round to the nearest whole number unlike the ls\n       implementations which rounds up always.\n\n       Pruning files and directories with the -I, -P and  --filelimit  options\n       will lead to incorrect file/directory count reports.\n\n       The  --prune  and --du options cause tree to accumulate the entire tree\n       in memory before emitting it. For large directory trees this can  cause\n       a significant delay in output and the use of large amounts of memory.\n\n       The  timefmt  expansion\tbuffer\tis limited to a ridiculously large 255\n       characters.  Output of time strings longer than this will be undefined,\n       but are guaranteed to not exceed 255 characters.\n\n       XML/JSON trees are not colored, which is a bit of a shame.\n\n       Probably more.\n\n\nSEE ALSO\n       dircolors(1), ls(1), find(1), du(1), strftime(3)\n\n\n\nTree 1.8.0\t\t\t\t\t\t\t       TREE(1)\n",
   "tldr_summary": "# tree\n\n> Show the contents of the current directory as a tree.\n\n- Print files and directories up to 'num' levels of depth (where 1 means the current directory):\n\n`tree -L {{num}}`\n\n- Print directories only:\n\n`tree -d`\n\n- Print hidden files too:\n\n`tree -a`\n\n- Print the tree without indentation lines, showing the full path instead (use `-N` to not escape whitespace and special characters):\n\n`tree -i -f`\n\n- Print the size of each node next to it, in human-readable format:\n\n`tree -s -h`\n\n- Filter the tree using a wildcard (glob) pattern:\n\n`tree -P {{*.txt}}`\n\n- Ignore entries that match a wildcard (glob) pattern:\n\n`tree -I {{*.txt}}`\n\n- Print the tree ignoring the given directories:\n\n`tree -I '{{directory_name1|directory_name2}}'`\n"
 },
 {
   "command": "a2dismod",
   "doc_url": "https://manpages.debian.org/buster/apache2/a2dismod.8.en.html",
   "doc_text": "\n\n\n\na2dismod(8) — apache2 — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / apache2\n     \n     \n     \n     / a2dismod(8)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXIT STATUS\n\n\nEXAMPLES\n\n\nFILES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.4.38-3+deb10u3\n\n\nbuster-backports 2.4.43-1~bpo10+1\n\n\ntesting 2.4.43-1\n\n\nunstable 2.4.43-1\n\n\n\n\n\n\nScroll to navigation\n\n\n\nA2ENMOD(8)\nSystem Manager's Manual\nA2ENMOD(8)\n\n\n\n\nNAME¶\na2enmod, a2dismod - enable or disable an apache2 module\n\n\nSYNOPSIS¶\na2enmod [ [-q|--quiet] module]\na2dismod [ [-q|--quiet] module]\n\n\nDESCRIPTION¶\nThis manual page documents briefly the a2enmod and a2dismod\n  commands.\na2enmod is a script that enables the specified module\n    within the apache2 configuration. It does this by creating symlinks\n    within /etc/apache2/mods-enabled. Likewise, a2dismod disables\n    a module by removing those symlinks. It is not an error to enable a module\n    which is already enabled, or to disable one which is already disabled.\nNote that many modules have, in addition to a .load file, an\n    associated .conf file. Enabling the module puts the configuration directives\n    in the .conf file as directives into the main server context of\n    apache2.\n\n\nOPTIONS¶\n\n-q, --quiet\nDon't show informative messages.\n-m, --maintmode\nEnables the maintainer mode, that is the program invocation is effectuated\n      automatically by a maintainer script. This switch should not be used by\n      end users.\n-p, --purge\nWhen disabling a module, purge all traces of the module in the internal\n      state data base.\n\n\n\nEXIT STATUS¶\na2enmod and a2dismod exit with status 0 if all modules are\n  processed successfully, 1 if errors occur, 2 if an invalid option was used.\n\n\nEXAMPLES¶\na2enmod imagemap\n\na2dismod mime_magic\nEnables the mod_imagemap module, and disables the\n    mod_mime_magic module.\n\n\nFILES¶\n\n/etc/apache2/mods-available\nDirectory with files giving information on available modules.\n/etc/apache2/mods-enabled\nDirectory with links to the files in mods-available for enabled\n      modules.\n\n\n\nSEE ALSO¶\napache2ctl(8), a2enconf(8), a2disconf(8).\n\n\nAUTHOR¶\nThis manual page was written by Daniel Stone <daniel@sfarc.net> for the\n  Debian GNU/Linux distribution, as it is a Debian-specific script with the\n  package.\n\n\n\n\n12 October 2006\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\na2dismod.8.en.gz (from apache2 2.4.38-3+deb10u3)\n\n\n\n\nSource last updated:\n\n\n2019-04-07T18:15:40Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:05:56Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# a2dismod\n\n> Disable an Apache module on Debian-based OSes.\n> More information: <https://manpages.debian.org/buster/apache2/a2dismod.8.en.html>.\n\n- Disable a module:\n\n`sudo a2dismod {{module}}`\n\n- Don't show informative messages:\n\n`sudo a2dismod --quiet {{module}}`\n"
 },
 {
   "command": "lvresize",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lvresize\n\n> Change the size of a logical volume.\n\n- Change a volume's size to 120GB:\n\n`lvresize -L {{120G}} {{logical_volume}}`\n\n- Reduce a volume's size by 120GB as well as the underlying filesystem:\n\n`lvresize --size -{{120G}} -r {{logical_volume}}`\n\n- Increase a volume's size to 100% of the free phyiscal volume space:\n\n`lvresize --size {{100}}%FREE {{logical_volume}}`\n"
 },
 {
   "command": "yank",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# yank\n\n> Read input from `stdin` and display a selection interface that allows a field to be selected and copied to the clipboard.\n\n- Yank using the default delimiters (\\f, \\n, \\r, \\s, \\t):\n\n`{{sudo dmesg}} | yank`\n\n- Yank an entire line:\n\n`{{sudo dmesg}} | yank -l`\n\n- Yank using a specific delimiter:\n\n`{{echo hello=world}} | yank -d {{=}}`\n\n- Only yank fields matching a specific pattern:\n\n`{{ps ux}} | yank -g {{\"[0-9]+\"}}`\n"
 },
 {
   "command": "dpkg",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dpkg\n\n> Debian package manager.\n\n- Install a package:\n\n`dpkg -i {{path/to/file.deb}}`\n\n- Remove a package:\n\n`dpkg -r {{package_name}}`\n\n- List installed packages:\n\n`dpkg -l {{pattern}}`\n\n- List package contents:\n\n`dpkg -L {{package_name}}`\n\n- List contents of a local package file:\n\n`dpkg -c {{path/to/file.deb}}`\n\n- Find out which package owns a file:\n\n`dpkg -S {{filename}}`\n"
 },
 {
   "command": "mountpoint",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mountpoint\n\n> Test if a directory is a filesystem mountpoint.\n\n- Check if a directory is a mountpoint:\n\n`mountpoint {{path/to/directory}}`\n\n- Check if a directory is a mountpoint without showing any output:\n\n`mountpoint -q {{path/to/directory}}`\n\n- Show major/minor numbers of a mountpoint's filesystem:\n\n`mountpoint --fs-devno {{path/to/directory}}`\n"
 },
 {
   "command": "edit",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# edit\n\n> An alias to a `run-mailcap`'s action edit.\n> Originally `run-mailcap` is used to process/edit mime-type/file.\n\n- Edit action can be used to view any file on default mailcap explorer:\n\n`edit {{filename}}`\n\n- With `run-mailcap`:\n\n`run-mailcap --action=edit {{filename}}`\n"
 },
 {
   "command": "apt-get",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apt-get\n\n> Debian and Ubuntu package management utility.\n> Search for packages using `apt-cache`.\n\n- Update the list of available packages and versions (it's recommended to run this before other `apt-get` commands):\n\n`apt-get update`\n\n- Install a package, or update it to the latest available version:\n\n`apt-get install {{package}}`\n\n- Remove a package:\n\n`apt-get remove {{package}}`\n\n- Remove a package and its configuration files:\n\n`apt-get purge {{package}}`\n\n- Upgrade all installed packages to their newest available versions:\n\n`apt-get upgrade`\n\n- Clean the local repository - removing package files (.deb) from interrupted downloads that can no longer be downloaded:\n\n`apt-get autoclean`\n\n- Remove all packages that are no longer needed:\n\n`apt-get autoremove`\n\n- Upgrade installed packages (like `upgrade`), but remove obsolete packages and install additional packages to meet new dependencies:\n\n`apt-get dist-upgrade`\n"
 },
 {
   "command": "kpartx",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# kpartx\n\n> Create device maps from partition tables.\n\n- Add partition mappings:\n\n`kpartx -a {{whole_disk.img}}`\n\n- Delete partition mappings:\n\n`kpartx -d {{whole_disk.img}}`\n\n- List partition mappings:\n\n`kpartx -l {{whole_disk.img}}`\n"
 },
 {
   "command": "hardinfo",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# hardinfo\n\n> Show hardware information in GUI window.\n\n- Start hardinfo:\n\n`hardinfo`\n\n- Print report to standard output:\n\n`hardinfo -r`\n\n- Save report to HTML file:\n\n`hardinfo -r -f html > hardinfo.html`\n"
 },
 {
   "command": "strace",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# strace\n\n> Troubleshooting tool for tracing system calls.\n\n- Start tracing a specific process by its PID:\n\n`strace -p {{pid}}`\n\n- Trace a process and filter output by system call:\n\n`strace -p {{pid}} -e {{system_call_name}}`\n\n- Count time, calls, and errors for each system call and report a summary on program exit:\n\n`strace -p {{pid}} -c`\n\n- Show the time spent in every system call:\n\n`strace -p {{pid}} -T`\n\n- Start tracing a program by executing it:\n\n`strace {{program}}`\n\n- Start tracing file operations of a program:\n\n`strace -e trace=file {{program}}`\n"
 },
 {
   "command": "avahi-browse",
   "doc_url": "https://www.avahi.org/",
   "doc_text": "\n\navahi - mDNS/DNS-SD\n\n\nWelcome to Avahi\nQuick Links\n\ndoxygen documentation\ndownload: avahi 0.8\ndownload: avahi 0.7\ngithub: lathiat/avahi (bug reports & pull requests)\ngithub: lathiat/nss-mdns (bug reports & pull requests)\nmailing list\n\nWhat is Avahi?\nAvahi is a system which facilitates service discovery on a local network via the mDNS/DNS-SD protocol suite. This enables you to plug your laptop or computer into a network and instantly be able to view other people who you can chat with, find printers to print to or find files being shared. Compatible technology is found in Apple MacOS X (branded \"Bonjour\" and sometimes \"Zeroconf\").\nAvahi is primarily targetted at Linux systems and ships by default in most distributions.  It is not ported to Windows at this stage, but will run on many other BSD-like systems.  The primary API is D-Bus and is required for usage of most of Avahi, however services can be published using an XML service definition placed in /etc/avahi/services.\nSee also the nss-mdns project, which allows hostname lookup of *.local hostnames via mDNS in all system programs using nsswitch\nDefinition at Wikipedia\nNews\nFebruary 2020\n * 2020-02-18: We have released Avahi 0.8! This release has a number of new features and a D-Bus/avahi-core API change related to racing signals with D-Bus object creation.  For full details of all bug fixes, changes and new features check out the release page or docs/NEWS!\nJuly 2017\n * 2017-07-10: We have released Avahi 0.7! The main new feature of this release is the ability to encode binary (non-text) TXT records into XML service definitions (/etc/avahi/services).  For full details of all bug fixes, changes and new features check the release page\nFebruary 2016\n * 2016-02-16: We have released Avahi 0.6.32! This is a bugfix release with a couple of minor new configuration options or default changes.  Full details and downloads at the link.  Please file any issues or pull requests through github.com/lathiat/avahi\nOctober 2015\n * 2015-10-10: We have a release candidate, 0.6.32-rc! This is mostly a bugfix release, see the NEWS (Change Log).  This is intended for release soon, please file any issues you notice through github.com/lathiat/avahi.\n\nFebruary 2012\n * 2012-02-15: We have released Avahi 0.6.31! This is a bugfix release.\n\nApril 2011\n * 2011-04-04: We have released Avahi 0.6.30! This is a bugfix release.\n\nMarch 2011\n * 2011-03-09: We have released Avahi 0.6.29! This is a bugfix release and fixes a minor security issue.\n\nAugust 2010\n * 2010-10-05: We have released Avahi 0.6.28! This is a bugfix release.\n\nJuly 2010\n * 2010-07-13: We have released Avahi 0.6.27! This is a bugfix release. \n\nJune 2010\n * 2010-06-29: We have released Avahi 0.6.26! This is a bugfix release and fixes a minor security issue.\n\n\n",
   "man_entry": "",
   "tldr_summary": "# avahi-browse\n\n> Displays services and hosts exposed on the local network via mDNS/DNS-SD.\n> Avahi is compatible with Bonjour (Zeroconf) found in Apple devices.\n> More information: <https://www.avahi.org/>.\n\n- List all services available on the local network along with their addresses and ports while ignoring local ones:\n\n`avahi-browse --all --resolve --ignore-local`\n\n- List all domains:\n\n`avahi-browse --browse-domains`\n\n- Limit the search to a particular domain:\n\n`avahi-browse --all --domain={{domain}}`\n"
 },
 {
   "command": "chfn",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nCHPASS(1)\t\t  BSD General Commands Manual\t\t     CHPASS(1)\n\nNAME\n     chpass, chfn, chsh -- add or change user database information\n\nSYNOPSIS\n     chpass [-l location] [-u authname] [-s newshell] [user]\n\nDESCRIPTION\n     The chpass utility allows editing of the user database information asso-\n     ciated with user or, by default, the current user.\n\n     The chpass utility cannot change the user's password on Open Directory\n     systems.  Use the passwd(1) utility instead.\n\n     The chfn, and chsh utilities behave identically to chpass.  (There is\n     only one program.)\n\n     The information is formatted and supplied to an editor for changes.\n\n     Only the information that the user is allowed to change is displayed.\n\n     The options are as follows:\n\n     -l location\n\t     If not specified, chpass will perform a search for the user\n\t     record on all available Open Directory nodes.  When specified,\n\t     chpass will edit the user record on the directory node at the\n\t     given location.\n\n     -u authname\n\t     The user name to use when authenticating to the directory node\n\t     containing the user.\n\n     -s newshell\n\t     Attempt to change the user's shell to newshell.\n\n     Possible display items are as follows:\n\n\t   Login:\t       user's login name\n\t   Uid: \t       user's login\n\t   Gid: \t       user's login group\n\t   Generated uid:      user's UUID\n\t   Full Name:\t       user's real name\n\t   Office Location:    user's office location\n\t   Office Phone:       user's office phone\n\t   Home Phone:\t       user's home phone\n\t   Home Directory:     user's home directory\n\t   Shell:\t       user's login shell\n\n     The login field is the user name used to access the computer account.\n\n     The uid field is the number associated with the login field.  Both of\n     these fields should be unique across the system (and often across a group\n     of systems) as they control file access.\n\n     While it is possible to have multiple entries with identical login names\n     and/or identical user id's, it is usually a mistake to do so.  Routines\n     that manipulate these files will often return only one of the multiple\n     entries, and that one by random selection.\n\n     The group field is the group that the user will be placed in at login.\n     Since BSD supports multiple groups (see groups(1)) this field currently\n     has little special meaning.  This field may be filled in with either a\n     number or a group name (see group(5)).\n\n     The generated uid field is the globally unique identifier (UUID) for the\n     user.  The full name field contains the full name of the user.\n\n     The user's home directory is the full UNIX path name where the user will\n     be placed at login.\n\n     The shell field is the command interpreter the user prefers.  If the\n     shell field is empty, the Bourne shell, /bin/sh, is assumed.  When alter-\n     ing a login shell, and not the super-user, the user may not change from a\n     non-standard shell or to a non-standard shell.  Non-standard is defined\n     as a shell not found in /etc/shells.\n\n     The picture field is the path to a picture to be displayed for the user.\n\nOPEN DIRECTORY\n     User database entries are under the control of DirectoryService(8) and\n     may be physically located in many different places, including the local\n     Directory Service node, and remote LDAP servers.  This version of chpass\n     uses Open Directory to change user database information.  It does not\n     interact with the historic flat file database /etc/master.passwd\n\nENVIRONMENT\n     The vi(1) editor will be used unless the environment variable EDITOR is\n     set to an alternate editor.  When the editor terminates, the information\n     is re-read and used to update the user database itself.  Only the user,\n     or the super-user, may edit the information associated with the user.\n\nFILES\n     /etc/chpass.XXXXXX  temporary copy of the data to edit\n     /etc/shells\t the list of approved shells\n\nSEE ALSO\n     login(1), passwd(1), getusershell(3), passwd(5)\n\n     Robert Morris and Ken Thompson, UNIX Password security.\n\nHISTORY\n     The chpass utility appeared in 4.3BSD-Reno.\n\nBSD\t\t\t       December 30, 1993\t\t\t   BSD\n",
   "tldr_summary": "# chfn\n\n> Update `finger` info for a user.\n\n- Update a user's \"Name\" field in the output of `finger`:\n\n`chfn -f {{new_display_name}} {{username}}`\n\n- Update a user's \"Office Room Number\" field for the output of `finger`:\n\n`chfn -o {{new_office_room_number}} {{username}}`\n\n- Update a user's \"Office Phone Number\" field for the output of `finger`:\n\n`chfn -p {{new_office_telephone_number}} {{username}}`\n\n- Update a user's \"Home Phone Number\" field for the output of `finger`:\n\n`chfn -h {{new_home_telephone_number}} {{username}}`\n"
 },
 {
   "command": "tlp",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# tlp\n\n> Advanced power management for Linux. See `tlp-stat` page for additional information.\n\n- Apply settings (according to the actual power source):\n\n`sudo tlp start`\n\n- Apply battery settings (ignoring the actual power source):\n\n`sudo tlp bat`\n\n- Apply AC settings (ignoring the actual power source):\n\n`sudo tlp ac`\n"
 },
 {
   "command": "shutdown",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nSHUTDOWN(8)\t\t  BSD System Manager's Manual\t\t   SHUTDOWN(8)\n\nNAME\n     shutdown -- close down the system at a given time\n\nSYNOPSIS\n     shutdown [-] [-h [-u] | -r | -s | -k] [-o [-n]] time\n\t      [warning-message ...]\n\nDESCRIPTION\n     The shutdown utility provides an automated shutdown procedure for super-\n     users to nicely notify users when the system is shutting down, saving\n     them from system administrators, hackers, and gurus, who would otherwise\n     not bother with such niceties.\n\n     The following options are available:\n\n     -h      The system is halted at the specified time.\n\n     -k      Kick everybody off.  The -k option does not actually halt the\n\t     system, but leaves the system multi-user with logins disabled\n\t     (for all but super-user).\n\n     -n      If the -o is specified, prevent the file system cache from being\n\t     flushed by passing -n option to halt(8) or reboot(8).  This\n\t     option should probably not be used.\n\n     -o      If -h or -r is specified, shutdown will execute halt(8) or\n\t     reboot(8) instead of sending a signal to launchd(8).\n\n     -r      The system is rebooted at the specified time.\n\n     -s      The system is put to sleep at the specified time.\n\n     -u      The system is halted up until the point of removing system power,\n\t     but waits before removing power for 5 minutes so that an external\n\t     UPS (uninterruptible power supply) can forcibly remove power.\n\t     This simulates a dirty shutdown to permit a later automatic power\n\t     on. OS X uses this mode automatically with supported UPSs in\n\t     emergency shutdowns.\n\n     time    Time is the time at which shutdown will bring the system down and\n\t     may be the word now (indicating an immediate shutdown) or specify\n\t     a future time in one of two formats: +number, or yymmddhhmm,\n\t     where the year, month, and day may be defaulted to the current\n\t     system values.  The first form brings the system down in number\n\t     minutes and the second at the absolute time specified.\n\n     warning-message\n\t     Any other arguments comprise the warning message that is broad-\n\t     cast to users currently logged into the system.\n\n     -\t     If `-' is supplied as an option, the warning message is read from\n\t     the standard input.\n\n     At intervals, becoming more frequent as apocalypse approaches and start-\n     ing at ten hours before shutdown, warning messages are displayed on the\n     terminals of all users logged in.\n\n     At shutdown time a message is written to the system log, containing the\n     time of shutdown, the person who initiated the shutdown and the reason.\n     Corresponding signal is then sent to launchd(8) to respectively halt,\n     reboot or bring the system down to single-user state (depending on the\n     above options).\n\n     A scheduled shutdown can be canceled by killing the shutdown process (a\n     SIGTERM should suffice).\n\nSIGTERM TO SIGKILL INTERVAL\n     Upon shutdown, all running processes are sent a SIGTERM followed by a\n     SIGKILL.  The SIGKILL will follow the SIGTERM by an intentionally inde-\n     terminate period of time.\tPrograms are expected to take only enough time\n     to flush all dirty data and exit.\tDevelopers are encouraged to file a\n     bug with the OS vendor, should they encounter an issue with this func-\n     tionality.\n\nSEE ALSO\n     kill(1), login(1), wall(1), halt(8), launchd(8), reboot(8)\n\nBACKWARD COMPATIBILITY\n     The hours and minutes in the second time format may be separated by a\n     colon (``:'') for backward compatibility.\n\nHISTORY\n     The shutdown utility appeared in 4.0BSD.\n\nBSD\t\t\t       December 11, 1998\t\t\t   BSD\n",
   "tldr_summary": "# shutdown\n\n> Shutdown and reboot the system.\n\n- Power off (halt) immediately:\n\n`shutdown -h now`\n\n- Reboot immediately:\n\n`shutdown -r now`\n\n- Reboot in 5 minutes:\n\n`shutdown -r +{{5}} &`\n\n- Shutdown at 1:00 pm (Uses 24h clock):\n\n`shutdown -h 13:00`\n\n- Cancel a pending shutdown/reboot operation:\n\n`shutdown -c`\n"
 },
 {
   "command": "phpquery",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# phpquery\n\n> PHP extension manager for Debian-based OSes.\n\n- List available PHP versions:\n\n`sudo phpquery -V`\n\n- List available SAPIs for PHP 7.3:\n\n`sudo phpquery -v {{7.3}} -S`\n\n- List enabled extensions for PHP 7.3 with the cli SAPI:\n\n`sudo phpquery -v {{7.3}} -s {{cli}} -M`\n\n- Check if the json extension is enabled for PHP 7.3 with the apache2 SAPI:\n\n`sudo phpquery -v {{7.3}} -s {{apache2}} -m {{json}}`\n"
 },
 {
   "command": "ul",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nUL(1)\t\t\t  BSD General Commands Manual\t\t\t UL(1)\n\nNAME\n     ul -- do underlining\n\nSYNOPSIS\n     ul [-i] [-t terminal] [file ...]\n\nDESCRIPTION\n     The ul utility reads the named files (or standard input if none are\n     given) and translates occurrences of underscores to the sequence which\n     indicates underlining for the terminal in use, as specified by the envi-\n     ronment variable TERM.  The file /etc/termcap is read to determine the\n     appropriate sequences for underlining.  If the terminal is incapable of\n     underlining, but is capable of a standout mode then that is used instead.\n     If the terminal can overstrike, or handles underlining automatically, ul\n     degenerates to cat(1).  If the terminal cannot underline, underlining is\n     ignored.\n\n     The following options are available:\n\n     -i      Underlining is indicated by a separate line containing appropri-\n\t     ate dashes `-'; this is useful when you want to look at the\n\t     underlining which is present in an nroff(1) output stream on a\n\t     crt-terminal.\n\n     -t terminal\n\t     Overrides the terminal type specified in the environment with\n\t     terminal.\n\nENVIRONMENT\n     The LANG, LC_ALL, LC_CTYPE and TERM environment variables affect the exe-\n     cution of ul as described in environ(7).\n\nEXIT STATUS\n     The ul utility exits 0 on success, and >0 if an error occurs.\n\nSEE ALSO\n     colcrt(1), man(1), nroff(1)\n\nHISTORY\n     The ul command appeared in 3.0BSD.\n\nBUGS\n     The nroff(1) command usually outputs a series of backspaces and under-\n     lines intermixed with the text to indicate underlining.  No attempt is\n     made to optimize the backward motion.\n\nBSD\t\t\t\tAugust 4, 2004\t\t\t\t   BSD\n",
   "tldr_summary": "# ul\n\n> Performs the underlining of a text.\n> Each character in a given string must be underlined separately.\n\n- Display the contents of the file with underlines where applicable:\n\n`ul {{file.txt}}`\n\n- Display the contents of the file with underlines made of dashes `-`:\n\n`ul -i {{file.txt}}`\n"
 },
 {
   "command": "wmctrl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# wmctrl\n\n> CLI for X Window Manager.\n\n- List all windows, managed by the window manager:\n\n`wmctrl -l`\n\n- Switch to the first window whose (partial) title matches:\n\n`wmctrl -a {{window_title}}`\n\n- Move a window to the current workspace, raise it and give it focus:\n\n`wmctrl -R {{window_title}}`\n\n- Switch to a workspace:\n\n`wmctrl -s {{workspace_number}}`\n\n- Select a window and toggle fullscreen:\n\n`wmctrl -r {{window_title}} -b toggle,fullscreen`\n\n- Select a window a move it to a workspace:\n\n`wmctrl -r {{window_title}} -t {{workspace_number}}`\n"
 },
 {
   "command": "wall",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nWALL(1) \t\t  BSD General Commands Manual\t\t       WALL(1)\n\nNAME\n     wall -- write a message to users\n\nSYNOPSIS\n     wall [-g group] [file]\n\nDESCRIPTION\n     The wall utility displays the contents of file or, by default, its stan-\n     dard input, on the terminals of all currently logged in users.\n\n     Only the super-user can write on the terminals of users who have chosen\n     to deny messages or are using a program which automatically denies mes-\n     sages.\n\n     -g      Send messages to users in this group.  This option may be speci-\n\t     fied multiple times, and any user in any of the specified groups\n\t     will receive the message.\n\nSEE ALSO\n     mesg(1), talk(1), write(1), shutdown(8)\n\nHISTORY\n     A wall command appeared in PWB UNIX.\n\nBUGS\n     The sender's LC_CTYPE setting is used to determine which characters are\n     safe to write to a terminal, not the receiver's (which wall has no way of\n     knowing).\n\n     The wall utility does not recognize multibyte characters.\n\nBSD\t\t\t\t July 17, 2004\t\t\t\t   BSD\n",
   "tldr_summary": "# wall\n\n> Write a message on the terminals of users currently logged in.\n\n- Send a message:\n\n`echo \"{{message}}\" | wall`\n\n- Send a message from a file:\n\n`wall {{file}}`\n\n- Send a message with timeout (default 300):\n\n`wall -t {{seconds}} {{file}}`\n"
 },
 {
   "command": "runuser",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# runuser\n\n> Run commands as a specific user and group without asking for password (needs root privileges).\n\n- Run command as a different user:\n\n`runuser {{user}} -c '{{command}}'`\n\n- Run command as a different user and group:\n\n`runuser {{user}} -g {{group}} -c '{{command}}'`\n\n- Start a login shell as a specific user:\n\n`runuser {{user}} -l`\n\n- Specify a shell for running instead of the default shell (also works for login):\n\n`runuser {{user}} -s {{/bin/sh}}`\n\n- Preserve the entire environment of root (only if `--login` is not specified):\n\n`runuser {{user}} --preserve-environment -c '{{command}}'`\n"
 },
 {
   "command": "zenity",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# zenity\n\n> Display dialogs from the command line/shell scripts.\n> Return user-inserted values or 1 if error.\n\n- Display the default question dialog:\n\n`zenity --question`\n\n- Display an info dialog displaying the text \"Hello!\":\n\n`zenity --info --text=\"{{Hello!}}\"`\n\n- Display a name/password form and output the data separated by \";\":\n\n`zenity --forms --add-entry=\"{{Name}}\" --add-password=\"{{Password}}\" --separator=\"{{;}}\"`\n\n- Display a file selection form in which the user can only select directories:\n\n`zenity --file-selection --directory`\n\n- Display a progress bar which updates its message every second and show a progress percent:\n\n`{{(echo \"#1\"; sleep 1; echo \"50\"; echo \"#2\"; sleep 1; echo \"100\")}} | zenity --progress`\n"
 },
 {
   "command": "pulseaudio",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pulseaudio\n\n> The pulseaudio sound system daemon and manager.\n\n- Check if pulseaudio is running (a non-zero exit code means it is not running):\n\n`pulseaudio --check`\n\n- Start the pulseaudio daemon in the background:\n\n`pulseaudio --start`\n\n- Kill the running pulseaudio daemon:\n\n`pulseaudio --kill`\n\n- List available modules:\n\n`pulseaudio --dump-modules`\n\n- Load a module into the currently running daemon with the specified arguments:\n\n`pulseaudio --load=\"{{module_name}} {{arguments}}\"`\n"
 },
 {
   "command": "taskset",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# taskset\n\n> Get or set a process' CPU affinity or start a new process with a defined CPU affinity.\n\n- Get a running process' CPU affinity by PID:\n\n`taskset --pid --cpu-list {{pid}}`\n\n- Set a running process' CPU affinity by PID:\n\n`taskset --pid --cpu-list {{cpu_id}} {{pid}}`\n\n- Start a new process with affinity for a single CPU:\n\n`taskset --cpu-list {{cpu_id}} {{command}}`\n\n- Start a new process with affinity for multiple non-sequential CPUs:\n\n`taskset --cpu-list {{cpu_id_1}} {{cpu_id_2}} {{cpu_id_3}}`\n\n- Start a new process with affinity for CPUs 1 through 4:\n\n`taskset --cpu-list {{cpu_id_1}},{{cpu_id_4}}`\n"
 },
 {
   "command": "check-support-status",
   "doc_url": "https://manpages.debian.org/buster/debian-security-support/check-support-status.1.en.html",
   "doc_text": "\n\n\n\ncheck-support-status(1) — debian-security-support — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / debian-security-support\n     \n     \n     \n     / check-support-status(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nVERSION\n\n\nSYNOPSIS\n\n\nOPTIONS\n\n\nBUGS\n\n\nAUTHOR\n\n\nCOPYRIGHT &amp; LICENSE\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2020.06.21~deb10u1\n\n\ntesting 2020.07.12\n\n\nunstable 1:11+2020.09.12\n\n\n\n\n\n\nScroll to navigation\n\n\n\nCHECK-SUPPORT-STAT(1)\n \nCHECK-SUPPORT-STAT(1)\n\n\n\n\nNAME¶\ncheck-support-status - check installed packages for security support\n  (debian-security-support)\n\n\nVERSION¶\nVersion 2020.06.21~deb10u1\n\n\nSYNOPSIS¶\nSearch for packages whose support is limited, has already ended or will end\n  earlier than the distribution’s end of life:\n\n    check-support-status\n\nSearch for packages with ended support from a custom list,\n    reporting each package only once:\n\n    check-support-status \\\n        --type ended \\\n        --status-db /path/to/status-db \\\n        --list /path/to/security-support-ended\n\n\n\nOPTIONS¶\n--list FILE\nUse the given file as the database of packages whose\n  support ends at a particular date or that is limited by specific conditions.\n  The file format is plain text in columns, separated by one or more whitespace\n  characters.\nFor --type earlyend:\n\n•source package name\n\n•last package version that will be supported\n\n•the date support will end\n\n•the rest (optional): details, and/or a URL for\n  further information.\nFor --type ended:\n\n•source package name\n\n•last package version that is supported\n\n•the date support was ended\n\n•the rest (optional): details, and/or a URL for\n  further information.\nFor --type limited:\n\n•source package name\n\n•the rest (optional): details, and/or a URL for\n  further information.\nIf no \"--list\" is provided, the script is run for\n    limited and date-defined end of support, using the lists shipped in the\n    package.\nBy default, check-support-status evaluates the status of the\n    packages according to the Debian version where it runs upon. This behavior\n    can be modified using the DEBIAN_VERSION environment variable, e.g.\n\n\nDEBIAN_VERSION=9 check-support-status\n\n\n\n--no-heading\nSkips printing a headline.\n--status-db FILE\nUse the given file to record alerts so each affected\n  package is reported only once.\nDefault: No records, any affected package will be reported every\n    time.\n\n--except PACKAGES\nDo not alert for the given binary packages\n  (comma-separated list).\nDefault: Alert for all packages (no exceptions).\n\n--type TYPE\nOne of the following:\n\n•\"earlyend\": Alert for packages whose\n  support will end earlier than the distribution’s.\n\n•\"ended\": Alert for packages where\n  security support has ended.\n\n•\"limited\": Alert for packages where\n  security support is limited.\n\n--version, --Version, -V\nShow the version number and exit.\n\n\nBUGS¶\nInstallations with mixed distributions like half-stable, half-testing are not\n  supported.\n\n\nAUTHOR¶\nChristoph Biedl <debian.axhn@manchmal.in-ulm.de>\n\n\nCOPYRIGHT & LICENSE¶\n\nCopyright (C) 2014 Christoph Biedl <debian.axhn@manchmal.in-ulm.de>\nThis package is free software; you can redistribute it and/or\nmodify it under the terms of the GNU General Public License\nversion 2 as published by the Free Software Foundation.\nThis package is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program. If not, see <http://www.gnu.org/licenses/>\nOn Debian systems, the complete text of the GNU General Public\nLicense version 2 can be found in\n\"/usr/share/common-licenses/GPL-2\".\n\n\n\n\n\n\n07/10/2020\n \n\n\n\n\n\n\n\n\n\nSource file:\n\n\ncheck-support-status.1.en.gz (from debian-security-support 2020.06.21~deb10u1)\n\n\n\n\nSource last updated:\n\n\n2020-07-10T17:29:25Z\n\n\n\n\nConverted to HTML:\n\n\n2020-09-12T15:17:52Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# check-support-status\n\n> Identify installed Debian packages for which support has had to be limited or prematurely ended.\n> More information: <https://manpages.debian.org/buster/debian-security-support/check-support-status.1.en.html>.\n\n- Display packages whose support is limited, has already ended or will end earlier than the distribution's end of life:\n\n`check-support-status`\n\n- Display only packages whose support has ended:\n\n`check-support-status --type {{ended}}`\n\n- Skip printing a headline:\n\n`check-support-status --no-heading`\n"
 },
 {
   "command": "extundelete",
   "doc_url": "http://extundelete.sourceforge.net",
   "doc_text": "\n\n\n\n\nextundelete: An ext3 and ext4 file undeletion utility\n\n\n\nAbout extundelete\n\nextundelete is a utility that can recover deleted files from an ext3 or ext4 partition.\nThe ext3 and ext4 file systems are the most common default file systems in Linux distributions like Mint, Mageia, or Ubuntu.\nextundelete uses information stored in the partition's journal to attempt to recover a file that has been deleted from the partition.\nThere is no guarantee that any particular file will be able to be undeleted, so always try to have a good backup system in place, or at least put one in place after recovering your files!\n\nDownload the latest version\n\nThe latest version of extundelete is 0.2.4, which was released in January 2013.\nDownload extundelete from its sourceforge project site.\nFor brief descriptions of the various options the program understands, see the extundelete command-line options summary.\nBinary packages are available for some distibutions, but may not have the latest version, which could contain improvements to make it more likely to recover a deleted file.\nTo take advantage of the latest features and bug fixes, read the notes on compiling and using the program below.\nextundelete has been recovering deleted files since April 2009, when the first version was released.\n\nWhy use extundelete?\n\nextundelete is a complex program that makes data recovery from an ext3 or ext4 partition simple.\nMost people are able to recover their files by running one command from the terminal, as explained in the next section.\nextundelete was the first program able to restore both the contents and the file name of a deleted file on an ext4 partition.\next3grep was the first program to use the filesystem's journal to recover data, and much of its code is shared by extundelete, but ext3grep only worked for ext3 partitions and could take hours to start recovering files if the files were on a large partition.\nextundelete, by contrast, starts recovering files immediately after parsing the filesystem's journal, usually within a minute or two after starting the program.\next4magic is a program to recover files that was based on extundelete, and has a slightly different set of features and limitations.\nextundelete makes heavy use of the ext2fs library, which allows it to automatically support many features of ext3 and ext4 file systems.\n\nDocumentation\nHow to compile and install extundelete\n\nTo compile and install this program, you must first install the binary and development packages for e2fsprogs (called libext2fs-devel on Mageia, or e2fslibs-dev on Ubuntu, or e2fsprogs-devel on Fedora).\nextundelete requires libext2fs version 1.39 or newer to run, but for ext4 support, ensure you have e2fsprogs version 1.41 or newer (which may be found by running the command 'dumpe2fs' and noting the version it outputs).\nYou must have g++ and GNU make to compile the program.\nYou can install those with the package called build-essential on Ubuntu, or gcc-c++ and make on Fedora, or gcc-c++ and make on Mageia.\n\n\nTo compile the program, simply enter the command\n“./configure” from the directory the tar.bz2 file was extracted to.\nThe configure step ensures all the necessary programs to install and run extundelete have been installed.\nThen, run “make” from the same directory to compile the program.\nThe command will generate an executable file called “extundelete” in the “src” directory.\nYou can the run “make install” to install the program in the /usr/bin directory, or it could be run from the “src” directory without this step.\n\nHow to use extundelete\n\nextundelete is designed to undelete files from an unmounted partition to a separate (mounted) partition.\nextundelete will restore any files it finds to a subdirectory of the current directory named “RECOVERED_FILES”.\nTo run the program, type “extundelete --help” to see various options available to you.\n\n\nTypical usage to restore all deleted files from a partition looks like this:\n$ extundelete /dev/sda4 --restore-all\n\n\nFor an example of running the program, see the file “README” included with the program.\nIt is normal for extundelete to appear to pause (while taking up a lot of cpu cycles) for a minute or longer; during this time, the program is reading the directory structure and looking for a recoverable file within it.  To restore important files quickly, you may use the --restore-file, --restore-files, or --restore-directory options.\n\n\nIf you have questions or comments about using extundelete or how to recover your lost files, or to report a success/failure of your recovery efforts with this utility, send a note to the extundelete mailing list.\n\nWhat to do if you've deleted a file (or multiple files)\n\nDo not save any more data to the partition with the deleted file for any reason!  Doing so may overwrite your deleted data and sabotage any recovery effort.  Many background processes will periodically write to disk, so work quickly until the partition is unmounted.\n\n\nIf you think the file may be still open by some program (for example, if it is a movie file currently being played by a movie player), and you know the filename, then first follow this procedure:\n\n$ lsof|grep \"/path/to/file\"\nprogname    5559     user    22r    REG    8,5  1282410   1294349  /path/to/file\n\nNotice the number in the second column is 5559 and the number in the fourth column is 22.  The command to restore that file is:\n\n$ cp /proc/5559/fd/22  restored.file\n\n\n\nIf lsof doesn't find your file, then immediately remount the partition read-only:\n\n$ mount -o remount,ro /dev/partition\nor unmount the partition:\n $ umount /dev/partition\nTypically, you would replace \"partition\" in the above examples by a device name like \"sda4\" or \"hdb7\".\nWhen either of those commands successfully completes, you can now take the next steps leisurely - you will no longer make anything worse by waiting.  If you would like to make a backup of your partition, you may do so by a command such as:\n$ dd bs=4M if=/dev/partition of=partition.backup\n\n\nNow is the time to run extundelete, which you may safely run on either the backup you may have made above or the raw device, as long as it is not mounted (or mounted read-only).\nSee the section above for details on how to use this program.\nIf extundelete was unable to recover your files, then you may try to recover your files with debugfs, a tool included with the e2fsprogs package.\nIf you unmounted the partition before the file system got a chance to fully delete the files you are interested in, running debugfs may allow you to recover the files before the file system deletes them (which it may do the next time the partition is mounted).\nThe 'dump' and 'rdump' commands in debugfs may be useful to you for these purposes.\nIf you were unable to recover your files using extundelete or debugfs, then you may try to recover your files with ext3grep or ext4magic.\nThe generation of ext3grep's stage2 cache file depends on the size and speed of your hard drive's partition, with typical speeds close to one minute for every 2 GB (30 s per GB, or 8 hours per TB).\n\n\nIf the above options didn't recover your files, then you may try a program that searches for identifying patterns throughout the entire partition, like foremost, scalpel, or Photorec.\next3grep's --search options may also be used for this purpose.\n\next3/4 filesystem details\n\nThis section lists resources about the extended filesystem families (ext2/3/4), which will be useful for those wanting to understand more about how the filesystem functions and how extundelete is able to undelete a file.\nAlso note that the ext3grep link provides an example of advanced usage of ext3grep, which can help explain how to use extundelete to comprehensively search for an important deleted file, as both programs have many features in common.\n\n\n\nInformation about the ext2 filesystem\n\n\ne2fsprogs: the standard utilities for ext2/3/4 filesystems\n\n\nCarlo Wood's explanation of the ext3 filesystem and ext3grep\n\n\nWhy recovering a deleted ext3 file is difficult\n\n\nHow extundelete works\n\nextundelete uses some concepts and code first shown to be successful by the ext3grep program.\nextundelete is able to recover the contents of an inode by searching the file system's journal for an old copy of that inode.\nIt then uses that information to determine the file's location within the file system.\nThen, extundelete reads the corresponding data and copies it to a file in the recovery directory.\n\n\nextundelete is able to match the inode number of a file to a file name by searching the deleted entries in a directory, which are often left behind after deleting the file.\nIf the deleted entry does not exist in the directory in the file system, extundelete will look for a match in older copies which are still in the journal.\n\nCurrent abilities of extundelete\n\n\nextundelete is able to undelete a file from an ext3 filesystem or an ext4 file system, as long as the ext4 filesystem has a journal.\n\n\nextundelete will not restore hardlinks or softlinks, but will restore the file a link points to.\n\n\nextundelete will not restore extended attributes.\n\n\nIf you run in to a problem that results in the program not working properly, please send a note to the mailing list, and it will likely be fixed in the next version.\nFor a complete example of how to use extundelete, see the README file.\n\n\nOther extundelete links\n\n\nextundelete SourceForge project page\n\n\nextundelete mailing list - Send a message here to report your experience with extundelete, or for any other questions or comments about extundelete.\n\n\nextundelete command-line options summary\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# extundelete\n\n> Recover deleted files from ext3 or ext4 partitions by parsing the journal.\n> See also `date` for Unix time information and `umount` for unmounting partitions.\n> More information: <http://extundelete.sourceforge.net>.\n\n- Restore all deleted files inside partition N on device X:\n\n`sudo extundelete {{/dev/sdXN}} --restore-all`\n\n- Restore a file from a path relative to root (Do not start the path with `/`):\n\n`extundelete {{/dev/sdXN}} --restore-file {{path/to/file}}`\n\n- Restore a directory from a path relative to root (Do not start the path with `/`):\n\n`extundelete {{/dev/sdXN}} --restore-directory {{path/to/directory}}`\n\n- Restore all files deleted after January 1st, 2020 (in Unix time):\n\n`extundelete {{/dev/sdXN}} --restore-all --after {{1577840400}}`\n"
 },
 {
   "command": "ethtool",
   "doc_url": "http://man7.org/linux/man-pages/man8/ethtool.8.html",
   "doc_text": "\n\n\n\n\nethtool(8) - Linux manual page\n\n\n\n\n\n\n\n\n\nman7.org > Linux > man-pages\n\n\n\nLinux/UNIX system programming training\n\n\n\n\n\n\nethtool(8) — Linux manual page\n\n\n\n\nNAME | SYNOPSIS | DESCRIPTION | OPTIONS | BUGS | AUTHOR | AVAILABILITY | COLOPHON\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nETHTOOL(8)                 System Manager's Manual                ETHTOOL(8)\n\nNAME          top\n       ethtool - query or control network driver and hardware settings\n\nSYNOPSIS          top\n       ethtool devname\n\n       ethtool -h|--help\n\n       ethtool --version\n\n       ethtool [--debug N] args\n\n       ethtool [--json] args\n\n       ethtool --monitor [ command ] [ devname ]\n\n       ethtool -a|--show-pause devname\n\n       ethtool -A|--pause devname [autoneg on|off] [rx on|off] [tx on|off]\n\n       ethtool -c|--show-coalesce devname\n\n       ethtool -C|--coalesce devname [adaptive-rx on|off]\n              [adaptive-tx on|off] [rx-usecs N] [rx-frames N]\n              [rx-usecs-irq N] [rx-frames-irq N] [tx-usecs N] [tx-frames N]\n              [tx-usecs-irq N] [tx-frames-irq N] [stats-block-usecs N]\n              [pkt-rate-low N] [rx-usecs-low N] [rx-frames-low N]\n              [tx-usecs-low N] [tx-frames-low N] [pkt-rate-high N]\n              [rx-usecs-high N] [rx-frames-high N] [tx-usecs-high N]\n              [tx-frames-high N] [sample-interval N]\n\n       ethtool -g|--show-ring devname\n\n       ethtool -G|--set-ring devname [rx N] [rx-mini N] [rx-jumbo N] [tx N]\n\n       ethtool -i|--driver devname\n\n       ethtool -d|--register-dump devname [raw on|off] [hex on|off] [file\n              name]\n\n       ethtool -e|--eeprom-dump devname [raw on|off] [offset N] [length N]\n\n       ethtool -E|--change-eeprom devname [magic N] [offset N] [length N]\n              [value N]\n\n       ethtool -k|--show-features|--show-offload devname\n\n       ethtool -K|--features|--offload devname feature on|off ...\n\n       ethtool -p|--identify devname [N]\n\n       ethtool -P|--show-permaddr devname\n\n       ethtool -r|--negotiate devname\n\n       ethtool -S|--statistics devname\n\n       ethtool --phy-statistics devname\n\n       ethtool -t|--test devname [offline|online|external_lb]\n\n       ethtool -s devname [speed N] [duplex half|full] [port tp|aui|bnc|mii]\n              [mdix auto|on|off] [autoneg on|off] [advertise N[/M] |\n              advertise mode on|off ...]  [phyad N] [xcvr internal|external]\n              [wol N[/M] | wol p|u|m|b|a|g|s|f|d...]\n              [sopass xx:yy:zz:aa:bb:cc] [master-slave preferred-\n              master|preferred-slave|forced-master|forced-slave] [msglvl\n              N[/M] | msglvl type on|off ...]\n\n       ethtool -n|-u|--show-nfc|--show-ntuple devname\n              [ rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6 |\n              rule N ]\n\n       ethtool -N|-U|--config-nfc|--config-ntuple devname\n              rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6\n              m|v|t|s|d|f|n|r... |\n              flow-type\n              ether|ip4|tcp4|udp4|sctp4|ah4|esp4|ip6|tcp6|udp6|ah6|esp6|sctp6\n              [src xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]]\n              [dst xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]] [proto N [m N]]\n              [src-ip ip-address [m ip-address]] [dst-ip ip-address [m ip-\n              address]] [tos N [m N]] [tclass N [m N]] [l4proto N [m N]]\n              [src-port N [m N]] [dst-port N [m N]] [spi N [m N]]\n              [l4data N [m N]] [vlan-etype N [m N]] [vlan N [m N]]\n              [user-def N [m N]] [dst-\n              mac xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]] [action N]\n              [context N] [loc N] |\n              delete N\n\n       ethtool -w|--get-dump devname [data filename]\n\n       ethtool -W|--set-dump devname N\n\n       ethtool -T|--show-time-stamping devname\n\n       ethtool -x|--show-rxfh-indir|--show-rxfh devname\n\n       ethtool -X|--set-rxfh-indir|--rxfh devname\n              [hkey xx:yy:zz:aa:bb:cc:...]  [start N] [ equal N | weight W0\n              W1 ... | default ] [hfunc FUNC] [context CTX | new] [delete]\n\n       ethtool -f|--flash devname file [N]\n\n       ethtool -l|--show-channels devname\n\n       ethtool -L|--set-channels devname [rx N] [tx N] [other N]\n              [combined N]\n\n       ethtool -m|--dump-module-eeprom|--module-info devname [raw on|off]\n              [hex on|off] [offset N] [length N]\n\n       ethtool --show-priv-flags devname\n\n       ethtool --set-priv-flags devname flag on|off ...\n\n       ethtool --show-eee devname\n\n       ethtool --set-eee devname [eee on|off] [tx-lpi on|off] [tx-timer N]\n              [advertise N]\n\n       ethtool --set-phy-tunable devname [ downshift on|off [count N] ] [\n              fast-link-down on|off [msecs N] ] [ energy-detect-power-down\n              on|off [msecs N] ]\n\n       ethtool --get-phy-tunable devname [downshift] [fast-link-down]\n              [energy-detect-power-down]\n\n       ethtool --get-tunable devname [rx-copybreak] [tx-copybreak] [pfc-\n              prevention-tout]\n\n       ethtool --set-tunable devname [rx-copybreak N] [tx-copybreak N]\n              [pfc-prevention-tout N]\n\n       ethtool --reset devname [flags N] [mgmt] [mgmt-shared] [irq] [irq-\n              shared] [dma] [dma-shared] [filter] [filter-shared] [offload]\n              [offload-shared] [mac] [mac-shared] [phy] [phy-shared] [ram]\n              [ram-shared] [ap] [ap-shared] [dedicated] [all]\n\n       ethtool --show-fec devname\n\n       ethtool --set-fec devname encoding auto|off|rs|baser|llrs [...]\n\n       ethtool -Q|--per-queue devname [queue_mask %x] sub_command ...\n               .\n\n       ethtool --cable-test devname\n\n       ethtool --cable-test-tdr devname [first N] [last N] [step N] [pair N]\n\nDESCRIPTION          top\n       ethtool is used to query and control network device driver and\n       hardware settings, particularly for wired Ethernet devices.\n\n       devname is the name of the network device on which ethtool should\n       operate.\n\nOPTIONS          top\n       ethtool with a single argument specifying the device name prints\n       current settings of the specified device.\n\n       -h --help\n              Shows a short help message.\n\n       --version\n              Shows the ethtool version number.\n\n       --debug N\n              Turns on debugging messages. Argument is interpreted as a\n              mask:\n\n              0x01  Parser information\n\n       --json Output results in JavaScript Object Notation (JSON). Only a\n              subset of options support this. Those which do not will\n              continue to output plain text in the presence of this option.\n\n       -a --show-pause\n              Queries the specified Ethernet device for pause parameter\n              information.\n\n       -A --pause\n              Changes the pause parameters of the specified Ethernet device.\n\n           autoneg on|off\n                  Specifies whether pause autonegotiation should be enabled.\n\n           rx on|off\n                  Specifies whether RX pause should be enabled.\n\n           tx on|off\n                  Specifies whether TX pause should be enabled.\n\n       -c --show-coalesce\n              Queries the specified network device for coalescing\n              information.\n\n       -C --coalesce\n              Changes the coalescing settings of the specified network\n              device.\n\n       -g --show-ring\n              Queries the specified network device for rx/tx ring parameter\n              information.\n\n       -G --set-ring\n              Changes the rx/tx ring parameters of the specified network\n              device.\n\n           rx N   Changes the number of ring entries for the Rx ring.\n\n           rx-mini N\n                  Changes the number of ring entries for the Rx Mini ring.\n\n           rx-jumbo N\n                  Changes the number of ring entries for the Rx Jumbo ring.\n\n           tx N   Changes the number of ring entries for the Tx ring.\n\n       -i --driver\n              Queries the specified network device for associated driver\n              information.\n\n       -d --register-dump\n              Retrieves and prints a register dump for the specified network\n              device.  The register format for some devices is known and\n              decoded others are printed in hex.  When raw is enabled, then\n              ethtool dumps the raw register data to stdout.  If file is\n              specified, then use contents of previous raw register dump,\n              rather than reading from the device.\n\n       -e --eeprom-dump\n              Retrieves and prints an EEPROM dump for the specified network\n              device.  When raw is enabled, then it dumps the raw EEPROM\n              data to stdout. The length and offset parameters allow dumping\n              certain portions of the EEPROM.  Default is to dump the entire\n              EEPROM.\n\n           raw on|off\n\n           offset N\n\n           length N\n\n       -E --change-eeprom\n              If value is specified, changes EEPROM byte for the specified\n              network device.  offset and value specify which byte and it's\n              new value. If value is not specified, stdin is read and\n              written to the EEPROM. The length and offset parameters allow\n              writing to certain portions of the EEPROM.  Because of the\n              persistent nature of writing to the EEPROM, a device-specific\n              magic key must be specified to prevent the accidental writing\n              to the EEPROM.\n\n       -k --show-features --show-offload\n              Queries the specified network device for the state of protocol\n              offload and other features.\n\n       -K --features --offload\n              Changes the offload parameters and other features of the\n              specified network device.  The following feature names are\n              built-in and others may be defined by the kernel.\n\n           rx on|off\n                  Specifies whether RX checksumming should be enabled.\n\n           tx on|off\n                  Specifies whether TX checksumming should be enabled.\n\n           sg on|off\n                  Specifies whether scatter-gather should be enabled.\n\n           tso on|off\n                  Specifies whether TCP segmentation offload should be\n                  enabled.\n\n           ufo on|off\n                  Specifies whether UDP fragmentation offload should be\n                  enabled\n\n           gso on|off\n                  Specifies whether generic segmentation offload should be\n                  enabled\n\n           gro on|off\n                  Specifies whether generic receive offload should be\n                  enabled\n\n           lro on|off\n                  Specifies whether large receive offload should be enabled\n\n           rxvlan on|off\n                  Specifies whether RX VLAN acceleration should be enabled\n\n           txvlan on|off\n                  Specifies whether TX VLAN acceleration should be enabled\n\n           ntuple on|off\n                  Specifies whether Rx ntuple filters and actions should be\n                  enabled\n\n           rxhash on|off\n                  Specifies whether receive hashing offload should be\n                  enabled\n\n       -p --identify\n              Initiates adapter-specific action intended to enable an\n              operator to easily identify the adapter by sight.  Typically\n              this involves blinking one or more LEDs on the specific\n              network port.\n\n           [ N]   Length of time to perform phys-id, in seconds.\n\n       -P --show-permaddr\n              Queries the specified network device for permanent hardware\n              address.\n\n       -r --negotiate\n              Restarts auto-negotiation on the specified Ethernet device, if\n              auto-negotiation is enabled.\n\n       -S --statistics\n              Queries the specified network device for NIC- and driver-\n              specific statistics.\n\n       --phy-statistics\n              Queries the specified network device for PHY specific\n              statistics.\n\n       -t --test\n              Executes adapter selftest on the specified network device.\n              Possible test modes are:\n\n           offline\n                  Perform full set of tests, possibly interrupting normal\n                  operation during the tests,\n\n           online Perform limited set of tests, not interrupting normal\n                  operation,\n\n           external_lb\n                  Perform full set of tests, as for offline, and\n                  additionally an external-loopback test.\n\n       -s --change\n              Allows changing some or all settings of the specified network\n              device.  All following options only apply if -s was specified.\n\n           speed N\n                  Set speed in Mb/s.  ethtool with just the device name as\n                  an argument will show you the supported device speeds.\n\n           duplex half|full\n                  Sets full or half duplex mode.\n\n           port tp|aui|bnc|mii\n                  Selects device port.\n\n           master-slave preferred-master|preferred-slave|forced-\n           master|forced-slave\n                  Configure MASTER/SLAVE role of the PHY. When the PHY is\n                  configured as MASTER, the PMA Transmit function shall\n                  source TX_TCLK from a local clock source. When configured\n                  as SLAVE, the PMA Transmit function shall source TX_TCLK\n                  from the clock recovered from data stream provided by\n                  MASTER. Not all devices support this.\n\n                  preferred-master   Prefer MASTER role on autonegotiation\n                  preferred-slave    Prefer SLAVE role on autonegotiation\n                  forced-master      Force the PHY in MASTER role. Can be used without autonegotiation\n                  forced-slave       Force the PHY in SLAVE role. Can be used without autonegotiation\n\n           mdix auto|on|off\n                  Selects MDI-X mode for port. May be used to override the\n                  automatic detection feature of most adapters. An argument\n                  of auto means automatic detection of MDI status, on forces\n                  MDI-X (crossover) mode, while off means MDI (straight\n                  through) mode.  The driver should guarantee that this\n                  command takes effect immediately, and if necessary may\n                  reset the link to cause the change to take effect.\n\n           autoneg on|off\n                  Specifies whether autonegotiation should be enabled.\n                  Autonegotiation is enabled by default, but in some network\n                  devices may have trouble with it, so you can disable it if\n                  really necessary.\n\n           advertise N\n                  Sets the speed and duplex advertised by autonegotiation.\n                  The argument is a hexadecimal value using one or a\n                  combination of the following values:\n\n                  0x001                  10baseT Half\n                  0x002                  10baseT Full\n                  0x004                  100baseT Half\n                  0x008                  100baseT Full\n                  0x80000000000000000    100baseT1 Full\n                  0x010                  1000baseT Half               (not supported by IEEE standards)\n                  0x020                  1000baseT Full\n                  0x100000000000000000   1000baseT1 Full\n                  0x20000                1000baseKX Full\n                  0x20000000000          1000baseX Full\n                  0x800000000000         2500baseT Full\n                  0x8000                 2500baseX Full               (not supported by IEEE standards)\n                  0x1000000000000        5000baseT Full\n                  0x1000                 10000baseT Full\n                  0x40000                10000baseKX4 Full\n                  0x80000                10000baseKR Full\n                  0x100000               10000baseR_FEC\n                  0x40000000000          10000baseCR  Full\n                  0x80000000000          10000baseSR  Full\n                  0x100000000000         10000baseLR  Full\n                  0x200000000000         10000baseLRM Full\n                  0x400000000000         10000baseER  Full\n                  0x200000               20000baseMLD2 Full           (not supported by IEEE standards)\n                  0x400000               20000baseKR2 Full            (not supported by IEEE standards)\n                  0x80000000             25000baseCR Full\n                  0x100000000            25000baseKR Full\n                  0x200000000            25000baseSR Full\n                  0x800000               40000baseKR4 Full\n                  0x1000000              40000baseCR4 Full\n                  0x2000000              40000baseSR4 Full\n                  0x4000000              40000baseLR4 Full\n                  0x400000000            50000baseCR2 Full\n                  0x800000000            50000baseKR2 Full\n                  0x10000000000          50000baseSR2 Full\n                  0x10000000000000       50000baseKR Full\n                  0x20000000000000       50000baseSR Full\n                  0x40000000000000       50000baseCR Full\n                  0x80000000000000       50000baseLR_ER_FR Full\n                  0x100000000000000      50000baseDR Full\n                  0x8000000              56000baseKR4 Full\n                  0x10000000             56000baseCR4 Full\n                  0x20000000             56000baseSR4 Full\n                  0x40000000             56000baseLR4 Full\n                  0x1000000000           100000baseKR4 Full\n                  0x2000000000           100000baseSR4 Full\n                  0x4000000000           100000baseCR4 Full\n                  0x8000000000           100000baseLR4_ER4 Full\n                  0x200000000000000      100000baseKR2 Full\n                  0x400000000000000      100000baseSR2 Full\n                  0x800000000000000      100000baseCR2 Full\n                  0x1000000000000000     100000baseLR2_ER2_FR2 Full\n                  0x2000000000000000     100000baseDR2 Full\n                  0x4000000000000000     200000baseKR4 Full\n                  0x8000000000000000     200000baseSR4 Full\n                  0x10000000000000000    200000baseLR4_ER4_FR4 Full\n                  0x20000000000000000    200000baseDR4 Full\n                  0x40000000000000000    200000baseCR4 Full\n\n           phyad N\n                  PHY address.\n\n           xcvr internal|external\n                  Selects transceiver type. Currently only internal and\n                  external can be specified, in the future further types\n                  might be added.\n\n           wol p|u|m|b|a|g|s|f|d...\n                  Sets Wake-on-LAN options.  Not all devices support this.\n                  The argument to this option is a string of characters\n                  specifying which options to enable.\n\n                  p   Wake on PHY activity\n                  u   Wake on unicast messages\n                  m   Wake on multicast messages\n                  b   Wake on broadcast messages\n                  a   Wake on ARP\n                  g   Wake on MagicPacketâ¢\n                  s   Enable SecureOnâ¢ password for MagicPacketâ¢\n                  f   Wake on filter(s)\n                  d   Disable (wake on nothing).  This option\n                      clears all previous options.\n\n           sopass xx:yy:zz:aa:bb:cc\n                  Sets the SecureOnâ¢ password.  The argument to this option\n                  must be 6 bytes in Ethernet MAC hex format\n                  (xx:yy:zz:aa:bb:cc).\n\n           msglvl N\n           msglvl type on|off ...\n                  Sets the driver message type flags by name or number. type\n                  names the type of message to enable or disable; N\n                  specifies the new flags numerically. The defined type\n                  names and numbers are:\n\n                  drv         0x0001  General driver status\n                  probe       0x0002  Hardware probing\n                  link        0x0004  Link state\n                  timer       0x0008  Periodic status check\n                  ifdown      0x0010  Interface being brought down\n                  ifup        0x0020  Interface being brought up\n                  rx_err      0x0040  Receive error\n                  tx_err      0x0080  Transmit error\n                  tx_queued   0x0100  Transmit queueing\n                  intr        0x0200  Interrupt handling\n                  tx_done     0x0400  Transmit completion\n                  rx_status   0x0800  Receive completion\n                  pktdata     0x1000  Packet contents\n                  hw          0x2000  Hardware status\n                  wol         0x4000  Wake-on-LAN status\n\n                  The precise meanings of these type flags differ between\n                  drivers.\n\n       -n -u --show-nfc --show-ntuple\n              Retrieves receive network flow classification options or\n              rules.\n\n           rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6\n                  Retrieves the hash options for the specified flow type.\n\n                  tcp4    TCP over IPv4\n                  udp4    UDP over IPv4\n                  ah4     IPSEC AH over IPv4\n                  esp4    IPSEC ESP over IPv4\n                  sctp4   SCTP over IPv4\n                  tcp6    TCP over IPv6\n                  udp6    UDP over IPv6\n                  ah6     IPSEC AH over IPv6\n                  esp6    IPSEC ESP over IPv6\n                  sctp6   SCTP over IPv6\n\n           rule N Retrieves the RX classification rule with the given ID.\n\n       -N -U --config-nfc --config-ntuple\n              Configures receive network flow classification options or\n              rules.\n\n           rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6\n           m|v|t|s|d|f|n|r...\n                  Configures the hash options for the specified flow type.\n\n                  m   Hash on the Layer 2 destination address of the rx packet.\n                  v   Hash on the VLAN tag of the rx packet.\n                  t   Hash on the Layer 3 protocol field of the rx packet.\n                  s   Hash on the IP source address of the rx packet.\n                  d   Hash on the IP destination address of the rx packet.\n                  f   Hash on bytes 0 and 1 of the Layer 4 header of the rx packet.\n                  n   Hash on bytes 2 and 3 of the Layer 4 header of the rx packet.\n                  r   Discard all packets of this flow type. When this option is\n                      set, all other options are ignored.\n\n           flow-type\n           ether|ip4|tcp4|udp4|sctp4|ah4|esp4|ip6|tcp6|udp6|ah6|esp6|sctp6\n                  Inserts or updates a classification rule for the specified\n                  flow type.\n\n                  ether   Ethernet\n                  ip4     Raw IPv4\n                  tcp4    TCP over IPv4\n                  udp4    UDP over IPv4\n                  sctp4   SCTP over IPv4\n                  ah4     IPSEC AH over IPv4\n                  esp4    IPSEC ESP over IPv4\n                  ip6     Raw IPv6\n                  tcp6    TCP over IPv6\n                  udp6    UDP over IPv6\n                  sctp6   SCTP over IPv6\n                  ah6     IPSEC AH over IPv6\n                  esp6    IPSEC ESP over IPv6\n\n           For all fields that allow both a value and a mask to be\n           specified, the mask may be specified immediately after the value\n           using the m keyword, or separately using the field name keyword\n           with -mask appended, e.g. src-mask.\n\n           src xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]\n                  Includes the source MAC address, specified as 6 bytes in\n                  hexadecimal separated by colons, along with an optional\n                  mask.  Valid only for flow-type ether.\n\n           dst xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]\n                  Includes the destination MAC address, specified as 6 bytes\n                  in hexadecimal separated by colons, along with an optional\n                  mask.  Valid only for flow-type ether.\n\n           proto N [m N]\n                  Includes the Ethernet protocol number (ethertype) and an\n                  optional mask.  Valid only for flow-type ether.\n\n           src-ip ip-address [m ip-address]\n                  Specify the source IP address of the incoming packet to\n                  match along with an optional mask.  Valid for all IP based\n                  flow-types.\n\n           dst-ip ip-address [m ip-address]\n                  Specify the destination IP address of the incoming packet\n                  to match along with an optional mask.  Valid for all IP\n                  based flow-types.\n\n           tos N [m N]\n                  Specify the value of the Type of Service field in the\n                  incoming packet to match along with an optional mask.\n                  Applies to all IPv4 based flow-types.\n\n           tclass N [m N]\n                  Specify the value of the Traffic Class field in the\n                  incoming packet to match along with an optional mask.\n                  Applies to all IPv6 based flow-types.\n\n           l4proto N [m N]\n                  Includes the layer 4 protocol number and optional mask.\n                  Valid only for flow-types ip4 and ip6.\n\n           src-port N [m N]\n                  Specify the value of the source port field (applicable to\n                  TCP/UDP packets) in the incoming packet to match along\n                  with an optional mask.  Valid for flow-types ip4, tcp4,\n                  udp4, and sctp4 and their IPv6 equivalents.\n\n           dst-port N [m N]\n                  Specify the value of the destination port field\n                  (applicable to TCP/UDP packets)in the incoming packet to\n                  match along with an optional mask.  Valid for flow-types\n                  ip4, tcp4, udp4, and sctp4 and their IPv6 equivalents.\n\n           spi N [m N]\n                  Specify the value of the security parameter index field\n                  (applicable to AH/ESP packets)in the incoming packet to\n                  match along with an optional mask.  Valid for flow-types\n                  ip4, ah4, and esp4 and their IPv6 equivalents.\n\n           l4data N [m N]\n                  Specify the value of the first 4 Bytes of Layer 4 in the\n                  incoming packet to match along with an optional mask.\n                  Valid for ip4 and ip6 flow-types.\n\n           vlan-etype N [m N]\n                  Includes the VLAN tag Ethertype and an optional mask.\n\n           vlan N [m N]\n                  Includes the VLAN tag and an optional mask.\n\n           user-def N [m N]\n                  Includes 64-bits of user-specific data and an optional\n                  mask.\n\n           dst-mac xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]\n                  Includes the destination MAC address, specified as 6 bytes\n                  in hexadecimal separated by colons, along with an optional\n                  mask.  Valid for all IP based flow-types.\n\n           action N\n                  Specifies the Rx queue to send packets to, or some other\n                  action.\n\n                  -1            Drop the matched flow\n                  -2            Use the matched flow as a Wake-on-LAN filter\n                  0 or higher   Rx queue to route the flow\n\n           context N\n                  Specifies the RSS context to spread packets over multiple\n                  queues; either 0 for the default RSS context, or a value\n                  returned by ethtool -X ... context new.\n\n           vf N   Specifies the Virtual Function the filter applies to. Not\n                  compatible with action.\n\n           queue N\n                  Specifies the Rx queue to send packets to. Not compatible\n                  with action.\n\n           loc N  Specify the location/ID to insert the rule. This will\n                  overwrite any rule present in that location and will not\n                  go through any of the rule ordering process.\n\n           delete N\n                  Deletes the RX classification rule with the given ID.\n\n       -w --get-dump\n              Retrieves and prints firmware dump for the specified network\n              device.  By default, it prints out the dump flag, version and\n              length of the dump data.  When data is indicated, then ethtool\n              fetches the dump data and directs it to a file.\n\n       -W --set-dump\n              Sets the dump flag for the device.\n\n       -T --show-time-stamping\n              Show the device's time stamping capabilities and associated\n              PTP hardware clock.\n\n       -x --show-rxfh-indir --show-rxfh\n              Retrieves the receive flow hash indirection table and/or RSS\n              hash key.\n\n       -X --set-rxfh-indir --rxfh\n              Configures the receive flow hash indirection table and/or RSS\n              hash key.\n\n           hkey   Sets RSS hash key of the specified network device. RSS\n                  hash key should be of device supported length.  Hash key\n                  format must be in xx:yy:zz:aa:bb:cc format meaning both\n                  the nibbles of a byte should be mentioned even if a nibble\n                  is zero.\n\n           hfunc  Sets RSS hash function of the specified network device.\n                  List of RSS hash functions which kernel supports is shown\n                  as a part of the --show-rxfh command output.\n\n           start N\n                  For the equal and weight options, sets the starting\n                  receive queue for spreading flows to N.\n\n           equal N\n                  Sets the receive flow hash indirection table to spread\n                  flows evenly between the first N receive queues.\n\n           weight W0 W1 ...\n                  Sets the receive flow hash indirection table to spread\n                  flows between receive queues according to the given\n                  weights.  The sum of the weights must be non-zero and must\n                  not exceed the size of the indirection table.\n\n           default\n                  Sets the receive flow hash indirection table to its\n                  default value.\n\n           context CTX | new\n                  Specifies an RSS context to act on; either new to allocate\n                  a new RSS context, or CTX, a value returned by a previous\n                  ... context new.\n\n           delete Delete the specified RSS context.  May only be used in\n                  conjunction with context and a non-zero CTX value.\n\n       -f --flash\n              Write a firmware image to flash or other non-volatile memory\n              on the device.\n\n           file   Specifies the filename of the firmware image.  The\n                  firmware must first be installed in one of the directories\n                  where the kernel firmware loader or firmware agent will\n                  look, such as /lib/firmware.\n\n           N      If the device stores multiple firmware images in separate\n                  regions of non-volatile memory, this parameter may be used\n                  to specify which region is to be written.  The default is\n                  0, requesting that all regions are written.  All other\n                  values are driver-dependent.\n\n       -l --show-channels\n              Queries the specified network device for the numbers of\n              channels it has.  A channel is an IRQ and the set of queues\n              that can trigger that IRQ.\n\n       -L --set-channels\n              Changes the numbers of channels of the specified network\n              device.\n\n           rx N   Changes the number of channels with only receive queues.\n\n           tx N   Changes the number of channels with only transmit queues.\n\n           other N\n                  Changes the number of channels used only for other\n                  purposes e.g. link interrupts or SR-IOV co-ordination.\n\n           combined N\n                  Changes the number of multi-purpose channels.\n\n       -m --dump-module-eeprom --module-info\n              Retrieves and if possible decodes the EEPROM from plugin\n              modules, e.g SFP+, QSFP.  If the driver and module support it,\n              the optical diagnostic information is also read and decoded.\n\n       --show-priv-flags\n              Queries the specified network device for its private flags.\n              The names and meanings of private flags (if any) are defined\n              by each network device driver.\n\n       --set-priv-flags\n              Sets the device's private flags as specified.\n\n           flag on|off Sets the state of the named private flag.\n\n       --show-eee\n              Queries the specified network device for its support of\n              Energy-Efficient Ethernet (according to the IEEE 802.3az\n              specifications)\n\n       --set-eee\n              Sets the device EEE behaviour.\n\n           eee on|off\n                  Enables/disables the device support of EEE.\n\n           tx-lpi on|off\n                  Determines whether the device should assert its Tx LPI.\n\n           advertise N\n                  Sets the speeds for which the device should advertise EEE\n                  capabilities.  Values are as for --change advertise\n\n           tx-timer N\n                  Sets the amount of time the device should stay in idle\n                  mode prior to asserting its Tx LPI (in microseconds). This\n                  has meaning only when Tx LPI is enabled.\n\n       --set-phy-tunable\n              Sets the PHY tunable parameters.\n\n           downshift on|off\n                  Specifies whether downshift should be enabled.\n\n                  count N\n                      Sets the PHY downshift re-tries count.\n\n           fast-link-down on|off\n                  Specifies whether Fast Link Down should be enabled and\n                  time until link down (if supported).\n\n                  msecs N\n                      Sets the period after which the link is reported as down. Note that the PHY may choose\n                      the closest supported value. Only on reading back the tunable do you get the actual value.\n\n           energy-detect-power-down on|off\n                  Specifies whether Energy Detect Power Down (EDPD) should\n                  be enabled (if supported).  This will put the RX and TX\n                  circuit blocks into a low power mode, and the PHY will\n                  wake up periodically to send link pulses to avoid any\n                  lock-up situation with a peer PHY that may also have EDPD\n                  enabled. By default, this setting will also enable the\n                  periodic transmission of TX pulses.\n\n                  msecs N\n                      Some PHYs support configuration of the wake-up interval to send TX pulses.\n                      This setting allows the control of this interval, and 0 disables TX pulses\n                      if the PHY supports this. Disabling TX pulses can create a lock-up situation\n                      where neither of the PHYs wakes the other one. If unspecified the default\n                      value (in milliseconds) will be used by the PHY.\n\n       --get-phy-tunable\n              Gets the PHY tunable parameters.\n\n           downshift\n                  For operation in cabling environments that are\n                  incompatible with 1000BASE-T, PHY device provides an\n                  automatic link speed downshift operation.  Link speed\n                  downshift after N failed 1000BASE-T auto-negotiation\n                  attempts.  Downshift is useful where cable does not have\n                  the 4 pairs instance.\n\n                  Gets the PHY downshift count/status.\n\n           fast-link-down\n                  Depending on the mode it may take 0.5s - 1s until a broken\n                  link is reported as down.  In certain use cases a link-\n                  down event needs to be reported as soon as possible.  Some\n                  PHYs support a Fast Link Down Feature and may allow\n                  configuration of the delay before a broken link is\n                  reported as being down.\n\n                  Gets the PHY Fast Link Down status / period.\n\n           energy-detect-power-down\n                  Gets the current configured setting for Energy Detect\n                  Power Down (if supported).\n\n       --get-tunable\n              Get the tunable parameters.\n\n           rx-copybreak\n                  Get the current rx copybreak value in bytes.\n\n           tx-copybreak\n                  Get the current tx copybreak value in bytes.\n\n           pfc-prevention-tout\n                  Get the current pfc prevention timeout value in msecs.\n\n       --set-tunable\n              Set driver's tunable parameters.\n\n           rx-copybreak N\n                  Set the rx copybreak value in bytes.\n\n           tx-copybreak N\n                  Set the tx copybreak value in bytes.\n\n           pfc-prevention-tout N\n                  Set pfc prevention timeout in msecs. Value of 0 means\n                  disable and 65535 means auto.\n\n       --reset\n              Reset hardware components specified by flags and components\n              listed below\n\n           flags N\n                  Resets the components based on direct flags mask\n\n           mgmt   Management processor\n\n           irq    Interrupt requester\n\n           dma    DMA engine\n\n           filter Filtering/flow direction\n\n           offload\n                  Protocol offload\n\n           mac    Media access controller\n\n           phy    Transceiver/PHY\n\n           ram    RAM shared between multiple components ap Application\n                  Processor\n\n           dedicated\n                  All components dedicated to this interface\n\n           all    All components used by this interface, even if shared\n\n       --show-fec\n              Queries the specified network device for its support of\n              Forward Error Correction.\n\n       --set-fec\n              Configures Forward Error Correction for the specified network\n              device.\n\n              Forward Error Correction modes selected by a user are expected\n              to be persisted after any hotplug events. If a module is\n              swapped that does not support the current FEC mode, the driver\n              or firmware must take the link down administratively and\n              report the problem in the system logs for users to correct.\n\n           encoding auto|off|rs|baser|llrs [...]\n\n                  Sets the FEC encoding for the device.  Combinations of\n                  options are specified as e.g.  encoding auto rs ; the\n                  semantics of such combinations vary between drivers.\n\n                  auto    Use the driver's default encoding\n                  off     Turn off FEC\n                  RS      Force RS-FEC encoding\n                  BaseR   Force BaseR encoding\n                  LLRS    Force LLRS-FEC encoding\n\n       -Q|--per-queue\n              Applies provided sub command to specific queues.\n\n           queue_mask %x\n                  Sets the specific queues which the sub command is applied\n                  to.  If queue_mask is not set, the sub command will be\n                  applied to all queues.\n\n           sub_command\n                  Sub command to apply. The supported sub commands include\n                  --show-coalesce and --coalesce.\n\n       q.B --cable-test\n              Perform a cable test and report the results. What results are\n              returned depends on the capabilities of the network interface.\n              Typically open pairs and shorted pairs can be reported, along\n              with pairs being O.K. When a fault is detected the approximate\n              distance to the fault may be reported.\n\n       --cable-test-tdr\n              Perform a cable test and report the raw Time Domain\n              Reflectometer data.  A pulse is sent down a cable pair and the\n              amplitude of the reflection, for a given distance, is\n              reported. A break in the cable returns a big reflection. Minor\n              damage to the cable returns a small reflection. If the cable\n              is shorted, the amplitude of the reflection can be negative.\n              By default, data is returned for lengths between 0 and 150m at\n              1m steps, for all pairs. However parameters can be passed to\n              restrict the collection of data. It should be noted, that the\n              interface will round the distances to whatever granularity is\n              actually implemented. This is often 0.8 of a meter. The\n              results should include the actual rounded first and last\n              distance and step size.\n\n           first  N\n                  Distance along the cable, in meters, where the first\n                  measurement should be made.\n\n           last  N\n                  Distance along the cable, in meters, where the last\n                  measurement should be made.\n\n           step  N\n                  Distance, in meters, between each measurement.\n\n           pair  N\n                  Which pair should be measured. Typically a cable has 4\n                  pairs. 0 = Pair A, 1 = Pair B, ...\n\n       --monitor\n              Listens to netlink notification and displays them.\n\n           command\n                  If argument matching a command is used, ethtool only shows\n                  notifications of this type. Without such argument or with\n                  --all, all notification types are shown.\n\n           devname\n                  If a device name is used as argument, only notification\n                  for this device are shown. Default is to show\n                  notifications for all devices.\n\nBUGS          top\n       Not supported (in part or whole) on all network drivers.\n\nAUTHOR          top\n       ethtool was written by David Miller.\n\n       Modifications by Jeff Garzik, Tim Hockin, Jakub Jelinek, Andre\n       Majorel, Eli Kupermann, Scott Feldman, Andi Kleen, Alexander Duyck,\n       Sucheta Chakraborty, Jesse Brandeburg, Ben Hutchings, Scott Branden.\n\nAVAILABILITY          top\n       ethtool is available from \n       â¨http://www.kernel.org/pub/software/network/ethtool/â©\n\nCOLOPHON          top\n       This page is part of the ethtool (utility for controlling network\n       drivers and hardware) project.  Information about the project can be\n       found at â¨https://www.kernel.org/pub/software/network/ethtool/â©.  If\n       you have a bug report for this manual page, send it to\n       bwh@kernel.org, netdev@vger.kernel.org.  This page was obtained from\n       the project's upstream Git repository\n       â¨git://git.kernel.org/pub/scm/network/ethtool/ethtool.gitâ© on\n       2020-08-13.  (At that time, the date of the most recent commit that\n       was found in the repository was 2020-08-04.)  If you discover any\n       rendering problems in this HTML version of the page, or you believe\n       there is a better or more up-to-date source for the page, or you have\n       corrections or improvements to the information in this COLOPHON\n       (which is not part of the original manual page), send a mail to\n       man-pages@man7.org\n\nEthtool version 5.8               Aug 2020                        ETHTOOL(8)\n\n\nPages that refer to this page: \n    veth(4),  \n    ip-link(8),  \n    ovs-l3ping(8)\n\n\n\n\n\n\n\n\n            HTML rendering created 2020-08-13\n            by Michael Kerrisk, \n            author of \n            The Linux Programming Interface, \n            maintainer of the \n            Linux man-pages project.\n        \n\n            For details of in-depth\n            Linux/UNIX system programming training courses\n            that I teach, look here.\n        \n\n            Hosting by jambit GmbH.\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# ethtool\n\n> Display and modify Network Interface Controller (NIC) parameters.\n> More information: <http://man7.org/linux/man-pages/man8/ethtool.8.html>.\n\n- Set the link speed, duplex mode, and parameter autonegotiation for a given interface:\n\n`ethtool -s {{eth0}} speed {{10|100|1000}} duplex {{half|full}} autoneg {{on|off}}`\n"
 },
 {
   "command": "guake",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# guake\n\n> A drop-down terminal for GNOME.\n\n- Toggle Guake visiblity:\n\n`F12`\n\n- Toggle fullscreen mode:\n\n`F11`\n\n- Open a new tab:\n\n`Ctrl+Shift+T`\n\n- Close the terminal:\n\n`Super+X`\n\n- Go to the previous tab:\n\n`Ctrl+PageUp`\n\n- Search the selected text in the browser:\n\n`Shift+Ctrl+L`\n"
 },
 {
   "command": "tcpflow",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# tcpflow\n\n> Capture TCP traffic for debugging and analysis.\n\n- Show all data on the given interface and port:\n\n`tcpflow -c -i {{eth0}} port {{80}}`\n"
 },
 {
   "command": "apt-file",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apt-file\n\n> Search for files in apt packages, including ones not yet installed.\n\n- Update the metadata database:\n\n`sudo apt update`\n\n- Search for packages that contain the specified file or path:\n\n`apt-file search {{part/of/filename}}`\n\n- List the contents of a specific package:\n\n`apt-file list {{package_name}}`\n"
 },
 {
   "command": "apt-add-repository",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apt-add-repository\n\n> Manages apt repository definitions.\n\n- Add a new apt repository:\n\n`apt-add-repository {{repository_spec}}`\n\n- Remove an apt repository:\n\n`apt-add-repository --remove {{repository_spec}}`\n\n- Update the package cache after adding a repository:\n\n`apt-add-repository --update {{repository_spec}}`\n\n- Enable source packages:\n\n`apt-add-repository --enable-source {{repository_spec}}`\n"
 },
 {
   "command": "squeue",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# squeue\n\n> View the jobs queued in the SLURM scheduler.\n\n- View the queue:\n\n`squeue`\n\n- View jobs queued by a specific user:\n\n`squeue -u {{username}}`\n\n- View the queue and refresh every 5 seconds:\n\n`squeue -i {{5}}`\n\n- View the queue with expected start times:\n\n`squeue --start`\n"
 },
 {
   "command": "mcookie",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mcookie\n\n> Generates random 128 bit hexadecimal numbers.\n\n- Generate a random number:\n\n`mcookie`\n\n- Generate a random number, using the contents of a file as a seed for the randomness:\n\n`mcookie --file {{path/to/file}}`\n\n- Generate a random number, using a specific number of bytes from a file as a seed for the randomness:\n\n`mcookie --file {{path/to/file}} --max-size {{number_of_bytes}}`\n\n- Print the details of the randomness used, such as the origin and seed for each source:\n\n`mcookie --verbose`\n"
 },
 {
   "command": "xfce4-terminal",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xfce4-terminal\n\n> The XFCE4 terminal emulator.\n\n- Open a new terminal window:\n\n`xfce4-terminal`\n\n- Set the initial title:\n\n`xfce4-terminal --initial-title \"{{initial_title}}\"`\n\n- Open a new tab in the current terminal window:\n\n`xfce4-terminal --tab`\n\n- Execute a command in a new terminal window:\n\n`xfce4-terminal --command \"{{command_with_args}}\"`\n\n- Keep the terminal around after the executed command finishes executing:\n\n`xfce4-terminal --command \"{{command_with_args}}\" --hold`\n\n- Open multiple new tabs, executing a command in each:\n\n`xfce4-terminal --tab --command \"{{command_a}}\" --tab --command \"{{command_b}}\"`\n"
 },
 {
   "command": "enum4linux",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# enum4linux\n\n> Tool for enumerating Windows and Samba information from remote systems.\n> It attempts to offer similar functionality to enum.exe formerly available from www.bindview.com.\n\n- Try to enumerate using all methods:\n\n`enum4linux -a {{remote_host}}`\n\n- Enumerate using given login credentials:\n\n`enum4liux -u {{user_name}} -p {{password}} {{remote_host}}`\n\n- List usernames from a given host:\n\n`enum4liux -U {{remote_host}}`\n\n- List shares:\n\n`enum4liux -S {{remote_host}}`\n\n- Get OS information:\n\n`enum4liux -o {{remote_host}}`\n"
 },
 {
   "command": "a2enmod",
   "doc_url": "https://manpages.debian.org/buster/apache2/a2enmod.8.en.html",
   "doc_text": "\n\n\n\na2enmod(8) — apache2 — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / apache2\n     \n     \n     \n     / a2enmod(8)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXIT STATUS\n\n\nEXAMPLES\n\n\nFILES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.4.38-3+deb10u3\n\n\nbuster-backports 2.4.46-1~bpo10+1\n\n\ntesting 2.4.46-1\n\n\nunstable 2.4.46-1\n\n\n\n\n\n\nScroll to navigation\n\n\n\nA2ENMOD(8)\nSystem Manager's Manual\nA2ENMOD(8)\n\n\n\n\nNAME¶\na2enmod, a2dismod - enable or disable an apache2 module\n\n\nSYNOPSIS¶\na2enmod [ [-q|--quiet] module]\na2dismod [ [-q|--quiet] module]\n\n\nDESCRIPTION¶\nThis manual page documents briefly the a2enmod and a2dismod\n  commands.\na2enmod is a script that enables the specified module\n    within the apache2 configuration. It does this by creating symlinks\n    within /etc/apache2/mods-enabled. Likewise, a2dismod disables\n    a module by removing those symlinks. It is not an error to enable a module\n    which is already enabled, or to disable one which is already disabled.\nNote that many modules have, in addition to a .load file, an\n    associated .conf file. Enabling the module puts the configuration directives\n    in the .conf file as directives into the main server context of\n    apache2.\n\n\nOPTIONS¶\n\n-q, --quiet\nDon't show informative messages.\n-m, --maintmode\nEnables the maintainer mode, that is the program invocation is effectuated\n      automatically by a maintainer script. This switch should not be used by\n      end users.\n-p, --purge\nWhen disabling a module, purge all traces of the module in the internal\n      state data base.\n\n\n\nEXIT STATUS¶\na2enmod and a2dismod exit with status 0 if all modules are\n  processed successfully, 1 if errors occur, 2 if an invalid option was used.\n\n\nEXAMPLES¶\na2enmod imagemap\n\na2dismod mime_magic\nEnables the mod_imagemap module, and disables the\n    mod_mime_magic module.\n\n\nFILES¶\n\n/etc/apache2/mods-available\nDirectory with files giving information on available modules.\n/etc/apache2/mods-enabled\nDirectory with links to the files in mods-available for enabled\n      modules.\n\n\n\nSEE ALSO¶\napache2ctl(8), a2enconf(8), a2disconf(8).\n\n\nAUTHOR¶\nThis manual page was written by Daniel Stone <daniel@sfarc.net> for the\n  Debian GNU/Linux distribution, as it is a Debian-specific script with the\n  package.\n\n\n\n\n12 October 2006\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\na2enmod.8.en.gz (from apache2 2.4.38-3+deb10u3)\n\n\n\n\nSource last updated:\n\n\n2019-10-15T19:53:42Z\n\n\n\n\nConverted to HTML:\n\n\n2020-09-01T03:18:56Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# a2enmod\n\n> Enable an Apache module on Debian-based OSes.\n> More information: <https://manpages.debian.org/buster/apache2/a2enmod.8.en.html>.\n\n- Enable a module:\n\n`sudo a2enmod {{module}}`\n\n- Don't show informative messages:\n\n`sudo a2enmod --quiet {{module}}`\n"
 },
 {
   "command": "cpuid",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# cpuid\n\n> Display detailed information about all CPUs.\n\n- Display information for all CPUs:\n\n`cpuid`\n\n- Display information only for the current CPU:\n\n`cpuid -1`\n\n- Display raw hex information with no decoding:\n\n`cpuid -r`\n"
 },
 {
   "command": "notify-send",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# notify-send\n\n> Uses the current desktop environment's notification system to create a notification.\n\n- Show a notification with the title \"Test\" and the content \"This is a test\":\n\n`notify-send {{\"Test\"}} {{\"This is a test\"}}`\n\n- Show a notification with a custom icon:\n\n`notify-send -i {{icon.png}} {{\"Test\"}} {{\"This is a test\"}}`\n\n- Show a notification for 5 seconds:\n\n`notify-send -t 5000 {{\"Test\"}} {{\"This is a test\"}}`\n\n- Show a notification with an app's icon:\n\n`notify-send {{\"Test\"}} --icon={{google-chrome}}`\n"
 },
 {
   "command": "ufw",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ufw\n\n> Uncomplicated Firewall.\n> Frontend for iptables aiming to make configuration of a firewall easier.\n\n- Enable ufw:\n\n`ufw enable`\n\n- Disable ufw:\n\n`ufw disable`\n\n- Show ufw rules, along with their numbers:\n\n`ufw status numbered`\n\n- Allow incoming traffic on port 5432 on this host with a comment identifying the service:\n\n`ufw allow {{5432}} comment {{\"Service\"}}`\n\n- Allow only TCP traffic from 192.168.0.4 to any address on this host, on port 22:\n\n`ufw allow proto {{tcp}} from {{192.168.0.4}} to {{any}} port {{22}}`\n\n- Deny traffic on port 80 on this host:\n\n`ufw deny {{80}}`\n\n- Deny all UDP traffic to port 22:\n\n`ufw deny proto {{udp}} from {{any}} to {{any}} port {{22}}`\n\n- Delete a particular rule. The rule number can be retrieved from the `ufw status numbered` command:\n\n`ufw delete {{rule_number}}`\n"
 },
 {
   "command": "mandb",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mandb\n\n> Manage the pre-formatted manual page database.\n\n- Purge and process manual pages:\n\n`mandb`\n\n- Update a single entry:\n\n`mandb --filename {{path/to/file}}`\n\n- Create entries from scratch instead of updating:\n\n`mandb --create`\n\n- Only process user databases:\n\n`mandb --user-db`\n\n- Do not purge obsolete entries:\n\n`mandb --no-purge`\n\n- Check the validity of manual pages:\n\n`mandb --test`\n"
 },
 {
   "command": "radeontop",
   "doc_url": "https://github.com/clbr/radeontop",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - clbr/radeontop\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclbr\n\n/\n\nradeontop\n\n\n\n\n\n\n\n    Watch\n \n      17\n    \n\n\n\n\n      Star\n\n\n      331\n    \n\n\n\n\n          Fork\n\n\n        44\n      \n\n\n\n\n\n\n\n            GPL-3.0 License\n        \n\n\n\n\n331\n        stars\n \n\n44\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n17\n \n\n\n\nPull requests\n4\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n15\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n\n\n\n \n\n\n\n\nclbr\n\nUpdate pot file\n\n\n\n…\n\n\n\nef27e8b\n\nApr 15, 2020\n\n\n\n\n\nUpdate pot file\n\n\nef27e8b\n\n\n\nGit stats\n\n\n\n\n\n269\ncommits\n\n\n\n\n\n\n\nFiles\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\ninclude\n\n\n\nTransparency support\n\n\n\nApr 15, 2020\n\n\n\n\n\n\n\ntranslations\n\n\n\nUpdate pot file\n\n\n\nApr 15, 2020\n\n\n\n\n\n\n\n.gitignore\n\n\n\nAdd optional unprivileged mode in Xorg\n\n\n\nJul 4, 2016\n\n\n\n\n\n\n\nCOPYING\n\n\n\nGPLv3 this\n\n\n\nJul 7, 2012\n\n\n\n\n\n\n\nMakefile\n\n\n\nRound the size of the percentage bar to the nearest integer\n\n\n\nNov 4, 2019\n\n\n\n\n\n\n\nREADME.md\n\n\n\nAdd Screenshot\n\n\n\nOct 18, 2019\n\n\n\n\n\n\n\namdgpu.c\n\n\n\nRework of DRM initialization code\n\n\n\nSep 30, 2019\n\n\n\n\n\n\n\nauth.c\n\n\n\nAdd a warning when failing to drop DRM master\n\n\n\nSep 30, 2019\n\n\n\n\n\n\n\nauth_xcb.c\n\n\n\nRework of DRM initialization code\n\n\n\nSep 30, 2019\n\n\n\n\n\n\n\ndetect.c\n\n\n\nAdd support to open DRM device nodes by pathname\n\n\n\nSep 30, 2019\n\n\n\n\n\n\n\ndump.c\n\n\n\nDisplay shader clock on APUs\n\n\n\nAug 14, 2019\n\n\n\n\n\n\n\nfamily_str.c\n\n\n\nUpdate pci ids: arcturus, renoir, navi12, navi14\n\n\n\nDec 18, 2019\n\n\n\n\n\n\n\nfamilycheck.sh\n\n\n\nAdd a script to check enum consistency\n\n\n\nOct 1, 2014\n\n\n\n\n\n\n\ngetamdgpuids.sh\n\n\n\nAdd support for Topaz, Tonga, and Carrizo\n\n\n\nAug 6, 2015\n\n\n\n\n\n\n\ngetver.sh\n\n\n\ngetver.sh: Only use git if its a git repo.\n\n\n\nDec 9, 2018\n\n\n\n\n\n\n\nradeon.c\n\n\n\nRework of DRM initialization code\n\n\n\nSep 30, 2019\n\n\n\n\n\n\n\nradeontop.1\n\n\n\nRefresh man page\n\n\n\nSep 30, 2019\n\n\n\n\n\n\n\nradeontop.asc\n\n\n\nAdd support to open DRM device nodes by pathname\n\n\n\nSep 30, 2019\n\n\n\n\n\n\n\nradeontop.c\n\n\n\nTransparency support\n\n\n\nApr 15, 2020\n\n\n\n\n\n\n\nradeontop.metainfo.xml\n\n\n\nAdd appstream info file, from luyatshimbalanga\n\n\n\nAug 7, 2017\n\n\n\n\n\n\n\nticks.c\n\n\n\nUse directly the backend functions to get GPU usage\n\n\n\nAug 14, 2019\n\n\n\n\n\n\n\nui.c\n\n\n\nTransparency style fixes\n\n\n\nApr 15, 2020\n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n        README.md\n      \n\n\nRadeonTop\nView your GPU utilization, both for the total activity percent and individual blocks.\nRequires access to /dev/dri/cardN files or /dev/mem (root privileges).\n\nSupported cards\nR600 and up, even Southern Islands should work fine.\nWorks with both the open drivers and AMD Catalyst.\nFor the Catalyst driver, only the mem path is currently supported - this\nmeans it won't run on the default Ubuntu kernels that block /dev/mem.\nThe total GPU utilization is also valid for OpenCL loads; the other blocks\nare only useful in GL loads.\nTranslations\nIf you'd like to translate RadeonTop to your own language, please go here:\nhttps://translations.launchpad.net/radeontop\nRunning\nPrerequisites\n\nlibdrm\nlibncurses\nlibpciaccess\nlibxcb\n\nSimply start radeontop and it auto-selects the first supported GPU:\n./radeontop\n\nRunning radeontop on a bus 0f:\n./radeontop -b 0f\n\nWriting values to stdout instead of showing a GUI:\n./radeontop -d -\n\nGetting all options:\n./radeontop --help\n\nBuilding\nPrerequisites\n\nall run time prerequisites with dev files\ngcc / clang\npkgconf\n\nBuilding\nIf all prerequisites are fullfilled, it can be build by simply running:\nmake\n\nBuild options\nBuild options can be specified to having the following variables being set to \"1\"\nnls     enable translations, default on\ndebug   enable debug symbols, default off\nnostrip disable stripping, default off\nplain   apply neither gcc's -g nor -s.\nxcb     enable libxcb to run unprivileged in Xorg, default on\namdgpu  enable amdgpu usage reporting, default auto (requires libdrm >= 2.4.63)\n\nExample:\nmake amdgpu=1 xcb=1\n\nThis will build radeontop with amdgpu reporting and xcb support.\n\n\n\n\n\n\n\n\nAbout\n\n      No description, website, or topics provided.\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        GPL-3.0 License\n    \n\n\n\n\n\n\n\n    Releases\n\n\n\n15\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 15\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n      + 4 contributors\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\nC\n65.0%\n\n\n\n\n\nC++\n24.6%\n\n\n\n\n\nMakefile\n4.7%\n\n\n\n\n\nRoff\n4.2%\n\n\n\n\n\nShell\n1.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# radeontop\n\n> Show utilisation of AMD GPUs.\n> More information: <https://github.com/clbr/radeontop>.\n\n- Show the utilisation of the default AMD GPU:\n\n`sudo radeontop`\n\n- Enable colourised output:\n\n`sudo radeontop --colour`\n\n- Select a specific GPU (the bus number is the first number in the output of `lspci`):\n\n`sudo radeontop --bus {{bus_number}}`\n\n- Specify the display refresh rate (higher means more GPU overhead):\n\n`sudo radeontop --ticks {{samples_per_second}}`\n"
 },
 {
   "command": "dash",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dash\n\n> Debian Almquist Shell.\n> Modern POSIX-compliant implementation of `sh` (isn't Bash compatible).\n\n- Start interactive shell:\n\n`dash`\n\n- Execute a command:\n\n`dash -c \"{{command}}\"`\n\n- Run commands from a file:\n\n`dash {{file.sh}}`\n\n- Run commands from a file, logging all commands executed to the terminal:\n\n`dash -x {{file.sh}}`\n"
 },
 {
   "command": "at",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nAT(1)\t\t\t  BSD General Commands Manual\t\t\t AT(1)\n\nNAME\n     at, batch, atq, atrm -- queue, examine, or delete jobs for later execu-\n     tion\n\nSYNOPSIS\n     at [-q queue] [-f file] [-mldbv] time\n     at [-q queue] [-f file] [-mldbv] -t [[CC]YY]MMDDhhmm[.SS]\n     at -c job [job ...]\n     at -l [job ...]\n     at -l -q queue\n     at -r job [job ...]\n\n     atq [-q queue] [-v]\n\n     atrm job [job ...]\n\n     batch [-q queue] [-f file] [-mv] [time]\n\nDESCRIPTION\n     The at and batch utilities read commands from standard input or a speci-\n     fied file.  The commands are executed at a later time, using sh(1).\n\n     at      executes commands at a specified time;\n\n     atq     lists the user's pending jobs, unless the user is the superuser;\n\t     in that case, everybody's jobs are listed;\n\n     atrm    deletes jobs;\n\n     batch   executes commands when system load levels permit; in other words,\n\t     when the load average drops below _LOADAVG_MX (1.5), or the value\n\t     specified in the invocation of atrun.\n\n     The at utility allows some moderately complex time specifications.  It\n     accepts times of the form HHMM or HH:MM to run a job at a specific time\n     of day.  (If that time is already past, the next day is assumed.)\tAs an\n     alternative, the following keywords may be specified: midnight, noon, or\n     teatime (4pm) and time-of-day may be suffixed with AM or PM for running\n     in the morning or the evening.  The day on which the job is to be run may\n     also be specified by giving a date in the form month-name day with an\n     optional year, or giving a date of the forms DD.MM.YYYY, DD.MM.YY,\n     MM/DD/YYYY, MM/DD/YY, MMDDYYYY, or MMDDYY.  The specification of a date\n     must follow the specification of the time of day.\tTime can also be spec-\n     ified as: [now] + count time-units, where the time-units can be minutes,\n     hours, days, weeks, months or years and at may be told to run the job\n     today by suffixing the time with today and to run the job tomorrow by\n     suffixing the time with tomorrow.\tThe shortcut next can be used instead\n     of + 1.\n\n     For example, to run a job at 4pm three days from now, use at 4pm + 3\n     days, to run a job at 10:00am on July 31, use at 10am Jul 31 and to run a\n     job at 1am tomorrow, use at 1am tomorrow.\n\n     The at utility also supports the POSIX time format (see -t option).\n\n     For both at and batch, commands are read from standard input or the file\n     specified with the -f option.  The working directory, the environment\n     (except for the variables TERM, TERMCAP, DISPLAY and _), and the umask\n     are retained from the time of invocation.\tAn at or batch command invoked\n     from a su(1) shell will retain the current userid.  The user will be\n     mailed standard error and standard output from his commands, if any.\n     Mail will be sent using the command sendmail(8).  If at is executed from\n     a su(1) shell, the owner of the login shell will receive the mail.\n\n     The superuser may use these commands in any case.\tFor other users, per-\n     mission to use at is determined by the files _PERM_PATH/at.allow and\n     _PERM_PATH/at.deny.\n\n     If the file _PERM_PATH/at.allow exists, only usernames mentioned in it\n     are allowed to use at.  In these two files, a user is considered to be\n     listed only if the user name has no blank or other characters before it\n     on its line and a newline character immediately after the name, even at\n     the end of the file.  Other lines are ignored and may be used for com-\n     ments.\n\n     If _PERM_PATH/at.allow does not exist, _PERM_PATH/at.deny is checked,\n     every username not mentioned in it is then allowed to use at.\n\n     If neither exists, only the superuser is allowed use of at.\n\nIMPLEMENTATION NOTES\n     Note that at is implemented through the launchd(8) daemon periodically\n     invoking atrun(8), which is disabled by default.  See atrun(8) for infor-\n     mation about enabling atrun.\n\nOPTIONS\n     -b      Is an alias for batch.\n\n     -c      Cat the jobs listed on the command line to standard output.\n\n     -d      Is an alias for atrm (this option is deprecated; use -r instead).\n\n     -f file\n\t     Read the job from file rather than standard input.\n\n     -l      With no arguments, list all jobs for the invoking user.  If one\n\t     or more job numbers are given, list only those jobs.\n\n     -m      Send mail to the user when the job has completed even if there\n\t     was no output.\n\n     -q queue\n\t     Use the specified queue.  A queue designation consists of a sin-\n\t     gle letter; valid queue designations range from a to z and A to\n\t     Z.  The _DEFAULT_AT_QUEUE queue (a) is the default for at and the\n\t     _DEFAULT_BATCH_QUEUE queue (b) is the default for batch.  Queues\n\t     with higher letters run with increased niceness.  If a job is\n\t     submitted to a queue designated with an uppercase letter, it is\n\t     treated as if it had been submitted to batch at that time.  If\n\t     atq is given a specific queue, it will only show jobs pending in\n\t     that queue.\n\n     -r      Remove the specified jobs.\n\n     -t      Specify the job time using the POSIX time format.\tThe argument\n\t     should be in the form [[CC]YY]MMDDhhmm[.SS] where each pair of\n\t     letters represents the following:\n\n\t\t   CC\t   The first two digits of the year (the century).\n\t\t   YY\t   The second two digits of the year.\n\t\t   MM\t   The month of the year, from 1 to 12.\n\t\t   DD\t   the day of the month, from 1 to 31.\n\t\t   hh\t   The hour of the day, from 0 to 23.\n\t\t   mm\t   The minute of the hour, from 0 to 59.\n\t\t   SS\t   The second of the minute, from 0 to 61.\n\n\t     If the CC and YY letter pairs are not specified, the values\n\t     default to the current year.  If the SS letter pair is not speci-\n\t     fied, the value defaults to 0.\n\n     -v      For atq, shows completed but not yet deleted jobs in the queue;\n\t     otherwise shows the time the job will be executed.\n\nFILES\n     _ATJOB_DIR \t   directory containing job files\n\t\t\t   (/usr/lib/cron/jobs/)\n     _ATJOB_DIR/_LOCKFILE  job-creation lock file (/usr/lib/cron/jobs/...)\n     _ATSPOOL_DIR\t   directory containing output spool files\n\t\t\t   (/usr/lib/cron/spool/)\n     _PERM_PATH/at.allow   allow permission control (/usr/lib/cron/at.allow)\n     _PERM_PATH/at.deny    deny permission control (/usr/lib/cron/at.deny)\n     /var/run/utmpx\t   login records\n\nSEE ALSO\n     nice(1), sh(1), umask(2), compat(5), atrun(8), cron(8), sendmail(8)\n\nBUGS\n     If the file /var/run/utmpx is not available or corrupted, or if the user\n     is not logged on at the time at is invoked, the mail is sent to the\n     userid found in the environment variable LOGNAME.\tIf that is undefined\n     or empty, the current userid is assumed.\n\n     The at and batch utilities as presently implemented are not suitable when\n     users are competing for resources.  If this is the case, another batch\n     system such as nqs may be more suitable.\n\n     Specifying a date past 2038 may not work on some systems.\n\nAUTHORS\n     At was mostly written by Thomas Koenig <ig25@rz.uni-karlsruhe.de>.  The\n     time parsing routines are by\n     David Parsons <orc@pell.chi.il.us>, with minor enhancements by\n     Joe Halpin <joe.halpin@attbi.com>.\n\nBSD\t\t\t       January 13, 2002 \t\t\t   BSD\n",
   "tldr_summary": "# at\n\n> Executes commands at a specified time.\n\n- Open an `at` prompt to create a new set of scheduled commands, press `Ctrl + D` to save and exit:\n\n`at {{hh:mm}}`\n\n- Execute the commands and email the result using a local mailing program such as sendmail:\n\n`at {{hh:mm}} -m`\n\n- Execute a script at the given time:\n\n`at {{hh:mm}} -f {{path/to/file}}`\n\n- Display a system notification at 11pm on February 18th:\n\n`echo \"notify-send '{{Wake up!}}'\" | at {{11pm}} {{Feb 18}}`\n"
 },
 {
   "command": "postfix",
   "doc_url": "http://postfix.org",
   "doc_text": "",
   "man_entry": "POSTFIX(1)\t\t\t\t\t\t\t    POSTFIX(1)\n\n\n\nNAME\n       postfix - Postfix control program\n\nSYNOPSIS\n       postfix [-Dv] [-c config_dir] command\n\nDESCRIPTION\n       This  command  is  reserved  for the superuser. To submit mail, use the\n       Postfix sendmail(1) command.\n\n       The postfix(1) command controls the operation of the Postfix mail  sys-\n       tem:  start  or stop the master(8) daemon, do a health check, and other\n       maintenance.\n\n       By default, the postfix(1) command sets up a  standardized  environment\n       and runs the postfix-script shell script to do the actual work.\n\n       However,  when  support\tfor  multiple Postfix instances is configured,\n       postfix(1) executes the command specified with the multi_instance_wrap-\n       per configuration parameter.  This command will execute the command for\n       each applicable Postfix instance.\n\n       The following commands are implemented:\n\n       check  Warn about bad directory/file ownership or permissions, and cre-\n\t      ate missing directories.\n\n       start  Start  the Postfix mail system. This also runs the configuration\n\t      check described above.\n\n       stop   Stop the Postfix mail system in an orderly fashion. If possible,\n\t      running  processes  are  allowed\tto terminate at their earliest\n\t      convenience.\n\n\t      Note: in order to refresh the Postfix mail system after  a  con-\n\t      figuration  change,  do  not  use the start and stop commands in\n\t      succession. Use the reload command instead.\n\n       abort  Stop the Postfix mail system  abruptly.  Running\tprocesses  are\n\t      signaled to stop immediately.\n\n       flush  Force delivery: attempt to deliver every message in the deferred\n\t      mail queue. Normally, attempts to deliver delayed mail happen at\n\t      regular  intervals,  the\tinterval  doubling  after  each failed\n\t      attempt.\n\n\t      Warning: flushing undeliverable mail frequently will  result  in\n\t      poor delivery performance of all other mail.\n\n       reload Re-read  configuration  files.  Running  processes  terminate at\n\t      their earliest convenience.\n\n       status Indicate if the Postfix mail system is currently running.\n\n       set-permissions [name=value ...]\n\t      Set the ownership and permissions of Postfix related  files  and\n\t      directories, as specified in the postfix-files file.\n\n\t      Specify  name=value to override and update specific main.cf con-\n\t      figuration parameters. Use this,\tfor  example,  to  change  the\n\t      mail_owner  or  setgid_group  setting  for  an already installed\n\t      Postfix system.\n\n\t      This feature is available in Postfix 2.1 and later.  With  Post-\n\t      fix   2.0   and\tearlier,  use  \"$config_directory/post-install\n\t      set-permissions\".\n\n       tls subcommand\n\t      Enable opportunistic TLS in the Postfix SMTP client  or  server,\n\t      and  manage  Postfix  SMTP  server TLS private keys and certifi-\n\t      cates.  See postfix-tls(1) for documentation.\n\n\t      This feature is available in Postfix 3.1 and later.\n\n       upgrade-configuration [name=value ...]\n\t      Update the main.cf and master.cf\tfiles  with  information  that\n\t      Postfix  needs  in order to run: add or update services, and add\n\t      or update configuration parameter settings.\n\n\t      Specify name=value to override and update specific main.cf  con-\n\t      figuration parameters.\n\n\t      This  feature is available in Postfix 2.1 and later.  With Post-\n\t      fix  2.0\tand   earlier,\t use   \"$config_directory/post-install\n\t      upgrade-configuration\".\n\n       The following options are implemented:\n\n       -c config_dir\n\t      Read  the main.cf and master.cf configuration files in the named\n\t      directory instead of the default configuration  directory.   Use\n\t      this  to\tdistinguish  between multiple Postfix instances on the\n\t      same host.\n\n\t      With Postfix 2.6 and later, this option  forces  the  postfix(1)\n\t      command to operate on the specified Postfix instance only.  This\n\t      behavior is inherited by\tpostfix(1)  commands  that  run  as  a\n\t      descendant of the current process.\n\n       -D (with postfix start only)\n\t      Run each Postfix daemon under control of a debugger as specified\n\t      via the debugger_command configuration parameter.\n\n       -v     Enable verbose  logging  for  debugging  purposes.  Multiple  -v\n\t      options make the software increasingly verbose.\n\nENVIRONMENT\n       The  postfix(1)\tcommand  exports  the  following environment variables\n       before executing the postfix-script file:\n\n       MAIL_CONFIG\n\t      This is set when the -c command-line option is present.\n\n\t      With Postfix 2.6 and later, this environment variable forces the\n\t      postfix(1)  command to operate on the specified Postfix instance\n\t      only.  This behavior is inherited by  postfix(1)\tcommands  that\n\t      run as a descendant of the current process.\n\n       MAIL_VERBOSE\n\t      This is set when the -v command-line option is present.\n\n       MAIL_DEBUG\n\t      This is set when the -D command-line option is present.\n\nCONFIGURATION PARAMETERS\n       The following main.cf configuration parameters are exported as environ-\n       ment variables with the same names:\n\n       config_directory (see 'postconf -d' output)\n\t      The default location of the Postfix main.cf and  master.cf  con-\n\t      figuration files.\n\n       command_directory (see 'postconf -d' output)\n\t      The location of all postfix administrative commands.\n\n       daemon_directory (see 'postconf -d' output)\n\t      The directory with Postfix support programs and daemon programs.\n\n       html_directory (see 'postconf -d' output)\n\t      The location of Postfix HTML files that describe how  to\tbuild,\n\t      configure or operate a specific Postfix subsystem or feature.\n\n       mail_owner (postfix)\n\t      The  UNIX  system  account  that owns the Postfix queue and most\n\t      Postfix daemon processes.\n\n       mailq_path (see 'postconf -d' output)\n\t      Sendmail compatibility feature that specifies where the  Postfix\n\t      mailq(1) command is installed.\n\n       manpage_directory (see 'postconf -d' output)\n\t      Where the Postfix manual pages are installed.\n\n       newaliases_path (see 'postconf -d' output)\n\t      Sendmail\tcompatibility  feature\tthat specifies the location of\n\t      the newaliases(1) command.\n\n       queue_directory (see 'postconf -d' output)\n\t      The location of the Postfix top-level queue directory.\n\n       readme_directory (see 'postconf -d' output)\n\t      The location of Postfix README files that describe how to build,\n\t      configure or operate a specific Postfix subsystem or feature.\n\n       sendmail_path (see 'postconf -d' output)\n\t      A  Sendmail compatibility feature that specifies the location of\n\t      the Postfix sendmail(1) command.\n\n       setgid_group (postdrop)\n\t      The  group  ownership  of  set-gid  Postfix  commands   and   of\n\t      group-writable Postfix directories.\n\n       Available in Postfix version 2.5 and later:\n\n       data_directory (see 'postconf -d' output)\n\t      The  directory  with  Postfix-writable  data files (for example:\n\t      caches, pseudo-random numbers).\n\n       Available in Postfix version 3.0 and later:\n\n       meta_directory (see 'postconf -d' output)\n\t      The location of non-executable files that are shared among  mul-\n\t      tiple  Postfix instances, such as postfix-files, dynamicmaps.cf,\n\t      and the multi-instance template  files  main.cf.proto  and  mas-\n\t      ter.cf.proto.\n\n       shlib_directory (see 'postconf -d' output)\n\t      The  location  of Postfix dynamically-linked libraries (libpost-\n\t      fix-*.so), and the default location of Postfix database  plugins\n\t      (postfix-*.so)  that  have  a  relative  pathname  in the dynam-\n\t      icmaps.cf file.\n\n       Available in Postfix version 3.1 and later:\n\n       openssl_path (openssl)\n\t      The location of the OpenSSL command line program openssl(1).\n\n       Other configuration parameters:\n\n       import_environment (see 'postconf -d' output)\n\t      The list of environment parameters that a Postfix  process  will\n\t      import from a non-Postfix parent process.\n\n       syslog_facility (mail)\n\t      The syslog facility of Postfix logging.\n\n       syslog_name (see 'postconf -d' output)\n\t      A  prefix  that  is  prepended  to  the  process\tname in syslog\n\t      records, so that, for example, \"smtpd\" becomes \"prefix/smtpd\".\n\n       Available in Postfix version 2.6 and later:\n\n       multi_instance_directories (empty)\n\t      An optional list of non-default Postfix  configuration  directo-\n\t      ries;  these  directories belong to additional Postfix instances\n\t      that share the Postfix executable files and  documentation  with\n\t      the  default  Postfix  instance,\tand that are started, stopped,\n\t      etc., together with the default Postfix instance.\n\n       multi_instance_wrapper (empty)\n\t      The pathname of a multi-instance manager command that the  post-\n\t      fix(1)   command\tinvokes  when  the  multi_instance_directories\n\t      parameter value is non-empty.\n\n       multi_instance_group (empty)\n\t      The optional instance group name of this Postfix instance.\n\n       multi_instance_name (empty)\n\t      The optional instance name of this Postfix instance.\n\n       multi_instance_enable (no)\n\t      Allow this Postfix instance to be started, stopped, etc.,  by  a\n\t      multi-instance manager.\n\nFILES\n       Prior  to Postfix version 2.6, all of the following files were in $con-\n       fig_directory. Some files are now in $daemon_directory so that they can\n       be shared among multiple instances that run the same Postfix version.\n\n       Use  the command \"postconf config_directory\" or \"postconf daemon_direc-\n       tory\" to expand the names into their actual values.\n\n       $config_directory/main.cf, Postfix configuration parameters\n       $config_directory/master.cf, Postfix daemon processes\n       $daemon_directory/postfix-files, file/directory permissions\n       $daemon_directory/postfix-script, administrative commands\n       $daemon_directory/post-install, post-installation configuration\n       $daemon_directory/dynamicmaps.cf, plug-in database clients\n\nSEE ALSO\n       Commands:\n       postalias(1), create/update/query alias database\n       postcat(1), examine Postfix queue file\n       postconf(1), Postfix configuration utility\n       postfix(1), Postfix control program\n       postfix-tls(1), Postfix TLS management\n       postkick(1), trigger Postfix daemon\n       postlock(1), Postfix-compatible locking\n       postlog(1), Postfix-compatible logging\n       postmap(1), Postfix lookup table manager\n       postmulti(1), Postfix multi-instance manager\n       postqueue(1), Postfix mail queue control\n       postsuper(1), Postfix housekeeping\n       mailq(1), Sendmail compatibility interface\n       newaliases(1), Sendmail compatibility interface\n       sendmail(1), Sendmail compatibility interface\n\n       Postfix configuration:\n       bounce(5), Postfix bounce message templates\n       master(5), Postfix master.cf file syntax\n       postconf(5), Postfix main.cf file syntax\n       postfix-wrapper(5), Postfix multi-instance API\n\n       Table-driven mechanisms:\n       access(5), Postfix SMTP access control table\n       aliases(5), Postfix alias database\n       canonical(5), Postfix input address rewriting\n       generic(5), Postfix output address rewriting\n       header_checks(5), body_checks(5), Postfix content inspection\n       relocated(5), Users that have moved\n       transport(5), Postfix routing table\n       virtual(5), Postfix virtual aliasing\n\n       Table lookup mechanisms:\n       cidr_table(5), Associate CIDR pattern with value\n       ldap_table(5), Postfix LDAP client\n       lmdb_table(5), Postfix LMDB database driver\n       memcache_table(5), Postfix memcache client\n       mysql_table(5), Postfix MYSQL client\n       nisplus_table(5), Postfix NIS+ client\n       pcre_table(5), Associate PCRE pattern with value\n       pgsql_table(5), Postfix PostgreSQL client\n       regexp_table(5), Associate POSIX regexp pattern with value\n       socketmap_table(5), Postfix socketmap client\n       sqlite_table(5), Postfix SQLite database driver\n       tcp_table(5), Postfix client-server table lookup\n\n       Daemon processes:\n       anvil(8), Postfix connection/rate limiting\n       bounce(8), defer(8), trace(8), Delivery status reports\n       cleanup(8), canonicalize and enqueue message\n       discard(8), Postfix discard delivery agent\n       dnsblog(8), DNS black/whitelist logger\n       error(8), Postfix error delivery agent\n       flush(8), Postfix fast ETRN service\n       local(8), Postfix local delivery agent\n       master(8), Postfix master daemon\n       oqmgr(8), old Postfix queue manager\n       pickup(8), Postfix local mail pickup\n       pipe(8), deliver mail to non-Postfix command\n       postscreen(8), Postfix zombie blocker\n       proxymap(8), Postfix lookup table proxy server\n       qmgr(8), Postfix queue manager\n       qmqpd(8), Postfix QMQP server\n       scache(8), Postfix connection cache manager\n       showq(8), list Postfix mail queue\n       smtp(8), lmtp(8), Postfix SMTP+LMTP client\n       smtpd(8), Postfix SMTP server\n       spawn(8), run non-Postfix server\n       tlsmgr(8), Postfix TLS cache and randomness manager\n       tlsproxy(8), Postfix TLS proxy server\n       trivial-rewrite(8), Postfix address rewriting\n       verify(8), Postfix address verification\n       virtual(8), Postfix virtual delivery agent\n\n       Other:\n       syslogd(8), system logging\n\nREADME FILES\n       Use \"postconf readme_directory\" or \"postconf html_directory\" to\tlocate\n       this information.\n       OVERVIEW, overview of Postfix commands and processes\n       BASIC_CONFIGURATION_README, Postfix basic configuration\n       ADDRESS_REWRITING_README, Postfix address rewriting\n       SMTPD_ACCESS_README, SMTP relay/access control\n       CONTENT_INSPECTION_README, Postfix content inspection\n       QSHAPE_README, Postfix queue analysis\n\nLICENSE\n       The Secure Mailer license must be distributed with this software.\n\nAUTHOR(S)\n       Wietse Venema\n       IBM T.J. Watson Research\n       P.O. Box 704\n       Yorktown Heights, NY 10598, USA\n\n       Wietse Venema\n       Google, Inc.\n       111 8th Avenue\n       New York, NY 10011, USA\n\n       TLS support by:\n       Lutz Jaenicke\n       Brandenburg University of Technology\n       Cottbus, Germany\n\n       Victor Duchovni\n       Morgan Stanley\n\n       SASL support originally by:\n       Till Franke\n       SuSE Rhein/Main AG\n       65760 Eschborn, Germany\n\n       LMTP support originally by:\n       Philip A. Prindeville\n       Mirapoint, Inc.\n       USA.\n\n       Amos Gouaux\n       University of Texas at Dallas\n       P.O. Box 830688, MC34\n       Richardson, TX 75083, USA\n\n       IPv6 support originally by:\n       Mark Huizer, Eindhoven University, The Netherlands\n       Jun-ichiro 'itojun' Hagino, KAME project, Japan\n       The Linux PLD project\n       Dean Strik, Eindhoven University, The Netherlands\n\n\n\n\t\t\t\t\t\t\t\t    POSTFIX(1)\n",
   "tldr_summary": "# postfix\n\n> Postfix mail transfer agent (MTA) control program.\n> See also `dovecot`, a mail delivery agent (MDA) that integrates with Postfix.\n> More information: <http://postfix.org>.\n\n- Check the configuration:\n\n`sudo postfix check`\n\n- Check the status of the Postfix daemon:\n\n`sudo postfix status`\n\n- Start Postfix:\n\n`sudo postfix start`\n\n- Gracefully stop Postfix:\n\n`sudo postfix stop`\n\n- Flush the mail queue:\n\n`sudo postfix flush`\n\n- Reload the configuration files:\n\n`sudo postfix reload`\n"
 },
 {
   "command": "wodim",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# wodim\n\n> Command (aliased as `cdrecord` on some systems) for recording data to CDs or DVDs.\n> Some invocations of wodim can cause destructive actions, such as erasing all the data on a disc.\n\n- Display optical drives available to `wodim`:\n\n`wodim --devices`\n\n- Record (\"burn\") an audio-only disc:\n\n`wodim dev=/dev/{{optical_drive}} -audio {{track*.cdaudio}}`\n\n- Burn a file to a disc, ejecting the disc once done (some recorders require this):\n\n`wodim -eject dev=/dev/{{optical_drive}} -data {{file.iso}}`\n\n- Burn a file to the disc in an optical drive, potentially writing to multiple discs in succession:\n\n`wodim -tao dev=/dev/{{optical_drive}} -data {{file.iso}}`\n"
 },
 {
   "command": "logger",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nLOGGER(1)\t\t  BSD General Commands Manual\t\t     LOGGER(1)\n\nNAME\n     logger -- make entries in the system log\n\nSYNOPSIS\n     logger [-is] [-f file] [-p pri] [-t tag] [message ...]\n\nDESCRIPTION\n     Logger provides a shell command interface to the syslog(3) system log\n     module.\n\n     Options:\n\n     -i       Log the process id of the logger process with each line.\n\n     -s       Log the message to standard error, as well as the system log.\n\n     -f file  Log the specified file.\n\n     -p pri   Enter the message with the specified priority.  The priority may\n\t      be specified numerically or as a ``facility.level'' pair.  For\n\t      example, ``-p local3.info'' logs the message(s) as informational\n\t      level in the local3 facility.  The default is ``user.notice.''\n\n     -t tag   Mark every line in the log with the specified tag.\n\n     message  Write the message to log; if not specified, and the -f flag is\n\t      not provided, standard input is logged.\n\n     The logger utility exits 0 on success, and >0 if an error occurs.\n\nEXAMPLES\n\t   logger System rebooted\n\n\t   logger -p local0.notice -t HOSTIDM -f /dev/idmc\n\nSEE ALSO\n     syslog(3), syslogd(8)\n\nSTANDARDS\n     The logger utility conforms to IEEE Std 1003.2-1992 (``POSIX.2'').\n\n4.3 Berkeley Distribution\t June 6, 1993\t     4.3 Berkeley Distribution\n",
   "tldr_summary": "# logger\n\n> Add messages to syslog (/var/log/syslog).\n\n- Log a message to syslog:\n\n`logger {{message}}`\n\n- Take input from `stdin` and log to syslog:\n\n`echo {{log_entry}} | logger`\n\n- Send the output to a remote syslog server running at a given port. Default port is 514:\n\n`echo {{log_entry}} | logger --server {{hostname}} --port {{port}}`\n\n- Use a specific tag for every line logged. Default is the name of logged in user:\n\n`echo {{log_entry}} | logger --tag {{tag}}`\n\n- Log messages with a given priority. Default is `user.notice`. See `man logger` for all priority options:\n\n`echo {{log_entry}} | logger --priority {{user.warning}}`\n"
 },
 {
   "command": "mkfs.exfat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs.exfat\n\n> Creates an exfat filesystem inside a partition.\n\n- Create an exfat filesystem inside partition 1 on device b (`sdb1`):\n\n`mkfs.exfat {{/dev/sdb1}}`\n\n- Create filesystem with a volume-name:\n\n`mkfs.exfat -n {{volume_name}} {{/dev/sdb1}}`\n\n- Create filesystem with a volume-id:\n\n`mkfs.exfat -i {{volume_id}} {{/dev/sdb1}}`\n"
 },
 {
   "command": "top",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nTOP(1)\t\t\t  BSD General Commands Manual\t\t\tTOP(1)\n\nNAME\n     top -- display and update sorted information about processes\n\nSYNOPSIS\n     top [-a | -d | -e | -c mode]\n\t [-F | -f]\n\t [-h]\n\t [-i interval]\n\t [-l samples]\n\t [-ncols columns]\n\t [-o key | -O skey]\n\t [-R | -r]\n\t [-S]\n\t [-s delay-secs]\n\t [-n nprocs]\n\t [-stats keys]\n\t [-pid processid]\n\t [-user username]\n\t [-U username]\n\t [-u]\n\nDESCRIPTION\n     The top program periodically displays a sorted list of system processes.\n     The default sorting key is pid, but other keys can be used instead.  Var-\n     ious output options are available.\n\nOPTIONS\n     Command line option specifications are processed from left to right.\n     Options can be specified more than once.  If conflicting options are\n     specified, later specifications override earlier ones.  This makes it\n     viable to create a shell alias for top with preferred defaults specified,\n     then override those preferred defaults as desired on the command line.\n\n     -a      Equivalent to Fl c Ar a .\n\n     -c mode\n\t     Set event counting mode to mode.  The supported modes are\n\n\t     a\t     Accumulative mode.  Count events cumulatively, starting\n\t\t     at the launch of top.  Calculate CPU usage and CPU time\n\t\t     since the launch of top.\n\n\t     d\t     Delta mode.  Count events relative to the previous sam-\n\t\t     ple.  Calculate CPU usage since the previous sample.\n\t\t     This mode by default disables the memory object map\n\t\t     reporting.  The memory object map reporting may be re-\n\t\t     enabled with the -r option or the interactive r command.\n\n\t     e\t     Absolute mode.  Count events using absolute counters.\n\n\t     n\t     Non-event mode (default).\tCalculate CPU usage since the\n\t\t     previous sample.\n\n     -d      Equivalent to -c d.\n\n     -e      Equivalent to -c e.\n\n     -F      Do not calculate statistics on shared libraries, also known as\n\t     frameworks.\n\n     -f      Calculate statistics on shared libraries, also known as frame-\n\t     works (default).\n\n     -h      Print command line usage information and exit.\n\n     -i interval\n\t     Update framework (-f) info every interval samples; see the\n\t     PERFORMANCE/ACCURACY TRADEOFF section for more details.\n\n     -l samples\n\t     Use logging mode and display samples samples, even if standard\n\t     output is a terminal.  0 is treated as infinity.  Rather than\n\t     redisplaying, output is periodically printed in raw form.\tNote\n\t     that the first sample displayed will have an invalid %CPU dis-\n\t     played for each process, as it is calculated using the delta\n\t     between samples.\n\n     -ncols columns\n\t     Display columns when using logging mode.  The default is infi-\n\t     nite.  The number must be >0 or an error will occur.\n\n     -n nprocs\n\t     Only display up to nprocs processes.\n\n     -O skey\n\t     Use skey as a secondary key when ordering the process display.\n\t     See -o for key names (pid is the default).\n\n     -o key  Order the process display by sorting on key in descending order.\n\t     A + or - can be prefixed to the key name to specify ascending or\n\t     descending order, respectively.  The supported keys are:\n\n\t     pid     Process ID (default).\n\n\t     command\n\t\t     Command name.\n\n\t     cpu     CPU usage.\n\n\t     cpu_me  CPU time charged to me by other processes.\n\n\t     cpu_others\n\t\t     CPU time charged to other processes by me.\n\n\t     csw     The number of context switches.\n\n\t     time    Execution time.\n\n\t     threads\n\t\t     alias: th\n\t\t     Number of threads (total/running).\n\n\t     ports   alias: prt\n\t\t     Number of Mach ports.\n\n\t     mregion\n\t\t     alias: mreg, reg\n\t\t     Number of memory regions.\n\n\t     mem     Physical memory footprint of the process.\n\n\t     rprvt   Resident private address space size.\n\n\t     purg    Purgeable memory size.\n\n\t     vsize   Total memory size.\n\n\t     vprvt   Private address space size.\n\n\t     kprvt   Private kernel memory size.\n\n\t     kshrd   Shared kernel memory size.\n\n\t     pgrp    Process group ID.\n\n\t     ppid    Parent process ID.\n\n\t     state   alias: pstate\n\t\t     Process state.\n\n\t     uid     User ID.\n\n\t     wq      alias: #wq, workqueue\n\t\t     The workqueue total/running.\n\n\t     faults  alias: fault\n\t\t     The number of page faults.\n\n\t     cow     alias: cow_faults\n\t\t     The copy-on-write faults.\n\n\t     user    alias: username\n\t\t     Username.\n\n\t     msgsent\n\t\t     Total number of Mach messages sent.\n\n\t     msgrecv\n\t\t     Total number of Mach messages received.\n\n\t     sysbsd  Total BSD syscalls.\n\n\t     sysmach\n\t\t     Total Mach syscalls.\n\n\t     pageins\n\t\t     Total pageins.\n\n\t     boosts  The number of boosts help by the process.\tThis is fol-\n\t\t     lowed by the number of times the process has transitioned\n\t\t     from unboosted to boosted in brackets.  An asterisk\n\t\t     before the value indicates that the process was able to\n\t\t     send boosts at some point since the previous update.  For\n\t\t     more information about boosts, see xpc_transac-\n\t\t     tion_begin(3).\n\n\t     instrs  The number of instructions retired by the process in both\n\t\t     user space and the kernel.\n\n\t     cycles  The number of cycles spent executing instructions in the\n\t\t     process in both user space and the kernel.\n\n     -R      Do not traverse and report the memory object map for each process\n\t     (default).\n\n     -r      Traverse and report the memory object map for each process.\n\n     -S      Display the global statistics for swap and purgeable memory.\n\n     -s delay-secs\n\t     Set the delay between updates to delay-secs seconds.  The default\n\t     delay between updates is 1 second.\n\n     -stats keys\n\t     Only display the comma separated statistics.  See the -o flag for\n\t     the valid keys.\n\n     -pid processid\n\t     Only display processid in top.  This option may be specified mul-\n\t     tiple times.\n\n     -user user\n\t     Only display processes owned by user\n\n     -U user\n\t     This is an alias for -user.\n\n     -u      This is an alas equivalent to: -o cpu -O time\n\nDISPLAY\n     The first several lines of the top display show various global state.\n     All of the information is labeled.  Following is an alphabetical list of\n     global state fields and their descriptions.\n\n     CPU\t Percentage of processor usage, broken into user, system, and\n\t\t idle components.  The time period for which these percentages\n\t\t are calculated depends on the event counting mode.\n\n     Disks\t Number and total size of disk reads and writes.\n\n     LoadAvg\t Load average over 1, 5, and 15 minutes.  The load average is\n\t\t the average number of jobs in the run queue.\n\n     MemRegions  Number and total size of memory regions, and total size of\n\t\t memory regions broken into private (broken into non-library\n\t\t and library) and shared components.\n\n     Networks\t Number and total size of input and output network packets.\n\n     PhysMem\t Physical memory usage, broken into wired, active, inactive,\n\t\t used, and free components.\n\n     Procs\t Total number of processes and number of processes in each\n\t\t process state.\n\n     SharedLibs  Resident sizes of code and data segments, and link editor\n\t\t memory usage.\n\n     Threads\t Number of threads.\n\n     Time\t Time, in H:MM:SS format.  When running in logging mode, Time\n\t\t is in YYYY/MM/DD HH:MM:SS format by default, but may be over-\n\t\t ridden with accumulative mode.  When running in accumulative\n\t\t event counting mode, the Time is in HH:MM:SS since the begin-\n\t\t ning of the top process.\n\n     VirtMem\t Total virtual memory, virtual memory consumed by shared\n\t\t libraries, and number of pageins and pageouts.\n\n     Swap\t Swap usage: total size of swap areas, amount of swap space in\n\t\t use and amount of swap space available.\n\n     Purgeable\t Number of pages purged and number of pages currently purge-\n\t\t able.\n\n     Below the global state fields, a list of processes is displayed.  The\n     fields that are displayed depend on the options that are set.  The pid\n     field displays the following for the architecture:\n\n     + for 64-bit native architecture, or - for 32-bit native architecture, or\n     * for a non-native architecture.\n\nINTERACTION\n     When top is run in interactive (non-logging) mode, it is possible to con-\n     trol the output of top, as well as interactively send signals to pro-\n     cesses.  The interactive command syntax is terse.\tEach command is one\n     character, followed by 0 to 2 arguments.  Commands that take arguments\n     prompt interactively for the arguments, and where applicable, the default\n     value is shown in square brackets.  The default value can be selected by\n     leaving the input field blank and pressing enter.\t^G escapes the inter-\n     active argument prompt, and has the same effect as leaving the input\n     field blank and pressing enter.\n\n     The following commands are supported:\n\n     ?\t     Display the help screen.  Any character exits help screen mode.\n\t     This command always works, even in the middle of a command.\n\n     ^L      Redraw the screen.\n\n     cmode   Set output mode to mode.  See the -c option for descriptions of\n\t     the allowed modes.\n\n     Oskey   Use skey as a secondary key when ordering the process display.\n\t     See the -o option for key names.\n\n     okey    Order the process display by sorting on key in descending order.\n\t     A + or - can be prefixed to the key name to specify ascending or\n\t     descending order, respectively.  The supported keys and alises\n\t     are listed with the -o option above.\n\n     q\t     Quit.\n\n     r\t     Toggle traversal and reporting of the memory object map for each\n\t     process.\n\n     Ssignalpid\n\t     Send signal signal to pid.  signal can be specified either as a\n\t     number or as a name (for example, HUP).  The default signal\n\t     starts out as TERM.  Each time a signal is successfully sent, the\n\t     default signal is updated to be that signal.  pid is a process\n\t     id.\n\n     s delay-secs\n\t     Set the delay between updates to delay-secs seconds.\n\n     U user  Only display processes owned by user. Either the username or uid\n\t     number can be specified.  To display all processes, press enter\n\t     without entering a username or uid number.\n\nPERFORMANCE/ACCURACY TRADEOFF\n     Calculating detailed memory statistics is fundamentally resource-inten-\n     sive.  To reduce the CPU usage in top, the -i option has been introduced\n     to allow the user to tune this tradeoff.  With the default value of 10,\n     framework stats will be updated once every 10 samples.  Specifying -i 1\n     will result in the most accurate display, at the expense of system\n     resources.\n\nNOT AVAILABLE\n     When N/A occurs in a stat, it's caused by the memory object map reporting\n     being disabled.  Memory object map reporting is disabled by default in\n     delta mode, but may be optionally enabled via -r or the interactive r\n     command.  To enable the -r option, use it after any -c mode options.\n\nEXAMPLES\n     top -o cpu -O +rsize -s 5 -n 20\n\t     Sort the processes according to CPU usage (descending) and resi-\n\t     dent memory size (ascending), sample and update the display at 5\n\t     second intervals, and limit the display to 20 processes.\n\n     top -c d\n\t     Run top in delta mode.\n\n     top -stats pid,command,cpu,th,pstate,time\n\t     Display only the specified statistics, regardless of any growth\n\t     of the terminal.  If the terminal is too small, only the statis-\n\t     tics that fit will be displayed.\n\nSEE ALSO\n     kill(2), vm_stat(1), signal(3), vmmap(1)\n\nDarwin\t\t\t\t 13 March 2017\t\t\t\tDarwin\n",
   "tldr_summary": "# top\n\n> Display dynamic real-time information about running processes.\n\n- Start top:\n\n`top`\n\n- Do not show any idle or zombie processes:\n\n`top -i`\n\n- Show only processes owned by given user:\n\n`top -u {{username}}`\n\n- Sort processes by a field:\n\n`top -o {{field_name}}`\n\n- Show the individual threads of a given process:\n\n`top -Hp {{process_id}}`\n\n- Show only the processes with the given PID(s), passed as a comma-separated list. (Normally you wouldn't know PIDs off hand. This example picks the PIDs from the process name):\n\n`top -p $(pgrep -d ',' {{process_name}})`\n\n- Get help about interactive commands:\n\n`?`\n"
 },
 {
   "command": "xsel",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xsel\n\n> X11 selection and clipboard manipulation tool.\n\n- Use a command's output as input of the clip[b]oard (equivalent to `Ctrl + C`):\n\n`echo 123 | xsel -ib`\n\n- Use the contents of a file as input of the clipboard:\n\n`cat {{file}} | xsel -ib`\n\n- Output the clipboard's contents into the terminal (equivalent to `Ctrl + V`):\n\n`xsel -ob`\n\n- Output the clipboard's contents into a file:\n\n`xsel -ob > {{file}}`\n\n- Clear the clipboard:\n\n`xsel -cb`\n\n- Output the X11 primary selection's contents into the terminal (equivalent to a mouse middle-click):\n\n`xsel -op`\n"
 },
 {
   "command": "export",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBUILTIN(1)\t\t  BSD General Commands Manual\t\t    BUILTIN(1)\n\nNAME\n     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,\n     breaksw, builtins, case, cd, chdir, command, complete, continue, default,\n     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,\n     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,\n     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,\n     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,\n     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,\n     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,\n     telltc, test, then, time, times, trap, true, type, ulimit, umask,\n     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,\n     where, which, while -- shell built-in commands\n\nSYNOPSIS\n     builtin [-options] [args ...]\n\nDESCRIPTION\n     Shell builtin commands are commands that can be executed within the run-\n     ning shell's process.  Note that, in the case of csh(1) builtin commands,\n     the command is executed in a subshell if it occurs as any component of a\n     pipeline except the last.\n\n     If a command specified to the shell contains a slash ``/'', the shell\n     will not execute a builtin command, even if the last component of the\n     specified command matches the name of a builtin command.  Thus, while\n     specifying ``echo'' causes a builtin command to be executed under shells\n     that support the echo builtin command, specifying ``/bin/echo'' or\n     ``./echo'' does not.\n\n     While some builtin commands may exist in more than one shell, their oper-\n     ation may be different under each shell which supports them.  Below is a\n     table which lists shell builtin commands, the standard shells that sup-\n     port them and whether they exist as standalone utilities.\n\n     Only builtin commands for the csh(1) and sh(1) shells are listed here.\n     Consult a shell's manual page for details on the operation of its builtin\n     commands.\tBeware that the sh(1) manual page, at least, calls some of\n     these commands ``built-in commands'' and some of them ``reserved words''.\n     Users of other shells may need to consult an info(1) page or other\n     sources of documentation.\n\n     Commands marked ``No**'' under External do exist externally, but are\n     implemented as scripts using a builtin command of the same name.\n\n\t   Command\t External    csh(1)    sh(1)\n\t   !\t\t No\t     No        Yes\n\t   %\t\t No\t     Yes       No\n\t   .\t\t No\t     No        Yes\n\t   :\t\t No\t     Yes       Yes\n\t   @\t\t No\t     Yes       Yes\n\t   {\t\t No\t     No        Yes\n\t   }\t\t No\t     No        Yes\n\t   alias\t No**\t     Yes       Yes\n\t   alloc\t No\t     Yes       No\n\t   bg\t\t No**\t     Yes       Yes\n\t   bind \t No\t     No        Yes\n\t   bindkey\t No\t     Yes       No\n\t   break\t No\t     Yes       Yes\n\t   breaksw\t No\t     Yes       No\n\t   builtin\t No\t     No        Yes\n\t   builtins\t No\t     Yes       No\n\t   case \t No\t     Yes       Yes\n\t   cd\t\t No**\t     Yes       Yes\n\t   chdir\t No\t     Yes       Yes\n\t   command\t No**\t     No        Yes\n\t   complete\t No\t     Yes       No\n\t   continue\t No\t     Yes       Yes\n\t   default\t No\t     Yes       No\n\t   dirs \t No\t     Yes       No\n\t   do\t\t No\t     No        Yes\n\t   done \t No\t     No        Yes\n\t   echo \t Yes\t     Yes       Yes\n\t   echotc\t No\t     Yes       No\n\t   elif \t No\t     No        Yes\n\t   else \t No\t     Yes       Yes\n\t   end\t\t No\t     Yes       No\n\t   endif\t No\t     Yes       No\n\t   endsw\t No\t     Yes       No\n\t   esac \t No\t     No        Yes\n\t   eval \t No\t     Yes       Yes\n\t   exec \t No\t     Yes       Yes\n\t   exit \t No\t     Yes       Yes\n\t   export\t No\t     No        Yes\n\t   false\t Yes\t     No        Yes\n\t   fc\t\t No**\t     No        Yes\n\t   fg\t\t No**\t     Yes       Yes\n\t   filetest\t No\t     Yes       No\n\t   fi\t\t No\t     No        Yes\n\t   for\t\t No\t     No        Yes\n\t   foreach\t No\t     Yes       No\n\t   getopts\t No**\t     No        Yes\n\t   glob \t No\t     Yes       No\n\t   goto \t No\t     Yes       No\n\t   hash \t No\t     No        Yes\n\t   hashstat\t No\t     Yes       No\n\t   history\t No\t     Yes       No\n\t   hup\t\t No\t     Yes       No\n\t   if\t\t No\t     Yes       Yes\n\t   jobid\t No\t     No        Yes\n\t   jobs \t No**\t     Yes       Yes\n\t   kill \t Yes\t     Yes       No\n\t   limit\t No\t     Yes       No\n\t   local\t No\t     No        Yes\n\t   log\t\t No\t     Yes       No\n\t   login\t Yes\t     Yes       No\n\t   logout\t No\t     Yes       No\n\t   ls-F \t No\t     Yes       No\n\t   nice \t Yes\t     Yes       No\n\t   nohup\t Yes\t     Yes       No\n\t   notify\t No\t     Yes       No\n\t   onintr\t No\t     Yes       No\n\t   popd \t No\t     Yes       No\n\t   printenv\t Yes\t     Yes       No\n\t   pushd\t No\t     Yes       No\n\t   pwd\t\t Yes\t     No        Yes\n\t   read \t No**\t     No        Yes\n\t   readonly\t No\t     No        Yes\n\t   rehash\t No\t     Yes       No\n\t   repeat\t No\t     Yes       No\n\t   return\t No\t     No        Yes\n\t   sched\t No\t     Yes       No\n\t   set\t\t No\t     Yes       Yes\n\t   setenv\t No\t     Yes       No\n\t   settc\t No\t     Yes       No\n\t   setty\t No\t     Yes       No\n\t   setvar\t No\t     No        Yes\n\t   shift\t No\t     Yes       Yes\n\t   source\t No\t     Yes       No\n\t   stop \t No\t     Yes       No\n\t   suspend\t No\t     Yes       No\n\t   switch\t No\t     Yes       No\n\t   telltc\t No\t     Yes       No\n\t   test \t Yes\t     No        Yes\n\t   then \t No\t     No        Yes\n\t   time \t Yes\t     Yes       No\n\t   times\t No\t     No        Yes\n\t   trap \t No\t     No        Yes\n\t   true \t Yes\t     No        Yes\n\t   type \t No\t     No        Yes\n\t   ulimit\t No\t     No        Yes\n\t   umask\t No**\t     Yes       Yes\n\t   unalias\t No**\t     Yes       Yes\n\t   uncomplete\t No\t     Yes       No\n\t   unhash\t No\t     Yes       No\n\t   unlimit\t No\t     Yes       No\n\t   unset\t No\t     Yes       Yes\n\t   unsetenv\t No\t     Yes       No\n\t   until\t No\t     No        Yes\n\t   wait \t No**\t     Yes       Yes\n\t   where\t No\t     Yes       No\n\t   which\t Yes\t     Yes       No\n\t   while\t No\t     Yes       Yes\n\nSEE ALSO\n     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),\n     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)\n\nHISTORY\n     The builtin manual page first appeared in FreeBSD 3.4.\n\nAUTHORS\n     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# export\n\n> Command to mark shell variables in the current environment to be exported with any newly forked child processes.\n\n- Set a new environment variable:\n\n`export {{VARIABLE}}={{value}}`\n\n- Remove an environment variable:\n\n`export -n {{VARIABLE}}`\n\n- Mark a shell function for export:\n\n`export -f {{FUNCTION_NAME}}`\n\n- Append something to the PATH variable:\n\n`export PATH=$PATH:{{path/to/append}}`\n"
 },
 {
   "command": "pvcreate",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pvcreate\n\n> Initialize a physical volume (disk or partition) for use by the Logical Volume Manager (LVM).\n\n- Initialize the `/dev/sda1` volume for use by LVM:\n\n`pvcreate {{/dev/sda1}}`\n\n- Force the creation without any confirmation prompts:\n\n`pvcreate --force {{/dev/sda1}}`\n"
 },
 {
   "command": "modinfo",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# modinfo\n\n> Extract information about a Linux kernel module.\n\n- List all attributes of a kernel module:\n\n`modinfo {{kernel_module}}`\n\n- List the specified attribute only:\n\n`modinfo -F {{author|description|license|parm|filename}} {{kernel_module}}`\n"
 },
 {
   "command": "hostnamectl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# hostnamectl\n\n> Get or set the hostname of the computer.\n\n- Get the hostname of the computer:\n\n`hostnamectl`\n\n- Set the hostname of the computer:\n\n`sudo hostnamectl set-hostname \"{{some_hostname}}\"`\n"
 },
 {
   "command": "sm",
   "doc_url": "https://github.com/nomeata/screen-message",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - nomeata/screen-message: Very simple tool to display some text as large as possible\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnomeata\n\n/\n\nscreen-message\n\n\n\n\n\n\n\n    Watch\n \n      3\n    \n\n\n\n\n      Star\n\n\n      30\n    \n\n\n\n\n          Fork\n\n\n        4\n      \n\n\n\n\n\n        Very simple tool to display some text as large as possible\n      \n\n\n\n30\n        stars\n \n\n4\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n3\n \n\n\n\nPull requests\n1\n \n\n\n\nActions\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n0\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n \n \nGit stats\n\n\n\n\n\n397\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\ndebian\n\n\n \n\n\n \n\n\n\n\n\n\n\n.travis.yml\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile.am\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.Win32.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME.md\n\n\n \n\n\n \n\n\n\n\n\n\n\nconfigure.ac\n\n\n \n\n\n \n\n\n\n\n\n\n\ngtkzoom.c\n\n\n \n\n\n \n\n\n\n\n\n\n\ngtkzoom.h\n\n\n \n\n\n \n\n\n\n\n\n\n\npush-sm.nomeata.de.sh\n\n\n \n\n\n \n\n\n\n\n\n\n\nsetup.iss.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm-128.png\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm-fsmi-ka.jpg\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.6\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.c\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.desktop.in\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.html\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.ico\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.png\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.py\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.rc\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.svg\n\n\n \n\n\n \n\n\n\n\n\n\n\nsm.webapp\n\n\n \n\n\n \n\n\n\n\n\n\n\nwebapp.html\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README.md\n      \n\n\n\n\n\n\n\n\nscreen-message\nIf you just want to display a word or a short, possibly multi-line, text as\nlarge and as quickly as possible on your screen, then screen-message is the\nright too for you. It has been used already twice at a Debian conference for\nthe Mugshots.\nscreen-message runs on Linux and Windows and there is an online version on http://sm.nomeata.de/.\nInstallation Linux\nGet it from your distribution with\napt install sm\n\nor install it from this source repository, if you know how to do these things.\nInstallation Windows\nGet the latest windows installer\nfrom my webpage. The windows installer lags behind a few versions; let me know if you need a new version.\nUsage\nScreen Message  will display a given multi-line message as large as possible, fullscreen\nand black on white. You can specify the text either when launching sm, or edit it  while\nthe program is running.\nAfter  a short timeout, the text entry and the quit button will disappear, leaving\nnothing on the screen but the entered text. To continue entering text, just start typing\nor (left-)click anywhere on the screen.\nTo clear the displayed text, press Escape.\nTo invert the colors of the text and the background, press Ctrl-I.\nTo quit the program, press Ctrl-Q, or Escape twice, or click the “Quit”-button.\nOptions\n\n\n[ text | - ]\nText  to  display at start up. Defaults to \":-)\". If \"-\" is passed to sm, it will\nread the text to display from the standard input, see REMOTE CONTROLLING SM.\n\n\n-f, --foreground=colordesc\nDefine a different color to use for the foreground of the text  to  display  than\nblack.  The text string can be in any of the forms accepted by XParseColor; these\ninclude name for a color from rgb.txt, such as DarkSlateGray, or a hex\nspecification such as #3050b2 or #35b.\n\n\n-b, --background=colordesc\nDefine  a  different  color to use for the background of the text to display than\nwhite. For possible values, see above.\n\n\n-i, --invert\nSwitch the roles for foreground and  background  colors.  Useful  if  you  prefer\nwhite-on-black.\n\n\n-n, --font=fontspec\nDefine  a  different font to use than the default sans-serif font of your system.\nThe fontspec be the complete name for a truetype  font  (like  \"DejaVu  Sans\"  or\n\"Bitstream  Vera  Serif\")  or  just  a  short font family specification (\"serif\",\n\"sans-serif\").\n\n\n-r, --rotate=rotation\nRotates the display by rotation * 90 degrees counter-clock-wise. So  -r 1  rotates\nthe display to the left, and -r 2 puts it upside down.\n\n\n-a, --align=alignment\nAligns the text centered (-a 0), left (-a 1) or right (-a 2).\n\n\n-- (Double  dash)\nEnd option parsing. This is used to be able to actually hand over\ntext that starts of with an dash.\n\n\n-h, --help\nThis option will give you  a  short  usage  message  summarizing  the  recognized\noptions and quits.\n\n\n-V --version\nThis prints the project name together with its version number quits.\n\n\nRemote controlling sm\nIf  sm  is  called  with - as a command line argument, it will read the text to be shown\nfrom the standard input. It will read the input until it reaches the end of the file, or\nthe  line  form character \\f, and show the input read so far at once. Newline characters\nat the beginning or the end are ignored. The input is assumed to be UTF-8  encoded.\nThis  can  be  used to create automatic displays of changing data or similar tricks. For\nexample, the following command will create a simple digital watch:\n(while sleep 1; do date +%T; printf '\\f'; done) | sm -\n\nContact\nUse the GitHub issue tracker or write to Joachim Breitner <mail@joachim-breitner.de>.\n\n\n\n\n\n\n\n\nAbout\n\n      Very simple tool to display some text as large as possible\n    \nResources\n\n\n\n      Readme\n \n\n\n\n\n\n\n    Releases\n\nNo releases published\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC\n45.0%\n\n\n\n\n\nHTML\n25.0%\n\n\n\n\n\nRoff\n10.4%\n\n\n\n\n\nPython\n10.3%\n\n\n\n\n\nM4\n5.0%\n\n\n\n\n\nMakefile\n3.9%\n\n\n\n\n\nShell\n0.4%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# sm\n\n> Displays a short message fullscreen.\n> More information: <https://github.com/nomeata/screen-message>.\n\n- Display a message in full-screen:\n\n`sm \"{{Hello World!}}\"`\n\n- Display a message with inverted colors:\n\n`sm -i \"{{Hello World!}}\"`\n\n- Display a message with a custom foreground color:\n\n`sm -f {{blue}} \"{{Hello World!}}\"`\n\n- Display a message with a custom background color:\n\n`sm -b {{#008888}} \"{{Hello World!}}\"`\n\n- Display a message rotated 3 times (in steps of 90 degrees, counterclockwise):\n\n`sm -r {{3}} \"{{Hello World!}}\"`\n\n- Display a message using the output from another command:\n\n`{{echo \"Hello World!\"}} | sm -`\n"
 },
 {
   "command": "ddrescue",
   "doc_url": "https://www.gnu.org/software/ddrescue/",
   "doc_text": "\n\n\nDdrescue - GNU Project - Free Software Foundation (FSF)\n\n\n\n\n\nDdrescue - Data recovery tool\n\n\n\n[ English\n| Español\n| Français\n| Italiano ]\n\nIntroduction\n\nGNU ddrescue is a data recovery tool. It copies data from one file or\nblock device (hard disc, cdrom, etc) to another, trying to rescue the\ngood parts first in case of read errors.\n\nDdrescuelog is a tool that manipulates ddrescue mapfiles, shows mapfile\ncontents, converts mapfiles to/from other formats, compares mapfiles,\ntests rescue status, and can delete a mapfile if the rescue is done.\nDdrescuelog operations can be restricted to one or several parts of the\nmapfile if the domain setting options are used.\n\nThe basic operation of ddrescue is fully automatic. That is, you don't\nhave to wait for an error, stop the program, restart it from a new\nposition, etc.\n\nIf you use the mapfile feature of ddrescue, the data are rescued very\nefficiently, (only the needed blocks are read). Also you can interrupt\nthe rescue at any time and resume it later at the same point. The\nmapfile is an essential part of ddrescue's effectiveness. Use it unless\nyou know what you are doing.\n\nDdrescue does not write zeros to the output when it finds bad sectors in\nthe input, and does not truncate the output file if not asked to. So,\nevery time you run it on the same output file, it tries to fill in the\ngaps without wiping out the data already rescued.\n\nAutomatic merging of backups: If you have two or more damaged copies of\na file, cdrom, etc, and run ddrescue on all of them, one at a time, with\nthe same output file, you will probably obtain a complete and error-free\nfile. This is so because the probability of having the same area damaged\nin all copies is low (if the errors are randomly located). Using the\nmapfile, only the needed blocks are read from the second and successive\ncopies.\n\nDdrescue recommends lzip\nfor compression of backups because the lzip format is designed for long-term\narchiving and provides data recovery capabilities which nicely complement\nthose of ddrescue. (Ddrescue fills unreadable sectors with data from other\ncopies, while lziprecover corrects corrupt sectors with data from other\ncopies). If the cause of file corruption is damaged media, the combination\nddrescue + lziprecover\nis the best option for recovering data from multiple damaged copies.\n\nRecordable CD and DVD media keep their data only for a finite time\n(typically for some years). After that time, data loss develops slowly\nwith read errors growing from the outer media region towards the inside.\nJust make two (or more) copies of every important CD-ROM/DVD you burn so\nthat you can later recover them with ddrescue.\n\nThe mapfile is periodically saved to disc. So in case of a crash you can\nresume the rescue with little recopying.\n\nAlso, the same mapfile can be used for multiple commands that copy\ndifferent areas of the file, and for multiple recovery attempts over\ndifferent subsets.\n\nDdrescue also features a \"fill mode\" able to selectively overwrite parts\nof the output file, which has a number of interesting uses like wiping\ndata, marking bad areas or even, in some cases, \"repair\" damaged\nsectors.\n\nOne of the great strengths of ddrescue is that it is interface-agnostic,\nand so can be used for any kind of device supported by your kernel (ATA,\nSATA, SCSI, old MFM drives, floppy discs, or even flash media cards like\nSD).\n\nDocumentation\n\nThe manual is available in the info system of the GNU\nOperating System. Use info to access the top level info\npage. Use info ddrescue to access the ddrescue section directly.\n\nAn online manual for ddrescue can be found\nhere.\n\nDownload\n\nThe latest released version of GNU ddrescue can be found at\n\nhttp://ftpmirror.gnu.org/ddrescue/\nor in the subdirectory /gnu/ddrescue/ on your favorite\nGNU mirror.\nFor other ways to obtain ddrescue, please read\nHow\nto get GNU Software. The latest released version will be the most\nrecent version available at \nhttp://ftp.gnu.org/gnu/ddrescue/.\n\nTo decompress ddrescue tarballs you may need lzip from\n\nhttp://www.nongnu.org/lzip/lzip.html.\nThen use \"tar -xf ddrescue[version].tar.lz\" or\n\"lzip -cd ddrescue[version].tar.lz | tar -xf -\"\nto extract the files.\n\nOld versions and testing versions can be found at\n\nhttp://download.savannah.gnu.org/releases/ddrescue/.\n\nHow to Get Help\n\nFor general discussion of bugs in ddrescue the mailing list\nbug-ddrescue@gnu.org\nis the most appropriate forum. Please send messages as plain text.\nPlease do not send messages encoded as HTML nor encoded as base64 MIME\nnor included as multiple formats. Please include a descriptive subject\nline. If all of the subject are \"bug in ddrescue\" it is impossible to\ndifferentiate them.\n\nAn archive of the bug report mailing list is available at\n\nhttp://lists.gnu.org/mailman/listinfo/bug-ddrescue.\n\nHow to Help\n\nTo contact the author, either to report a bug or to contribute fixes or\nimprovements, send mail to\nbug-ddrescue@gnu.org.\nPlease send messages as plain text. If posting patches they should be in\nunified diff format against the latest version. They should include a\ntext description.\n\nYou may also help ddrescue by\n\ndonating money via PayPal or debit/credit card.\n\nSee also the\nddrescue\nproject page at Savannah.\n\nLinks\n\nDDRescue-GUI -\nA simple GUI (Graphical User Interface) for ddrescue.\nDdrescueview -\nA graphical viewer for GNU ddrescue mapfiles.\nDdrutility -\nA set of tools designed to work with ddrescue to aid with data recovery.\n\nLicensing\n\nDdrescue is free software: you can redistribute it and/or modify it\nunder the terms of the GNU General Public License as published by the\nFree Software Foundation, either version 2 of the License, or (at your\noption) any later version.\n\n\nValid HTML 4.01 Strict\n\n\n\nReturn to GNU's home page.\n\nPlease send FSF & GNU inquiries & questions to\ngnu@gnu.org. There are also\nother ways to contact\nthe FSF.\n\nPlease send comments on this particular web page to\nbug-ddrescue@gnu.org,\nsend comments about www.gnu.org web pages in general to\nwebmasters@www.gnu.org,\nsend other questions to gnu@gnu.org.\n\nCopyright © 2020 Free Software Foundation, Inc., 51 Franklin St, Fifth\nFloor, Boston, MA 02110-1301 USA\n\nVerbatim copying and distribution of this entire article is\npermitted in any medium, provided this notice is preserved.\n\nUpdated: $Date: 2020/03/03 12:23:04 $ $Author: antonio $\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# ddrescue\n\n> Data recovery tool that reads data from damaged block devices.\n> More information: <https://www.gnu.org/software/ddrescue/>.\n\n- Take an image of a device, creating a log file:\n\n`sudo ddrescue {{/dev/sdb}} {{path/to/image.dd}} {{path/to/log.txt}}`\n\n- Clone Disk A to Disk B, creating a log file:\n\n`sudo ddrescue --force --no-scrape {{/dev/sda}} {{/dev/sdb}} {{path/to/log.txt}}`\n"
 },
 {
   "command": "phpdismod",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# phpdismod\n\n> Disable PHP extensions on Debian-based OSes.\n\n- Disable the json extension for every SAPI of every PHP version:\n\n`sudo phpdismod {{json}}`\n\n- Disable the json extension for PHP 7.3 with the cli SAPI:\n\n`sudo phpdismod -v {{7.3}} -s {{cli}} {{json}}`\n"
 },
 {
   "command": "lastcomm",
   "doc_url": "https://manpages.debian.org/stable/acct/lastcomm.1.en.html",
   "doc_text": "\n\n\n\nlastcomm(1) — acct — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / acct\n     \n     \n     \n     / lastcomm(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nFILES\n\n\nAUTHOR\n\n\nSEE ALSO\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 6.6.4-2\n\n\ntesting 6.6.4-3\n\n\nunstable 6.6.4-3\n\n\n\n\n\n\nScroll to navigation\n\n\n\nLASTCOMM(1)\nGeneral Commands Manual\nLASTCOMM(1)\n\n\n\n\nNAME¶\nlastcomm - print out information about previously executed commands.\n\n\nSYNOPSIS¶\n\nlastcomm\n[ command-name ... ]\n    \n    [ user-name ... ]\n    \n    [ terminal-name ... ]\n    \n    [ OPTION ... ]\n\n\n\nDESCRIPTION¶\nlastcomm prints out information about previously executed commands. If no\n  arguments are specified, lastcomm will print info about all of the\n  commands in acct (the record file). If called with one or more of\n  command-name, user-name, or terminal-name, only records\n  containing those items will be displayed. For example, to find out which users\n  used command `a.out' and which users were logged into `tty0', type:\n\nlastcomm a.out tty0\n\n\nThis will print any entry for which `a.out' or `tty0' matches in\n    any of the record's fields (command, name, or terminal). If you want to find\n    only items that match *all* of the arguments on the command line, you must\n    use the '-strict-match' option. For example, to list all of the executions\n    of command a.out by user root on terminal tty0, type:\n  \n  lastcomm --strict-match --command a.out --user root --tty tty0\n  \n\n\nThe order of the arguments is not important.\nFor each entry the following information is printed:\n   + command name of the process\n   + flags, as recorded by the system accounting routines:\n   S -- command executed by super-user\n   F -- command executed after a fork but without a following exec\n   C -- command run in PDP-11 compatibility mode (VAX only)\n   D -- command terminated with the generation of a core file\n   X -- command was terminated with the signal SIGTERM\n   + the name of the user who ran the process\n   + time the process started\n\n\nOPTIONS¶\n\n--strict-match\nPrint only entries that match *all* of the arguments on the command\n    line.\n--print-controls\nPrint control characters.\n--user name\nList records for user with name. This is useful if you're trying to\n      match a username that happens to be the same as a command (e.g., ed\n      ).\n--command name\nList records for command name.\n--tty name\nList records for tty name.\n--forwards\nRead file forwards instead of backwards. This avoids trying to seek on the\n      file and can be used to read from a pipe. This must be specified prior to\n      any -f arguments.\n-f filename, --file filename\nRead from the file filename instead of acct. A filename of\n      \"-\" will result in reading from stdin. This must either be the\n      first -f option, or --forwards must precede all -f\n      options.\n--ahz hz\nUse this flag to tell the program what AHZ should be (in hertz).\n      This option is useful if you are trying to view an acct file\n      created on another machine which has the same byte order and file format\n      as your current machine, but has a different value for AHZ.\n-p, --show-paging\nPrint paging statistics.\n--pid\nShow PID and PPID of the process if acct version 3 format is supported by\n      kernel.\n--pid\nAdd pid of the process and pid of the process parent to the output (pid is\n      the last but one and parent pid the last column). These values are shown\n      only when they are generated by acct function (depends on the version of\n      kernel)\n--debug\nPrint verbose internal information.\n-V, --version\nPrint the version number of lastcomm.\n-h, --help\nPrints the usage string and default locations of system files to standard\n      output and exits.\n    \n\n\n\n\nFILES¶\nacct\nThe system wide process accounting file. See\n  acct(5) (or pacct(5)) for further details.\n  /var/log/account\nThis directory contains pacct files which contain the\n  binary process accounting data as written by the kernel.\n\n\n\nAUTHOR¶\nThe GNU accounting utilities were written by Noel Cragg\n  <noel@gnu.ai.mit.edu>. The man page was adapted from the accounting\n  texinfo page by Susan Kleinmann <sgk@sgk.tiac.net>.\n\n\nSEE ALSO¶\nlast(1), acct(5)\n\n\n\n\n\n1995 October 31\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\nlastcomm.1.en.gz (from acct 6.6.4-2)\n\n\n\n\nSource last updated:\n\n\n2018-08-23T16:01:38Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:10:34Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "\nLASTCOMM(1)\t\t  BSD General Commands Manual\t\t   LASTCOMM(1)\n\nNAME\n     lastcomm -- show last commands executed in reverse order\n\nSYNOPSIS\n     lastcomm [-f file] [command ...] [user ...] [terminal ...]\n\nDESCRIPTION\n     lastcomm gives information on previously executed commands.  With no\n     arguments, lastcomm prints information about all the commands recorded\n     during the current accounting file's lifetime.\n\n     Option:\n\n     -f file\t Read from file rather than the default accounting file.\n\n     If called with arguments, only accounting entries with a matching command\n     name, user name, or terminal name are printed.  So, for example:\n\n\t   lastcomm a.out root ttyd0\n\n     would produce a listing of all the executions of commands named a.out by\n     user root on the terminal ttyd0.\n\n     For each process entry, the following are printed.\n\n\t   o   The name of the user who ran the process.\n\t   o   Flags, as accumulated by the accounting facilities in the sys-\n\t       tem.\n\t   o   The command name under which the process was called.\n\t   o   The amount of cpu time used by the process (in seconds).\n\t   o   The time the process started.\n\t   o   The elapsed time of the process.\n\n     The flags are encoded as follows: ``S'' indicates the command was exe-\n     cuted by the super-user, ``F'' indicates the command ran after a fork,\n     but without a following exec(3), ``C'' indicates the command was run in\n     PDP-11 compatibility mode (VAX only), ``D'' indicates the command termi-\n     nated with the generation of a core file, and ``X'' indicates the command\n     was terminated with a signal.\n\nFILES\n     /var/account/acct\tDefault accounting file.\n\nSEE ALSO\n     last(1), sigaction(2), acct(5), core(5)\n\nHISTORY\n     The lastcomm command appeared in 3.0BSD.\n\nBSD\t\t\t       December 22, 2006\t\t\t   BSD\n",
   "tldr_summary": "# lastcomm\n\n> Show last commands executed.\n> More information: <https://manpages.debian.org/stable/acct/lastcomm.1.en.html>.\n\n- Print informations about all of the commands in the acct (record file):\n\n`lastcomm`\n\n- Display commands executed by a given user:\n\n`lastcomm --user {{user}}`\n\n- Display information about a given command executed on the system:\n\n`lastcomm --command {{command}}`\n\n- Display information about commands executed on a given terminal:\n\n`lastcomm --tty {{terminal_name}}`\n"
 },
 {
   "command": "cp",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nCP(1)\t\t\t  BSD General Commands Manual\t\t\t CP(1)\n\nNAME\n     cp -- copy files\n\nSYNOPSIS\n     cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file target_file\n     cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file ...\n\ttarget_directory\n\nDESCRIPTION\n     In the first synopsis form, the cp utility copies the contents of the\n     source_file to the target_file.  In the second synopsis form, the con-\n     tents of each named source_file is copied to the destination\n     target_directory.\tThe names of the files themselves are not changed.  If\n     cp detects an attempt to copy a file to itself, the copy will fail.\n\n     The following options are available:\n\n     -a    Same as -pPR options. Preserves structure and attributes of files\n\t   but not directory structure.\n\n     -f    If the destination file cannot be opened, remove it and create a\n\t   new file, without prompting for confirmation regardless of its per-\n\t   missions.  (The -f option overrides any previous -n option.)\n\n\t   The target file is not unlinked before the copy.  Thus, any exist-\n\t   ing access rights will be retained.\n\n     -H    If the -R option is specified, symbolic links on the command line\n\t   are followed.  (Symbolic links encountered in the tree traversal\n\t   are not followed.)\n\n     -i    Cause cp to write a prompt to the standard error output before\n\t   copying a file that would overwrite an existing file.  If the\n\t   response from the standard input begins with the character `y' or\n\t   `Y', the file copy is attempted.  (The -i option overrides any pre-\n\t   vious -n option.)\n\n     -L    If the -R option is specified, all symbolic links are followed.\n\n     -n    Do not overwrite an existing file.  (The -n option overrides any\n\t   previous -f or -i options.)\n\n     -P    If the -R option is specified, no symbolic links are followed.\n\t   This is the default.\n\n     -p    Cause cp to preserve the following attributes of each source file\n\t   in the copy: modification time, access time, file flags, file mode,\n\t   user ID, and group ID, as allowed by permissions.  Access Control\n\t   Lists (ACLs) and Extended Attributes (EAs), including resource\n\t   forks, will also be preserved.\n\n\t   If the user ID and group ID cannot be preserved, no error message\n\t   is displayed and the exit value is not altered.\n\n\t   If the source file has its set-user-ID bit on and the user ID can-\n\t   not be preserved, the set-user-ID bit is not preserved in the\n\t   copy's permissions.\tIf the source file has its set-group-ID bit on\n\t   and the group ID cannot be preserved, the set-group-ID bit is not\n\t   preserved in the copy's permissions.  If the source file has both\n\t   its set-user-ID and set-group-ID bits on, and either the user ID or\n\t   group ID cannot be preserved, neither the set-user-ID nor set-\n\t   group-ID bits are preserved in the copy's permissions.\n\n     -R    If source_file designates a directory, cp copies the directory and\n\t   the entire subtree connected at that point.\tIf the source_file\n\t   ends in a /, the contents of the directory are copied rather than\n\t   the directory itself.  This option also causes symbolic links to be\n\t   copied, rather than indirected through, and for cp to create spe-\n\t   cial files rather than copying them as normal files.  Created\n\t   directories have the same mode as the corresponding source direc-\n\t   tory, unmodified by the process' umask.\n\n\t   In -R mode, cp will continue copying even if errors are detected.\n\n\t   Note that cp copies hard-linked files as separate files.  If you\n\t   need to preserve hard links, consider using tar(1), cpio(1), or\n\t   pax(1) instead.\n\n     -v    Cause cp to be verbose, showing files as they are copied.\n\n     -X    Do not copy Extended Attributes (EAs) or resource forks.\n\n     -c    copy files using clonefile(2)\n\n     For each destination file that already exists, its contents are overwrit-\n     ten if permissions allow.\tIts mode, user ID, and group ID are unchanged\n     unless the -p option was specified.\n\n     In the second synopsis form, target_directory must exist unless there is\n     only one named source_file which is a directory and the -R flag is speci-\n     fied.\n\n     If the destination file does not exist, the mode of the source file is\n     used as modified by the file mode creation mask (umask, see csh(1)).  If\n     the source file has its set-user-ID bit on, that bit is removed unless\n     both the source file and the destination file are owned by the same user.\n     If the source file has its set-group-ID bit on, that bit is removed\n     unless both the source file and the destination file are in the same\n     group and the user is a member of that group.  If both the set-user-ID\n     and set-group-ID bits are set, all of the above conditions must be ful-\n     filled or both bits are removed.\n\n     Appropriate permissions are required for file creation or overwriting.\n\n     Symbolic links are always followed unless the -R flag is set, in which\n     case symbolic links are not followed, by default.\tThe -H or -L flags (in\n     conjunction with the -R flag) cause symbolic links to be followed as\n     described above.  The -H, -L and -P options are ignored unless the -R\n     option is specified.  In addition, these options override each other and\n     the command's actions are determined by the last one specified.\n\n     If cp receives a SIGINFO (see the status argument for stty(1)) signal,\n     the current input and output file and the percentage complete will be\n     written to the standard output.\n\nEXIT STATUS\n     The cp utility exits 0 on success, and >0 if an error occurs.\n\nCOMPATIBILITY\n     Historic versions of the cp utility had a -r option.  This implementation\n     supports that option; however, its use is strongly discouraged, as it\n     does not correctly copy special files, symbolic links, or fifo's.\n\n     The -v and -n options are non-standard and their use in scripts is not\n     recommended.\n\nLEGACY DESCRIPTION\n     In legacy mode, -f will override -i.  Also, under the -f option, the tar-\n     get file is always unlinked before the copy.  Thus, new access rights\n     will always be set.\n\n     In -R mode, copying will terminate if an error is encountered.\n\n     For more information about legacy mode, see compat(5).\n\nSEE ALSO\n     mv(1), rcp(1), umask(2), fts(3), compat(5), symlink(7)\n\nSTANDARDS\n     The cp command is expected to be IEEE Std 1003.2 (``POSIX.2'') compati-\n     ble.\n\nHISTORY\n     A cp command appeared in Version 1 AT&T UNIX.\n\nBSD\t\t\t       February 23, 2005\t\t\t   BSD\n",
   "tldr_summary": "# cp\n\n> Copy files and directories.\n\n- Copy a file to another location:\n\n`cp {{path/to/source_file.ext}} {{path/to/target_file.ext}}`\n\n- Copy a file into another directory, keeping the filename:\n\n`cp {{path/to/source_file.ext}} {{path/to/target_parent_directory}}`\n\n- Recursively copy a directory's contents to another location (if the destination exists, the directory is copied inside it):\n\n`cp -r {{path/to/source_directory}} {{path/to/target_directory}}`\n\n- Copy a directory recursively, in verbose mode (shows files as they are copied):\n\n`cp -vr {{path/to/source_directory}} {{path/to/target_directory}}`\n\n- Copy text files to another location, in interactive mode (prompts user before overwriting):\n\n`cp -i {{*.txt}} {{path/to/target_directory}}`\n\n- Dereference symbolic links before copying:\n\n`cp -L {{link}} {{path/to/target_directory}}`\n\n- Use the full path of source files, creating any missing intermediate directories when copying:\n\n`cp --parents {{source/path/to/file}} {{path/to/target_file}}`\n"
 },
 {
   "command": "reportbug",
   "doc_url": "https://manpages.debian.org/buster/reportbug/reportbug.1.en.html",
   "doc_text": "\n\n\n\nreportbug(1) — reportbug — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / reportbug\n     \n     \n     \n     / reportbug(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXAMPLES\n\n\nCONFIGURATION FILES\n\n\nENVIRONMENT\n\n\nNOTES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 7.5.3~deb10u1\n\n\ntesting 7.7.0\n\n\nunstable 7.7.0\n\n\n\n\n\n\nScroll to navigation\n\n\n\nreportbug(1)\nGeneral Commands Manual\nreportbug(1)\n\n\n\n\nNAME¶\nreportbug - reports a bug to a debbugs server\n\n\nSYNOPSIS¶\nreportbug [options] <package | pseudo-package |\n  absolute-pathname>\n\n\nDESCRIPTION¶\nreportbug is primarily designed to report bugs in the Debian\n  distribution; by default, it creates an email to the Debian bug tracking\n  system at submit@bugs.debian.org with information about the bug you've\n  found, and makes a carbon copy of the report for you as well.\nUsing the --bts option, you can also report bugs to other\n    servers that use the Debian bug tracking system, debbugs.\nYou may specify either a package name or a filename; if you use a\n    filename, it must either be an absolute filename (so beginning with a\n    /) or if you want reportbug to search the system for a\n    filename, see the --filename and --path options below. If\n    installed, also dlocate is used to identify the filename location and\n    thus the package containing it.\nYou can also specify a pseudo-package; these are used in\n    the Debian bug tracking system to track issues that are not related to one\n    specific package. Run reportbug without any arguments, then enter\n    other at the package prompt, to see a list of the most commonly-used\n    pseudo-packages.\n\n\nOPTIONS¶\nThe program follows the usual GNU command line syntax, with long options\n  starting with two dashes (`--'). A summary of options are included\n  below.\n\n-h, --help\nShow summary of options.\n--version\nShow the version of reportbug and exit.\n-A FILENAME, --attach=FILENAME\nAttach a file to the bug report; both text and binary files are\n      acceptable; this option can be specified multiple times to attach several\n      files. This routine will create a MIME attachment with the file included;\n      in some cases (usually text files), it is probably better to use\n      -i/--include option. (Please note that Debian's bug tracking system\n      has limited support for MIME attachments.)\n    This option supports also globbing (i.e. names with wildcards,\n        like file.*) but remember to include them between single quotes (the\n        previous example becomes: 'file.*') else the shell would expand it\n        before calling reportbug leading to an error.\nBe aware that when using an external MUA to send the message\n        (such as mutt), the attachment feature is not available and no file will\n        be attached at all: the MUA feature to attach files must be used instead\n        (so from within the MUA).\n\n-b, --no-query-bts\nDon't check the Debian bug tracking system to see if this problem has\n      already been reported; useful for offline use or if you're really\n      sure it's a bug.\n--query-bts\nCheck the Debian bug tracking system to see if this problem has already\n      been reported (default).\n-B SYSTEM, --bts=SYSTEM\nInstead of the Debian bug server (or the bug server specified in\n      /etc/reportbug.conf, use the server specified by\n    SYSTEM.\n--body=BODY\nUse the specified BODY as the body of the message. The body text\n      will be wrapped at 70 columns, and the normal reportbug headers and\n      footers will be added as appropriate. The editor prompt and any\n      \"special\" prompting will be bypassed.\n--body-file=BODYFILE, --bodyfile=BODYFILE\nThe contents of the (assumed to be) text file BODYFILE will be used\n      as the message body. This file is assumed to be properly formatted (i.e.\n      reasonable line lengths, etc.). The usual headers and footers will be\n      added, and the editor step and \"special\" prompts will be\n      skipped. (BODYFILE may also be a named pipe; using a device special\n      file may lead to unusual results.)\n-c, --no-config-files\nOmit configuration files from the bug report without asking. By default,\n      you are asked if you want to include them; in some cases, doing so may\n      cause sensitive information to be sent via email.\n-C CLASS, --class=CLASS\nSpecify report class for GNATS BTSes.\n--configure\nRerun the reportbug first time configuration routine, and write a\n      new $HOME/.reportbugrc file. This will erase any pre-existing\n      settings in the file; however, a backup will be written as\n      $HOME/.reportbugrc~.\n--check-available\nCheck for newer releases of the package at packages.debian.org\n      (default). In advanced and expert mode, check\n      incoming.debian.org and\n      http://ftp-master.debian.org/new.html too.\n--no-check-available\nDo not check for newer releases of the package at\n      packages.debian.org.\n--debconf\nInclude debconf settings in your report.\n--no-debconf\nDo not include debconf settings from your report.\n-d, --debug\nDon't send a real bug report to Debian; send it to yourself instead. This\n      is primarily used for testing by the maintainer.\n--test\nOperate in test mode (maintainer use only).\n--draftpath=DRAFTPATH\nSave the draft (for example, when exiting and saving the report without\n      reporting it) into DRAFTPATH directory(default /tmp).\n-e EDITOR, --editor=EDITOR\nSpecify the editor to use, overriding any EDITOR or VISUAL\n      environment variable setting.\n--email=ADDRESS\nSet the email address your report should appear to be sent from (i.e. the\n      address that appears in the From header). This should be the actual\n      Internet email address on its own (i.e. without a real name or comment\n      part, like foo@example.com). This setting will override the\n      EMAIL and DEBEMAIL environment variables, but not\n      REPORTBUGEMAIL.\n--envelope-from\nSpecify the Envelope From mail header (also known as Return-path); by\n      default it's the From address but it can be selected a different one in\n      case the MTA doesn't canonicalize local users to public addresses.\n    \n\n--mbox-reader-cmd=MBOX_READER_CMD\nSpecify a command to open the bug reports mbox file. You can use %s\n      to substitute the mbox file to be used, and %% to insert a literal\n      percent sign. If no %s is specified, the mbox file name is supplied\n      at the end of the argument list.\n--exit-prompt\nDisplay a prompt before exiting; this is useful if reportbug is run\n      in a transient terminal (i.e. from its Debian menu entry).\n-f FILENAME, --filename=FILENAME\nReport a bug in the package containing FILENAME so you don't have\n      to figure out what package the file belongs to. The path will be searched\n      for an exact path for FILENAME before attempting to broaden the\n      search to all files. If dlocate is installed, FILENAME is\n      actually a regular expression.\n--from-buildd=BUILDD_FORMAT\nThis options is a shortcut for buildd admins to report bugs from buildd\n      log; the option expects a value in the format of $source_$version\n      where $source is the source package the bug will be reported\n      against and $version is its version.\n--path\nIf the -f/--filename option is also specified, only search the path\n      for the specified FILENAME. Specifying an absolute path with the\n      -f/--filename option (i.e. one beginning with a /) overrides\n      this behavior.\n-g, --gnupg, --gpg\nAttach a digital signature to the bug report using GnuPG (the GNU\n      Privacy Guard). (This argument will be ignored if you are using an MUA to\n      edit and send your report.)\n-G, --gnus\nUse the Gnus mail and news reader to send your report, rather than using\n      the editor.\n-H HEADER, --header=HEADER\nAdd a custom RFC2822 header to your email; for example, to send a carbon\n      copy of the report to debian-68k@lists.linux-m68k.org you could use\n      -H 'X-Debbugs-CC: debian-68k@lists.linux-m68k.org'\n-i FILE, --include=FILE\nInclude the specified FILE as part of the body of the message to be\n      edited. Can be used multiple times to add multiple files; text-only\n      please! From a suggestion by Michael Alan Dorman in the bug mailing\n      list. (See also the -A/--attach option.)\n-I, --no-check-installed\nDo not check whether the package is installed before filing a report. This\n      is generally only useful when filing a report on a package you know is not\n      installed on your system.\n--check-installed\nCheck if the specified package is installed when filing reports. (This is\n      the default behavior of reportbug.)\n-j JUSTIFICATION, --justification=JUSTIFICATION\nBugs in Debian that have serious, grave, or critical\n      severities must meet certain criteria to be classified as such. This\n      option allows you to specify the justification for a release-critical bug,\n      instead of being prompted for it.\n-k, --kudos\nSend appreciative email to the recorded maintainer address, rather than\n      filing a bug report. (You can also send kudos to\n      packagename@packages.debian.org, for packages in the Debian\n      archive; however, this option uses the Maintainer address from the control\n      file, so it works with other package sources too.)\n-K KEYID, --keyid=KEYID\nPrivate key to use for PGP/GnuPG signatures. If not specified, the first\n      key in the secret keyring that matches your email address will be\n    used.\n--latest-first\nDisplay the bug reports list sorted and with the latest reports at the\n      top.\n--license\nShow reportbug's copyright and license information on standard\n      output.\n--list-cc=ADDRESS\nSend a carbon copy of the report to the specified list after a report\n      number is assigned; this is the equivalent to the option -H\n      'X-Debbugs-CC: ADDRESS'. This option will only work as intended with\n      debbugs systems.\n--list-cc-me\nSend a carbon copy of the report to your automatically detected email\n      address after a report number is assigned. This sets an\n      X-Debbugs-CC header specifying that address. This option will only\n      work as intended with debbugs systems. See the documentation for\n      the --email option and the ENVIRONMENT section for\n      information on how reportbug detects your email address.\n-m, --maintonly\nOnly send the bug to the package maintainer; the bug tracking system will\n      not send a copy to the bug report distribution lists.\n--max-attachment-size=MAX_ATTACHMENT_SIZE\nSpecify the maximum size any attachment file can have (this also include\n      the file for --body-file option). If an attachment file is too big, there\n      could be problems in delivering the email (and also to compose it), so we\n      set a limit to attachment size. By default this is 10 megabytes.\n--mirror=MIRRORS\nAdd a BTS mirror.\n--mode=MODE\nSet the operating mode for reportbug. reportbug currently\n      has four operating modes: novice (the default), standard,\n      advanced, and expert.\n    novice mode is designed to minimize prompting about\n        things that \"ordinary users\" would be unlikely to know or care\n        about, shifting the triage burden onto the maintainer. Checking for new\n        versions is only done for the stable distribution in this mode. It is\n        currently the default mode.\nstandard mode includes a relatively large number of\n        prompts and tries to encourage users to not file frivolous or duplicate\n        bug reports.\nadvanced mode is like standard mode, but may\n        include shortcuts suitable for more advanced users of Debian, without\n        being as close to the metal (and potential flamage) as expert\n        mode. (Currently, the only differences from standard mode are\n        that it assumes familiarity with the \"incoming\" queue; it\n        allows the reporting of bugs on \"dependency\" packages; and it\n        does not prompt where to insert the report text in the editor.)\nexpert mode is designed to minimize prompts that are\n        designed to discourage frivolous or unnecessary bug reports,\n        \"severity inflation,\" and the like. In expert mode,\n        reportbug assumes the user is thoroughly familiar with Debian\n        policies. In practice, this means that reporters are no longer required\n        to justify setting a high severity on a bug report, and certain\n        automated cleanups of the message are bypassed. Individuals who do not\n        regularly contribute to the Debian project are highly discouraged\n        from using expert mode, as it can lead to flamage from maintainers when\n        used improperly.\n\n-M, --mutt\nInstead of spawning an editor to revise the bug report, use the\n      mutt mail reader to edit and send it.\n--mta=MTA\nSpecify an alternate MTA, instead of /usr/sbin/sendmail (the\n      default). Any smtphost setting will override this one.\n--mua=MUA\nInstead of spawning an editor to revise the bug report, use the specified\n      MUA (mail user agent) to edit and send it. --mutt and\n      --nmh options are processed.\n-n, --mh, --nmh\nInstead of spawning an editor to revise the bug report, use the\n      comp command (part of the nmh and mh mail systems) to\n      edit and send it.\n-N BUGNUMBER, --bugnumber BUGNUMBER\nRun reportbug against the specified bug report, useful when\n      following-up a bug and its number is already known.\n--no-bug-script\nDo not execute the bug script (if present); this option can be useful\n      together with --template to suppress every interactive actions, since some\n      bug scripts can ask questions.\n--no-cc-menu\nDon't display the menu to enter additional addresses (CC).\n--no-tags-menu\nDon't display the menu to enter additional tags.\n-o FILE, --output=FILE\nInstead of sending an email, redirect it to the specified filename.\n    The output file is a full dump of the email message, so it\n        contains both headers and mail body. If you want to use it as a template\n        to create a new bug report, then you have to remove all the headers\n        (mind the Subject one, though) and start the report at the\n        Package pseudo-header.\n\n-O, --offline\nDisable all external queries. Currently has the same effect as\n      --no-check-available --no-query-bts.\n-p, --print\nInstead of sending an email, print the bug report to standard output, so\n      you can redirect it to a file or pipe it to another program.\n    This option only outputs a template for a bug report (but,\n        differently from --template it's more interactive); you will need\n        to fill in the long description.\n\n--paranoid\nShow the contents of the message before it is sent, including all headers.\n      Automatically disabled if in template mode.\n--no-paranoid\nDon't show the full contents of the message before it is sent\n    (default).\n--pgp\nAttach a digital signature to the bug report using PGP (Pretty Good\n      Privacy). Please note, however, that the Debian project is phasing out the\n      use of PGP in favor of GnuPG. (This argument will be ignored\n      if using an MUA to edit and send your report.)\n--proxy=PROXY, --http_proxy=PROXY\nSpecify the WWW proxy server to use to handle the query of the bug\n      tracking system. You should only need this parameter if you are behind a\n      firewall. The PROXY argument should be formatted as a valid HTTP\n      URL, including (if necessary) a port number; for example,\n      http://192.168.1.1:3128/.\n-P PSEUDO-HEADER, --pseudo-header=PSEUDO-HEADER\nAdd a custom pseudo-header to your report; for example, to add the\n      mytag usertag for the user humberto@example.com to the bug,\n      you could use -P 'User: humberto@example.com' -P 'Usertags:\nmytag'.\n-q, --quiet\nSuppress diagnostic messages to standard error.\n-Q, --query-only\nDo not submit a bug report; just query the BTS. Option ignored if you\n      specify --no-bts-query.\n--query-source\nQuery on all binary packages built by the same source, not just the binary\n      package specified.\n--no-query-source\nOnly query on the binary package specified on the command line.\n--realname=NAME\nSet the real name (human-readable name) to use for your report.\n--report-quiet\nRegister the bug in the bug tracking system, but don't send a report to\n      the package maintainer or anyone else. Don't do this unless you're the\n      maintainer of the package in question, or you really know what you are\n      doing.\n--reply-to=ADDRESS, --replyto=ADDRESS\nSet the Reply-To address header in your report.\n-s SUBJECT, --subject=SUBJECT\nSet the subject of the bug report (i.e. a brief explanation of the\n      problem, less than 60 characters). If you do not specify this switch, you\n      will be prompted for a subject.\n--security-team\nIf the 'security' tag is set, this option will explicitly specify to send\n      the report only to the Debian Security Team, as this is an undisclosed\n      vulnerability.\n--no-security-team\nIf the 'security' tag is set, this option will explicitly specify to not\n      send the report only to the Debian Security Team, as this is not an\n      undisclosed vulnerability.\n-S SEVERITY, --severity=SEVERITY\nSpecify a severity level, from critical, grave,\n      serious, important, normal, minor, and\n      wishlist.\n--smtphost=HOST[:PORT]\nUse the mail transport agent (MTA) at HOST to send your report,\n      instead of your local /usr/sbin/sendmail program. This should\n      generally be your ISP's outgoing mail server; you can also use 'localhost'\n      if you have a working mail server running on your machine. If the\n      PORT is omitted, the standard port for SMTP, port 25, is used.\n--timeout=SECONDS\nSpecify the network timeout, the number of seconds to wait for a resource\n      to respond. If nothing is specified, a default timeout of 1 minute is\n      selected.\n    In case of a network error, there are chances it's due to a\n        too low timeout: try passing the --timeout option with a higher value\n        than default.\n\n--tls\nIf using SMTP, use Transport Layer Security (TLS) encryption to secure the\n      connection to the mail server. Some SMTP servers may require this\n    option.\n--smtpuser=USERNAME\nIf using SMTP, use the specified USERNAME for authentication.\n--smtppasswd=PASSWORD\nIf using SMTP, use the specified PASSWORD for authentication. If\n      the password isn't specified on the command line or in the configuration\n      file, a prompt will be displayed asking for it.\n    Use of this option is insecure on multiuser systems. Instead,\n        you should set this option in $HOME/.reportbugrc and ensure it is\n        only readable by your user (e.g. with chmod 600\n$HOME/.reportbugrc).\n\n--src, --source\nSpecify to report the bug against the source package, and not the binary\n      package (default behaviour). In order for this option to work, you have to\n      populate the relevant 'deb-src' lines in /etc/apt/sources.list so that apt\n      cache will know about source packages too.\n-t TYPE, --type=TYPE\nSpecify the type of report to be submitted; currently accepts either\n      gnats or debbugs.\n-T TAG, --tag=TAG\nSpecify a tag to be filed on this report, for example --tag=patch.\n      Multiple tags can be specified using multiple -T/--tag arguments.\n    Alternatively, you can specify the 'tag' none to bypass\n        the tags prompt without specifying any tags; this will also ignore any\n        tags specified on the command line.\n\n--template\nOutput a template report to standard output. Differently from\n      -p/--print, it tries to be not interactive, and presents a template\n      without user's input.\n-u INTERFACE, --interface=INTERFACE, --ui=INTERFACE\nSpecify the user interface to use. Valid options are text,\n      urwid, and gtk; default is taken from the reportbug\n      configuration files.\n-v, --verify\nVerify the integrity of the package (if installed) using debsums\n      before reporting.\n--no-verify\nDo not verify the integrity of the package with debsums.\n-V VERSION, --package-version=VERSION\nSpecify the version of the package the problem was found in. This is\n      probably most useful if you are reporting a bug in a package that is not\n      installable or installed on a different system.\n-x, --no-cc\nDon't send a blind carbon copy (BCC) of the bug report to the submitter\n      (i.e. yourself).\n-z, --no-compress\nDon't compress configuration files by removing comments and blank\n    lines.\n\n\n\nEXAMPLES¶\n\nreportbug lynx-ssl\nReport a bug in the lynx-ssl package.\nreportbug --path --filename=ls\nReport a bug in the installed package that includes a program in your path\n      called ls.\n\n\n\nCONFIGURATION FILES¶\nFrom version 0.22 on, reportbug has supported a simple run control file\n  syntax. Commands are read from /etc/reportbug.conf and\n  $HOME/.reportbugrc with commands in the latter overriding those in the\n  former.\nCommands are not case sensitive, and currently take 0 or 1\n    argument; arguments containing whitespace must be enclosed in quotes.\nAny line starting with # is taken to be a comment and will\n    be ignored.\nGenerally, options corresponding to the long options for\n    reportbug are supported, without leading -- sequences. See\n    reportbug.conf(5) for all acceptable options and detailed\n    information.\n\n\nENVIRONMENT¶\n\nVISUAL\nEditor to use for editing your bug report.\nEDITOR\nEditor to use for editing the bug report (overridden by\n    VISUAL).\nREPORTBUGEMAIL, DEBEMAIL, EMAIL\nEmail address to use as your from address (in this order). If no\n      environment variable exists, the default is taken from your user name and\n      /etc/mailname.\nDEBFULLNAME, DEBNAME, NAME\nReal name to use; default is taken from /etc/passwd.\nREPLYTO\nAddress for Reply-To header in outgoing mail.\nMAILCC\nUse the specified CC address on your email. Note you can also use the\n      -H option for this (and for Bcc's too).\nMAILBCC\nUse the specified BCC address, instead of your email address. (CC and BCC\n      based on suggestions from Herbert Thielen in the bug\n    wishlist).\nhttp_proxy\nProvides the address of a proxy server to handle the BTS query. This\n      should be a valid http URL for a proxy server, including any\n      required port number (simply specifying a hostname, or omitting a port\n      other than 80, WILL NOT WORK).\n\n\n\nNOTES¶\nreportbug should probably be compatible with other bug tracking systems,\n  like bugzilla (used by the GNOME and Mozilla projects) and\n  jitterbug (used by Samba, AbiSource and FreeCiv) but it isn't.\n\n\nSEE ALSO¶\nreportbug.conf(5), http://www.debian.org/Bugs/Developer#tags for\n  available tags, querybts(1)\n\n\nAUTHOR¶\nChris Lawrence <lawrencc@debian.org>, Sandro Tosi\n  <morph@debian.org>.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\nreportbug.1.en.gz (from reportbug 7.5.3~deb10u1)\n\n\n\n\nSource last updated:\n\n\n2019-08-30T11:52:06Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:05:46Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# reportbug\n\n> Bug report tool of Debian distribution.\n> More information: <https://manpages.debian.org/buster/reportbug/reportbug.1.en.html>.\n\n- Generate a bug report about a specific package, then send it by e-mail:\n\n`reportbug {{package}}`\n\n- Report a bug that is not about a specific package (general problem, infrastructure, etc.):\n\n`reportbug other`\n\n- Write the bug report to a file instead of sending it by e-mail:\n\n`reportbug -o {{filename}} {{package}}`\n"
 },
 {
   "command": "calcurse",
   "doc_url": "https://calcurse.org",
   "doc_text": "\n\ncalcurse: a text-based calendar and scheduling application\n\n\n\n\n\n\n\n\n\n\n\nAbout\nDownloads\nSupport\nDevelopment\n❤ Donate\n\n\n\n\n\n\nDownload now\ncalcurse 4.6.0 (source)\n\n\nMD5 checksum\nSignature\nBinary packages\nRelease notes\n\n\nWhat is calcurse?\n\n\tcalcurse is a calendar and scheduling application for the command line.\n\tIt helps keep track of events, appointments and everyday tasks. A\n\tconfigurable notification system reminds user of upcoming deadlines,\n\tthe curses based interface can be customized to suit user needs and a\n\tvery powerful set of command line options can be used to filter and\n\tformat appointments, making it suitable for use in scripts.\n\n\nNever miss a release again.\n\n\tIf you want to receive release announcements, you can add your\n\temail address to the announcement mailing list\n\there.\n\n\nLove calcurse?\n\n\tContribute by writing code or\n\tmake a donation to support the\n\tproject.\n\n\n\n\nImportant features\n\nhooks – run scripts when loading/saving data, e.g. to put your calendar data under version control\nexperimental CalDAV support – synchronize calcurse with your mobile devices!\nsupport for various types of appointments and TODO items, including all-day events and recurring appointments\nfast and customizable curses-based interface\npowerful non-interactive command line interface that can be used by scripts\nuser-definable key bindings\nfully user-configurable notification system (ability to send mails or anything else that could remind you of your upcoming appointments)\nimport capabilities with support for iCalendar format\nexport capabilities with support for iCalendar and pcal formats\nability to attach notes to each calendar element, and to edit them with your favorite text editor\nsupport for internationalization with texts translated to English, French, German, Dutch, Spanish and Italian\nUTF-8 support\n\n\n\n\t\t\tCopyright © 2012–2020\n\t\t\tcalcurse Development Team.\n\t\t\tLicensed under the terms of the BSD License.\n\t\t\n\n",
   "man_entry": "",
   "tldr_summary": "# calcurse\n\n> A text-based calendar and scheduling application for the command line.\n> More information: <https://calcurse.org>.\n\n- Start calcurse on interactive mode:\n\n`calcurse`\n\n- Print the appointments and events for the current day and exit:\n\n`calcurse --appointment`\n\n- Remove all local calcurse items and import remote objects:\n\n`calcurse-caldav --init=keep-remote`\n\n- Remove all remote objects and push local calcurse items:\n\n`calcurse-caldav --init=keep-local`\n\n- Copy local objects to the CalDAV server and vice versa:\n\n`calcurse-caldav --init=two-way`\n"
 },
 {
   "command": "see",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# see\n\n> Alias to `run-mailcap`'s view.\n> An alias to a `run-mailcap`'s action print.\n\n- See action can be used to view any file (usually image) on default mailcap explorer:\n\n`see {{filename}}`\n\n- Using with `run-mailcap`:\n\n`run-mailcap --action=view {{filename}}`\n"
 },
 {
   "command": "isoinfo",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# isoinfo\n\n> Utility programs for dumping and verifying ISO disk images.\n\n- List all the files included in an ISO image:\n\n`isoinfo -f -i {{path/to/image.iso}}`\n\n- E[x]tract a specific file from an ISO image and send it out `stdout`:\n\n`isoinfo -i {{path/to/image.iso}} -x {{/PATH/TO/FILE/INSIDE/ISO.EXT}}`\n\n- Show header information for an ISO disk image:\n\n`isoinfo -d -i {{path/to/image.iso}}`\n"
 },
 {
   "command": "sensible-browser",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# sensible-browser\n\n> Open the default browser.\n\n- Open a new window of the default browser:\n\n`sensible-browser`\n\n- Open a url in the default browser:\n\n`sensible-browser {{url}}`\n"
 },
 {
   "command": "thunar",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# thunar\n\n> Graphical file manager for XFCE desktop environments.\n\n- Open a new window showing the current directory:\n\n`thunar`\n\n- Open the bulk rename utility:\n\n`thunar --bulk-rename`\n\n- Close all open thunar windows:\n\n`thunar --quit`\n"
 },
 {
   "command": "debuild",
   "doc_url": "https://manpages.debian.org/debuild",
   "doc_text": "\n\n\n\ndebuild(1) — devscripts — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / devscripts\n     \n     \n     \n     / debuild(1)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nDirectory name checking\n\n\nENVIRONMENT VARIABLES\n\n\nSUPERUSER REQUIREMENTS\n\n\nHOOKS\n\n\nOPTIONS\n\n\nCONFIGURATION VARIABLES\n\n\nEXAMPLES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.19.5+deb10u1\n\n\nbuster-backports 2.20.4~bpo10+1\n\n\ntesting 2.20.4\n\n\nunstable 2.20.4\n\n\n\n\n\n\nother languages\n\n\n\n\nDeutsch\n\n\nEnglish\n\n\nfrançais\n\n\n\n\n\n\nScroll to navigation\n\n\n\nDEBUILD(1)\nGeneral Commands Manual\nDEBUILD(1)\n\n\n\n\nNAME¶\ndebuild - build a Debian package\n\n\nSYNOPSIS¶\ndebuild [debuild options] [dpkg-buildpackage options]\n  [--lintian-opts lintian options]\n\ndebuild [debuild options] --\n  binary|binary-arch|binary-indep|clean ...\n\n\nDESCRIPTION¶\ndebuild creates all the files necessary for uploading a Debian package.\n  It first runs dpkg-buildpackage, then runs lintian on the\n  .changes file created (assuming that lintian is installed), and\n  finally signs the appropriate files (using debsign(1) to do this\n  instead of dpkg-buildpackage(1) itself; all relevant key-signing\n  options are passed on). Signing will be skipped if the distribution is\n  UNRELEASED, unless dpkg-buildpackage's --force-sign\n  option is used. Parameters can be passed to dpkg-buildpackage and\n  lintian, where the parameters to the latter are indicated with the\n  --lintian-opts option. The allowable options in this case are\n  --lintian and --no-lintian to force or skip the lintian\n  step, respectively. The default is to run lintian. There are also\n  various options available for setting and preserving environment variables, as\n  described below in the Environment Variables section. In this method of\n  running debuild, we also save a build log to the file\n  ../<package>_<version>_<arch>.build.\nAn alternative way of using debuild is to use one or more\n    of the parameters binary, binary-arch, binary-indep and\n    clean, in which case debuild will attempt to gain root\n    privileges and then run debian/rules with the given parameters. A\n    --rootcmd=gain-root-command or\n    -rgain-root-command option may be used to specify a method of\n    gaining root privileges. The gain-root-command is likely to be one of\n    fakeroot, sudo or super. See below for further\n    discussion of this point. Again, the environment preservation options may be\n    used. In this case, debuild will also attempt to run\n    dpkg-checkbuilddeps first; this can be explicitly requested or\n    switched off using the options -D and -d respectively. Note\n    also that if either of these or a -r option is specified in the\n    configuration file option DEBUILD_DPKG_BUILDPACKAGE_OPTS, then it\n    will be recognised even in this method of invocation of debuild.\ndebuild also reads the devscripts configuration\n    files as described below. This allows default options to be given.\n\n\nDirectory name checking¶\nIn common with several other scripts in the devscripts package,\n  debuild will climb the directory tree until it finds a\n  debian/changelog file before attempting to build the package. As a\n  safeguard against stray files causing potential problems, it will examine the\n  name of the parent directory once it finds the debian/changelog file,\n  and check that the directory name corresponds to the package name. Precisely\n  how it does this is controlled by two configuration file variables\n  DEVSCRIPTS_CHECK_DIRNAME_LEVEL and\n  DEVSCRIPTS_CHECK_DIRNAME_REGEX, and their corresponding command-line\n  options --check-dirname-level and --check-dirname-regex.\nDEVSCRIPTS_CHECK_DIRNAME_LEVEL can take the following\n    values:\n\n0\nNever check the directory name.\n1\nOnly check the directory name if we have had to change directory in our\n      search for debian/changelog. This is the default behaviour.\n2\nAlways check the directory name.\n\nThe directory name is checked by testing whether the current\n    directory name (as determined by pwd(1)) matches the regex given by\n    the configuration file option DEVSCRIPTS_CHECK_DIRNAME_REGEX or by\n    the command line option --check-dirname-regex regex. Here\n    regex is a Perl regex (see perlre(3perl)), which will be\n    anchored at the beginning and the end. If regex contains a '/', then\n    it must match the full directory path. If not, then it must match the full\n    directory name. If regex contains the string ´PACKAGE', this\n    will be replaced by the source package name, as determined from the\n    changelog. The default value for the regex is:\n    ´PACKAGE(-.+)?', thus matching directory names such as PACKAGE and\n    PACKAGE-version.\n\n\nENVIRONMENT VARIABLES¶\nAs environment variables can affect the building of a package, often\n  unintentionally, debuild sanitises the environment by removing all\n  environment variables except for TERM, HOME, LOGNAME,\n  GNUPGHOME, PGPPATH, GPG_AGENT_INFO, GPG_TTY,\n  DBUS_SESSION_BUS_ADDRESS, FAKEROOTKEY, DEBEMAIL,\n  DEB_ *, the (C, CPP, CXX, LD and\n  F)FLAGS variables and their _APPEND counterparts and the\n  locale variables LANG and LC_*. TERM is set to\n  `dumb' if it is unset, and PATH is set to\n  \"/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11\".\nIf a particular environment variable is required to be passed\n    through untouched to the build process, this may be specified by using a\n    --preserve-envvar envvar (which can also be written as\n    -e envvar option). The environment may be left untouched by\n    using the --preserve-env option. However, even in this case, the\n    PATH will be set to the sane value described above. The only\n    way to prevent PATH from being reset is to specify a\n    --preserve-envvar PATH option. But you are warned that using programs\n    from non-standard locations can easily result in the package being broken,\n    as it will not be able to be built on standard systems.\nNote that one may add directories to the beginning of the\n    sanitised PATH, using the --prepend-path option. This is\n    useful when one wishes to use tools such as ccache or distcc\n    for building.\nIt is also possible to avoid having to type something like\n    FOO =bar debuild -e FOO by writing\n    debuild -e FOO=bar or the long form\n    debuild --set-envvar FOO=bar.\n\n\nSUPERUSER REQUIREMENTS¶\ndebuild needs to be run as superuser to function properly. There are\n  three fundamentally different ways to do this. The first, and preferable,\n  method is to use some root-gaining command. The best one to use is probably\n  fakeroot(1), since it does not involve granting any genuine privileges.\n  super(1) and sudo(1) are also possibilities. If no -r (or\n  --rootcmd) option is given (and recall that dpkg-buildpackage\n  also accepts a -r option) and neither of the following methods is used,\n  then -rfakeroot will silently be assumed.\nThe second method is to use some command such as su(1) to\n    become root, and then to do everything as root. Note, though, that\n    lintian will abort if it is run as root or setuid root; this can be\n    overcome using the --allow-root option of lintian if you know\n    what you are doing.\nThe third possible method is to have debuild installed as\n    setuid root. This is not the default method, and will have to be installed\n    as such by the system administrator. It must also be realised that anyone\n    who can run debuild as root or setuid root has full access\n    to the whole machine. This method is therefore not recommended, but will\n    work. debuild could be installed with mode 4754, so that only members\n    of the owning group could run it. A disadvantage of this method would be\n    that other users would then not be able to use the program. There are many\n    other variants of this option involving multiple copies of debuild,\n    or the use of programs such as sudo or super to grant root\n    privileges to users selectively. If the sysadmin wishes to do this, she\n    should use the dpkg-statoverride program to change the permissions of\n    /usr/bin/debuild. This will ensure that these permissions are\n    preserved across upgrades.\n\n\nHOOKS¶\ndebuild supports a number of hooks when running dpkg-buildpackage.\n  Note that the hooks dpkg-buildpackage to lintian (inclusive) are\n  passed through to dpkg-buildpackage using its corresponding\n  --hook-name option. The available hooks are as follows:\n\ndpkg-buildpackage-hook\nRun before dpkg-buildpackage begins by calling\n      dpkg-checkbuilddeps.\n\n\n\nHook is run inside the unpacked source.\n\nCorresponds to dpkg's init hook.\n\n\nclean-hook\nRun before dpkg-buildpackage runs debian/rules clean to\n      clean the source tree. (Run even if the tree is not being cleaned because\n      -nc is used.)\n\n\n\nHook is run inside the unpacked source.\n\nCorresponds to dpkg's preclean hook.\n\n\ndpkg-source-hook\nRun after cleaning the tree and before running dpkg-source. (Run\n      even if dpkg-source is not being called because -b,\n      -B, or -A is used.)\n\n\n\nHook is run inside the unpacked source.\n\nCorresponds to dpkg's source hook.\n\n\ndpkg-build-hook\nRun after dpkg-source and before calling debian/rules build.\n      (Run even if this is a source-only build, so debian/rules build is\n      not being called.)\n\n\n\nHook is run inside the unpacked source.\n\nCorresponds to dpkg's build hook.\n\n\ndpkg-binary-hook\nRun between debian/rules build and debian/rules\n      binary(-arch). Run only if a binary package is being\n      built.\n\n\n\nHook is run inside the unpacked source.\n\nCorresponds to dpkg's binary hook.\n\n\ndpkg-genchanges-hook\nRun after the binary package is built and before calling\n      dpkg-genchanges.\n\n\n\nHook is run inside the unpacked source.\n\nCorresponds to dpkg's changes hook.\n\n\nfinal-clean-hook\nRun after dpkg-genchanges and before the final debian/rules\n      clean. (Run even if we are not cleaning the tree post-build, which is\n      the default.)\n\n\n\nHook is run inside the unpacked source.\n\nCorresponds to dpkg's postclean hook.\n\n\nlintian-hook\nRun (once) before calling lintian. (Run even if we are not calling\n      lintian.)\n\n\n\nHook is run from parent directory of unpacked source.\n\nCorresponds to dpkg's check hook.\n\n\nsigning-hook\nRun after calling lintian before any signing takes place. (Run even\n      if we are not signing anything.)\n\n\n\nHook is run from parent directory of unpacked source.\n\nCorresponds to dpkg's sign hook, but is run by\n      debuild.\n\n\npost-dpkg-buildpackage-hook\nRun after everything has finished.\n\n\n\nHook is run from parent directory of unpacked source.\n\nCorresponds to dpkg's done hook, but is run by\n      debuild.\n\nA hook command can be specified either in the configuration file\n    as, for example, DEBUILD_SIGNING_HOOK='foo' (note the hyphens change into\n    underscores!) or as a command line option --signing-hook-foo. The\n    command will have certain percent substitutions made on it: %% will\n    be replaced by a single % sign, %p will be replaced by the\n    package name, %v by the package version number, %s by the\n    source version number, %u by the upstream version number. Neither\n    %s nor %u will contain an epoch. %a will be 1 if\n    the immediately following action is to be performed and 0 if not (for\n    example, in the dpkg-source hook, %a will become 1 if\n    dpkg-source is to be run and 0 if not). Then it will be handed\n    to the shell to deal with, so it can include redirections and stuff. For\n    example, to only run the dpkg-source hook if dpkg-source is to\n    be run, the hook could be something like: \"if [ %a -eq 1 ]; then ...;\n    fi\".\nPlease take care with hooks, as misuse of them can lead to\n    packages which FTBFS (fail to build from source). They can be useful for\n    taking snapshots of things or the like.\n\n\nOPTIONS¶\nFor details, see above.\n\n--no-conf, --noconf\nDo not read any configuration files. This can only be used as the first\n      option given on the command-line.\n--rootcmd=gain-root-command,\n    -rgain-root-command\nCommand to gain root (or fake root) privileges.\n--preserve-env\nDo not clean the environment, except for PATH.\n--preserve-envvar=var, -evar\nDo not clean the var variable from the environment.\n\n\n\nIf var ends in an asterisk (\"*\") then all variables with\n      names that match the portion of var before the asterisk will be\n      preserved.\n\n\n--set-envvar=var=value,\n    -evar=value\nSet the environment variable var to value and do not remove\n      it from the environment.\n--prepend-path=value \nOnce the normalized PATH has been set, prepend value to it.\n--lintian\nRun lintian after dpkg-buildpackage. This is the default\n      behaviour, and it overrides any configuration file directive to the\n      contrary.\n--no-lintian\nDo not run lintian after dpkg-buildpackage.\n--no-tgz-check\nEven if we're running dpkg-buildpackage and the version number has\n      a Debian revision, do not check that the .orig.tar.gz file or\n      .orig directory exists before starting the build.\n--tgz-check\nIf we're running dpkg-buildpackage and the version number has a\n      Debian revision, check that the .orig.tar.gz file or .orig\n      directory exists before starting the build. This is the default\n    behaviour.\n--username username\nWhen signing, use debrsign instead of debsign.\n      username specifies the credentials to be used.\n--foo-hook=hook\nSet a hook as described above. If hook is blank, this unsets the\n      hook.\n--clear-hooks\nClears all hooks. They may be reinstated by later command line\n    options.\n--check-dirname-level N\nSee the above section Directory name checking for an explanation of\n      this option.\n--check-dirname-regex regex\nSee the above section Directory name checking for an explanation of\n      this option.\n-d\nDo not run dpkg-checkbuilddeps to check build dependencies.\n-D\nRun dpkg-checkbuilddeps to check build dependencies.\n\n\n\nCONFIGURATION VARIABLES¶\nThe two configuration files /etc/devscripts.conf and ~/.devscripts\n  are sourced by a shell in that order to set configuration variables. Command\n  line options can be used to override some of these configuration file\n  settings, otherwise the --no-conf option can be used to prevent reading\n  these files. Environment variable settings are ignored when these\n  configuration files are read. The currently recognised variables are:\n\nDEBUILD_PRESERVE_ENV\nIf this is set to yes, then it is the same as the\n      --preserve-env command line parameter being used.\nDEBUILD_PRESERVE_ENVVARS\nWhich environment variables to preserve. This should be a comma-separated\n      list of variables. This corresponds to using possibly multiple\n      --preserve-envvar or -e options.\nDEBUILD_SET_ENVVAR_var=value\nThis corresponds to\n    --set-envvar=var=value.\nDEBUILD_PREPEND_PATH\nThis corresponds to --prepend-path.\nDEBUILD_ROOTCMD\nSetting this variable to prog is the equivalent of\n      -rprog.\nDEBUILD_TGZ_CHECK\nSetting this variable to no is the same as the\n      --no-tgz-check command line option.\nDEBUILD_SIGNING_USERNAME\nSetting this variable is the same as using the --username command\n      line option.\nDEBUILD_DPKG_BUILDPACKAGE_OPTS\nThese are options which should be passed to the invocation of\n      dpkg-buildpackage. They are given before any command-line options.\n      Due to issues of shell quoting, if a word containing spaces is required as\n      a single option, extra quotes will be required. For example, to ensure\n      that your own GPG key is always used, even for sponsored uploads, the\n      configuration file might contain the line:\n\n\n\n\nDEBUILD_DPKG_BUILDPACKAGE_OPTS=\"-k'Julian Gilbey <jdg@debian.org>' -sa\"\n    \n\n\nwhich gives precisely two options. Without the extra single quotes,\n      dpkg-buildpackage would reasonably complain that Gilbey is\n      an unrecognised option (it doesn't start with a - sign).\n\nAlso, if this option contains any -r, -d or -D\n      options, these will always be taken account of by debuild. Note\n      that a -r option in this variable will override the setting in\n      DEBUILD_ROOTCMD.\n\n\nDEBUILD_FOO_HOOK\nThe hook variable for the foo hook. See the section on hooks above\n      for more details. By default, this is empty.\nDEBUILD_LINTIAN\nShould we run lintian? If this is set to no, then\n      lintian will not be run.\nDEBUILD_LINTIAN_OPTS\nThese are options which should be passed to the invocation of\n      lintian. They are given before any command-line options, and the\n      usage of this variable is as described for the\n      DEBUILD_DPKG_BUILDPACKAGE_OPTS variable.\nDEVSCRIPTS_CHECK_DIRNAME_LEVEL,\n    DEVSCRIPTS_CHECK_DIRNAME_REGEX\nSee the above section Directory name checking for an explanation of\n      these variables. Note that these are package-wide configuration variables,\n      and will therefore affect all devscripts scripts which check their\n      value, as described in their respective manpages and in\n      devscripts.conf(5).\n\n\n\nEXAMPLES¶\nTo build your own package, simply run debuild from inside the source\n  tree. dpkg-buildpackage(1) options may be given on the command line.\nThe typical command line options to build only the binary\n    package(s) without signing the .changes file (or the non-existent .dsc\n    file):\n\n\n\ndebuild -i -us -uc -b\n    \n\n\nChange the -b to -S to build only a source\n  package.\nAn example using lintian to check the resulting packages\n    and passing options to it:\n\n\n\ndebuild --lintian-opts -i\n    \n\n\nNote the order of options here: the debuild options come\n    first, then the dpkg-buildpackage ones, then finally the checker\n    options. (And lintian is called by default.) If you find yourself\n    using the same dpkg-buildpackage options repeatedly, consider using\n    the DEBUILD_DPKG_BUILDPACKAGE_OPTS configuration file option as\n    described above.\nTo build a package for a sponsored upload, given\n    foobar_1.0-1.dsc and the respective source files, run something like\n    the following commands:\n\n\n\ndpkg-source -x foobar_1.0-1.dsc\ncd foobar-1.0\ndebuild -k0x12345678\n    \n\n\nwhere 0x12345678 is replaced by your GPG key ID or other key\n    identifier such as your email address. Again, you could also use the\n    DEBUILD_DPKG_BUILDPACKAGE_OPTS configuration file option as described\n    above to avoid having to type the -k option each time you do a\n    sponsored upload.\n\n\nSEE ALSO¶\nchmod(1), debsign(1), dpkg-buildpackage(1),\n  dpkg-checkbuilddeps(1), fakeroot(1), lintian(1),\n  su(1), sudo(1), super(1), devscripts.conf(5),\n  dpkg-statoverride(8)\n\n\nAUTHOR¶\nThe original debuild program was written by Christoph Lameter\n  <clameter@debian.org>. The current version has been written by Julian\n  Gilbey <jdg@debian.org>.\n\n\n\n\nDebian Utilities\nDEBIAN\n\n\n\n\n\n\n\n\n\nSource file:\n\n\ndebuild.1.en.gz (from devscripts 2.19.5+deb10u1)\n\n\n\n\nSource last updated:\n\n\n2019-08-04T21:15:44Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:08:51Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# debuild\n\n> Tool to build a Debian package from source.\n> More information: <https://manpages.debian.org/debuild>.\n\n- Build the package in the current directory:\n\n`debuild`\n\n- Build a binary package only:\n\n`debuild -b`\n\n- Do not run lintian after building the package:\n\n`debuild --no-lintian`\n"
 },
 {
   "command": "pamac",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# pamac\n\n> A command line utility for the GUI package manager pamac.\n\n- Install a new package:\n\n`pamac install {{package_name}}`\n\n- Remove a package and its no longer required dependencies (orphans):\n\n`pamac remove -o {{package_name}}`\n\n- Search the package database for a package:\n\n`pamac search {{package_name}}`\n\n- List installed packages:\n\n`pamac list -i`\n\n- Check for package updates:\n\n`pamac checkupdates`\n"
 },
 {
   "command": "foreman",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# foreman\n\n> Manage Procfile-based applications.\n\n- Start an application with the Procfile in the current directory:\n\n`foreman start`\n\n- Start an application with a specified Procfile:\n\n`foreman start -f {{Procfile}}`\n\n- Start a specific application:\n\n`foreman start {{process}}`\n\n- Validate Procfile format:\n\n`foreman check`\n\n- Run one-off commands with the process's environment:\n\n`foreman run {{command}}`\n\n- Start all processes except the one named \"worker\":\n\n`foreman start -m all=1,{{worker}}=0`\n"
 },
 {
   "command": "lastb",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lastb\n\n> Show a listing of last logged in users.\n\n- Show a list of all last logged in users:\n\n`sudo lastb`\n\n- Show a list of all last logged in users since a given time:\n\n`sudo lastb --since {{YYYY-MM-DD}}`\n\n- Show a list of all last logged in users until a given time:\n\n`sudo lastb --until {{YYYY-MM-DD}}`\n\n- Show a list of all logged in users at a specific time:\n\n`sudo lastb --present {{hh:mm}}`\n\n- Show a list of all last logged in users and translate the IP into a hostname:\n\n`sudo lastb --dns`\n"
 },
 {
   "command": "prename",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rename\n\n> Rename multiple files.\n> NOTE: this page refers to the command from the `prename` Fedora package.\n\n- Rename files using a Perl Common Regular Expression (substitute 'foo' with 'bar' wherever found):\n\n`rename {{'s/foo/bar/'}} {{*}}`\n\n- Dry-run - display which renames would occur without performing them:\n\n`rename -n {{'s/foo/bar/'}} {{*}}`\n\n- Force renaming even if the operation would remove existing destination files:\n\n`rename -f {{'s/foo/bar/'}} {{*}}`\n\n- Convert filenames to lower case (use `-f` in case-insensitive filesystems to prevent \"already exists\" errors):\n\n`rename 'y/A-Z/a-z/' {{*}}`\n\n- Replace whitespace with underscores:\n\n`rename 's/\\s+/_/g' {{*}}`\n"
 },
 {
   "command": "poweroff",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# poweroff\n\n> Shutdown the system.\n\n- Poweroff the system:\n\n`sudo poweroff`\n"
 },
 {
   "command": "e2label",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# e2label\n\n> Change the label on an ext2/ext3/ext4 filesystem.\n\n- Change the volume label on a specific ext partition:\n\n`e2label {{/dev/sda1}} {{\"label_name\"}}`\n"
 },
 {
   "command": "lsattr",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lsattr\n\n> List file attributes on a Linux file system.\n\n- Display the attributes of the files in the current directory:\n\n`lsattr`\n\n- List the attributes of files in a particular path:\n\n`lsattr {{path}}`\n\n- List file attributes recursively in the current and subsequent directories:\n\n`lsattr -R`\n\n- Show attributes of all the files in the current directory, including hidden ones:\n\n`lsattr -a`\n\n- Display attributes of directories in the current directory:\n\n`lsattr -d`\n"
 },
 {
   "command": "getent",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# getent\n\n> Get entries from Name Service Switch libraries.\n\n- Get list of all groups:\n\n`getent group`\n\n- See the members of a group:\n\n`getent group {{group_name}}`\n\n- Get list of all services:\n\n`getent services`\n\n- Find a username by UID:\n\n`getent passwd 1000`\n\n- Perform a reverse DNS lookup:\n\n`getent hosts {{host}}`\n"
 },
 {
   "command": "ascii",
   "doc_url": "http://www.catb.org/~esr/ascii/",
   "doc_text": "\n\n\n\n\n\n\nResource page for ascii 3.18\n\n\n\n\n\n\nResource page for ascii 3.18\n\n20 Mar 2019\n\n\n\n\n\nHome Page\nWhat's New\nSite Map\nSoftware\n\n\n\nSummary\nList ASCII idiomatic names and octal/decimal code-point forms.\nProvides easy conversion between various byte representations and the\nAmerican Standard Code for Information Interchange (ASCII) character\ntable.  It knows about a wide variety of hex, binary, octal, Teletype\nmnemonic, ISO/ECMA code point, slang names, XML entity names, and\nother representations.  Given any one on the command line, it will try\nto display all others.  Called with no arguments it displays a handy\nsmall ASCII chart.\n\nResources\n\n\nREADMEroadmap file\nascii-3.18.tar.gzgzipped source tarball\nCOPYINGproject license\nNEWSproject news\nascii.htmlHTML rendering of ascii.1\n\n\nThe project repository is at https://gitlab.com/esr/ascii.\nIf you appreciate this code (and especially if you make money by using it) please support me on Patreon.\nRecent Changes\n\n  Fix a packaging error, include NEWS in the tarball.\n\n\nSupporters\nThis work is funded by...\nMy Bronze supporters on Patreon: Martin Hohenberg, Jae\nYang, Daniel Garber, Kyle Burkholder, Mike Nichols,\nMark Ping, Tom Taylor, Arnold F. Williams,\nGeorge Brower, Michael Nygard, Brendan Long, Sven\nDowideit, Dave Witten, Jonathan Cast, James Cronin, David L. Jessup,\nChristopher Chang, Killer Delicious, Jacob Lyles, Neil Anuskiewicz,\nMordant, Clemens Ladisch, Wojciech Woytniak, Masa Bando, John Carmack,\nXingyu Wang, Jane Tang, Steven Evans, Jan Roudaut, Hsueh Sung.\n\nMy Institutional supporters on Patreon: Jason Azze and the DEVOPS team\nat his $DAYJOB.\n\n\n\n",
   "man_entry": "\nASCII(7)\t     BSD Miscellaneous Information Manual\t      ASCII(7)\n\nNAME\n     ascii -- octal, hexadecimal and decimal ASCII character sets\n\nDESCRIPTION\n     The octal set:\n\n     000 nul  001 soh  002 stx\t003 etx  004 eot  005 enq  006 ack  007 bel\n     010 bs   011 ht   012 nl\t013 vt\t 014 np   015 cr   016 so   017 si\n     020 dle  021 dc1  022 dc2\t023 dc3  024 dc4  025 nak  026 syn  027 etb\n     030 can  031 em   032 sub\t033 esc  034 fs   035 gs   036 rs   037 us\n     040 sp   041  !   042  \"\t043  #\t 044  $   045  %   046\t&   047  '\n     050  (   051  )   052  *\t053  +\t 054  ,   055  -   056\t.   057  /\n     060  0   061  1   062  2\t063  3\t 064  4   065  5   066\t6   067  7\n     070  8   071  9   072  :\t073  ;\t 074  <   075  =   076\t>   077  ?\n     100  @   101  A   102  B\t103  C\t 104  D   105  E   106\tF   107  G\n     110  H   111  I   112  J\t113  K\t 114  L   115  M   116\tN   117  O\n     120  P   121  Q   122  R\t123  S\t 124  T   125  U   126\tV   127  W\n     130  X   131  Y   132  Z\t133  [\t 134  \\   135  ]   136\t^   137  _\n     140  `   141  a   142  b\t143  c\t 144  d   145  e   146\tf   147  g\n     150  h   151  i   152  j\t153  k\t 154  l   155  m   156\tn   157  o\n     160  p   161  q   162  r\t163  s\t 164  t   165  u   166\tv   167  w\n     170  x   171  y   172  z\t173  {\t 174  |   175  }   176\t~   177 del\n\n     The hexadecimal set:\n\n     00 nul   01 soh   02 stx\t03 etx\t 04 eot   05 enq   06 ack   07 bel\n     08 bs    09 ht    0a nl\t0b vt\t 0c np\t  0d cr    0e so    0f si\n     10 dle   11 dc1   12 dc2\t13 dc3\t 14 dc4   15 nak   16 syn   17 etb\n     18 can   19 em    1a sub\t1b esc\t 1c fs\t  1d gs    1e rs    1f us\n     20 sp    21  !    22  \"\t23  #\t 24  $\t  25  %    26  &    27\t'\n     28  (    29  )    2a  *\t2b  +\t 2c  ,\t  2d  -    2e  .    2f\t/\n     30  0    31  1    32  2\t33  3\t 34  4\t  35  5    36  6    37\t7\n     38  8    39  9    3a  :\t3b  ;\t 3c  <\t  3d  =    3e  >    3f\t?\n     40  @    41  A    42  B\t43  C\t 44  D\t  45  E    46  F    47\tG\n     48  H    49  I    4a  J\t4b  K\t 4c  L\t  4d  M    4e  N    4f\tO\n     50  P    51  Q    52  R\t53  S\t 54  T\t  55  U    56  V    57\tW\n     58  X    59  Y    5a  Z\t5b  [\t 5c  \\\t  5d  ]    5e  ^    5f\t_\n     60  `    61  a    62  b\t63  c\t 64  d\t  65  e    66  f    67\tg\n     68  h    69  i    6a  j\t6b  k\t 6c  l\t  6d  m    6e  n    6f\to\n     70  p    71  q    72  r\t73  s\t 74  t\t  75  u    76  v    77\tw\n     78  x    79  y    7a  z\t7b  {\t 7c  |\t  7d  }    7e  ~    7f del\n\n     The decimal set:\n\n       0 nul\t1 soh\t 2 stx\t  3 etx    4 eot    5 enq    6 ack    7 bel\n       8 bs\t9 ht\t10 nl\t 11 vt\t  12 np    13 cr    14 so    15 si\n      16 dle   17 dc1\t18 dc2\t 19 dc3   20 dc4   21 nak   22 syn   23 etb\n      24 can   25 em\t26 sub\t 27 esc   28 fs    29 gs    30 rs    31 us\n      32 sp    33  !\t34  \"\t 35  #\t  36  $    37  %    38\t&    39  '\n      40  (    41  )\t42  *\t 43  +\t  44  ,    45  -    46\t.    47  /\n      48  0    49  1\t50  2\t 51  3\t  52  4    53  5    54\t6    55  7\n      56  8    57  9\t58  :\t 59  ;\t  60  <    61  =    62\t>    63  ?\n      64  @    65  A\t66  B\t 67  C\t  68  D    69  E    70\tF    71  G\n      72  H    73  I\t74  J\t 75  K\t  76  L    77  M    78\tN    79  O\n      80  P    81  Q\t82  R\t 83  S\t  84  T    85  U    86\tV    87  W\n      88  X    89  Y\t90  Z\t 91  [\t  92  \\    93  ]    94\t^    95  _\n      96  `    97  a\t98  b\t 99  c\t 100  d   101  e   102\tf   103  g\n     104  h   105  i   106  j\t107  k\t 108  l   109  m   110\tn   111  o\n     112  p   113  q   114  r\t115  s\t 116  t   117  u   118\tv   119  w\n     120  x   121  y   122  z\t123  {\t 124  |   125  }   126\t~   127 del\n\nFILES\n     /usr/share/misc/ascii\n\nHISTORY\n     An ascii manual page appeared in Version 7 AT&T UNIX.\n\nBSD\t\t\t\t June 5, 1993\t\t\t\t   BSD\n",
   "tldr_summary": "# ascii\n\n> Show ASCII character aliases.\n> More information: <http://www.catb.org/~esr/ascii/>.\n\n- Show ASCII aliases of a character:\n\n`ascii {{a}}`\n\n- Show ASCII aliases in short, script-friendly mode:\n\n`ascii -t {{a}}`\n\n- Show ASCII aliases of multiple characters:\n\n`ascii -s {{tldr}}`\n\n- Show ASCII table in decimal:\n\n`ascii -d`\n\n- Show ASCII table in hexadecimal:\n\n`ascii -x`\n\n- Show ASCII table in octal:\n\n`ascii -o`\n\n- Show ASCII table in binary:\n\n`ascii -b`\n\n- Show options summary and complete ASCII table:\n\n`ascii`\n"
 },
 {
   "command": "bluetoothctl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# bluetoothctl\n\n> Handling bluetooth devices from the shell.\n\n- Enter the bluetoothctl shell:\n\n`bluetoothctl`\n\n- List devices:\n\n`bluetoothctl -- devices`\n\n- Pair a device:\n\n`bluetoothctl -- pair {{mac_address}}`\n\n- Remove a device:\n\n`bluetoothctl -- remove {{mac_address}}`\n\n- Connect a paired device:\n\n`bluetoothctl -- connect {{mac_address}}`\n\n- Disconnect a paired device:\n\n`bluetoothctl -- disconnect {{mac_address}}`\n"
 },
 {
   "command": "mkfs.vfat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs.vfat\n\n> Creates an MS-DOS filesystem inside a partition.\n\n- Create a.vfat filesystem inside partition 1 on device b (`sdb1`):\n\n`mkfs.vfat {{/dev/sdb1}}`\n\n- Create filesystem with a volume-name:\n\n`mkfs.vfat -n {{volume_name}} {{/dev/sdb1}}`\n\n- Create filesystem with a volume-id:\n\n`mkfs.vfat -i {{volume_id}} {{/dev/sdb1}}`\n\n- Use 5 instead of 2 file allocation tables:\n\n`mkfs.vfat -f 5 {{/dev/sdb1}}`\n"
 },
 {
   "command": "nft",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# nft\n\n> Allows configuration of tables, chains and rules provided by the Linux kernel firewall.\n> Nftables replaces iptables.\n\n- View current configuration:\n\n`sudo nft list ruleset`\n\n- Add a new table with family \"inet\" and table \"filter\":\n\n`sudo nft add table {{inet}} {{filter}}`\n\n- Add a new chain to accept all inbound traffic:\n\n`sudo nft add chain {{inet}} {{filter}} {{input}} \\{ type {{filter}} hook {{input}} priority {{0}} \\; policy {{accept}} \\}`\n\n- Add a new rule to accept several TCP ports:\n\n`sudo nft add rule {{inet}} {{filter}} {{input}} {{tcp}} {{dport \\{ telnet, ssh, http, https \\} accept}}`\n\n- Show rule handles:\n\n`sudo nft --handle --numeric list chain {{family}} {{table}} {{chain}}`\n\n- Delete a rule:\n\n`sudo nft delete rule {{inet}} {{filter}} {{input}} handle {{3}}`\n\n- Save current configuration:\n\n`sudo nft list ruleset > {{/etc/nftables.conf}}`\n"
 },
 {
   "command": "ark",
   "doc_url": "https://docs.kde.org/stable5/en/kdeutils/ark/",
   "doc_text": "The Ark Handbook The Ark Handbookhttp://docs.kde.org/ NextThe Ark HandbookMatt Johnston (mattj  flashmail.com)Henrique Pinto (henrique.pinto  kdemail.net)Ragnar Thomsen (rthomsen6  gmail.com)Revision Applications 16.12 (2016-09-10)Copyright © 2000 Matt JohnstonCopyright © 2004 Henrique PintoCopyright © 2015, 2016 Ragnar ThomsenLegal NoticeArk is an archive manager by KDE.Table of Contents1. Introduction2. Using ArkOpening ArchivesArchive OperationsArchive CommentsWorking with FilesEditing FilesExtracting FilesThe Extract dialogCreating Archives and Adding FilesCompressionPassword ProtectionMulti-volume Archive3. Using Ark in the Filemanager4. Advanced Batch Mode5. Credits and License Next   Introductionhttp://docs.kde.org/",
   "man_entry": "",
   "tldr_summary": "# ark\n\n> KDE archiving tool.\n> More information: <https://docs.kde.org/stable5/en/kdeutils/ark/>.\n\n- Extract an archive into the current directory:\n\n`ark --batch {{archive}}`\n\n- Change extraction directory:\n\n`ark --batch --destination {{path/to/directory}} {{archive}}`\n\n- Create an archive if it does not exist and add files to it:\n\n`ark --add-to {{archive}} {{file1}} {{file2}}`\n"
 },
 {
   "command": "medusa",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# Medusa\n\n> A modular and parallel login brute-forcer for a variety of protocols.\n\n- Execute brute force against an FTP server using a file containing usernames and a file containing passwords:\n\n`medusa -M ftp -h host -U {{path/to/username_file}} -P {{path/to/password_file}}`\n\n- Execute a login attempt against a HTTP server using the username, password and user-agent specified:\n\n`medusa -M HTTP -h host -u {{username}} -p {{password}} -m USER-AGENT:\"{{Agent}}\"`\n\n- Execute a brute force against a MySQL server using a file cointaining usernames and a hash:\n\n`medusa -M mysql -h host -U {{path/to/username_file}} -p {{hash}} -m PASS:HASH`\n\n- Execute a brute force against a list of SMB servers using a username and a pwdump file:\n\n`medusa -M smbnt -H {{path/to/hosts_file}} -C {{path/to/pwdump_file}} -u {{username}} -m PASS:HASH`\n"
 },
 {
   "command": "blkdiscard",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# blkdiscard\n\n> Discards device sectors on storage devices. Useful for SSDs.\n\n- Discard all sectors on a device, removing all data:\n\n`blkdiscard /dev/{{device}}`\n\n- Securely discard all blocks on a device, removing all data:\n\n`blkdiscard --secure /dev/{{device}}`\n\n- Discard the first 100MB of a device:\n\n`blkdiscard --length {{100MB}} /dev/{{device}}`\n"
 },
 {
   "command": "cal",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nCAL(1)\t\t\t  BSD General Commands Manual\t\t\tCAL(1)\n\nNAME\n     cal, ncal -- displays a calendar and the date of Easter\n\nSYNOPSIS\n     cal [-3hjy] [-A number] [-B number] [[month] year]\n     cal [-3hj] [-A number] [-B number] -m month [year]\n     ncal [-3hjJpwy] [-A number] [-B number] [-s country_code] [[month] year]\n     ncal [-3hJeo] [-A number] [-B number] [year]\n     ncal [-CN] [-H yyyy-mm-dd] [-d yyyy-mm]\n\nDESCRIPTION\n     The cal utility displays a simple calendar in traditional format and ncal\n     offers an alternative layout, more options and the date of Easter.  The\n     new format is a little cramped but it makes a year fit on a 25x80 termi-\n     nal.  If arguments are not specified, the current month is displayed.\n\n     The options are as follows:\n\n     -h      Turns off highlighting of today.\n\n     -J      Display Julian Calendar, if combined with the -e option, display\n\t     date of Easter according to the Julian Calendar.\n\n     -e      Display date of Easter (for western churches).\n\n     -j      Display Julian days (days one-based, numbered from January 1).\n\n     -m month\n\t     Display the specified month.  If month is specified as a decimal\n\t     number, it may be followed by the letter `f' or `p' to indicate\n\t     the following or preceding month of that number, respectively.\n\n     -o      Display date of Orthodox Easter (Greek and Russian Orthodox\n\t     Churches).\n\n     -p      Print the country codes and switching days from Julian to Grego-\n\t     rian Calendar as they are assumed by ncal.  The country code as\n\t     determined from the local environment is marked with an asterisk.\n\n     -s country_code\n\t     Assume the switch from Julian to Gregorian Calendar at the date\n\t     associated with the country_code.\tIf not specified, ncal tries\n\t     to guess the switch date from the local environment or falls back\n\t     to September 2, 1752.  This was when Great Britain and her\n\t     colonies switched to the Gregorian Calendar.\n\n     -w      Print the number of the week below each week column.\n\n     -y      Display a calendar for the specified year.\n\n     -3      Display the previous, current and next month surrounding today.\n\n     -A number\n\t     Display the number of months after the current month.\n\n     -B number\n\t     Display the number of months before the current month.\n\n     -C      Switch to cal mode.\n\n     -N      Switch to ncal mode.\n\n     -d yyyy-mm\n\t     Use yyyy-mm as the current date (for debugging of date selec-\n\t     tion).\n\n     -H yyyy-mm-dd\n\t     Use yyyy-mm-dd as the current date (for debugging of highlight-\n\t     ing).\n\n     A single parameter specifies the year (1-9999) to be displayed; note the\n     year must be fully specified: ``cal 89'' will not display a calendar for\n     1989.  Two parameters denote the month and year; the month is either a\n     number between 1 and 12, or a full or abbreviated name as specified by\n     the current locale.  Month and year default to those of the current sys-\n     tem clock and time zone (so ``cal -m 8'' will display a calendar for the\n     month of August in the current year).\n\n     Not all options can be used together. For example ``-3 -A 2 -B 3 -y -m\n     7'' would mean: show me the three months around the seventh month, three\n     before that, two after that and the whole year.  ncal will warn about\n     these combinations.\n\n     A year starts on January 1.\n\n     Highlighting of dates is disabled if stdout is not a tty.\n\nSEE ALSO\n     calendar(3), strftime(3)\n\nHISTORY\n     A cal command appeared in Version 5 AT&T UNIX.  The ncal command appeared\n     in FreeBSD 2.2.6.\n\nAUTHORS\n     The ncal command and manual were written by Wolfgang Helbig\n     <helbig@FreeBSD.org>.\n\nBUGS\n     The assignment of Julian-Gregorian switching dates to country codes is\n     historically naive for many countries.\n\n     Not all options are compatible and using them in different orders will\n     give varying results.\n\nBSD\t\t\t\tMarch 14, 2009\t\t\t\t   BSD\n",
   "tldr_summary": "# cal\n\n> Prints calendar information, with the current day highlighted.\n\n- Display a calendar for the current month:\n\n`cal`\n\n- Display previous, current and next month:\n\n`cal -3`\n\n- Use monday as the first day of the week:\n\n`cal --monday`\n\n- Display a calendar for a specific year (4 digits):\n\n`cal {{year}}`\n\n- Display a calendar for a specific month and year:\n\n`cal {{month}} {{year}}`\n"
 },
 {
   "command": "dos2unix",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# dos2unix\n\n> Change DOS-style line endings to Unix-style.\n> Replaces CRLF with CR.\n\n- Change the line endings of a file:\n\n`dos2unix {{filename}}`\n\n- Create a copy with Unix-style line endings:\n\n`dos2unix -n {{filename}} {{new_filename}}`\n"
 },
 {
   "command": "homeshick",
   "doc_url": "https://github.com/andsens/homeshick/wiki",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nHome · andsens/homeshick Wiki · GitHub\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nandsens\n\n/\n\nhomeshick\n\n\n\n\n\n\n\n    Watch\n \n      61\n    \n\n\n\n\n      Star\n\n\n      1.6k\n    \n\n\n\n\n          Fork\n\n\n        125\n      \n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n14\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nWiki\n\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Wiki\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\nHome\n\nJump to bottom\n\n\n\n      Joseph Frazier edited this page Mar 5, 2017\n      ·\n      \n        31 revisions\n      \n\n\n\n\n\n\n\nTable of contents\n\nHow does it work?\n\nInstallation\n\nHomebrew\n\nCompletion (bash zsh fish)\n\n\n\nCommands (link clone pull check list track generate refresh cd)\n\n\nSwitches (quiet skip force batch)\n\n\n\nTutorials\n\nBootstrapping\nAdding other machines\nRefreshing\nUpdating your castle\n\n\nAutomatic deployment\n\nPackages\n\nAvailable packages\nPackaging homeshick\n\n\n\nSymlinking\n\nLinking table\nCombining directories\nRepos with no home directory\nShallow symlinking\nFiles outside your home directory\n\n\n\nTesting\n\nDependencies\nFixtures\nInteractive testing\nGNU coreutils on OSX\n\n\nFAQ\nUsing myrepos to manage multiple castles across machines\nSimplistic bootstrapping script alternative\nForks\nhomeshick and homesick\n\n\nHow does it work?\nSymlinking.\nOn the simplest level, all homeshick really does is look for files and folders\nin your cloned repositories and symlink them to your home directory (the linking table explains the symlinking process in more detail).\nThe symlinked files must however reside in a folder named home.\nThis way you can prevent homeshick from cluttering your home folder with\nfiles that are only included from elsewhere.\nA repository managed by homeshick is referred to as a castle.\n\n\n\n\n\n\n\n\n\n\n\n      Pages 13\n\n\n\n\n\n\n\n\nHome\n\n\nAutomatic deployment\n\n\nCommands\n\n\nFAQ\n\n\nForks\n\n\nhomeshick and homesick\n\n\nInstallation\n\n\nMyrepos\n\n\nPackages\n\n\nSimplistic bootstraping script\n\n\nSymlinking\n\n\nTesting\n\n\nTutorials\n\n\n\n\n\nClone this wiki locally\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# Homeshick\n\n> Synchronize Git dotfiles.\n> More information <https://github.com/andsens/homeshick/wiki>.\n\n- Create a new castle:\n\n`homeshick generate {{castle_name}}`\n\n- Add a file to your castle:\n\n`homeshick track {{castle_name}} {{path/to/file}}`\n\n- Go to a castle:\n\n`homeshick cd {{castle_name}}`\n\n- Clone a castle:\n\n`homeshick clone {{github_username}}/{{repository_name}}`\n\n- Symlink all files from a castle:\n\n`homeshick link {{castle_name}}`\n"
 },
 {
   "command": "rc-service",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# rc-service\n\n> Locate and run OpenRC services with arguments.\n> See also `openrc`.\n\n- Show a service's status:\n\n`rc-service {{service_name}} status`\n\n- Start a service:\n\n`sudo rc-service {{service_name}} start`\n\n- Stop a service:\n\n`sudo rc-servie {{service_name}} stop`\n\n- Restart a service:\n\n`sudo rc-service {{service_name}} restart`\n\n- Simulate running a service's custom command:\n\n`sudo rc-service --dry-run {{service_name}} {{command_name}}`\n\n- Actually run a service's custom command:\n\n`sudo rc-service {{service_name}} {{command_name}}`\n\n- Resolve the location of a service definition on disk:\n\n`sudo rc-service --resolve {{service_name}}`\n"
 },
 {
   "command": "tune2fs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# tune2fs\n\n> Adjust parameters of an ext2, ext3 or ext4 filesystem.\n> May be used on mounted filesystems.\n\n- Set the max number of counts before a filesystem is checked to 2:\n\n`tune2fs -c {{2}} {{/dev/sdXN}}`\n\n- Set the filesystem label to MY_LABEL:\n\n`tune2fs -L {{'MY_LABEL'}} {{/dev/sdXN}}`\n\n- Enable discard and user-specified extended attributes for a filesystem:\n\n`tune2fs -o {{discard,user_xattr}} {{/dev/sdXN}}`\n\n- Enable journaling for a filesystem:\n\n`tune2fs -o^{{nobarrier}} {{/dev/sdXN}}`\n"
 },
 {
   "command": "sinfo",
   "doc_url": "https://slurm.schedmd.com/sinfo.html",
   "doc_text": "\n\n\n\nSlurm Workload Manager - sinfo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSlurm Workload Manager\n\n\n\n\nSchedMD\n\n\n\n\n\nNavigation\n\nSlurm Workload Manager\nVersion 20.02\n\n\n\nAbout\n\nOverview\nRelease Notes\nSlurm Team\nMeetings\nTestimonials\nLegal Notices\n\n\n\nUsing\n\nTutorials\nDocumentation\nFAQ\nPublications\n\n\n\nInstalling\n\nDownload\nInstallation Guide\n\n\n\nGetting Help\n\nSupport\nMailing Lists\nTraining\nTroubleshooting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsinfo\nSection: Slurm Commands (1)Updated: Slurm CommandsIndex\n\n \n\nNAME\n\nsinfo - View information about Slurm nodes and partitions.\n\n \n\nSYNOPSIS\nsinfo [OPTIONS...]\n \n\nDESCRIPTION\nsinfo is used to view partition and node information for a\nsystem running Slurm.\n\n \n\nOPTIONS\n\n\n\n-a, --all\nDisplay information about all partitions. This causes information to be\ndisplayed about partitions that are configured as hidden and partitions that\nare unavailable to the user's group.\n\n\n-d, --dead\nIf set, only report state information for non-responding (dead) nodes.\n\n\n-e, --exact\nIf set, do not group node information on multiple nodes unless\ntheir configurations to be reported are identical. Otherwise\ncpu count, memory size, and disk space for nodes will be listed\nwith the minimum value followed by a \"+\" for nodes with the\nsame partition and state (e.g. \"250+\").\n\n\n--federation\nShow all partitions from the federation if a member of one.\n\n\n-h, --noheader\nDo not print a header on the output.\n\n\n--help\nPrint a message describing all sinfo options.\n\n\n--hide\nDo not display information about hidden partitions. Partitions\nthat are configured as hidden or are not available to the user's group\nwill not be displayed. This is the default behavior.\n\n\n-i <seconds>, --iterate=<seconds>\nPrint the state on a periodic basis.\nSleep for the indicated number of seconds between reports.\nBy default prints a time stamp with the header.\n\n\n--local\nShow only jobs local to this cluster. Ignore other clusters in this federation\n(if any). Overrides --federation.\n\n\n-l, --long\nPrint more detailed information.\nThis is ignored if the --format option is specified.\n\n\n-M, --clusters=<string>\nClusters to issue commands to.  Multiple cluster names may be comma separated.\nA value of of 'all' will query all clusters. Note that the\nSlurmDBD must be up for this option to work properly.\nThis option implicitly sets the --local option.\n\n\n-n <nodes>, --nodes=<nodes>\nPrint information about the specified node(s).\nMultiple nodes may be comma separated or expressed using a\nnode range expression (e.g. \"linux[00-17]\")\nLimiting the query to just the relevant nodes can measurably improve the\nperformance of the command for large clusters.\n\n\n--noconvert\nDon't convert units from their original type (e.g. 2048M won't be converted to\n2G).\n\n\n-N, --Node\nPrint information in a node-oriented format with one line per node\nand partition. That is, if a node belongs to more than one partition, then one\nline for each node-partition pair will be shown.\nIf --partition is also specified, then only one line per node in this\npartition is shown.\nThe default is to print information in a partition-oriented format.\nThis is ignored if the --format option is specified.\n\n\n-o <output_format>, --format=<output_format>\nSpecify the information to be displayed using an sinfo\nformat string.\nIf the command is executed in a federated cluster environment and information\nabout more than one cluster is to be displayed and the -h, --noheader\noption is used, then the cluster name will be displayed before the default\noutput formats shown below.\nFormat strings transparently used by sinfo when running with various\noptions are:\n\n\ndefault\n\n\"%#P %.5a %.10l %.6D %.6t %N\"\n--summarize\n\n\"%#P %.5a %.10l %.16F  %N\"\n--long\n\n\"%#P %.5a %.10l %.10s %.4r %.8h %.10g %.6D %.11T %N\"\n--Node\n\n\"%#N %.6D %#P %6t\"\n--long --Node\n\n\"%#N %.6D %#P %.11T %.4c %.8z %.6m %.8d %.6w %.8f %20E\"\n--list-reasons\n\n\"%20E %9u %19H %N\"\n--long --list-reasons\n\n\"%20E %12U %19H %6t %N\"\n\n\n\n\nIn the above format strings, the use of \"#\" represents the\nmaximum length of any partition name or node list to be printed.\nA pass is made over the records to be printed to establish the size in order\nto align the sinfo output, then a second pass is made over the records to\nprint them.\nNote that the literal character \"#\" itself is not a valid field length\nspecification, but is only used to document this behaviour.\n\nThe field specifications available include:\n\n\n\n%all\nPrint all fields available for this data type with a vertical bar separating\neach field.\n\n%a\nState/availability of a partition.\n\n%A\nNumber of nodes by state in the format \"allocated/idle\".\nDo not use this with a node state option (\"%t\" or \"%T\") or\nthe different node states will be placed on separate lines.\n\n%b\nFeatures currently active on the nodes, also see %f.\n\n%B\nThe max number of CPUs per node available to jobs in the partition.\n\n%c\nNumber of CPUs per node.\n\n%C\nNumber of CPUs by state in the format\n\"allocated/idle/other/total\". Do not use this with a node\nstate option (\"%t\" or \"%T\") or the different node states will\nbe placed on separate lines.\n\n%d\nSize of temporary disk space per node in megabytes.\n\n%D\nNumber of nodes.\n\n%e\nFree memory of a node.\n\n%E\nThe reason a node is unavailable (down, drained, or draining states).\n\n%f\nFeatures available the nodes, also see %b.\n\n%F\nNumber of nodes by state in the format\n\"allocated/idle/other/total\".  Note the use of this format option with a node\nstate format option (\"%t\" or \"%T\") will result in the different node states\nbeing be reported on separate lines.\n\n%g\nGroups which may use the nodes.\n\n%G\nGeneric resources (gres) associated with the nodes.\n\n%h\nPrint the OverSubscribe setting for the partition.\n\n%H\nPrint the timestamp of the reason a node is unavailable.\n\n%I\nPartition job priority weighting factor.\n\n%l\nMaximum time for any job in the format \"days-hours:minutes:seconds\"\n\n%L\nDefault time for any job in the format \"days-hours:minutes:seconds\"\n\n%m\nSize of memory per node in megabytes.\n\n%M\nPreemptionMode.\n\n%n\nList of node hostnames.\n\n%N\nList of node names.\n\n%o\nList of node communication addresses.\n\n%O\nCPU load of a node.\n\n%p\nPartition scheduling tier priority.\n\n%P\nPartition name followed by \"*\" for the default partition, also see %R.\n\n%r\nOnly user root may initiate jobs, \"yes\" or \"no\".\n\n%R\nPartition name, also see %P.\n\n%s\nMaximum job size in nodes.\n\n%S\nAllowed allocating nodes.\n\n%t\nState of nodes, compact form.\n\n%T\nState of nodes, extended form.\n\n%u\nPrint the user name of who set the reason a node is unavailable.\n\n%U\nPrint the user name and uid of who set the reason a node is unavailable.\n\n%v\nPrint the version of the running slurmd daemon.\n\n%V\nPrint the cluster name if running in a federation.\n\n%w\nScheduling weight of the nodes.\n\n%X\nNumber of sockets per node.\n\n%Y\nNumber of cores per socket.\n\n%Z\nNumber of threads per core.\n\n%z\nExtended processor information: number of sockets, cores, threads (S:C:T) per node.\n\n%.<*>\nRight justification of the field.\n\n%<Number><*>\nSize of the field.\n\n\n\n\n-O <output_format>, --Format=<output_format>\nSpecify the information to be displayed.\nAlso see the -o <output_format>, --format=<output_format>\noption (which supports greater flexibility in formatting, but\ndoes not support access to all fields because we ran out of letters).\nRequests a comma separated list of job information to be displayed.\n\n\nThe format of each field is \"type[:[.]size]\"\n\n\nsize\nThe minimum field size.\nIf no size is specified, 20 characters will be allocated to print the information.\n .\nIndicates the output should be right justified and size must be specified.\nBy default, output is left justified.\n\n\n\n\nValid type specifications include:\n\n\n\nAll\n\nPrint all fields available in the -o format for this data type with a\nvertical bar separating each field.\n\n\nAllocMem\nPrints the amount of allocated memory on a node.\n\nAllocNodes\nAllowed allocating nodes.\n\nAvailable\nState/availability of a partition.\n\nCluster\nPrint the cluster name if running in a federation.\n\nCores\n\nNumber of cores per socket.\n\n\nCPUs\n\nNumber of CPUs per node.\n\n\nCPUsLoad\nCPU load of a node.\n\nCPUsState\nNumber of CPUs by state in the format\n\"allocated/idle/other/total\". Do not use this with a node\nstate option (\"%t\" or \"%T\") or the different node states will\nbe placed on separate lines.\n\nDefaultTime\nDefault time for any job in the format \"days-hours:minutes:seconds\".\n\nDisk\n\nSize of temporary disk space per node in megabytes.\n\n\nFeatures\nFeatures available on the nodes. Also see features_act.\n\nfeatures_act\nFeatures currently active on the nodes. Also see features.\n\nFreeMem\nFree memory of a node.\n\nGres\n\nGeneric resources (gres) associated with the nodes.\n\n\nGresUsed\nGeneric resources (gres) currently in use on the nodes.\n\nGroups\n\nGroups which may use the nodes.\n\n\nMaxCPUsPerNode\nThe max number of CPUs per node available to jobs in the partition.\n\nMemory\n\nSize of memory per node in megabytes.\n\n\nNodeAddr\nList of node communication addresses.\n\nNodeAI\n\nNumber of nodes by state in the format \"allocated/idle\".\nDo not use this with a node state option (\"%t\" or \"%T\") or\nthe different node states will be placed on separate lines.\n\n\nNodeAIOT\nNumber of nodes by state in the format\n\"allocated/idle/other/total\".  Do not use this with a node\nstate option (\"%t\" or \"%T\") or the different node states will\nbe placed on separate lines.\n\nNodeHost\nList of node hostnames.\n\nNodeList\nList of node names.\n\nNodes\n\nNumber of nodes.\n\n\nOverSubscribe\nWhether jobs may oversubscribe compute resources (e.g. CPUs).\n\nPartition\nPartition name followed by \"*\" for the default partition, also see %R.\n\nPartitionName\nPartition name, also see %P.\n\nPort\n\nNode TCP port.\n\n\nPreemptMode\nPreemption mode.\n\nPriorityJobFactor\nPartition factor used by priority/multifactor plugin in calculating job priority.\n\nPriorityTier or Priority\nPartition scheduling tier priority.\n\nReason\n\nThe reason a node is unavailable (down, drained, or draining states).\n\n\nRoot\n\nOnly user root may initiate jobs, \"yes\" or \"no\".\n\n\nSize\n\nMaximum job size in nodes.\n\n\nSocketCoreThread\nExtended processor information: number of sockets, cores, threads (S:C:T) per node.\n\nSockets\nNumber of sockets per node.\n\nStateCompact\nState of nodes, compact form.\n\nStateLong\nState of nodes, extended form.\n\nThreads\nNumber of threads per core.\n\nTime\n\nMaximum time for any job in the format \"days-hours:minutes:seconds\".\n\n\nTimeStamp\nPrint the timestamp of the reason a node is unavailable.\n\nUser\n\nPrint the user name of who set the reason a node is unavailable.\n\n\nUserLong\nPrint the user name and uid of who set the reason a node is unavailable.\n\nVersion\nPrint the version of the running slurmd daemon.\n\nWeight\n\nScheduling weight of the nodes.\n\n\n\n\n\n-p <partition>, --partition=<partition>\nPrint information only about the specified partition(s). Multiple partitions\nare separated by commas.\n\n\n-r, --responding\nIf set only report state information for responding nodes.\n\n\n-R, --list-reasons\nList reasons nodes are in the down, drained, fail or failing state.\nWhen nodes are in these states Slurm supports the inclusion\nof a \"reason\" string by an administrator.\nThis option will display the first 20 characters of the reason\nfield and list of nodes with that reason for all nodes that are,\nby default, down, drained, draining or failing.\nThis option may be used with other node filtering options\n(e.g. -r, -d, -t, -n),\nhowever, combinations of these options that result in a\nlist of nodes that are not down or drained or failing will\nnot produce any output.\nWhen used with -l the output additionally includes\nthe current node state.\n\n\n-s, --summarize\nList only a partition state summary with no node state details.\nThis is ignored if the --format option is specified.\n\n\n-S <sort_list>, --sort=<sort_list>\nSpecification of the order in which records should be reported.\nThis uses the same field specification as the <output_format>.\nMultiple sorts may be performed by listing multiple sort fields\nseparated by commas.  The field specifications may be preceded\nby \"+\" or \"-\" for ascending (default) and descending order\nrespectively.  The partition field specification, \"P\", may be\npreceded by a \"#\" to report partitions in the same order that\nthey appear in Slurm's  configuration file, slurm.conf.\nFor example, a sort value of \"+P,-m\" requests that records\nbe printed in order of increasing partition name and within a\npartition by decreasing memory size.  The default value of sort\nis \"#P,-t\" (partitions ordered as configured then decreasing\nnode state).  If the --Node option is selected, the\ndefault sort value is \"N\" (increasing node name).\n\n\n-t <states> , --states=<states>\nList nodes only having the given state(s).  Multiple states\nmay be comma separated and the comparison is case insensitive.\nPossible values include (case insensitive): ALLOC, ALLOCATED,\nCOMP, COMPLETING, DOWN, DRAIN (for node in DRAINING or DRAINED\nstates), DRAINED, DRAINING, FAIL, FUTURE, FUTR,\nIDLE, MAINT, MIX, MIXED, NO_RESPOND, NPC, PERFCTRS,\nPOWER_DOWN, POWERING_DOWN, POWER_UP, RESV, RESERVED, UNK, and UNKNOWN.\nBy default nodes in the specified state are reported whether\nthey are responding or not.\nThe --dead and --responding options may be\nused to filter nodes by the corresponding flag.\n\n\n-T, --reservation\nOnly display information about Slurm reservations.\n\nNOTE: This option causes sinfo to ignore most other options,\nwhich are focused on partition and node information.\n\n\n--usage\nPrint a brief message listing the sinfo options.\n\n\n-v, --verbose\nProvide detailed event logging through program execution.\n\n\n-V, --version\nPrint version information and exit.\n\n\n \n\nOUTPUT FIELD DESCRIPTIONS\n\n\nAVAIL\nPartition state. Can be either up, down, drain, or inact\n(for INACTIVE). See the partition definition's State parameter in the\nslurm.conf(5) man page for more information.\n\nCPUS\nCount of CPUs (processors) on these nodes.\n\nS:C:T\nCount of sockets (S), cores (C), and threads (T) on these nodes.\n\nSOCKETS\nCount of sockets on these nodes.\n\nCORES\nCount of cores on these nodes.\n\nTHREADS\nCount of threads on these nodes.\n\nGROUPS\nResource allocations in this partition are restricted to the\nnamed groups.  all indicates that all groups may use\nthis partition.\n\nJOB_SIZE\nMinimum and maximum node count that can be allocated to any\nuser job.  A single number indicates the minimum and maximum\nnode count are the same.  infinite is used to identify\npartitions without a maximum node count.\n\nTIMELIMIT\nMaximum time limit for any user job in\ndays-hours:minutes:seconds.  infinite is used to identify\npartitions without a job time limit.\n\nMEMORY\nSize of real memory in megabytes on these nodes.\n\nNODELIST\nNames of nodes associated with this particular configuration.\n\nNODES\nCount of nodes with this particular configuration.\n\nNODES(A/I)\nCount of nodes with this particular configuration by node\nstate in the form \"available/idle\".\n\nNODES(A/I/O/T)\nCount of nodes with this particular configuration by node\nstate in the form \"available/idle/other/total\".\n\nPARTITION\nName of a partition.  Note that the suffix \"*\" identifies the\ndefault partition.\n\nPORT\nLocal TCP port used by slurmd on the node.\n\nROOT\nIs the ability to allocate resources in this partition\nrestricted to user root, yes or no.\n\nOVERSUBSCRIBE\nWhether jobs allocated resources in this partition can/will oversubscribe\nthose compute resources (e.g. CPUs).\nNO indicates resources are never oversubscribed.\nEXCLUSIVE indicates whole nodes are dedicated to jobs\n(equivalent to srun --exclusive option, may be used even\nwith select/cons_res managing individual processors).\nFORCE indicates resources are always available to be oversubscribed.\nYES indicates resource may be oversubscribed, if requested by the job's\nresource allocation.\n\nNOTE: If OverSubscribe is set to FORCE or YES,\nthe OversubScribe value will be appended to the output.\n\nSTATE\nState of the nodes.\nPossible states include: allocated, completing, down,\ndrained, draining, fail, failing, future, idle, maint, mixed,\nperfctrs, power_down, power_up, reserved, and unknown.\nTheir abbreviated forms are: alloc, comp, down, drain, drng,\nfail, failg, futr, idle, maint, mix, npc, pow_dn, pow_up, resv,\nand unk respectively.\n\nNOTE: The suffix \"*\" identifies nodes that are presently\nnot responding.\n\nTMP_DISK\nSize of temporary disk space in megabytes on these nodes.\n\n\n \n\nNODE STATE CODES\n\n\nNode state codes are shortened as required for the field size.\nThese node states may be followed by a special character to identify\nstate flags associated with the node.\nThe following node suffixes and states are used:\n\n\n*\nThe node is presently not responding and will not be allocated\nany new work.  If the node remains non-responsive, it will\nbe placed in the DOWN state (except in the case of\nCOMPLETING, DRAINED, DRAINING,\nFAIL, FAILING nodes).\n\n~\nThe node is presently in a power saving mode (typically\nrunning at reduced frequency).\n\n#\nThe node is presently being powered up or configured.\n\n%\nThe node is presently being powered down.\n\n$\nThe node is currently in a reservation with a flag value of \"maintenance\".\n\n@\nThe node is pending reboot.\n\nALLOCATED\nThe node has been allocated to one or more jobs.\n\nALLOCATED+\nThe node is allocated to one or more active jobs plus\none or more jobs are in the process of COMPLETING.\n\nCOMPLETING\nAll jobs associated with this node are in the process of\nCOMPLETING.  This node state will be removed when\nall of the job's processes have terminated and the Slurm\nepilog program (if any) has terminated. See the Epilog\nparameter description in the slurm.conf(5) man page for\nmore information.\n\nDOWN\nThe node is unavailable for use. Slurm can automatically\nplace nodes in this state if some failure occurs. System\nadministrators may also explicitly place nodes in this state. If\na node resumes normal operation, Slurm can automatically\nreturn it to service. See the ReturnToService\nand SlurmdTimeout parameter descriptions in the\nslurm.conf(5) man page for more information.\n\nDRAINED\nThe node is unavailable for use per system administrator\nrequest.  See the update node command in the\nscontrol(1) man page or the slurm.conf(5) man page\nfor more information.\n\nDRAINING\nThe node is currently executing a job, but will not be allocated\nadditional jobs. The node state will be changed to state\nDRAINED when the last job on it completes. Nodes enter\nthis state per system administrator request. See the update\nnode command in the scontrol(1) man page or the\nslurm.conf(5) man page for more information.\n\nFAIL\nThe node is expected to fail soon and is unavailable for\nuse per system administrator request.\nSee the update node command in the scontrol(1)\nman page or the slurm.conf(5) man page for more information.\n\nFAILING\nThe node is currently executing a job, but is expected to fail\nsoon and is unavailable for use per system administrator request.\nSee the update node command in the scontrol(1)\nman page or the slurm.conf(5) man page for more information.\n\nFUTURE\nThe node is currently not fully configured, but expected to be available at\nsome point in the indefinite future for use.\n\nIDLE\nThe node is not allocated to any jobs and is available for use.\n\nMAINT\nThe node is currently in a reservation with a flag value of \"maintenance\".\n\nREBOOT\nThe node is currently scheduled to be rebooted.\n\nMIXED\nThe node has some of its CPUs ALLOCATED while others are IDLE.\n\nPERFCTRS (NPC)\nNetwork Performance Counters associated with this node are in use, rendering\nthis node as not usable for any other jobs\n\nPOWER_DOWN\nThe node is currently powered down and not capable of running any jobs.\n\nPOWERING_DOWN\nThe node is in the process of powering down and not capable of running any jobs.\n\nPOWER_UP\nThe node is in the process of being powered up.\n\nRESERVED\nThe node is in an advanced reservation and not generally available.\n\nUNKNOWN\nThe Slurm controller has just started and the node's state\nhas not yet been determined.\n\n\n \n\nPERFORMANCE\n\n\nExecuting sinfo sends a remote procedure call to slurmctld. If\nenough calls from sinfo or other Slurm client commands that send remote\nprocedure calls to the slurmctld daemon come in at once, it can result in\na degradation of performance of the slurmctld daemon, possibly resulting\nin a denial of service.\n\n\nDo not run sinfo or other Slurm client commands that send remote procedure\ncalls to slurmctld from loops in shell scripts or other programs. Ensure\nthat programs limit calls to sinfo to the minimum necessary for the\ninformation you are trying to gather.\n\n \n\nENVIRONMENT VARIABLES\n\n\nSome sinfo options may\nbe set via environment variables. These environment variables,\nalong with their corresponding options, are listed below.\nNOTE: Command line options will always override these settings.\n\n\nSINFO_ALL\nSame as -a, --all\n\nSINFO_FEDERATION\nSame as --federation\n\nSINFO_FORMAT\nSame as -o <output_format>, --format=<output_format>\n\nSINFO_LOCAL\nSame as --local\n\nSINFO_PARTITION\nSame as -p <partition>, --partition=<partition>\n\nSINFO_SORT\nSame as -S <sort>, --sort=<sort>\n\nSLURM_CLUSTERS\nSame as --clusters\n\nSLURM_CONF\nThe location of the Slurm configuration file.\n\nSLURM_TIME_FORMAT\nSpecify the format used to report time stamps. A value of standard, the\ndefault value, generates output in the form \"year-month-dateThour:minute:second\".\nA value of relative returns only \"hour:minute:second\" if the current day.\nFor other dates in the current year it prints the \"hour:minute\" preceded by\n\"Tomorr\" (tomorrow), \"Ystday\" (yesterday), the name of the day for the coming\nweek (e.g. \"Mon\", \"Tue\", etc.), otherwise the date (e.g. \"25 Apr\").\nFor other years it returns a date month and year without a time (e.g.\n\"6 Jun 2012\"). All of the time stamps use a 24 hour format.\n\nA valid strftime() format can also be specified. For example, a value of\n\"%a %T\" will report the day of the week and a time stamp (e.g. \"Mon 12:34:56\").\n\n\n \n\nEXAMPLES\n\n\nReport basic node and partition configurations:\n\n\n\n> sinfo\nPARTITION AVAIL TIMELIMIT NODES STATE  NODELIST\nbatch     up     infinite     2 alloc  adev[8-9]\nbatch     up     infinite     6 idle   adev[10-15]\ndebug*    up        30:00     8 idle   adev[0-7]\n\n\n\nReport partition summary information:\n\n\n> sinfo -s\nPARTITION AVAIL TIMELIMIT NODES(A/I/O/T) NODELIST\nbatch     up     infinite 2/6/0/8        adev[8-15]\ndebug*    up        30:00 0/8/0/8        adev[0-7]\n\n\n\nReport more complete information about the partition debug:\n\n\n> sinfo --long --partition=debug\nPARTITION AVAIL TIMELIMIT JOB_SIZE ROOT OVERSUBS GROUPS NODES STATE NODELIST\ndebug*    up        30:00        8 no   no       all        8 idle  dev[0-7]\n\n\nReport only those nodes that are in state DRAINED:\n\n\n> sinfo --states=drained\nPARTITION AVAIL NODES TIMELIMIT STATE  NODELIST\ndebug*    up        2     30:00 drain  adev[6-7]\n\n\n\nReport node-oriented information with details and exact matches:\n\n\n> sinfo -Nel\nNODELIST    NODES PARTITION STATE  CPUS MEMORY TMP_DISK WEIGHT FEATURES REASON\nadev[0-1]       2 debug*    idle      2   3448    38536     16 (null)   (null)\nadev[2,4-7]     5 debug*    idle      2   3384    38536     16 (null)   (null)\nadev3           1 debug*    idle      2   3394    38536     16 (null)   (null)\nadev[8-9]       2 batch     allocated 2    246    82306     16 (null)   (null)\nadev[10-15]     6 batch     idle      2    246    82306     16 (null)   (null)\n\n\n\nReport only down, drained and draining nodes and their reason field:\n\n\n> sinfo -R\nREASON                              NODELIST\nMemory errors                       dev[0,5]\nNot Responding                      dev8\n\n\n\n \n\nCOPYING\n\nCopyright (C) 2002-2007 The Regents of the University of California.\nProduced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).\n\n\nCopyright (C) 2008-2009 Lawrence Livermore National Security.\n\n\nCopyright (C) 2010-2017 SchedMD LLC.\n\n\nThis file is part of Slurm, a resource management program.\nFor details, see <https://slurm.schedmd.com/>.\n\n\nSlurm is free software; you can redistribute it and/or modify it under\nthe terms of the GNU General Public License as published by the Free\nSoftware Foundation; either version 2 of the License, or (at your option)\nany later version.\n\n\nSlurm is distributed in the hope that it will be useful, but WITHOUT ANY\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\nFOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\ndetails.\n\n \n\nSEE ALSO\nscontrol(1), squeue(1),\nslurm_load_ctl_conf (3), slurm_load_jobs (3),\nslurm_load_node (3),\nslurm_load_partitions (3),\nslurm_reconfigure (3), slurm_shutdown (3),\nslurm_update_job (3), slurm_update_node (3),\nslurm_update_partition (3),\nslurm.conf(5)\n\n\n Index\n\nNAME\nSYNOPSIS\nDESCRIPTION\nOPTIONS\nOUTPUT FIELD DESCRIPTIONS\nNODE STATE CODES\nPERFORMANCE\nENVIRONMENT VARIABLES\nEXAMPLES\nCOPYING\nSEE ALSO\n\n\nThis document was created by\nman2html using the manual pages.\nTime: 19:40:53 GMT, August 28, 2020\n\t\t\t \n \n \n \n\n\n\nLegal Notices\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# sinfo\n\n> View information about Slurm nodes and partitions.\n> See also `squeue` and `sbatch`, which are also part of the Slurm workload manager.\n> More information: <https://slurm.schedmd.com/sinfo.html>.\n\n- Show a quick summary overview of the cluster:\n\n`sinfo --summarize`\n\n- View the detailed status of all partitions across the entire cluster:\n\n`sinfo`\n\n- View the detailed status of a specific partition:\n\n`sinfo --partition {{partition_name}}`\n\n- View information about idle nodes:\n\n`sinfo --states {{idle}}`\n\n- Summarise dead nodes:\n\n`sinfo --dead`\n\n- List dead nodes and the reasons why:\n\n`sinfo --list-reasons`\n"
 },
 {
   "command": "fallocate",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# fallocate\n\n> Reserve or deallocate disk space to files.\n> The utility allocates space without zeroing.\n\n- Reserve a file taking up 700MB of disk space:\n\n`fallocate --length {{700M}} {{path/to/file}}`\n\n- Shrink an already allocated file by 200MB:\n\n`fallocate --collapse-range --length {{200M}} {{path/to/file}}`\n\n- Shrink 20MB of space after 100MB in a file:\n\n`fallocate --collapse-range --offset {{100M}} --length {{20M}} {{path/to/file}}`\n"
 },
 {
   "command": "brctl",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nBRCTL(1)\t\t  BSD General Commands Manual\t\t      BRCTL(1)\n\nNAME\n     brctl -- Manage the CloudDocs daemon\n\nSYNOPSIS\n     brctl <command> [command-options and arguments]\n\nDESCRIPTION\n     brctl understands the following commands:\n\n     diagnose [options] [<diagnosis-output-path>]\n\t diagnose and collect logs\n\n\t -M,--collect-mobile-documents[=<container>]  (default: all contain-\n     ers)\n\t -s,--sysdiagnose     Do not collect what's already part of sysdiag-\n     nose\n\t -n,--name=<name>     Change the device name\n\t [<diagnosis-output-path>]\n\t\t\t      Specifies the output path of the diagnosis; -n\n     becomes useless.\n\n     download <path>\n\t download a local copy of the document at this path\n\n     evict <path>\n\t evict the local copy of the document at this path\n\n     log [options] [<command>]\n\n\t -c,--color[={yes,no}]\n\t\t\t      turn on or off color use\n\t -d,--path=<logs-dir> use <logs-dir> instead of default\n\t -H,--home=<home-dir> use this as the ~ prefix, to look for ~/L/\n\t -f,--filter=<predicate>\n\t\t\t      only show lines matching predicate\n\t -m,--multiline[={yes,no}]\n\t\t\t      turn on or off multiple line logging\n\t -n=<number>\t      number of initial lines to display\n\t -p,--page\t      use paging\n\t -w,--wait\t      wait for new logs continuously (syslog -w)\n\t -t,--shorten\t      Shorten UUIDs, paths, etc\n\t -s,--digest\t      Only print digest logs\n\n     dump [options] [<container>]\n\t dump the CloudDocs database\n\n\t -o,--output=<file-path>\n\t\t\t      redirect output to <file-path>\n\t -d,--database-path=<db-path>\n\t\t\t      Use the database at <db-path>\n\t [<container>]\t      the container to be dumped\n\n     monitor [options] <container>\n\t use NSMetadataQuery to monitor the container\n\n\t -S,--scope=<scope>\n\t\t\t      restrict the NSMDQ scope to DOCS, DATA, or BOTH\n\n     versions [options] <path> [ALL|etags...]\n\t list the non-local versions of the document at this path.\n\n\t -a,--all\t      List all non-local versions including those that\n\t\t\t      are locally cached\n\nSEE ALSO\n     bird(8)\n\nMac OS\t\t\t      September 25, 2020\t\t\tMac OS\n",
   "tldr_summary": "# brctl\n\n> Ethernet bridge administration.\n\n- Show a list with information about currently existing ethernet bridges:\n\n`sudo brctl show`\n\n- Create a new ethernet bridge interface:\n\n`sudo brctl add {{bridge_name}}`\n\n- Delete an existing ethernet bridge interface:\n\n`sudo brctl del {{bridge_name}}`\n\n- Add an interface to an existing bridge:\n\n`sudo brctl addif {{bridge_name}} {{interface_name}}`\n\n- Remove an interface from an existing bridge:\n\n`sudo brctl delif {{bridge_name}} {{interface_name}}`\n"
 },
 {
   "command": "ncdu",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ncdu\n\n> Disk usage analyzer with an ncurses interface.\n\n- Analyze the current working directory:\n\n`ncdu`\n\n- Analyze a given directory:\n\n`ncdu {{path/to/directory}}`\n\n- Save results to a file:\n\n`ncdu -o {{path/to/file}}`\n\n- Exclude files that match a pattern, argument can be given multiple times to add more patterns:\n\n`ncdu --exclude '{{*.txt}}'`\n"
 },
 {
   "command": "ncat",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ncat\n\n> Use the normal `cat` functionality over networks.\n\n- Listen for input on the specified port and write it to the specified file:\n\n`ncat -l {{port}} > {{path/to/file}}`\n\n- Accept multiple connections and keep ncat open after they have been closed:\n\n`ncat -lk {{port}}`\n\n- Write output of specified file to the specified host on the specified port:\n\n`ncat {{address}} {{port}} < {{path/to/file}}`\n"
 },
 {
   "command": "extrace",
   "doc_url": "https://github.com/chneukirchen/extrace",
   "doc_text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub - leahneukirchen/extrace: trace exec() calls system-wide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkip to content\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Sign up\n              \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    Why GitHub?\n                    \n\n\n\n\nFeatures →\n\nCode review\nProject management\nIntegrations\nActions\nPackages\nSecurity\nTeam management\nHosting\nMobile\n\n\nCustomer stories →\nSecurity →\n\n\n\n\n\nTeam\n\n\nEnterprise\n\n\n\n\n                    Explore\n                    \n\n\n\n\n\nExplore GitHub →\n\nLearn & contribute\n\nTopics\nCollections\nTrending\nLearning Lab\nOpen source guides\n\nConnect with others\n\nEvents\nCommunity forum\nGitHub Education\nGitHub Stars program\n\n\n\n\n\nMarketplace\n\n\n\n\n                    Pricing\n                    \n\n\n\n\nPlans →\n\nCompare plans\nContact Sales\n\n\nNonprofit →\nEducation →\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        In this repository\n      \n\n        All GitHub\n      \n↵\n\n\n      Jump to\n      ↵\n\n\n\n\n\n\n \n\n\n\n          Sign in\n        \n\n              Sign up\n            \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nleahneukirchen\n\n/\n\nextrace\n\n\n\n\n\n\n\n    Watch\n \n      8\n    \n\n\n\n\n      Star\n\n\n      63\n    \n\n\n\n\n          Fork\n\n\n        4\n      \n\n\n\n\n\n        trace exec() calls system-wide\n      \n\n\n\n            View license\n        \n\n\n\n\n63\n        stars\n \n\n4\n        forks\n \n\n\n\n\n      Star\n\n\n\n\n\n    Watch\n\n\n\n\n\n\n\n\n\nCode\n\n \n\n\n\nIssues\n2\n \n\n\n\nPull requests\n0\n \n\n\n\nActions\n\n \n\n\n\nProjects\n0\n \n\n\n\nSecurity\n\n \n\n\n\nInsights\n\n \n \n\n\n\n\nMore\n\n \n\n\n\n\n                    Code\n \n\n\n                    Issues\n \n\n\n                    Pull requests\n \n\n\n                    Actions\n \n\n\n                    Projects\n \n\n\n                    Security\n \n\n\n                    Insights\n \n\n\n \n\n\n\n\n\n\n\n\n\n\n          Dismiss\n        \nJoin GitHub today\nGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.\nSign up\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nbranch\n\n\n\n8\ntags\n\n\n\n\n    Go to file\n\n\n\n\n\n\n      Code\n      \n \n\n\n\n\n\n\n\n\n  Clone\n\n\n\n\n\n\n            HTTPS\n \n            GitHub CLI\n \n\n\n\n\n\n\n\n\n\n      Use Git or checkout with SVN using the web URL.\n    \n\n\n\n\n\n\n\n\n\n      Work fast with our official CLI.\n      Learn more.\n    \n\n\n\n\n\n\n\n                Open with GitHub Desktop\n \n\n\n\n                Download ZIP\n \n\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching GitHub Desktop\nIf nothing happens, download GitHub Desktop and try again.\nGo back\n\n\nLaunching Xcode\nIf nothing happens, download Xcode and try again.\nGo back\n\n\nLaunching Visual Studio\nIf nothing happens, download the GitHub extension for Visual Studio and try again.\nGo back\n\n\n\n\n\n\n\n\n\nLatest commit\n\n\n\n \n \nGit stats\n\n\n\n\n\n70\ncommits\n\n\n\n\n\n\n\nFiles\n\nPermalink\n\n\n  \n    Failed to load latest commit information.\n\n \n\n\nType\nName\nLatest commit message\nCommit time\n\n\n\n\n\n\nLICENSE\n\n\n \n\n\n \n\n\n\n\n\n\n\nMakefile\n\n\n \n\n\n \n\n\n\n\n\n\n\nNEWS.md\n\n\n \n\n\n \n\n\n\n\n\n\n\nREADME\n\n\n \n\n\n \n\n\n\n\n\n\n\nextrace-bpf\n\n\n \n\n\n \n\n\n\n\n\n\n\nextrace.1\n\n\n \n\n\n \n\n\n\n\n\n\n\nextrace.c\n\n\n \n\n\n \n\n\n\n\n\n\n\npwait.1\n\n\n \n\n\n \n\n\n\n\n\n\n\npwait.c\n\n\n \n\n\n \n\n\n\n\n\n        View code\n      \n\n\n\n\n\n\n\n        README\n      \n\n\nEXTRACE(1)                  General Commands Manual                 EXTRACE(1)\n\nNAME\n     extrace – trace exec() calls system-wide\n\nSYNOPSIS\n     extrace [-deflqtu] [-o file] [-p pid | cmd ...]\n\nDESCRIPTION\n     extrace traces all program executions occurring on a system.\n\n     The options are as follows:\n\n     -d      Print the current working directory of the new process.\n\n     -e      Print environment of process, or ‘-’ if unreadable.\n\n     -f      Generate flat output without indentation.  By default, the line\n             indentation reflects the process hierarchy.\n\n     -l      Resolve full path of the executable.  By default, argv[0] is\n             shown.\n\n     -q      Suppress printing of exec(3) arguments.\n\n     -t      Also display process exit status and duration.\n\n     -u      Also display the user running the process.\n\n     -o file\n             Redirect trace output to file.\n\n     -p pid  Only trace exec(3) calls descendant of pid.\n\n     cmd ...\n             Run cmd ... and only trace descendants of this command.\n\n             By default, all exec(3) calls are traced globally.\n\nEXIT STATUS\n     The extrace utility exits 0 on success, and >0 if an error occurs.\n\nERRORS\n     Check these prerequisites if you see this error:\n\n           binding sk_nl error: Operation not permitted\n\n     extrace requires special permissions to run, either root or the Linux\n     CAP_NET_ADMIN capability.\n\n     extrace only works on Linux kernels with the kernel options\n\n           CONFIG_CONNECTOR=y\n           CONFIG_PROC_EVENTS=y\n\nSEE ALSO\n     fatrace(1), ps(1), pwait(1), strace(1)\n\nAUTHORS\n     Leah Neukirchen <leah@vuxu.org>\n\n     May contain traces of code from Guillaume Thouvenin, Matt Helsley, and\n     Sebastian Krahmer.\n\nBUGS\n     While process tracing is exact, looking up all information is inherently\n     sensitive to race conditions.  In doubt, you can only trust the PID was\n     written correctly.\n\nLICENSE\n     extrace is licensed under the terms of the GPLv2.\n\nVoid Linux                       June 19, 2018                      Void Linux\n\n------------------------------------------------------------------------------\n\nPWAIT(1)                    General Commands Manual                   PWAIT(1)\n\nNAME\n     pwait – wait for processes to terminate\n\nSYNOPSIS\n     pwait [-v] [-c] pid ...\n\nDESCRIPTION\n     pwait waits until each of the given processes has terminated.\n\n     The options are as follows:\n\n     -v      Print the exit status when each process terminates.\n\n     -c      Return 111 if any process exited non-successfully.\n\nEXIT STATUS\n     The pwait utility exits 0 on success, and >0 if an error occurs.\n\n     Invalid pids elicit a warning message but are otherwise ignored.\n\nERRORS\n     Check these prerequisites if you see this error:\n\n           binding sk_nl error: Operation not permitted\n\n     pwait requires special permissions to run, either root or the Linux\n     CAP_NET_ADMIN capability.\n\n     pwait only works on Linux kernels with the kernel options\n\n           CONFIG_CONNECTOR=y\n           CONFIG_PROC_EVENTS=y\n\nSEE ALSO\n     extrace(1), kill(1), pkill(1), ps(1), wait(1)\n\nAUTHORS\n     Leah Neukirchen <leah@vuxu.org>\n\n     Built upon code from FreeBSD pwait written by Jilles Tjoelker.\n\nLICENSE\n     pwait is licensed under the terms of the GPLv2.\n\nVoid Linux                    September 17, 2018                    Void Linux\n\n\n\n\n\n\n\n\nAbout\n\n      trace exec() calls system-wide\n    \nResources\n\n\n\n      Readme\n \nLicense\n\n\n\n        View license\n    \n\n\n\n\n\n\n\n    Releases\n\n\n\n8\ntags\n\n\n\n\n\n\n\n    Packages 0\n\n\n        No packages published \n\n\n\n\n\n\n\n\n\n\n\n\n\n    Contributors 3\n\n\n\n\n\n \n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\nLanguages\n\n\n\n\n\n\n\n\n\n\n\nC\n77.2%\n\n\n\n\n\nRuby\n10.6%\n\n\n\n\n\nRoff\n10.4%\n\n\n\n\n\nMakefile\n1.8%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n© 2020 GitHub, Inc.\nTerms\nPrivacy\nSecurity\nStatus\nHelp\n\n\n\n\n\nContact GitHub\nPricing\nAPI\nTraining\nBlog\nAbout\n\n\n\n\n\n\n\n\n\n\n\n    You can’t perform that action at this time.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou signed in with another tab or window. Reload to refresh your session.\nYou signed out in another tab or window. Reload to refresh your session.\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# extrace\n\n> Trace exec() calls.\n> More information: <https://github.com/chneukirchen/extrace>.\n\n- Trace all program executions occurring on the system:\n\n`sudo extrace`\n\n- Run a command and only trace descendants of this command:\n\n`sudo extrace {{command}}`\n\n- Print the current working directory of each process:\n\n`sudo extrace -d`\n\n- Resolve the full path of each executable:\n\n`sudo extrace -l`\n\n- Display the user running each process:\n\n`sudo extrace -u`\n"
 },
 {
   "command": "ipcalc",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ipcalc\n\n> Perform simple operations and calculations on IP addresses and networks.\n\n- Show information about an address or network with a given subnet mask:\n\n`ipcalc {{1.2.3.4}} {{255.255.255.0}}`\n\n- Show information about an address or network in CIDR notation:\n\n`ipcalc {{1.2.3.4}}/{{24}}`\n\n- Show the broadcast address of an address or network:\n\n`ipcalc -b {{1.2.3.4}}/{{30}}`\n\n- Show the network address of provided IP address and netmask:\n\n`ipcalc -n {{1.2.3.4}}/{{24}}`\n\n- Display geographic information about a given IP address:\n\n`ipcalc -g {{1.2.3.4}}`\n"
 },
 {
   "command": "terminator",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# terminator\n\n> Arrange multiple GNOME terminals in one window.\n\n- Start terminator window:\n\n`terminator`\n\n- Start with a fullscreen window:\n\n`terminator -f`\n\n- Split terminals horizontally:\n\n`Ctrl + Shift + O`\n\n- Split terminals vertically:\n\n`Ctrl + Shift + E`\n\n- Open new tab:\n\n`Ctrl + Shift + T`\n"
 },
 {
   "command": "i7z",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# i7z\n\n> An Intel CPU (only i3, i5 and i7) realtime reporting tool.\n\n- Start i7z (needs to be run in super user mode):\n\n`sudo i7z`\n"
 },
 {
   "command": "etckeeper",
   "doc_url": "http://etckeeper.branchable.com/",
   "doc_text": "\n\n\netckeeper\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\netckeeper\n\n\n\n\n\n\n\n\n\n\n\nEdit\nRecentChanges\nHistory\nPreferences\nBranchable\n\n\n\n\nREADME\nInstall\nNews\nTodo\nForum\n\n\n\netckeeper is a collection of tools to let /etc be stored in a git,\nmercurial, bazaar or darcs repository. This lets you use git to review or\nrevert changes that were made to /etc. Or even push the repository\nelsewhere for backups or cherry-picking configuration changes.\nIt hooks into package managers like apt to automatically commit changes\nmade to /etc during package upgrades. It tracks file metadata that git does\nnot normally support, but that is important for /etc, such as the\npermissions of /etc/shadow.\nIt's quite modular and configurable, while also being simple to use if you\nunderstand the basics of working with version control.\n\n\n\n\n\n\n\n\nLast edited Sat Mar 10 16:32:52 2018\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# etckeeper\n\n> Track system configuration files in git.\n> More information: <http://etckeeper.branchable.com/>.\n\n- Set up a git repo and perform various setup tasks (run from /etc):\n\n`sudo etckeeper init`\n\n- Commit all changes in /etc:\n\n`sudo etckeeper commit {{message}}`\n\n- Run arbitrary git commands:\n\n`sudo etckeeper vcs {{status}}`\n\n- Check if there are uncommitted changes (only returns an exit code):\n\n`sudo etckeeper unclean`\n\n- Destroy existing repo and stop tracking changes:\n\n`sudo etckeeper uninit`\n"
 },
 {
   "command": "macchanger",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# macchanger\n\n> Command-line utility for manipulating network interface MAC addresses.\n\n- View the current and permanent MAC addresses of a interface:\n\n`macchanger --show {{interface}}`\n\n- Set interface to a random MAC:\n\n`macchanger --random {{interface}}`\n\n- Set interface to a specific MAC:\n\n`macchanger --mac {{XX:XX:XX:XX:XX:XX}} {{interface}}`\n\n- Reset interface to its permanent hardware MAC:\n\n`macchanger --permanent {{interface}}`\n"
 },
 {
   "command": "namei",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# namei\n\n> Follows a pathname (which can be a symbolic link) until a terminal point is found (a file/directory/char device etc).\n> This program is useful for finding \"too many levels of symbolic links\" problems.\n\n- Resolve the pathnames specified as the argument parameters:\n\n`namei {{path/to/a}} {{path/to/b}} {{path/to/c}}`\n\n- Display the results in a long-listing format:\n\n`namei --long {{path/to/a}} {{path/to/b}} {{path/to/c}}`\n\n- Show the mode bits of each file type in the style of `ls`:\n\n`namei --modes {{path/to/a}} {{path/to/b}} {{path/to/c}}`\n\n- Show owner and group name of each file:\n\n`namei --owners {{path/to/a}} {{path/to/b}} {{path/to/c}}`\n\n- Don't follow symlinks while resolving:\n\n`namei --nosymlinks {{path/to/a}} {{path/to/b}} {{path/to/c}}`\n"
 },
 {
   "command": "reflector",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# reflector\n\n> Arch script to fetch and sort mirrorlists.\n\n- Get all mirrors, sort for download speed and save them:\n\n`sudo reflector --sort {{rate}} --save {{/etc/pacman.d/mirrorlist}}`\n\n- Only get German HTTPS mirrors:\n\n`reflector --country {{Germany}} --protocol {{https}}`\n\n- Only get the 10 recently sync'd mirrors:\n\n`reflector --latest {{10}}`\n"
 },
 {
   "command": "ports",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# ports\n\n> Update/list the ports tree on a CRUX system.\n\n- Update the ports tree:\n\n`ports -u`\n\n- List the ports in the current tree:\n\n`ports -l`\n\n- Check the differences between installed packages and the ports tree:\n\n`ports -d`\n"
 },
 {
   "command": "lvs",
   "doc_url": "https://www.man7.org/linux/man-pages/man8/lvs.8.html",
   "doc_text": "\n\n\n\n\nlvs(8) - Linux manual page\n\n\n\n\n\n\n\n\n\nman7.org > Linux > man-pages\n\n\n\nLinux/UNIX system programming training\n\n\n\n\n\n\nlvs(8) — Linux manual page\n\n\n\n\nNAME | SYNOPSIS | DESCRIPTION | USAGE | OPTIONS | VARIABLES | ENVIRONMENT VARIABLES | NOTES | SEE ALSO | COLOPHON\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nLVS(8)                     System Manager's Manual                    LVS(8)\n\nNAME          top\n       lvs - Display information about logical volumes\n\nSYNOPSIS          top\n       lvs\n           [ option_args ]\n           [ position_args ]\n\nDESCRIPTION          top\n       lvs produces formatted output about LVs.\n\nUSAGE          top\n       lvs\n           [ -H|--history ]\n           [ -a|--all ]\n           [ -o|--options String ]\n           [ -S|--select String ]\n           [ -O|--sort String ]\n           [    --segments ]\n           [    --aligned ]\n           [    --binary ]\n           [    --configreport log|vg|lv|pv|pvseg|seg ]\n           [    --foreign ]\n           [    --ignorelockingfailure ]\n           [    --logonly ]\n           [    --nameprefixes ]\n           [    --noheadings ]\n           [    --nosuffix ]\n           [    --readonly ]\n           [    --reportformat basic|json ]\n           [    --rows ]\n           [    --separator String ]\n           [    --shared ]\n           [    --unbuffered ]\n           [    --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E ]\n           [    --unquoted ]\n           [ COMMON_OPTIONS ]\n           [ VG|LV|Tag ... ]\n\n       Common options for lvm:\n           [ -d|--debug ]\n           [ -h|--help ]\n           [ -q|--quiet ]\n           [ -t|--test ]\n           [ -v|--verbose ]\n           [ -y|--yes ]\n           [    --commandprofile String ]\n           [    --config String ]\n           [    --driverloaded y|n ]\n           [    --lockopt String ]\n           [    --longhelp ]\n           [    --nolocking ]\n           [    --profile String ]\n           [    --version ]\n\nOPTIONS          top\n       --aligned\n              Use with --separator to align the output columns\n\n       -a|--all\n              Show information about internal LVs.  These are components of\n              normal LVs, such as mirrors, which are not independently\n              accessible, e.g. not mountable.\n\n       --binary\n              Use binary values \"0\" or \"1\" instead of descriptive literal\n              values for columns that have exactly two valid values to\n              report (not counting the \"unknown\" value which denotes that\n              the value could not be determined).\n\n       --commandprofile String\n              The command profile to use for command configuration.  See\n              lvm.conf(5) for more information about profiles.\n\n       --config String\n              Config settings for the command. These override lvm.conf\n              settings.  The String arg uses the same format as lvm.conf, or\n              may use section/field syntax.  See lvm.conf(5) for more\n              information about config.\n\n       --configreport log|vg|lv|pv|pvseg|seg\n              See lvmreport(7).\n\n       -d|--debug ...\n              Set debug level. Repeat from 1 to 6 times to increase the\n              detail of messages sent to the log file and/or syslog (if\n              configured).\n\n       --driverloaded y|n\n              If set to no, the command will not attempt to use device-\n              mapper.  For testing and debugging.\n\n       --foreign\n              Report/display foreign VGs that would otherwise be skipped.\n              See lvmsystemid(7) for more information about foreign VGs.\n\n       -h|--help\n              Display help text.\n\n       -H|--history\n              Include historical LVs in the output.  (This has no effect\n              unless LVs were removed while lvm.conf\n              metadata/record_lvs_history was enabled.\n\n       --ignorelockingfailure\n              Allows a command to continue with read-only metadata\n              operations after locking failures.\n\n       --lockopt String\n              Used to pass options for special cases to lvmlockd.  See\n              lvmlockd(8) for more information.\n\n       --logonly\n              Suppress command report and display only log report.\n\n       --longhelp\n              Display long help text.\n\n       --nameprefixes\n              Add an \"LVM2_\" prefix plus the field name to the output.\n              Useful with --noheadings to produce a list of field=value\n              pairs that can be used to set environment variables (for\n              example, in udev rules).\n\n       --noheadings\n              Suppress the headings line that is normally the first line of\n              output.  Useful if grepping the output.\n\n       --nolocking\n              Disable locking.\n\n       --nosuffix\n              Suppress the suffix on output sizes. Use with --units (except\n              h and H) if processing the output.\n\n       -o|--options String\n              Comma-separated, ordered list of fields to display in columns.\n              String arg syntax is: [+|-|#]Field1[,Field2 ...]  The prefix +\n              will append the specified fields to the default fields, - will\n              remove the specified fields from the default fields, and #\n              will compact specified fields (removing them when empty for\n              all rows.)  Use -o help to view the list of all available\n              fields.  Use separate lists of fields to add, remove or\n              compact by repeating the -o option: -o+field1,field2 -o-\n              field3,field4 -o#field5.  These lists are evaluated from left\n              to right.  Use field name lv_all to view all LV fields, vg_all\n              all VG fields, pv_all all PV fields, pvseg_all all PV segment\n              fields, seg_all all LV segment fields, and pvseg_all all PV\n              segment columns.  See the lvm.conf report section for more\n              config options.  See lvmreport(7) for more information about\n              reporting.\n\n       --profile String\n              An alias for --commandprofile or --metadataprofile, depending\n              on the command.\n\n       -q|--quiet ...\n              Suppress output and log messages. Overrides --debug and\n              --verbose.  Repeat once to also suppress any prompts with\n              answer 'no'.\n\n       --readonly\n              Run the command in a special read-only mode which will read\n              on-disk metadata without needing to take any locks. This can\n              be used to peek inside metadata used by a virtual machine\n              image while the virtual machine is running. No attempt will be\n              made to communicate with the device-mapper kernel driver, so\n              this option is unable to report whether or not LVs are\n              actually in use.\n\n       --reportformat basic|json\n              Overrides current output format for reports which is defined\n              globally by the report/output_format setting in lvm.conf.\n              basic is the original format with columns and rows.  If there\n              is more than one report per command, each report is prefixed\n              with the report name for identification. json produces report\n              output in JSON format. See lvmreport(7) for more information.\n\n       --rows\n              Output columns as rows.\n\n       --segments\n              Use default columns that emphasize segment information.\n\n       -S|--select String\n              Select objects for processing and reporting based on specified\n              criteria.  The criteria syntax is described by --select help\n              and lvmreport(7).  For reporting commands, one row is\n              displayed for each object matching the criteria.  See\n              --options help for selectable object fields.  Rows can be\n              displayed with an additional \"selected\" field (-o selected)\n              showing 1 if the row matches the selection and 0 otherwise.\n              For non-reporting commands which process LVM entities, the\n              selection is used to choose items to process.\n\n       --separator String\n              String to use to separate each column. Useful if grepping the\n              output.\n\n       --shared\n              Report/display shared VGs that would otherwise be skipped when\n              lvmlockd is not being used on the host.  See lvmlockd(8) for\n              more information about shared VGs.\n\n       -O|--sort String\n              Comma-separated ordered list of columns to sort by. Replaces\n              the default selection. Precede any column with - for a reverse\n              sort on that column.\n\n       -t|--test\n              Run in test mode. Commands will not update metadata.  This is\n              implemented by disabling all metadata writing but nevertheless\n              returning success to the calling function. This may lead to\n              unusual error messages in multi-stage operations if a tool\n              relies on reading back metadata it believes has changed but\n              hasn't.\n\n       --unbuffered\n              Produce output immediately without sorting or aligning the\n              columns properly.\n\n       --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E\n              All sizes are output in these units: human-(r)eadable with '<'\n              rounding indicator, (h)uman-readable, (b)ytes, (s)ectors,\n              (k)ilobytes, (m)egabytes, (g)igabytes, (t)erabytes,\n              (p)etabytes, (e)xabytes.  Capitalise to use multiples of 1000\n              (S.I.) instead of 1024.  Custom units can be specified, e.g.\n              --units 3M.\n\n       --unquoted\n              When used with --nameprefixes, output values in the\n              field=value pairs are not quoted.\n\n       -v|--verbose ...\n              Set verbose level. Repeat from 1 to 4 times to increase the\n              detail of messages sent to stdout and stderr.\n\n       --version\n              Display version information.\n\n       -y|--yes\n              Do not prompt for confirmation interactively but always assume\n              the answer yes. Use with extreme caution.  (For automatic no,\n              see -qq.)\n\nVARIABLES          top\n       VG\n              Volume Group name.  See lvm(8) for valid names.\n\n       LV\n              Logical Volume name.  See lvm(8) for valid names.  An LV\n              positional arg generally includes the VG name and LV name,\n              e.g. VG/LV.\n\n       Tag\n              Tag name.  See lvm(8) for information about tag names and\n              using tags in place of a VG, LV or PV.\n\n       String\n              See the option description for information about the string\n              content.\n\n       Size[UNIT]\n              Size is an input number that accepts an optional unit.  Input\n              units are always treated as base two values, regardless of\n              capitalization, e.g. 'k' and 'K' both refer to 1024.  The\n              default input unit is specified by letter, followed by |UNIT.\n              UNIT represents other possible input units: bBsSkKmMgGtTpPeE.\n              b|B is bytes, s|S is sectors of 512 bytes, k|K is kilobytes,\n              m|M is megabytes, g|G is gigabytes, t|T is terabytes, p|P is\n              petabytes, e|E is exabytes.  (This should not be confused with\n              the output control --units, where capital letters mean\n              multiple of 1000.)\n\nENVIRONMENT VARIABLES          top\n       See lvm(8) for information about environment variables used by lvm.\n       For example, LVM_VG_NAME can generally be substituted for a required\n       VG parameter.\n\nNOTES          top\n       The lv_attr bits are:\n\n       1  Volume type: (C)ache, (m)irrored, (M)irrored without initial sync,\n          (o)rigin, (O)rigin with merging snapshot, (r)aid, (R)aid without\n          initial sync, (s)napshot, merging (S)napshot, (p)vmove, (v)irtual,\n          mirror or raid (i)mage, mirror or raid (I)mage out-of-sync, mirror\n          (l)og device, under (c)onversion, thin (V)olume, (t)hin pool,\n          (T)hin pool data, v(d)o pool, v(D)o pool data, raid or pool\n          m(e)tadata or pool metadata spare.\n\n       2  Permissions: (w)riteable, (r)ead-only, (R)ead-only activation of\n          non-read-only volume\n\n       3  Allocation policy:  (a)nywhere, (c)ontiguous, (i)nherited,\n          c(l)ing, (n)ormal This is capitalised if the volume is currently\n          locked against allocation changes, for example during pvmove(8).\n\n       4  fixed (m)inor\n\n       5  State: (a)ctive, (h)istorical, (s)uspended, (I)nvalid snapshot,\n          invalid (S)uspended snapshot, snapshot (m)erge failed, suspended\n          snapshot (M)erge failed, mapped (d)evice present without tables,\n          mapped device present with (i)nactive table, thin-pool (c)heck\n          needed, suspended thin-pool (C)heck needed, (X) unknown\n\n       6  device (o)pen, (X) unknown\n\n       7  Target type: (C)ache, (m)irror, (r)aid, (s)napshot, (t)hin,\n          (u)nknown, (v)irtual.  This groups logical volumes related to the\n          same kernel target together.  So, for example, mirror images,\n          mirror logs as well as mirrors themselves appear as (m) if they\n          use the original device-mapper mirror kernel driver; whereas the\n          raid equivalents using the md raid kernel driver all appear as\n          (r).  Snapshots using the original device-mapper driver appear as\n          (s); whereas snapshots of thin volumes using the new thin\n          provisioning driver appear as (t).\n\n       8  Newly-allocated data blocks are overwritten with blocks of\n          (z)eroes before use.\n\n       9  Volume Health, where there are currently three groups of\n          attributes identified:\n\n          Common ones for all Logical Volumes: (p)artial, (X) unknown.\n          (p)artial signifies that one or more of the Physical Volumes this\n          Logical Volume uses is missing from the system. (X) unknown\n          signifies the status is unknown.\n\n          Related to RAID Logical Volumes: (r)efresh needed, (m)ismatches\n          exist, (w)ritemostly.\n          (r)efresh signifies that one or more of the Physical Volumes this\n          RAID Logical Volume uses had suffered a write error. The write\n          error could be due to a temporary failure of that Physical Volume\n          or an indication that it is failing.  The device should be\n          refreshed or replaced. (m)ismatches signifies that the RAID\n          logical volume has portions of the array that are not coherent.\n          Inconsistencies are detected by initiating a \"check\" on a RAID\n          logical volume.  (The scrubbing operations, \"check\" and \"repair\",\n          can be performed on a RAID logical volume via the 'lvchange'\n          command.)  (w)ritemostly signifies the devices in a RAID 1 logical\n          volume that have been marked write-mostly.  Re(s)haping signifies\n          a RAID Logical Volume is either undergoing a stripe\n          addition/removal, a stripe size or RAID algorithm change.\n          (R)emove after reshape signifies freed striped raid images to be\n          removed.\n\n          Related to Thin pool Logical Volumes: (F)ailed, out of (D)ata\n          space, (M)etadata read only.\n          (F)ailed is set if thin pool encounters serious failures and hence\n          no further I/O is permitted at all. The out of (D)ata space is set\n          if thin pool has run out of data space. (M)etadata read only\n          signifies that thin pool encounters certain types of failures but\n          it's still possible to do reads at least, but no metadata changes\n          are allowed.\n\n          Related to Thin Logical Volumes: (F)ailed.\n          (F)ailed is set when related thin pool enters Failed state and no\n          further I/O is permitted at all.\n\n          Related to writecache logical volumes: (E)rror.\n          (E)rror is set dm-writecache reports an error.\n\n       10 s(k)ip activation: this volume is flagged to be skipped during\n          activation.\n\nSEE ALSO          top\n       lvm(8) lvm.conf(5) lvmconfig(8)\n\n       pvchange(8) pvck(8) pvcreate(8) pvdisplay(8) pvmove(8) pvremove(8)\n       pvresize(8) pvs(8) pvscan(8)\n\n       vgcfgbackup(8) vgcfgrestore(8) vgchange(8) vgck(8) vgcreate(8)\n       vgconvert(8) vgdisplay(8) vgexport(8) vgextend(8) vgimport(8)\n       vgimportclone(8) vgmerge(8) vgmknodes(8) vgreduce(8) vgremove(8)\n       vgrename(8) vgs(8) vgscan(8) vgsplit(8)\n\n       lvcreate(8) lvchange(8) lvconvert(8) lvdisplay(8) lvextend(8)\n       lvreduce(8) lvremove(8) lvrename(8) lvresize(8) lvs(8) lvscan(8)\n\n       lvm-fullreport(8) lvm-lvpoll(8) lvm2-activation-generator(8)\n       blkdeactivate(8) lvmdump(8)\n\n       dmeventd(8) lvmpolld(8) lvmlockd(8) lvmlockctl(8) cmirrord(8)\n       lvmdbusd(8)\n\n       lvmsystemid(7) lvmreport(7) lvmraid(7) lvmthin(7) lvmcache(7)\n\nCOLOPHON          top\n       This page is part of the lvm2 (Logical Volume Manager 2) project.\n       Information about the project can be found at \n       â¨http://www.sourceware.org/lvm2/â©.  If you have a bug report for this\n       manual page, see â¨https://github.com/lvmteam/lvm2/issuesâ©.  This page\n       was obtained from the tarball\n       https://github.com/lvmteam/lvm2/archive/v2_03_10.tar.gz fetched from\n       â¨https://github.com/lvmteam/lvm2/releasesâ© on 2020-08-13.  If you\n       discover any rendering problems in this HTML version of the page, or\n       you believe there is a better or more up-to-date source for the page,\n       or you have corrections or improvements to the information in this\n       COLOPHON (which is not part of the original manual page), send a mail\n       to man-pages@man7.org\n\nRed Hat, Inc.         LVM TOOLS 2.03.10(2) (2020-08-09)               LVS(8)\n\n\nPages that refer to this page: \n    lvmcache(7),  \n    lvmreport(7),  \n    lvmthin(7),  \n    lvmvdo(7),  \n    fullreport(8),  \n    lvchange(8),  \n    lvconvert(8),  \n    lvcreate(8),  \n    lvdisplay(8),  \n    lvextend(8),  \n    lvm(8),  \n    lvm-config(8),  \n    lvmconfig(8),  \n    lvmdiskscan(8),  \n    lvm-dumpconfig(8),  \n    lvm-fullreport(8),  \n    lvm-lvpoll(8),  \n    lvpoll(8),  \n    lvreduce(8),  \n    lvremove(8),  \n    lvrename(8),  \n    lvresize(8),  \n    lvs(8),  \n    lvscan(8),  \n    pvchange(8),  \n    pvck(8),  \n    pvcreate(8),  \n    pvdisplay(8),  \n    pvmove(8),  \n    pvremove(8),  \n    pvresize(8),  \n    pvs(8),  \n    pvscan(8),  \n    vgcfgbackup(8),  \n    vgcfgrestore(8),  \n    vgchange(8),  \n    vgck(8),  \n    vgconvert(8),  \n    vgcreate(8),  \n    vgdisplay(8),  \n    vgexport(8),  \n    vgextend(8),  \n    vgimport(8),  \n    vgimportclone(8),  \n    vgmerge(8),  \n    vgmknodes(8),  \n    vgreduce(8),  \n    vgremove(8),  \n    vgrename(8),  \n    vgs(8),  \n    vgscan(8),  \n    vgsplit(8)\n\n\n\n\n\n\n\n\n            HTML rendering created 2020-08-13\n            by Michael Kerrisk, \n            author of \n            The Linux Programming Interface, \n            maintainer of the \n            Linux man-pages project.\n        \n\n            For details of in-depth\n            Linux/UNIX system programming training courses\n            that I teach, look here.\n        \n\n            Hosting by jambit GmbH.\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# lvs\n\n> Display information about LVM logical volumes.\n> More information: <https://www.man7.org/linux/man-pages/man8/lvs.8.html>.\n\n- Display information about logical volumes:\n\n`lvs`\n\n- Display all logical volumes:\n\n`lvs -a`\n\n- Change default display to show more details:\n\n`lvs -v`\n\n- Display only specific fields:\n\n`lvs -o {{field_name_1}},{{field_name_2}}`\n\n- Append field to default display:\n\n`lvs -o +{{field_name}}`\n\n- Suppress heading line:\n\n`lvs --noheadings`\n\n- Use a separator to separate fields:\n\n`lvs --separator {{=}}`\n"
 },
 {
   "command": "reset",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "tput(1) \t\t\t\t\t\t\t       tput(1)\n\n\n\nNAME\n       tput, reset - initialize a terminal or query terminfo database\n\nSYNOPSIS\n       tput [-Ttype] capname [parms ... ]\n       tput [-Ttype] init\n       tput [-Ttype] reset\n       tput [-Ttype] longname\n       tput -S\t<<\n       tput -V\n\nDESCRIPTION\n       The  tput utility uses the terminfo database to make the values of ter-\n       minal-dependent capabilities and information  available\tto  the  shell\n       (see  sh(1)),  to  initialize or reset the terminal, or return the long\n       name of the requested terminal type.  The result depends upon the capa-\n       bility's type:\n\n\t      string\n\t\t   tput writes the string to the standard output.  No trailing\n\t\t   newline is supplied.\n\n\t      integer\n\t\t   tput writes the decimal value to the standard output,  with\n\t\t   a trailing newline.\n\n\t      boolean\n\t\t   tput  simply sets the exit code (0 for TRUE if the terminal\n\t\t   has the capability, 1 for FALSE if it does not), and writes\n\t\t   nothing to the standard output.\n\n       Before  using  a value returned on the standard output, the application\n       should test the exit code (e.g., $?, see sh(1)) to be  sure  it\tis  0.\n       (See  the EXIT CODES and DIAGNOSTICS sections.)\tFor a complete list of\n       capabilities and the capname associated with each, see terminfo(5).\n\n       -Ttype indicates the type of terminal.  Normally this option is\tunnec-\n\t      essary,  because the default is taken from the environment vari-\n\t      able TERM.  If -T is specified, then the shell  variables  LINES\n\t      and COLUMNS will be ignored,and the operating system will not be\n\t      queried for the actual screen size.\n\n       capname\n\t      indicates the capability from the terminfo database.  When term-\n\t      cap  support is compiled in, the termcap name for the capability\n\t      is also accepted.\n\n       parms  If the capability is a string that takes parameters,  the  argu-\n\t      ments parms will be instantiated into the string.\n\n\t      Most  parameters\tare numbers.  Only a few terminfo capabilities\n\t      require string parameters; tput uses a table to decide which  to\n\t      pass  as\tstrings.  Normally tput uses tparm (3X) to perform the\n\t      substitution.  If no parameters are given  for  the  capability,\n\t      tput writes the string without performing the substitution.\n\n       -S     allows  more  than  one  capability per invocation of tput.  The\n\t      capabilities must be passed to  tput  from  the  standard  input\n\t      instead  of  from the command line (see example).  Only one cap-\n\t      name is allowed per line.  The -S option changes the meaning  of\n\t      the  0  and  1 boolean and string exit codes (see the EXIT CODES\n\t      section).\n\n\t      Again, tput uses a table and the presence of parameters  in  its\n\t      input  to decide whether to use tparm (3X), and how to interpret\n\t      the parameters.\n\n       -V     reports the version of ncurses which was used in\tthis  program,\n\t      and exits.\n\n       init   If  the terminfo database is present and an entry for the user's\n\t      terminal exists (see -Ttype, above), the following will occur:\n\n\t      (1)    if present, the terminal's initialization strings will be\n\t\t     output as detailed in the terminfo(5) section on Tabs and\n\t\t     Initialization,\n\n\t      (2)    any delays (e.g., newline) specified in the entry will be\n\t\t     set in the tty driver,\n\n\t      (3)    tabs  expansion will be turned on or off according to the\n\t\t     specification in the entry, and\n\n\t      (4)    if tabs are not  expanded,  standard  tabs  will  be  set\n\t\t     (every 8 spaces).\n\n\t      If  an  entry does not contain the information needed for any of\n\t      the four\tabove  activities,  that  activity  will  silently  be\n\t      skipped.\n\n       reset  Instead  of  putting  out initialization strings, the terminal's\n\t      reset strings will be output if present (rs1, rs2, rs3, rf).  If\n\t      the  reset  strings  are not present, but initialization strings\n\t      are, the initialization  strings\twill  be  output.   Otherwise,\n\t      reset acts identically to init.\n\n       longname\n\t      If  the terminfo database is present and an entry for the user's\n\t      terminal exists (see -Ttype above), then the long  name  of  the\n\t      terminal will be put out.  The long name is the last name in the\n\t      first line of the terminal's description in the  terminfo  data-\n\t      base [see term(5)].\n\n       If  tput  is invoked by a link named reset, this has the same effect as\n       tput reset.  See tset for comparison, which has similar behavior.\n\nEXAMPLES\n       tput init\n\t    Initialize the terminal according to the type of terminal  in  the\n\t    environmental  variable  TERM.  This command should be included in\n\t    everyone's .profile after the environmental variable TERM has been\n\t    exported, as illustrated on the profile(5) manual page.\n\n       tput -T5620 reset\n\t    Reset  an  AT&T  5620 terminal, overriding the type of terminal in\n\t    the environmental variable TERM.\n\n       tput cup 0 0\n\t    Send the sequence to move the cursor to row 0, column 0 (the upper\n\t    left  corner  of  the  screen,  usually known as the \"home\" cursor\n\t    position).\n\n       tput clear\n\t    Echo the clear-screen sequence for the current terminal.\n\n       tput cols\n\t    Print the number of columns for the current terminal.\n\n       tput -T450 cols\n\t    Print the number of columns for the 450 terminal.\n\n       bold=`tput smso` offbold=`@TPUT@ rmso`\n\t    Set the shell variables bold, to begin  stand-out  mode  sequence,\n\t    and offbold, to end standout mode sequence, for the current termi-\n\t    nal.  This might be followed by a prompt: echo \"${bold}Please type\n\t    in your name: ${offbold}\\c\"\n\n       tput hc\n\t    Set  exit  code to indicate if the current terminal is a hard copy\n\t    terminal.\n\n       tput cup 23 4\n\t    Send the sequence to move the cursor to row 23, column 4.\n\n       tput cup\n\t    Send the terminfo string for cursor-movement, with\tno  parameters\n\t    substituted.\n\n       tput longname\n\t    Print  the\tlong  name  from the terminfo database for the type of\n\t    terminal specified in the environmental variable TERM.\n\n\t    tput -S <<!\n\t    > clear\n\t    > cup 10 10\n\t    > bold\n\t    > !\n\n\t    This example shows tput processing\tseveral  capabilities  in  one\n\t    invocation.   It  clears  the screen, moves the cursor to position\n\t    10, 10 and turns on bold (extra bright) mode.  The list is\ttermi-\n\t    nated by an exclamation mark (!) on a line by itself.\n\nFILES\n       /usr/share/terminfo\n\t      compiled terminal description database\n\n       /usr/share/tabset/*\n\t      tab  settings  for some terminals, in a format appropriate to be\n\t      output to the terminal (escape sequences that  set  margins  and\n\t      tabs);  for  more information, see the \"Tabs and Initialization\"\n\t      section of terminfo(5)\n\nEXIT CODES\n       If the -S option is used, tput checks for errors from each line, and if\n       any  errors  are  found, will set the exit code to 4 plus the number of\n       lines with errors.  If no errors are found, the exit  code  is  0.   No\n       indication  of which line failed can be given so exit code 1 will never\n       appear.\tExit codes 2, 3, and 4 retain their usual interpretation.   If\n       the  -S\toption\tis not used, the exit code depends on the type of cap-\n       name:\n\n\t    boolean\n\t\t   a value of 0 is set for TRUE and 1 for FALSE.\n\n\t    string a value of 0 is set if the capname is defined for this ter-\n\t\t   minal  type\t(the  value of capname is returned on standard\n\t\t   output); a value of 1 is set if capname is not defined  for\n\t\t   this terminal type (nothing is written to standard output).\n\n\t    integer\n\t\t   a value of 0 is always  set,  whether  or  not  capname  is\n\t\t   defined for this terminal type.  To determine if capname is\n\t\t   defined for this terminal type,  the  user  must  test  the\n\t\t   value written to standard output.  A value of -1 means that\n\t\t   capname is not defined for this terminal type.\n\n\t    other  reset or init may fail to find their respective files.   In\n\t\t   that case, the exit code is set to 4 + errno.\n\n       Any other exit code indicates an error; see the DIAGNOSTICS section.\n\nDIAGNOSTICS\n       tput  prints  the  following  error messages and sets the corresponding\n       exit codes.\n\n\n       exit code   error message\n       ---------------------------------------------------------------------\n       0\t   (capname is a numeric variable that is not specified  in\n\t\t   the\tterminfo(5)  database  for this terminal type, e.g.\n\t\t   tput -T450 lines and @TPUT@ -T2621 xmc)\n       1\t   no error message is printed, see the EXIT CODES section.\n       2\t   usage error\n       3\t   unknown terminal type or no terminfo database\n       4\t   unknown terminfo capability capname\n       >4\t   error occurred in -S\n       ---------------------------------------------------------------------\n\nPORTABILITY\n       The longname and -S options, and  the  parameter-substitution  features\n       used in the cup example, are not supported in BSD curses or in AT&T/USL\n       curses before SVr4.\n\n       X/Open documents only the operands for clear, init and reset.  In  this\n       implementation,\tclear is part of the capname support.  Other implemen-\n       tations of tput on SVr4-based systems such as Solaris, IRIX64 and  HPUX\n       as well as others such as AIX and Tru64 provide support for capname op-\n       erands.\tA few platforms such as FreeBSD and NetBSD  recognize  termcap\n       names  rather  than  terminfo capability names in their respective tput\n       commands.\n\nSEE ALSO\n       clear(1), stty(1), tabs(1), terminfo(5).\n\n       This describes ncurses version 5.7 (patch 20081102).\n\n\n\n\t\t\t\t\t\t\t\t       tput(1)\n",
   "tldr_summary": "# reset\n\n> Reinitialises the current terminal. Clears the entire terminal screen.\n\n- Reinitialise the current terminal:\n\n`reset`\n\n- Display the terminal type instead:\n\n`reset -q`\n"
 },
 {
   "command": "lspci",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# lspci\n\n> List all PCI devices.\n\n- Show a brief list of devices:\n\n`lspci`\n\n- Display additional info:\n\n`lspci -v`\n\n- Display drivers and modules handling each device:\n\n`lspci -k`\n\n- Show a specific device:\n\n`lspci -s {{00:18.3}}`\n\n- Dump info in a readable form:\n\n`lspci -vm`\n"
 },
 {
   "command": "readelf",
   "doc_url": "http://man7.org/linux/man-pages/man1/readelf.1.html",
   "doc_text": "\n\n\n\n\nreadelf(1) - Linux manual page\n\n\n\n\n\n\n\n\n\nman7.org > Linux > man-pages\n\n\n\nLinux/UNIX system programming training\n\n\n\n\n\n\nreadelf(1) — Linux manual page\n\n\n\n\nNAME | SYNOPSIS | DESCRIPTION | OPTIONS | SEE ALSO | COPYRIGHT | COLOPHON\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\nREADELF(1)                  GNU Development Tools                 READELF(1)\n\nNAME          top\n       readelf - display information about ELF files\n\nSYNOPSIS          top\n       readelf [-a|--all]\n               [-h|--file-header]\n               [-l|--program-headers|--segments]\n               [-S|--section-headers|--sections]\n               [-g|--section-groups]\n               [-t|--section-details]\n               [-e|--headers]\n               [-s|--syms|--symbols]\n               [--dyn-syms]\n               [-n|--notes]\n               [-r|--relocs]\n               [-u|--unwind]\n               [-d|--dynamic]\n               [-V|--version-info]\n               [-A|--arch-specific]\n               [-D|--use-dynamic]\n               [-L|--lint|--enable-checks]\n               [-x <number or name>|--hex-dump=<number or name>]\n               [-p <number or name>|--string-dump=<number or name>]\n               [-R <number or name>|--relocated-dump=<number or name>]\n               [-z|--decompress]\n               [-c|--archive-index]\n               [-w[lLiaprmfFsoORtUuTgAckK]|\n                --debug-dump[=rawline,=decodedline,=info,=abbrev,=pubnames,=aranges,=macro,=frames,=frames-interp,=str,=str-offsets,=loc,=Ranges,=pubtypes,=trace_info,=trace_abbrev,=trace_aranges,=gdb_index,=addr,=cu_index,=links,=follow-links]]\n               [--dwarf-depth=n]\n               [--dwarf-start=n]\n               [--ctf=section]\n               [--ctf-parent=section]\n               [--ctf-symbols=section]\n               [--ctf-strings=section]\n               [-I|--histogram]\n               [-v|--version]\n               [-W|--wide]\n               [-T|--silent-truncation]\n               [-H|--help]\n               elffile...\n\nDESCRIPTION          top\n       readelf displays information about one or more ELF format object\n       files.  The options control what particular information to display.\n\n       elffile... are the object files to be examined.  32-bit and 64-bit\n       ELF files are supported, as are archives containing ELF files.\n\n       This program performs a similar function to objdump but it goes into\n       more detail and it exists independently of the BFD library, so if\n       there is a bug in BFD then readelf will not be affected.\n\nOPTIONS          top\n       The long and short forms of options, shown here as alternatives, are\n       equivalent.  At least one option besides -v or -H must be given.\n\n       -a\n       --all\n           Equivalent to specifying --file-header, --program-headers,\n           --sections, --symbols, --relocs, --dynamic, --notes,\n           --version-info, --arch-specific, --unwind, --section-groups and\n           --histogram.\n\n           Note - this option does not enable --use-dynamic itself, so if\n           that option is not present on the command line then dynamic\n           symbols and dynamic relocs will not be displayed.\n\n       -h\n       --file-header\n           Displays the information contained in the ELF header at the start\n           of the file.\n\n       -l\n       --program-headers\n       --segments\n           Displays the information contained in the file's segment headers,\n           if it has any.\n\n       -S\n       --sections\n       --section-headers\n           Displays the information contained in the file's section headers,\n           if it has any.\n\n       -g\n       --section-groups\n           Displays the information contained in the file's section groups,\n           if it has any.\n\n       -t\n       --section-details\n           Displays the detailed section information. Implies -S.\n\n       -s\n       --symbols\n       --syms\n           Displays the entries in symbol table section of the file, if it\n           has one.  If a symbol has version information associated with it\n           then this is displayed as well.  The version string is displayed\n           as a suffix to the symbol name, preceeded by an @ character.  For\n           example foo@VER_1.  If the version is the default version to be\n           used when resolving unversioned references to the symbol then it\n           is displayed as a suffix preceeded by two @ characters.  For\n           example foo@@VER_2.\n\n       --dyn-syms\n           Displays the entries in dynamic symbol table section of the file,\n           if it has one.  The output format is the same as the format used\n           by the --syms option.\n\n       -e\n       --headers\n           Display all the headers in the file.  Equivalent to -h -l -S.\n\n       -n\n       --notes\n           Displays the contents of the NOTE segments and/or sections, if\n           any.\n\n       -r\n       --relocs\n           Displays the contents of the file's relocation section, if it has\n           one.\n\n       -u\n       --unwind\n           Displays the contents of the file's unwind section, if it has\n           one.  Only the unwind sections for IA64 ELF files, as well as ARM\n           unwind tables (\".ARM.exidx\" / \".ARM.extab\") are currently\n           supported.  If support is not yet implemented for your\n           architecture you could try dumping the contents of the .eh_frames\n           section using the --debug-dump=frames or\n           --debug-dump=frames-interp options.\n\n       -d\n       --dynamic\n           Displays the contents of the file's dynamic section, if it has\n           one.\n\n       -V\n       --version-info\n           Displays the contents of the version sections in the file, it\n           they exist.\n\n       -A\n       --arch-specific\n           Displays architecture-specific information in the file, if there\n           is any.\n\n       -D\n       --use-dynamic\n           When displaying symbols, this option makes readelf use the symbol\n           hash tables in the file's dynamic section, rather than the symbol\n           table sections.\n\n           When displaying relocations, this option makes readelf display\n           the dynamic relocations rather than the static relocations.\n\n       -L\n       --lint\n       --enable-checks\n           Displays warning messages about possible problems with the\n           file(s) being examined.  If used on its own then all of the\n           contents of the file(s) will be examined.  If used with one of\n           the dumping options then the warning messages will only be\n           produced for the things being displayed.\n\n       -x <number or name>\n       --hex-dump=<number or name>\n           Displays the contents of the indicated section as a hexadecimal\n           bytes.  A number identifies a particular section by index in the\n           section table; any other string identifies all sections with that\n           name in the object file.\n\n       -R <number or name>\n       --relocated-dump=<number or name>\n           Displays the contents of the indicated section as a hexadecimal\n           bytes.  A number identifies a particular section by index in the\n           section table; any other string identifies all sections with that\n           name in the object file.  The contents of the section will be\n           relocated before they are displayed.\n\n       -p <number or name>\n       --string-dump=<number or name>\n           Displays the contents of the indicated section as printable\n           strings.  A number identifies a particular section by index in\n           the section table; any other string identifies all sections with\n           that name in the object file.\n\n       -z\n       --decompress\n           Requests that the section(s) being dumped by x, R or p options\n           are decompressed before being displayed.  If the section(s) are\n           not compressed then they are displayed as is.\n\n       -c\n       --archive-index\n           Displays the file symbol index information contained in the\n           header part of binary archives.  Performs the same function as\n           the t command to ar, but without using the BFD library.\n\n       -w[lLiaprmfFsOoRtUuTgAckK]\n       --debug-dump[=rawline,=decodedline,=info,=abbrev,=pubnames,=aranges,=macro,=frames,=frames-interp,=str,=str-offsets,=loc,=Ranges,=pubtypes,=trace_info,=trace_abbrev,=trace_aranges,=gdb_index,=addr,=cu_index,=links,=follow-links]\n           Displays the contents of the DWARF debug sections in the file, if\n           any are present.  Compressed debug sections are automatically\n           decompressed (temporarily) before they are displayed.  If one or\n           more of the optional letters or words follows the switch then\n           only those type(s) of data will be dumped.  The letters and words\n           refer to the following information:\n\n           \"a\"\n           \"=abbrev\"\n               Displays the contents of the .debug_abbrev section.\n\n           \"A\"\n           \"=addr\"\n               Displays the contents of the .debug_addr section.\n\n           \"c\"\n           \"=cu_index\"\n               Displays the contents of the .debug_cu_index and/or\n               .debug_tu_index sections.\n\n           \"f\"\n           \"=frames\"\n               Display the raw contents of a .debug_frame section.\n\n           \"F\"\n           \"=frame-interp\"\n               Display the interpreted contents of a .debug_frame section.\n\n           \"g\"\n           \"=gdb_index\"\n               Displays the contents of the .gdb_index and/or .debug_names\n               sections.\n\n           \"i\"\n           \"=info\"\n               Displays the contents of the .debug_info section.  Note: the\n               output from this option can also be restricted by the use of\n               the --dwarf-depth and --dwarf-start options.\n\n           \"k\"\n           \"=links\"\n               Displays the contents of the .gnu_debuglink and/or\n               .gnu_debugaltlink sections.  Also displays any links to\n               separate dwarf object files (dwo), if they are specified by\n               the DW_AT_GNU_dwo_name or DW_AT_dwo_name attributes in the\n               .debug_info section.\n\n           \"K\"\n           \"=follow-links\"\n               Display the contents of any selected debug sections that are\n               found in linked, separate debug info file(s).  This can\n               result in multiple versions of the same debug section being\n               displayed if it exists in more than one file.\n\n               In addition, when displaying DWARF attributes, if a form is\n               found that references the separate debug info file, then the\n               referenced contents will also be displayed.\n\n           \"l\"\n           \"=rawline\"\n               Displays the contents of the .debug_line section in a raw\n               format.\n\n           \"L\"\n           \"=decodedline\"\n               Displays the interpreted contents of the .debug_line section.\n\n           \"m\"\n           \"=macro\"\n               Displays the contents of the .debug_macro and/or\n               .debug_macinfo sections.\n\n           \"o\"\n           \"=loc\"\n               Displays the contents of the .debug_loc and/or\n               .debug_loclists sections.\n\n           \"O\"\n           \"=str-offsets\"\n               Displays the contents of the .debug_str_offsets section.\n\n           \"p\"\n           \"=pubnames\"\n               Displays the contents of the .debug_pubnames and/or\n               .debug_gnu_pubnames sections.\n\n           \"r\"\n           \"=aranges\"\n               Displays the contents of the .debug_aranges section.\n\n           \"R\"\n           \"=Ranges\"\n               Displays the contents of the .debug_ranges and/or\n               .debug_rnglists sections.\n\n           \"s\"\n           \"=str\"\n               Displays the contents of the .debug_str, .debug_line_str\n               and/or .debug_str_offsets sections.\n\n           \"t\"\n           \"=pubtype\"\n               Displays the contents of the .debug_pubtypes and/or\n               .debug_gnu_pubtypes sections.\n\n           \"T\"\n           \"=trace_aranges\"\n               Displays the contents of the .trace_aranges section.\n\n           \"u\"\n           \"=trace_abbrev\"\n               Displays the contents of the .trace_abbrev section.\n\n           \"U\"\n           \"=trace_info\"\n               Displays the contents of the .trace_info section.\n\n           Note: displaying the contents of .debug_static_funcs,\n           .debug_static_vars and debug_weaknames sections is not currently\n           supported.\n\n       --dwarf-depth=n\n           Limit the dump of the \".debug_info\" section to n children.  This\n           is only useful with --debug-dump=info.  The default is to print\n           all DIEs; the special value 0 for n will also have this effect.\n\n           With a non-zero value for n, DIEs at or deeper than n levels will\n           not be printed.  The range for n is zero-based.\n\n       --dwarf-start=n\n           Print only DIEs beginning with the DIE numbered n.  This is only\n           useful with --debug-dump=info.\n\n           If specified, this option will suppress printing of any header\n           information and all DIEs before the DIE numbered n.  Only\n           siblings and children of the specified DIE will be printed.\n\n           This can be used in conjunction with --dwarf-depth.\n\n       --ctf=section\n           Display the contents of the specified CTF section.  CTF sections\n           themselves contain many subsections, all of which are displayed\n           in order.\n\n       --ctf-parent=section\n           Specify the name of another section from which the CTF dictionary\n           can inherit types.  (If none is specified, we assume the CTF\n           dictionary inherits types from the default-named member of the\n           archive contained within this section.)\n\n       --ctf-symbols=section\n       --ctf-strings=section\n           Specify the name of another section from which the CTF file can\n           inherit strings and symbols.  By default, the \".symtab\" and its\n           linked string table are used.\n\n           If either of --ctf-symbols or --ctf-strings is specified, the\n           other must be specified as well.\n\n       -I\n       --histogram\n           Display a histogram of bucket list lengths when displaying the\n           contents of the symbol tables.\n\n       -v\n       --version\n           Display the version number of readelf.\n\n       -W\n       --wide\n           Don't break output lines to fit into 80 columns. By default\n           readelf breaks section header and segment listing lines for\n           64-bit ELF files, so that they fit into 80 columns. This option\n           causes readelf to print each section header resp. each segment\n           one a single line, which is far more readable on terminals wider\n           than 80 columns.\n\n       -T\n       --silent-truncation\n           Normally when readelf is displaying a symbol name, and it has to\n           truncate the name to fit into an 80 column display, it will add a\n           suffix of \"[...]\" to the name.  This command line option disables\n           this behaviour, allowing 5 more characters of the name to be\n           displayed and restoring the old behaviour of readelf (prior to\n           release 2.35).\n\n       -H\n       --help\n           Display the command-line options understood by readelf.\n\n       @file\n           Read command-line options from file.  The options read are\n           inserted in place of the original @file option.  If file does not\n           exist, or cannot be read, then the option will be treated\n           literally, and not removed.\n\n           Options in file are separated by whitespace.  A whitespace\n           character may be included in an option by surrounding the entire\n           option in either single or double quotes.  Any character\n           (including a backslash) may be included by prefixing the\n           character to be included with a backslash.  The file may itself\n           contain additional @file options; any such options will be\n           processed recursively.\n\nSEE ALSO          top\n       objdump(1), and the Info entries for binutils.\n\nCOPYRIGHT          top\n       Copyright (c) 1991-2020 Free Software Foundation, Inc.\n\n       Permission is granted to copy, distribute and/or modify this document\n       under the terms of the GNU Free Documentation License, Version 1.3 or\n       any later version published by the Free Software Foundation; with no\n       Invariant Sections, with no Front-Cover Texts, and with no Back-Cover\n       Texts.  A copy of the license is included in the section entitled\n       \"GNU Free Documentation License\".\n\nCOLOPHON          top\n       This page is part of the binutils (a collection of tools for working\n       with executable binaries) project.  Information about the project can\n       be found at â¨http://www.gnu.org/software/binutils/â©.  If you have a\n       bug report for this manual page, see\n       â¨http://sourceware.org/bugzilla/enter_bug.cgi?product=binutilsâ©.\n       This page was obtained from the tarball binutils-2.35.tar.gz fetched\n       from â¨https://ftp.gnu.org/gnu/binutils/â© on 2020-08-13.  If you disâ\n       cover any rendering problems in this HTML version of the page, or you\n       believe there is a better or more up-to-date source for the page, or\n       you have corrections or improvements to the information in this\n       COLOPHON (which is not part of the original manual page), send a mail\n       to man-pages@man7.org\n\nbinutils-2.35                    2020-07-24                       READELF(1)\n\n\nPages that refer to this page: \n    elfedit(1),  \n    ld(1),  \n    objdump(1),  \n    size(1),  \n    strings(1),  \n    dl_iterate_phdr(3),  \n    edata(3),  \n    end(3),  \n    etext(3),  \n    elf(5)\n\n\n\n\n\n\n\n\n            HTML rendering created 2020-08-13\n            by Michael Kerrisk, \n            author of \n            The Linux Programming Interface, \n            maintainer of the \n            Linux man-pages project.\n        \n\n            For details of in-depth\n            Linux/UNIX system programming training courses\n            that I teach, look here.\n        \n\n            Hosting by jambit GmbH.\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# readelf\n\n> Displays information about ELF files.\n> More information: <http://man7.org/linux/man-pages/man1/readelf.1.html>.\n\n- Display all information about the ELF file:\n\n`readelf -all {{path/to/binary}}`\n\n- Display all the headers present in the ELF file:\n\n`readelf --headers {{path/to/binary}}`\n\n- Display the entries in symbol table section of the ELF file, if it has one:\n\n`readelf --symbols {{path/to/binary}}`\n\n- Display the information contained in the ELF header at the start of the file:\n\n`readelf --file-header {{path/to/binary}}`\n"
 },
 {
   "command": "htop",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "HTOP(1) \t\t\t     Utils\t\t\t       HTOP(1)\n\n\n\nNAME\n       htop - interactive process viewer\n\nSYNOPSIS\n       htop [-dChustv]\n\nDESCRIPTION\n       Htop is a free (GPL) ncurses-based process viewer for Linux.\n\n       It  is similar to top, but allows you to scroll vertically and horizon-\n       tally, so you can see all the processes running on  the\tsystem,  along\n       with  their  full  command  lines, as well as viewing them as a process\n       tree, selecting multiple processes and acting on them all at once.\n\n       Tasks related to processes (killing,  renicing)\tcan  be  done  without\n       entering their PIDs.\n\nCOMMAND-LINE OPTIONS\n       Mandatory  arguments  to  long  options are mandatory for short options\n       too.\n\n\n       -d --delay=DELAY\n\t      Delay between updates, in tenths of seconds\n\n       -C --no-color --no-colour\n\t      Start htop in monochrome mode\n\n       -h --help\n\t      Display a help message and exit\n\n       -p --pid=PID,PID...\n\t      Show only the given PIDs\n\n       -s --sort-key COLUMN\n\t      Sort by this column (use --sort-key help for a column list)\n\n       -u --user=USERNAME\n\t      Show only the processes of a given user\n\n       -v --version\n\t      Output version information and exit\n\n       -t --tree\n\t      Show processes in tree view\n\n\nINTERACTIVE COMMANDS\n       The following commands are supported while in htop:\n\n\n       Up, Alt-k\n\t    Select (highlight) the  previous  process  in  the\tprocess  list.\n\t    Scroll the list if necessary.\n\n       Down, Alt-j\n\t    Select  (highlight)  the  next process in the process list. Scroll\n\t    the list if necessary.\n\n       Left, Alt-h\n\t    Scroll the process list left.\n\n       Right, Alt-l\n\t    Scroll the process list right.\n\n       PgUp, PgDn\n\t    Scroll the process list up or down one window.\n\n       Home Scroll to the top  of  the\tprocess  list  and  select  the  first\n\t    process.\n\n       End  Scroll  to\tthe  bottom  of  the  process list and select the last\n\t    process.\n\n       Ctrl-A, ^\n\t    Scroll left to the beginning of the process entry (i.e.  beginning\n\t    of line).\n\n       Ctrl-E, $\n\t    Scroll right to the end of the process entry (i.e. end of line).\n\n       Space\n\t    Tag or untag a process. Commands that can operate on multiple pro-\n\t    cesses, like \"kill\", will then apply over the list of tagged  pro-\n\t    cesses, instead of the currently highlighted one.\n\n       U    Untag all processes (remove all tags added with the Space key).\n\n       s    Trace  process  system  calls: if strace(1) is installed, pressing\n\t    this key will attach it to the currently  selected\tprocess,  pre-\n\t    senting a live update of system calls issued by the process.\n\n       l    Display  open files for a process: if lsof(1) is installed, press-\n\t    ing this key will display the list of file descriptors  opened  by\n\t    the process.\n\n       F1, h, ?\n\t    Go to the help screen\n\n       F2, S\n\t    Go\tto  the  setup screen, where you can configure the meters dis-\n\t    played at the top of the  screen,  set  various  display  options,\n\t    choose  among  color  schemes,  and  select which columns are dis-\n\t    played, in which order.\n\n       F3, /\n\t    Incrementally search the command lines of all the  displayed  pro-\n\t    cesses.  The  currently selected (highlighted) command will update\n\t    as you type. While in search mode, pressing F3 will cycle  through\n\t    matching occurrences.\n\n       F4, \\\n\t    Incremental  process  filtering: type in part of a process command\n\t    line and only processes whose names match will be shown. To cancel\n\t    filtering, enter the Filter option again and press Esc.\n\n       F5, t\n\t    Tree  view: organize processes by parenthood, and layout the rela-\n\t    tions between them as a tree. Toggling the key will switch between\n\t    tree and your previously selected sort view. Selecting a sort view\n\t    will exit tree view.\n\n       F6   On sorted view,  select  a\tfield  for  sorting,  also  accessible\n\t    through  <\tand >.\tThe current sort field is indicated by a high-\n\t    light in the header.  On tree view, expand or collapse the current\n\t    subtree.  A  \"+\"  indicator  in the tree node indicates that it is\n\t    collapsed.\n\n       F7, ]\n\t    Increase the selected process's  priority  (subtract  from\t'nice'\n\t    value).  This can only be done by the superuser.\n\n       F8, [\n\t    Decrease the selected process's priority (add to 'nice' value)\n\n       F9, k\n\t    \"Kill\" process: sends a signal which is selected in a menu, to one\n\t    or a group of processes. If processes were tagged, sends the  sig-\n\t    nal to all tagged processes.  If none is tagged, sends to the cur-\n\t    rently selected process.\n\n       F10, q\n\t    Quit\n\n       I    Invert the sort order: if sort  order  is  increasing,  switch  to\n\t    decreasing, and vice-versa.\n\n       +, - When in tree view mode, expand or collapse subtree. When a subtree\n\t    is collapsed a \"+\" sign shows to the left of the process name.\n\n       a (on multiprocessor machines)\n\t    Set CPU affinity: mark which CPUs a process is allowed to use.\n\n       u    Show only processes owned by a specified user.\n\n       M    Sort by memory usage (top compatibility key).\n\n       P    Sort by processor usage (top compatibility key).\n\n       T    Sort by time (top compatibility key).\n\n       F    \"Follow\" process: if the sort order causes the currently  selected\n\t    process  to  move  in  the list, make the selection bar follow it.\n\t    This is useful for monitoring a process: this way, you can keep  a\n\t    process  always  visible  on  screen. When a movement key is used,\n\t    \"follow\" loses effect.\n\n       K    Hide kernel threads: prevent the threads belonging the  kernel  to\n\t    be displayed in the process list. (This is a toggle key.)\n\n       H    Hide user threads: on systems that represent them differently than\n\t    ordinary processes (such as recent NPTL-based systems),  this  can\n\t    hide  threads  from userspace processes in the process list. (This\n\t    is a toggle key.)\n\n       p    Show full paths to running programs, where applicable. (This is  a\n\t    toggle key.)\n\n       Ctrl-L\n\t    Refresh: redraw screen and recalculate values.\n\n       Numbers\n\t    PID search: type in process ID and the selection highlight will be\n\t    moved to it.\n\n\nCOLUMNS\n       The following columns can display data about each process. A  value  of\n       '-' in all the rows indicates that a column is unsupported on your sys-\n       tem, or currently unimplemented in htop. The names below are  the  ones\n       used  in the \"Available Columns\" section of the setup screen. If a dif-\n       ferent name is shown in htop's main screen, it is shown below in paren-\n       thesis.\n\n\n       Command\n\t    The  full command line of the process (i.e. program name and argu-\n\t    ments).\n\n       PID  The process ID.\n\n       STATE (S)\n\t    The state of the process:\n\t       S for sleeping (idle)\n\t       R for running\n\t       D for disk sleep (uninterruptible)\n\t       Z for zombie (waiting for parent to read its exit status)\n\t       T for traced or suspended (e.g by SIGTSTP)\n\t       W for paging\n\n       PPID The parent process ID.\n\n       PGRP The process's group ID.\n\n       SESSION (SID)\n\t    The process's session ID.\n\n       TTY_NR (TTY)\n\t    The controlling terminal of the process.\n\n       TPGID\n\t    The process ID of the foreground process group of the  controlling\n\t    terminal.\n\n       MINFLT\n\t    The number of page faults happening in the main memory.\n\n       CMINFLT\n\t    The  number  of minor faults for the process's waited-for children\n\t    (see MINFLT above).\n\n       MAJFLT\n\t    The number of page faults happening out of the main memory.\n\n       CMAJFLT\n\t    The number of major faults for the process's  waited-for  children\n\t    (see MAJFLT above).\n\n       UTIME (UTIME+)\n\t    The  user  CPU  time,  which is the amount of time the process has\n\t    spent executing on the CPU in user mode (i.e. everything but  sys-\n\t    tem calls), measured in clock ticks.\n\n       STIME (STIME+)\n\t    The  system  CPU  time, which is the amount of time the kernel has\n\t    spent executing system calls on behalf of the process, measured in\n\t    clock ticks.\n\n       CUTIME (CUTIME+)\n\t    The  children's  user  CPU\ttime,  which is the amount of time the\n\t    process's waited-for children have spent executing\tin  user  mode\n\t    (see UTIME above).\n\n       CSTIME (CSTIME+)\n\t    The  children's  system  CPU time, which is the amount of time the\n\t    kernel has spent executing system  calls  on  behalf  of  all  the\n\t    process's waited-for children (see STIME above).\n\n       PRIORITY (PRI)\n\t    The  kernel's  internal priority for the process, usually just its\n\t    nice value plus twenty. Different for real-time processes.\n\n       NICE (NI)\n\t    The nice value of a process, from 19 (low priority) to  -20  (high\n\t    priority).\tA  high value means the process is being nice, letting\n\t    others have a higher relative priority. The  usual\tOS  permission\n\t    restrictions for adjusting priority apply.\n\n       STARTTIME (START)\n\t    The time the process was started.\n\n       PROCESSOR (CPU)\n\t    The ID of the CPU the process last executed on.\n\n       M_SIZE (VIRT)\n\t    The size of the virtual memory of the process.\n\n       M_RESIDENT (RES)\n\t    The  resident  set size (text + data + stack) of the process (i.e.\n\t    the size of the process's used physical memory).\n\n       M_SHARE (SHR)\n\t    The size of the process's shared pages.\n\n       M_TRS (CODE)\n\t    The text resident set size of the process (i.e. the  size  of  the\n\t    process's executable instructions).\n\n       M_DRS (DATA)\n\t    The data resident set size (data + stack) of the process (i.e. the\n\t    size of anything except the process's executable instructions).\n\n       M_LRS (LIB)\n\t    The library size of the process.\n\n       M_DT (DIRTY)\n\t    The size of the dirty pages of the process.\n\n       ST_UID (UID)\n\t    The user ID of the process owner.\n\n       PERCENT_CPU (CPU%)\n\t    The percentage of the CPU  time  that  the\tprocess  is  currently\n\t    using.\n\n       PERCENT_MEM (MEM%)\n\t    The  percentage of memory the process is currently using (based on\n\t    the process's resident memory size, see M_RESIDENT above).\n\n       USER The username of the process owner, or the  user  ID  if  the  name\n\t    can't be determined.\n\n       TIME (TIME+)\n\t    The  time,\tmeasured  in clock ticks that the process has spent in\n\t    user and system time (see UTIME, STIME above).\n\n       NLWP The number of threads in the process.\n\n       TGID The thread group ID.\n\n       CTID OpenVZ container ID, a.k.a virtual environment ID.\n\n       VPID OpenVZ process ID.\n\n       VXID VServer process ID.\n\n       RCHAR (RD_CHAR)\n\t    The number of bytes the process has read.\n\n       WCHAR (WR_CHAR)\n\t    The number of bytes the process has written.\n\n       SYSCR (RD_SYSC)\n\t    The number of read(2) syscalls for the process.\n\n       SYSCW (WR_SYSC)\n\t    The number of write(2) syscalls for the process.\n\n       RBYTES (IO_RBYTES)\n\t    Bytes of read(2) I/O for the process.\n\n       WBYTES (IO_WBYTES)\n\t    Bytes of write(2) I/O for the process.\n\n       CNCLWB (IO_CANCEL)\n\t    Bytes of cancelled write(2) I/O.\n\n       IO_READ_RATE (DISK READ)\n\t    The I/O rate of read(2) in bytes per second, for the process.\n\n       IO_WRITE_RATE (DISK WRITE)\n\t    The I/O rate of write(2) in bytes per second, for the process.\n\n       IO_RATE (DISK R/W)\n\t    The I/O rate, IO_READ_RATE + IO_WRITE_RATE (see above).\n\n       CGROUP\n\t    Which cgroup the process is in.\n\n       OOM  OOM killer score.\n\n       IO_PRIORITY (IO)\n\t    The I/O scheduling class followed by the  priority\tif  the  class\n\t    supports it:\n\t       R for Realtime\n\t       B for Best-effort\n\t       id for Idle\n\n       PERCENT_CPU_DELAY (CPUD%)\n\t    The  percentage  of time spent waiting for a CPU (while runnable).\n\t    Requires CAP_NET_ADMIN.\n\n       PERCENT_IO_DELAY (IOD%)\n\t    The percentage of time spent waiting for the  completion  of  syn-\n\t    chronous block I/O. Requires CAP_NET_ADMIN.\n\n       PERCENT_SWAP_DELAY (SWAPD%)\n\t    The   percentage   of  time  spent\tswapping  in  pages.  Requires\n\t    CAP_NET_ADMIN.\n\n       All other flags\n\t    Currently unsupported (always displays '-').\n\n\nCONFIG FILE\n       By default htop reads its configuration\tfrom  the  XDG-compliant  path\n       ~/.config/htop/htoprc  --  the  configuration  file  is\toverwritten by\n       htop's in-program Setup configuration, so it should not be hand-edited.\n       If no user configuration exists htop tries to read the system-wide con-\n       figuration from ${prefix}/etc/htoprc and as a last resort,  falls  back\n       to its hard coded defaults.\n\n       You may override the location of the configuration file using the $HTO-\n       PRC environment variable (so you can have multiple  configurations  for\n       different machines that share the same home directory, for example).\n\n\nMEMORY SIZES\n       Memory  sizes  in  htop are displayed as they are in tools from the GNU\n       Coreutils (when ran with the --human-readable option). This means  that\n       sizes are printed in powers of 1024. (e.g., 1023M = 1072693248 Bytes)\n\n       The  decision  to  use  this  convention  was made in order to conserve\n       screen space and make memory size representations consistent throughout\n       htop.\n\n\nSEE ALSO\n       proc(5), top(1), free(1), ps(1), uptime(1), limits.conf(5)\n\n\nAUTHORS\n       htop is developed by Hisham Muhammad <hisham@gobolinux.org>.\n\n       This  man  page\twas  written  by  Bartosz Fenski <fenio@o2.pl> for the\n       Debian GNU/Linux distribution (but it may be used by  others).  It  was\n       updated\tby Hisham Muhammad, and later by Vincent Launchbury, who wrote\n       the 'Columns' section.\n\n\n\nhtop 2.2.0\t\t\t     2015\t\t\t       HTOP(1)\n",
   "tldr_summary": "# htop\n\n> Display dynamic real-time information about running processes. An enhanced version of `top`.\n\n- Start htop:\n\n`htop`\n\n- Start htop displaying only processes owned by given user:\n\n`htop -u {{username}}`\n\n- Sort processes by a column (use `--sort-key help` for a column list):\n\n`htop -s {{column_name}}`\n\n- Get help about interactive commands:\n\n`?`\n"
 },
 {
   "command": "apk",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# apk\n\n> Alpine Linux package management tool.\n\n- Update repository indexes from all remote repositories:\n\n`apk update`\n\n- Install a new package:\n\n`apk add {{package}}`\n\n- Remove a package:\n\n`apk del {{package}}`\n\n- Repair package or upgrade it without modifying main dependencies:\n\n`apk fix {{package}}`\n\n- Search package via keyword:\n\n`apk search {{keyword}}`\n\n- Get info about a specific package:\n\n`apk info {{package}}`\n"
 },
 {
   "command": "snap",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# snap\n\n> Tool for managing the \"snap\" self-contained software packages.\n> Similar to what `apt` is for \".deb\".\n\n- Search for a package:\n\n`snap find {{package_name}}`\n\n- Install a package:\n\n`snap install {{package_name}}`\n\n- Update a package:\n\n`snap refresh {{package_name}}`\n\n- Update all packages:\n\n`snap refresh`\n\n- Display basic information about installed snap software:\n\n`snap list`\n\n- Uninstall a package:\n\n`snap remove {{package_name}}`\n\n- Check for recent snap changes in the system:\n\n`snap changes`\n"
 },
 {
   "command": "xar",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "XAR(1)\t\t\t\t User Commands\t\t\t\tXAR(1)\n\n\n\nNAME\n       xar - eXtensible ARchiver\n\nSYNOPSIS\n       xar -[ctx][v] ...\n\nDESCRIPTION\n       The  XAR  project  aims to provide an easily extensible archive format.\n       Important design decisions include an easily extensible\tXML  table  of\n       contents  (TOC) for random access to archived files, storing the TOC at\n       the beginning of  the  archive  to  allow  for  efficient  handling  of\n       streamed  archives,  the  ability  to handle files of arbitrarily large\n       sizes, the ability to choose independent encodings for individual files\n       in  the archive, the ability to store checksums for individual files in\n       both compressed and uncompressed form, and the ability to query the ta-\n       ble of content's rich meta-data.\n\nFUNCTIONS\n       One of the following options must be used:\n\n       -c     Creates an archive\n\n       -t     Lists the contents of an archive\n\n       -x     Extracts an archive\n\n       NOTE:  all  of the above require the use of the -f option (filename) as\n       this release of xar doesn't correctly handle pipes or sockets.\n\n       -f     The  filename  to use for creation, listing or extraction.  With\n\t      extraction, this can be a POSIX regular expression.\n\nOPTIONS\n       --compression\n\t      Specifies the compression type  to  use.\t Valid\tvalues:  none,\n\t      gzip, bzip2, lzma (on some systems).  Default value: gzip\n\n       -C <path>\n\t      On extract, xar will chdir to the specified path before extract-\n\t      ing the archive.\n\n       -a     Synonym for --compression=lzma\n\n       -j     Synonym for --compression=bzip2\n\n       -z     Synonym for --compression=gzip\n\n       --compression-args=<arguments>\n\t      Specifies arguments to the compression engine  selected.\t gzip,\n\t      bzip2, and lzma all take a single integer argument between 0 and\n\t      9 specifying the compression level to use.\n\n       --dump-toc=<filename>\n\t      Has xar dump the xml header into the specified file.  \"-\" can be\n\t      specified to mean stdout.\n\n       --dump-toc-cksum\n\t      Dumps the ToC checksum to stdout along with the algorithm of the\n\t      ToC.\n\n       --dump-header\n\t      Has xar print out the xar binary header information to stdout.\n\n       --extract-subdoc=<name>\n\t      Extracts the specified subdocument to a document\tin  cwd  named\n\t      <name>.xml\n\n       --list-subdocs\n\t      List the subdocuments in the xml header\n\n       --toc-cksum\n\t      Specifies  the hashing algorithm to use for xml header verifica-\n\t      tion.  Valid values: md5 (on some systems),  sha1,  sha256,  and\n\t      sha512.  Default value: sha1\n\n       --file-cksum\n\t      Specifies  the hashing algorithm to use for file content verifi-\n\t      cation.  Valid values: md5 (on some systems), sha1, sha256,  and\n\t      sha512.  Default value: sha1\n\n       -l     On archival, stay on the local device.\n\n       -P     On  extract, set ownership based on uid/gid.  If the uid/gid can\n\t      be set on the extracted file, setuid/setgid bits\twill  also  be\n\t      preserved.\n\n       -p     On  extract, set ownership based on symbolic names, if possible.\n\t      If the uid/gid can be set on the extracted  file,  setuid/setgid\n\t      bits will also be preserved.\n\n       -s <filename>\n\t      On  extract,  specifies the file to extract subdocuments to.  On\n\t      archival, specifies an xml file to add as a subdocument.\n\n       -v     Verbose output\n\n       --exclude\n\t      Specifies a POSIX regular expression of files  to  exclude  from\n\t      adding  to  the  archive during creation or from being extracted\n\t      during extraction.  This option can be specified multiple times.\n\n       --rsize\n\t      Specifies  a size (in bytes) for the internal libxar read buffer\n\t      while performing I/O.\n\n       --coalesce-heap\n\t      When multiple files in the archive are identical, only store one\n\t      copy  of\tthe  data in the heap.\tThis creates smaller archives,\n\t      but the archives created are not streamable.\n\n       --link-same\n\t      When the data section of multiple files are identical,  hardlink\n\t      them within the archive.\n\n       --no-compress\n\t      Specifies  a  POSIX  regular expression of files to archive, but\n\t      not compress.  The archived files will be copied\traw  into  the\n\t      archive.\tThis can be used to exclude already gzipped files from\n\t      being gzipped during the archival process.\n\n       --prop-include\n\t      Specifies a file property to be included in the  archive.   When\n\t      this  option  is\tspecified,  only the specified options will be\n\t      included.  Anything not specifically included with  this\toption\n\t      will be omitted.\tThis option can be used multiple times.\n\n       --prop-exclude\n\t      Specifies a file property to be excluded from the archive.  When\n\t      this option is specified, all file properties will  be  included\n\t      except the specified properties.\tThis option can be used multi-\n\t      ple times.\n\n       --distribution\n\t      Creates an archive to only contain file properties safe for file\n\t      distribution.   Currently,  only\tname, type, mode, and data are\n\t      preserved with this option.\n\n       --keep-existing\n\t      Does not overwrite existing files during extraction.  Keeps  any\n\t      previously existing files while extracting.\n\n       -k     Synonym for --keep-existing.\n\n       --keep-setuid\n\t      When extracting without -p or -P options, xar will extract files\n\t      as the uid/gid of the extracting process.   In  this  situation,\n\t      xar  will  strip setuid/setgid bits from the extracted files for\n\t      security reasons.  --keep-setuid will preserve the setuid/setgid\n\t      bits  even  though  the uid/gid of the extracted file is not the\n\t      same as the archived file.\n\nEXAMPLES\n       xar -cf sample.xar /home/uid\n\t      Create a xar archive of all files in /home/uid\n\n       xar -tf sample.xar\n\t      List the contents of the xar archive sample.xar\n\n       xar -xf sample.xar\n\t      Extract the contents of sample.xar to the current working direc-\n\t      tory\n\nBUGS\n       Doesn't\tcurrently  work  with  pipes  or streams.  Might be fixed in a\n       future release.\n\n       Probably  one  or  two  more somewhere in there. If you find one please\n       report it to http://code.google.com/p/xar/\n\nAUTHORS\n       Rob Braun <bbraun AT synack DOT net>\n       Landon Fuller <landonf AT bikemonkey DOT org>\n       David Leimbach\n       Kevin Van Vechten\n\n\n\n\nversion 1.8\t\t\t June 4, 2015\t\t\t\tXAR(1)\n",
   "tldr_summary": "# xar\n\n> Manage .xar archives.\n\n- Create a xar archive of all files in a given directory:\n\n`xar -cf {{archive.xar}} {{path/to/directory}}`\n\n- List the contents of a given xar archive:\n\n`xar -tf {{archive.xar}}`\n\n- Extract the contents of a given xar archive to the current directory:\n\n`xar -xf {{archive.xar}}`\n"
 },
 {
   "command": "xclock",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# xclock\n\n> Display the time in analog or digital form.\n\n- Display an analog clock:\n\n`xclock`\n\n- Display a 24-hour digital clock with the hour and minute fields only:\n\n`xclock -digital -brief`\n\n- Display a digital clock using an strftime format string (see strftime(3)):\n\n`xclock -digital -strftime {{format}}`\n\n- Display a 24-hour digital clock with the hour, minute and second fields that updates every second:\n\n`xclock -digital -strftime '%H:%M:%S' -update 1`\n\n- Display a 12-hour digital clock with the hour and minute fields only:\n\n`xclock -digital -twelve -brief`\n"
 },
 {
   "command": "mkfs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkfs\n\n> Build a Linux filesystem on a hard disk partition.\n> This command is deprecated in favor of filesystem specific mkfs.<type> utils.\n\n- Build a Linux ext2 filesystem on a partition:\n\n`mkfs {{path/to/partition}}`\n\n- Build a filesystem of a specified type:\n\n`mkfs -t {{ext4}} {{path/to/partition}}`\n\n- Build a filesystem of a specified type and check for bad blocks:\n\n`mkfs -c -t {{ntfs}} {{path/to/partition}}`\n"
 },
 {
   "command": "mimetype",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mimetype\n\n> Automatically determine the MIME type of a file.\n\n- Print the MIME type of a given file:\n\n`mimetype {{path/to/file}}`\n\n- Display only the MIME type, and not the filename:\n\n`mimetype --brief {{path/to/file}}`\n\n- Display a description of the MIME type:\n\n`mimetype --describe {{path/to/file}}`\n\n- Determine the MIME type of stdin (does not check a filename):\n\n`{{some_command}} | mimetype --stdin`\n\n- Display debug information about how the MIME type was determined:\n\n`mimetype --debug {{path/to/file}}`\n\n- Display all the possible MIME types of a given file in confidence order:\n\n`mimetype --all {{path/to/file}}`\n\n- Explicitly specify the 2-letter language code of the output:\n\n`mimetype --language {{path/to/file}}`\n"
 },
 {
   "command": "iw",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# iw\n\n> Show and manipulate wireless devices.\n\n- Scan for available wireless networks:\n\n`iw dev {{wlp}} scan`\n\n- Join an open wireless network:\n\n`iw dev {{wlp}} connect {{SSID}}`\n\n- Close the current connection:\n\n`iw dev {{wlp}} disconnect`\n\n- Show information about the current connection:\n\n`iw dev {{wlp}} link`\n"
 },
 {
   "command": "halt",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nREBOOT(8)\t\t  BSD System Manager's Manual\t\t     REBOOT(8)\n\nNAME\n     halt, reboot -- stopping and restarting the system\n\nSYNOPSIS\n     halt [-lnqu]\n     reboot [-lnq]\n\nDESCRIPTION\n     The halt and reboot utilities flush the file system cache to disk, send\n     all running processes a SIGTERM (and subsequently a SIGKILL) and, respec-\n     tively, halt or restart the system.  The action is logged, including\n     entering a shutdown record into the wtmp(5) file.\n\n     When the system is halted with the halt command, the system is powered\n     off.\n\n     The options are as follows:\n\n     -l      The halt or reboot is not recorded in the system log.  This\n\t     option is intended for applications such as shutdown(8), that\n\t     call reboot or halt and log this themselves.\n\n     -n      The file system cache is not flushed.  This option should proba-\n\t     bly not be used.\n\n     -q      The system is halted or restarted quickly and ungracefully, and\n\t     only the flushing of the file system cache is performed (if the\n\t     -n option is not specified).  This option should probably not be\n\t     used.\n\n     -u      The system is halted up until the point of removing system power,\n\t     but waits before removing power for 5 minutes so that an external\n\t     UPS (uninterruptible power supply) can forcibly remove power.\n\t     This simulates a dirty shutdown to permit a later automatic power\n\t     on. OS X uses this mode automatically with supported UPSs in\n\t     emergency shutdowns.\n\n     Normally, the shutdown(8) utility is used when the system needs to be\n     halted or restarted, giving users advance warning of their impending doom\n     and cleanly terminating specific programs.\n\nSIGTERM TO SIGKILL INTERVAL\n     The SIGKILL will follow the SIGTERM by an intentionally indeterminate\n     period of time.  Programs are expected to take only enough time to flush\n     all dirty data and exit.  Developers are encouraged to file a bug with\n     the OS vendor, should they encounter an issue with this functionality.\n\nSEE ALSO\n     wtmp(5), shutdown(8), sync(8)\n\nHISTORY\n     A reboot utility appeared in Version 6 AT&T UNIX.\n\nBSD\t\t\t\t June 9, 1993\t\t\t\t   BSD\n",
   "tldr_summary": "# halt\n\n> Power off or reboot the machine.\n\n- Power the machine off:\n\n`halt`\n\n- Reboot the machine:\n\n`halt --reboot`\n"
 },
 {
   "command": "chattr",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# chattr\n\n> Change attributes of files or directories.\n\n- Make a file or directory immutable to changes and deletion, even by superuser:\n\n`chattr +i {{path/to/file_or_directory}}`\n\n- Make a file or directory mutable:\n\n`chattr -i {{path/to/file_or_directory}}`\n\n- Recursively make an entire directory and contents immutable:\n\n`chattr -R +i {{path/to/directory}}`\n"
 },
 {
   "command": "a2disconf",
   "doc_url": "https://manpages.debian.org/buster/apache2/a2disconf.8.en.html",
   "doc_text": "\n\n\n\na2disconf(8) — apache2 — Debian buster — Debian Manpages\n\n\n\n\n\n\n\n\n\n\n\n\n\nMANPAGES\n\n\n\n\n\n\n\n\n\n\n\n\nSkip Quicknav\n\nIndex\nAbout Manpages\nFAQ\nService Information\n\n\n \n     \n     / buster\n     \n     \n     \n     / apache2\n     \n     \n     \n     / a2disconf(8)\n     \n     \n\n\n\n\n\nlinks\n\n\n\n\nlanguage-indep link\n\n\npackage tracker\n\n\nraw man page\n\n\n\n\n\n\n\ntable of contents\n\n\n\n\nNAME\n\n\nSYNOPSIS\n\n\nDESCRIPTION\n\n\nOPTIONS\n\n\nEXIT STATUS\n\n\nEXAMPLES\n\n\nFILES\n\n\nSEE ALSO\n\n\nAUTHOR\n\n\n\n\n\n\n\nother versions\n\n\n\n\nbuster 2.4.38-3+deb10u3\n\n\nbuster-backports 2.4.43-1~bpo10+1\n\n\ntesting 2.4.43-1\n\n\nunstable 2.4.43-1\n\n\n\n\n\n\nScroll to navigation\n\n\n\nA2ENCONF(8)\nSystem Manager's Manual\nA2ENCONF(8)\n\n\n\n\nNAME¶\na2enconf, a2disconf - enable or disable an apache2 configuration file\n\n\nSYNOPSIS¶\na2enconf [ [-q|--quiet] configuration]\na2disconf [ [-q|--quiet] configuration]\n\n\nDESCRIPTION¶\nThis manual page documents briefly the a2enconf and a2disconf\n  commands.\na2enconf is a script that enables the specified\n    configuration file within the apache2 configuration. It does this by\n    creating symlinks within /etc/apache2/conf-enabled. Likewise,\n    a2disconf disables a specific configuration part by removing those\n    symlinks. It is not an error to enable a configuration which is already\n    enabled, or to disable one which is already disabled.\nNote that many configuration file may have a dependency to\n    specific modules. Unlike module dependencies, these are not resolved\n    automatically. Configuration fragments stored in the conf-available\n    directory are considered non-essential or being installed and manged by\n    reverse dependencies (e.g. web scripts).\n\n\nOPTIONS¶\n\n-q, --quiet\nDon't show informative messages.\n-m, --maintmode\nEnables the maintainer mode, that is the program invocation is effectuated\n      automatically by a maintainer script. This switch should not be used by\n      end users.\n-p, --purge\nWhen disabling a module, purge all traces of the module in the internal\n      state data base.\n\n\n\nEXIT STATUS¶\na2enconf and a2disconf exit with status 0 if all\n  configurations are processed successfully, 1 if errors occur, 2 if an\n  invalid option was used.\n\n\nEXAMPLES¶\na2enconf security\n\na2disconf charset\nEnables Apache security directives stored in the security\n    configuration files, and disables the charset configuration.\n\n\nFILES¶\n\n/etc/apache2/conf-available\nDirectory with files giving information on available configuration\n    files.\n/etc/apache2/conf-enabled\nDirectory with links to the files in conf-available for enabled\n      configuration files.\n\n\n\nSEE ALSO¶\napache2ctl(8), a2enmod(8), a2dismod(8).\n\n\nAUTHOR¶\nThis manual page was written by Arno Toell <debian@toell.net> for the\n  Debian GNU/Linux distribution, as it is a Debian-specific script with the\n  package.\n\n\n\n\n14 February 2012\n\n\n\n\n\n\n\n\n\n\nSource file:\n\n\na2disconf.8.en.gz (from apache2 2.4.38-3+deb10u3)\n\n\n\n\nSource last updated:\n\n\n2019-04-07T18:15:40Z\n\n\n\n\nConverted to HTML:\n\n\n2020-08-08T10:05:54Z\n\n\n\n\n\ndebiman 503568d, see github.com/Debian/debiman.\nFound a problem? See the FAQ.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# a2disconf\n\n> Disable an Apache configuration file on Debian-based OSes.\n> More information: <https://manpages.debian.org/buster/apache2/a2disconf.8.en.html>.\n\n- Disable a configuration file:\n\n`sudo a2disconf {{configuration_file}}`\n\n- Don't show informative messages:\n\n`sudo a2disconf --quiet {{configuration_file}}`\n"
 },
 {
   "command": "locate",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nLOCATE(1)\t\t  BSD General Commands Manual\t\t     LOCATE(1)\n\nNAME\n     locate -- find filenames quickly\n\nSYNOPSIS\n     locate [-0Scims] [-l limit] [-d database] pattern ...\n\nDESCRIPTION\n     The locate program searches a database for all pathnames which match the\n     specified pattern.  The database is recomputed periodically (usually\n     weekly or daily), and contains the pathnames of all files which are pub-\n     licly accessible.\n\n     Shell globbing and quoting characters (``*'', ``?'', ``\\'', ``['' and\n     ``]'') may be used in pattern, although they will have to be escaped from\n     the shell.  Preceding any character with a backslash (``\\'') eliminates\n     any special meaning which it may have.  The matching differs in that no\n     characters must be matched explicitly, including slashes (``/'').\n\n     As a special case, a pattern containing no globbing characters (``foo'')\n     is matched as though it were ``*foo*''.\n\n     Historically, locate only stored characters between 32 and 127.  The cur-\n     rent implementation store any character except newline (`\\n') and NUL\n     (`\\0').  The 8-bit character support does not waste extra space for plain\n     ASCII file names.\tCharacters less than 32 or greater than 127 are stored\n     in 2 bytes.\n\n     The following options are available:\n\n     -0 \t Print pathnames separated by an ASCII NUL character (charac-\n\t\t ter code 0) instead of default NL (newline, character code\n\t\t 10).\n\n     -S \t Print some statistics about the database and exit.\n\n     -c \t Suppress normal output; instead print a count of matching\n\t\t file names.\n\n     -d database\n\t\t Search in database instead of the default file name database.\n\t\t Multiple -d options are allowed.  Each additional -d option\n\t\t adds the specified database to the list of databases to be\n\t\t searched.\n\n\t\t The option database may be a colon-separated list of data-\n\t\t bases.  A single colon is a reference to the default data-\n\t\t base.\n\n\t\t $ locate -d $HOME/lib/mydb: foo\n\n\t\t will first search string ``foo'' in $HOME/lib/mydb and then\n\t\t in /var/db/locate.database.\n\n\t\t $ locate -d $HOME/lib/mydb::/cdrom/locate.database foo\n\n\t\t will first search string ``foo'' in $HOME/lib/mydb and then\n\t\t in /var/db/locate.database and then in\n\t\t /cdrom/locate.database.\n\n\t\t       $ locate -d db1 -d db2 -d db3 pattern\n\n\t\t is the same as\n\n\t\t       $ locate -d db1:db2:db3 pattern\n\n\t\t or\n\n\t\t       $ locate -d db1:db2 -d db3 pattern\n\n\t\t If - is given as the database name, standard input will be\n\t\t read instead.\tFor example, you can compress your database\n\t\t and use:\n\n\t\t $ zcat database.gz | locate -d - pattern\n\n\t\t This might be useful on machines with a fast CPU and little\n\t\t RAM and slow I/O.  Note: you can only use one pattern for\n\t\t stdin.\n\n     -i \t Ignore case distinctions in both the pattern and the data-\n\t\t base.\n\n     -l number\t Limit output to number of file names and exit.\n\n     -m \t Use mmap(2) instead of the stdio(3) library.  This is the\n\t\t default behavior and is faster in most cases.\n\n     -s \t Use the stdio(3) library instead of mmap(2).\n\nENVIRONMENT\n     LOCATE_PATH  path to the locate database if set and not empty, ignored if\n\t\t  the -d option was specified.\n\nFILES\n     /var/db/locate.database\t\t\t\t   locate database\n     /usr/libexec/locate.updatedb\t\t\t   Script to update\n\t\t\t\t\t\t\t   the locate database\n     /System/Library/LaunchDaemons/com.apple.locate.plist  Job that starts the\n\t\t\t\t\t\t\t   database rebuild\n\nSEE ALSO\n     find(1), whereis(1), which(1), fnmatch(3), locate.updatedb(8)\n\n     Woods, James A., \"Finding Files Fast\", ;login, 8:1, pp. 8-10, 1983.\n\nHISTORY\n     The locate command first appeared in 4.4BSD.  Many new features were\n     added in FreeBSD 2.2.\n\nBUGS\n     The locate program may fail to list some files that are present, or may\n     list files that have been removed from the system.  This is because\n     locate only reports files that are present in the database, which is typ-\n     ically only regenerated once a week by the\n     /System/Library/LaunchDaemons/com.apple.locate.plist job.\tUse find(1) to\n     locate files that are of a more transitory nature.\n\n     The locate database is typically built by user ``nobody'' and the\n     locate.updatedb(8) utility skips directories which are not readable for\n     user ``nobody'', group ``nobody'', or world.  For example, if your HOME\n     directory is not world-readable, none of your files are in the database.\n\n     The locate database is not byte order independent.  It is not possible to\n     share the databases between machines with different byte order.  The cur-\n     rent locate implementation understands databases in host byte order or\n     network byte order if both architectures use the same integer size.  So\n     on a FreeBSD/i386 machine (little endian), you can read a locate database\n     which was built on SunOS/sparc machine (big endian, net).\n\n     The locate utility does not recognize multibyte characters.\n\nBSD\t\t\t\tAugust 17, 2006 \t\t\t   BSD\n",
   "tldr_summary": "# locate\n\n> Find filenames quickly.\n\n- Look for pattern in the database. Note: the database is recomputed periodically (usually weekly or daily):\n\n`locate {{pattern}}`\n\n- Look for a file by its exact filename (a pattern containing no globbing characters is interpreted as `*pattern*`):\n\n`locate */{{filename}}`\n\n- Recompute the database. You need to do it if you want to find recently added files:\n\n`sudo updatedb`\n"
 },
 {
   "command": "vboxmanage",
   "doc_url": "https://www.virtualbox.org/manual/ch08.html#vboxmanage-intro",
   "doc_text": "Chapter 8. VBoxManageChapter 8. VBoxManageTable of Contents8.1. Introduction8.2. Commands Overview8.3. General Options8.4. VBoxManage list8.5. VBoxManage showvminfo8.6. VBoxManage registervm/unregistervm8.7. VBoxManage createvm8.8. VBoxManage modifyvm8.8.1. General Settings8.8.2. Networking Settings8.8.3. Miscellaneous Settings8.8.4. Recording Settings8.8.5. Remote Machine Settings8.8.6. Teleporting Settings8.8.7. Debugging Settings8.8.8. USB Card Reader Settings8.8.9. Autostarting VMs During Host System Boot8.9. VBoxManage movevm8.10. VBoxManage import8.10.1. Import from OVF8.10.2. Import from Oracle Cloud Infrastructure8.11. VBoxManage export8.11.1. Export to OVF8.11.2. Export to Oracle Cloud Infrastructure8.12. VBoxManage startvm8.13. VBoxManage controlvm8.14. VBoxManage discardstate8.15. VBoxManage adoptstate8.16. VBoxManage closemedium8.17. VBoxManage storageattach8.18. VBoxManage storagectl8.19. VBoxManage bandwidthctl8.20. VBoxManage showmediuminfo8.21. VBoxManage createmedium8.22. VBoxManage modifymedium8.23. VBoxManage clonemedium8.24. VBoxManage mediumproperty8.25. VBoxManage encryptmedium8.26. VBoxManage checkmediumpwd8.27. VBoxManage convertfromraw8.28. VBoxManage getextradata/setextradata8.29. VBoxManage setproperty8.30. VBoxManage usbfilter add/modify/remove8.31. VBoxManage guestproperty8.32. VBoxManage guestcontrol8.33. VBoxManage metrics8.34. VBoxManage natnetwork8.35. VBoxManage hostonlyif8.36. VBoxManage usbdevsource8.37. VBoxManage unattended8.38. VBoxManage snapshot8.39. VBoxManage clonevm8.40. VBoxManage sharedfolder8.41. VBoxManage extpack8.42. VBoxManage dhcpserver8.43. VBoxManage debugvm8.44. VBoxManage cloudprofile8.45. VBoxManage cloud8.46. vboximg-mount8.1. Introduction\n      As briefly mentioned in Section 1.16, “Alternative Front-Ends”,\n      VBoxManage is the command-line interface to\n      Oracle VM VirtualBox. With it, you can completely control Oracle VM VirtualBox\n      from the command line of your host operating system.\n      VBoxManage supports all the features that the\n      graphical user interface gives you access to, but it supports a\n      lot more than that. It exposes all the features of the\n      virtualization engine, even those that cannot be accessed from the\n      GUI.\n    \n      You will need to use the command line if you want to do the\n      following:\n    \n          Use a different user interface than the main GUI such as the\n          VBoxHeadless server.\n        \n          Control some of the more advanced and experimental\n          configuration settings for a VM.\n        \n      There are two main things to keep in mind when using\n      VBoxManage. First,\n      VBoxManage must always be used with a specific\n      subcommand, such as list or\n      createvm or startvm. All the\n      subcommands that VBoxManage supports are\n      described in detail in Chapter 8, VBoxManage.\n    \n      Second, most of these subcommands require that you specify a\n      particular virtual machine after the subcommand. There are two\n      ways you can do this:\n    \n          You can specify the VM name, as it is shown in the\n          Oracle VM VirtualBox GUI. Note that if that name contains spaces,\n          then you must enclose the entire name in double quotes. This\n          is always required with command line arguments that contain\n          spaces. For example:\n        VBoxManage startvm \"Windows XP\"\n          You can specify the UUID, which is the internal unique\n          identifier that Oracle VM VirtualBox uses to refer to the virtual\n          machine. Assuming that the VM called \"Windows XP\" has the UUID\n          shown below, the following command has the same effect as the\n          previous example:\n        VBoxManage startvm 670e746d-abea-4ba6-ad02-2a3b043810a5\n      You can enter VBoxManage list vms to have all\n      currently registered VMs listed with all their settings, including\n      their respective names and UUIDs.\n    \n      Some typical examples of how to control Oracle VM VirtualBox from the\n      command line are listed below:\n    \n          To create a new virtual machine from the command line and\n          immediately register it with Oracle VM VirtualBox, use\n          VBoxManage createvm with the\n          --register option, as follows:\n        $ VBoxManage createvm --name \"SUSE 10.2\" --register\nVirtualBox Command Line Management Interface Version version-number\n(C) 2005-2018 Oracle Corporation\nAll rights reserved.\n\nVirtual machine 'SUSE 10.2' is created.\nUUID: c89fc351-8ec6-4f02-a048-57f4d25288e5\nSettings file: '/home/username/.config/VirtualBox/Machines/SUSE 10.2/SUSE 10.2.xml'\n          As can be seen from the above output, a new virtual machine\n          has been created with a new UUID and a new XML settings file.\n        \n          For more details, see\n          Section 8.7, “VBoxManage createvm”.\n        \n          To show the configuration of a particular VM, use\n          VBoxManage showvminfo. See\n          Section 8.5, “VBoxManage showvminfo” for details\n          and an example.\n        \n          To change settings while a VM is powered off, use\n          VBoxManage modifyvm. For example:\n        VBoxManage modifyvm \"Windows XP\" --memory 512\n          See also Section 8.8, “VBoxManage modifyvm”.\n        \n          To change the storage configuration, such as to add a storage\n          controller and then a virtual disk, use VBoxManage\n          storagectl and VBoxManage\n          storageattach. See\n          Section 8.18, “VBoxManage storagectl” and\n          Section 8.17, “VBoxManage storageattach”.\n        \n          To control VM operation, use one of the following:\n        \n              To start a VM that is currently powered off, use\n              VBoxManage startvm. See\n              Section 8.12, “VBoxManage startvm”.\n            \n              To pause or save a VM that is currently running or change\n              some of its settings, use VBoxManage\n              controlvm. See\n              Section 8.13, “VBoxManage controlvm”.\n            8.2. Commands Overview\n      When running VBoxManage without parameters or\n      when supplying an invalid command line, the following command\n      syntax list is shown. Note that the output will be slightly\n      different depending on the host platform. If in doubt, check the\n      output of VBoxManage for the commands available\n      on your particular host.\n    Usage:\n\n  VBoxManage [<general option>] <command>\n \n \nGeneral Options:\n \n  [-v|--version]            print version number and exit\n  [-q|--nologo]             suppress the logo\n  [--settingspw <pw>]       provide the settings password\n  [--settingspwfile <file>] provide a file containing the settings password\n  [@<response-file>]        load arguments from the given response file (bourne style)\n \n \nCommands:\n \n  list [--long|-l] [--sorted|-s]          vms|runningvms|ostypes|hostdvds|hostfloppies|\n                            intnets|bridgedifs|hostonlyifs|natnets|dhcpservers|\n                            hostinfo|hostcpuids|hddbackends|hdds|dvds|floppies|\n                            usbhost|usbfilters|systemproperties|extpacks|\n                            groups|webcams|screenshotformats|cloudproviders|\n                            cloudprofiles|cloudnets\n\n  showvminfo                <uuid|vmname> [--details]\n                            [--machinereadable]\n  showvminfo                <uuid|vmname> --log <idx>\n\n  registervm                <filename>\n\n  unregistervm              <uuid|vmname> [--delete]\n\n  createvm                  --name <name>\n                            [--groups <group>, ...]\n                            [--ostype <ostype>]\n                            [--register]\n                            [--basefolder <path>]\n                            [--uuid <uuid>]\n                            [--default]\n\n  modifyvm                  <uuid|vmname>\n                            [--name <name>]\n                            [--groups <group>, ...]\n                            [--description <desc>]\n                            [--ostype <ostype>]\n                            [--iconfile <filename>]\n                            [--memory <memorysize in MB>]\n                            [--pagefusion on|off]\n                            [--vram <vramsize in MB>]\n                            [--acpi on|off]\n                            [--ioapic on|off]\n                            [--hpet on|off]\n                            [--triplefaultreset on|off]\n                            [--apic on|off]\n                            [--x2apic on|off]\n                            [--paravirtprovider none|default|legacy|minimal|\n                                                hyperv|kvm]\n                            [--paravirtdebug <key=value> [,<key=value> ...]]\n                            [--hwvirtex on|off]\n                            [--nestedpaging on|off]\n                            [--largepages on|off]\n                            [--vtxvpid on|off]\n                            [--vtxux on|off]\n                            [--pae on|off]\n                            [--longmode on|off]\n                            [--ibpb-on-vm-exit on|off]\n                            [--ibpb-on-vm-entry on|off]\n                            [--spec-ctrl on|off]\n                            [--l1d-flush-on-sched on|off]\n                            [--l1d-flush-on-vm-entry on|off]\n                            [--mds-clear-on-sched on|off]\n                            [--mds-clear-on-vm-entry on|off]\n                            [--nested-hw-virt on|off]\n                            [--cpu-profile \"host|Intel 80[86|286|386]\"]\n                            [--cpuid-portability-level <0..3>]\n                            [--cpuid-set <leaf[:subleaf]> <eax> <ebx> <ecx> <edx>]\n                            [--cpuid-remove <leaf[:subleaf]>]\n                            [--cpuidremoveall]\n                            [--hardwareuuid <uuid>]\n                            [--cpus <number>]\n                            [--cpuhotplug on|off]\n                            [--plugcpu <id>]\n                            [--unplugcpu <id>]\n                            [--cpuexecutioncap <1-100>]\n                            [--rtcuseutc on|off]\n                            [--graphicscontroller none|vboxvga|vmsvga|vboxsvga]\n                            [--monitorcount <number>]\n                            [--accelerate3d on|off]\n                            [--accelerate2dvideo on|off]\n                            [--firmware bios|efi|efi32|efi64]\n                            [--chipset ich9|piix3]\n                            [--bioslogofadein on|off]\n                            [--bioslogofadeout on|off]\n                            [--bioslogodisplaytime <msec>]\n                            [--bioslogoimagepath <imagepath>]\n                            [--biosbootmenu disabled|menuonly|messageandmenu]\n                            [--biosapic disabled|apic|x2apic]\n                            [--biossystemtimeoffset <msec>]\n                            [--biospxedebug on|off]\n                            [--system-uuid-le on|off]\n                            [--boot<1-4> none|floppy|dvd|disk|net>]\n                            [--nic<1-N> none|null|nat|bridged|intnet|hostonly|\n                                        generic|natnetwork]\n                            [--nictype<1-N> Am79C970A|Am79C973|Am79C960|\n                                            82540EM|82543GC|82545EM|\n                                            virtio]\n                            [--cableconnected<1-N> on|off]\n                            [--nictrace<1-N> on|off]\n                            [--nictracefile<1-N> <filename>]\n                            [--nicproperty<1-N> name=[value]]\n                            [--nicspeed<1-N> <kbps>]\n                            [--nicbootprio<1-N> <priority>]\n                            [--nicpromisc<1-N> deny|allow-vms|allow-all]\n                            [--nicbandwidthgroup<1-N> none|<name>]\n                            [--bridgeadapter<1-N> none|<devicename>]\n                            [--hostonlyadapter<1-N> none|<devicename>]\n                            [--intnet<1-N> <network name>]\n                            [--nat-network<1-N> <network name>]\n                            [--nicgenericdrv<1-N> <driver>]\n                            [--natnet<1-N> <network>|default]\n                            [--natsettings<1-N> [<mtu>],[<socksnd>],\n                                                [<sockrcv>],[<tcpsnd>],\n                                                [<tcprcv>]]\n                            [--natpf<1-N> [<rulename>],tcp|udp,[<hostip>],\n                                          <hostport>,[<guestip>],<guestport>]\n                            [--natpf<1-N> delete <rulename>]\n                            [--nattftpprefix<1-N> <prefix>]\n                            [--nattftpfile<1-N> <file>]\n                            [--nattftpserver<1-N> <ip>]\n                            [--natbindip<1-N> <ip>]\n                            [--natdnspassdomain<1-N> on|off]\n                            [--natdnsproxy<1-N> on|off]\n                            [--natdnshostresolver<1-N> on|off]\n                            [--nataliasmode<1-N> default|[log],[proxyonly],\n                                                         [sameports]]\n                            [--macaddress<1-N> auto|<mac>]\n                            [--mouse ps2|usb|usbtablet|usbmultitouch]\n                            [--keyboard ps2|usb]\n                            [--uart<1-N> off|<I/O base> <IRQ>]\n                            [--uartmode<1-N> disconnected|\n                                             server <pipe>|\n                                             client <pipe>|\n                                             tcpserver <port>|\n                                             tcpclient <hostname:port>|\n                                             file <file>|\n                                             <devicename>]\n                            [--uarttype<1-N> 16450|16550A|16750]\n                            [--lpt<1-N> off|<I/O base> <IRQ>]\n                            [--lptmode<1-N> <devicename>]\n                            [--guestmemoryballoon <balloonsize in MB>]\n                            [--vm-process-priority default|flat|low|normal|high]\n                            [--audio none|null|dsound|oss|alsa|pulse|\n                                     oss|pulse|coreaudio]\n                            [--audioin on|off]\n                            [--audioout on|off]\n                            [--audiocontroller ac97|hda|sb16]\n                            [--audiocodec stac9700|ad1980|stac9221|sb16]\n                            [--clipboard-mode disabled|hosttoguest|guesttohost|\n                                              bidirectional]\n                            [--draganddrop disabled|hosttoguest|guesttohost|\n                                           bidirectional]\n                            [--vrde on|off]\n                            [--vrdeextpack default|<name>]\n                            [--vrdeproperty <name=[value]>]\n                            [--vrdeport <hostport>]\n                            [--vrdeaddress <hostip>]\n                            [--vrdeauthtype null|external|guest]\n                            [--vrdeauthlibrary default|<name>]\n                            [--vrdemulticon on|off]\n                            [--vrdereusecon on|off]\n                            [--vrdevideochannel on|off]\n                            [--vrdevideochannelquality <percent>]\n                            [--usbohci on|off]\n                            [--usbehci on|off]\n                            [--usbxhci on|off]\n                            [--usbrename <oldname> <newname>]\n                            [--snapshotfolder default|<path>]\n                            [--teleporter on|off]\n                            [--teleporterport <port>]\n                            [--teleporteraddress <address|empty>]\n                            [--teleporterpassword <password>]\n                            [--teleporterpasswordfile <file>|stdin]\n                            [--tracing-enabled on|off]\n                            [--tracing-config <config-string>]\n                            [--tracing-allow-vm-access on|off]\n                            [--usbcardreader on|off]\n                            [--autostart-enabled on|off]\n                            [--autostart-delay <seconds>]\n                            [--recording on|off]\n                            [--recordingscreens all|<screen ID> [<screen ID> ...]]\n                            [--recordingfile <filename>]\n                            [--recordingvideores <width> <height>]\n                            [--recordingvideorate <rate>]\n                            [--recordingvideofps <fps>]\n                            [--recordingmaxtime <s>]\n                            [--recordingmaxsize <MB>]\n                            [--recordingopts <key=value> [,<key=value> ...]]\n                            [--defaultfrontend default|<name>]\n\n  movevm                    <uuid|vmname>\n                            --type basic\n                            [--folder <path>]\n\n  import                    <ovfname/ovaname>\n                            [--dry-run|-n]\n                            [--options keepallmacs|keepnatmacs|importtovdi]\n                            [--vmname <name>]\n                            [--cloud]\n                            [--cloudprofile <cloud profile name>]\n                            [--cloudinstanceid <instance id>]\n                            [--cloudbucket <bucket name>]\n                            [more options]\n                            (run with -n to have options displayed\n                             for a particular OVF. It doesn't work for the Cloud import.)\n\n  export                    <machines> --output|-o <name>.<ovf/ova/tar.gz>\n                            [--legacy09|--ovf09|--ovf10|--ovf20|--opc10]\n                            [--manifest]\n                            [--iso]\n                            [--options manifest|iso|nomacs|nomacsbutnat]\n                            [--vsys <number of virtual system>]\n                                    [--vmname <name>]\n                                    [--product <product name>]\n                                    [--producturl <product url>]\n                                    [--vendor <vendor name>]\n                                    [--vendorurl <vendor url>]\n                                    [--version <version info>]\n                                    [--description <description info>]\n                                    [--eula <license text>]\n                                    [--eulafile <filename>]\n                            [--cloud <number of virtual system>]\n                                    [--vmname <name>]\n                                    [--cloudprofile <cloud profile name>]\n                                    [--cloudbucket <bucket name>]\n                                    [--cloudkeepobject <true/false>]\n                                    [--cloudlaunchmode EMULATED|PARAVIRTUALIZED]\n                                    [--cloudlaunchinstance <true/false>]\n                                    [--clouddomain <domain>]\n                                    [--cloudshape <shape>]\n                                    [--clouddisksize <disk size in GB>]\n                                    [--cloudocivcn <OCI vcn id>]\n                                    [--cloudocisubnet <OCI subnet id>]\n                                    [--cloudpublicip <true/false>]\n                                    [--cloudprivateip <ip>]\n\n  startvm                   <uuid|vmname>...\n                            [--type gui|sdl|headless|separate]\n                            [-E|--putenv <NAME>[=<VALUE>]]\n\n  controlvm                 <uuid|vmname>\n                            pause|resume|reset|poweroff|savestate|\n                            acpipowerbutton|acpisleepbutton|\n                            keyboardputscancode <hex> [<hex> ...]|\n                            keyboardputstring <string1> [<string2> ...]|\n                            keyboardputfile <filename>|\n                            setlinkstate<1-N> on|off |\n                            nic<1-N> null|nat|bridged|intnet|hostonly|generic|\n                                     natnetwork [<devicename>] |\n                            nictrace<1-N> on|off |\n                            nictracefile<1-N> <filename> |\n                            nicproperty<1-N> name=[value] |\n                            nicpromisc<1-N> deny|allow-vms|allow-all |\n                            natpf<1-N> [<rulename>],tcp|udp,[<hostip>],\n                                        <hostport>,[<guestip>],<guestport> |\n                            natpf<1-N> delete <rulename> |\n                            guestmemoryballoon <balloonsize in MB> |\n                            usbattach <uuid>|<address>\n                                      [--capturefile <filename>] |\n                            usbdetach <uuid>|<address> |\n                            audioin on|off |\n                            audioout on|off |\n                            clipboard mode disabled|hosttoguest|guesttohost|\n                                           bidirectional |\n                            draganddrop disabled|hosttoguest|guesttohost|\n                                        bidirectional |\n                            vrde on|off |\n                            vrdeport <port> |\n                            vrdeproperty <name=[value]> |\n                            vrdevideochannelquality <percent> |\n                            setvideomodehint <xres> <yres> <bpp>\n                                            [[<display>] [<enabled:yes|no> |\n                                              [<xorigin> <yorigin>]]] |\n                            setscreenlayout <display> on|primary <xorigin> <yorigin> <xres> <yres> <bpp> | off\n                            screenshotpng <file> [display] |\n                            recording on|off |\n                            recording screens all|none|<screen>,[<screen>...] |\n                            recording filename <file> |\n                            recording videores <width>x<height> |\n                            recording videorate <rate> |\n                            recording videofps <fps> |\n                            recording maxtime <s> |\n                            recording maxfilesize <MB> |\n                            setcredentials <username>\n                                           --passwordfile <file> | <password>\n                                           <domain>\n                                           [--allowlocallogon <yes|no>] |\n                            teleport --host <name> --port <port>\n                                     [--maxdowntime <msec>]\n                                     [--passwordfile <file> |\n                                      --password <password>] |\n                            plugcpu <id> |\n                            unplugcpu <id> |\n                            cpuexecutioncap <1-100>\n                            webcam <attach [path [settings]]> | <detach [path]> | <list>\n                            addencpassword <id>\n                                           <password file>|-\n                                           [--removeonsuspend <yes|no>]\n                            removeencpassword <id>\n                            removeallencpasswords\n                            changeuartmode<1-N> disconnected|\n                                                server <pipe>|\n                                                client <pipe>|\n                                                tcpserver <port>|\n                                                tcpclient <hostname:port>|\n                                                file <file>|\n                                                <devicename>\n                            vm-process-priority default|flat|low|normal|high\n\n  discardstate              <uuid|vmname>\n\n  adoptstate                <uuid|vmname> <state_file>\n\n  closemedium               [disk|dvd|floppy] <uuid|filename>\n                            [--delete]\n\n  storageattach             <uuid|vmname>\n                            --storagectl <name>\n                            [--port <number>]\n                            [--device <number>]\n                            [--type dvddrive|hdd|fdd]\n                            [--medium none|emptydrive|additions|\n                                      <uuid|filename>|host:<drive>|iscsi]\n                            [--mtype normal|writethrough|immutable|shareable|\n                                     readonly|multiattach]\n                            [--comment <text>]\n                            [--setuuid <uuid>]\n                            [--setparentuuid <uuid>]\n                            [--passthrough on|off]\n                            [--tempeject on|off]\n                            [--nonrotational on|off]\n                            [--discard on|off]\n                            [--hotpluggable on|off]\n                            [--bandwidthgroup <name>]\n                            [--forceunmount]\n                            [--server <name>|<ip>]\n                            [--target <target>]\n                            [--tport <port>]\n                            [--lun <lun>]\n                            [--encodedlun <lun>]\n                            [--username <username>]\n                            [--password <password>]\n                            [--passwordfile <file>]\n                            [--initiator <initiator>]\n                            [--intnet]\n\n  storagectl                <uuid|vmname>\n                            --name <name>\n                            [--add ide|sata|scsi|floppy|sas|usb|pcie|virtio]\n                            [--controller LSILogic|LSILogicSAS|BusLogic|\n                                          IntelAHCI|PIIX3|PIIX4|ICH6|I82078|\n                            [             USB|NVMe|VirtIO]\n                            [--portcount <1-n>]\n                            [--hostiocache on|off]\n                            [--bootable on|off]\n                            [--rename <name>]\n                            [--remove]\n\n  bandwidthctl              <uuid|vmname>\n                            add <name> --type disk|network\n                                --limit <megabytes per second>[k|m|g|K|M|G] |\n                            set <name>\n                                --limit <megabytes per second>[k|m|g|K|M|G] |\n                            remove <name> |\n                            list [--machinereadable]\n                            (limit units: k=kilobit, m=megabit, g=gigabit,\n                                          K=kilobyte, M=megabyte, G=gigabyte)\n\n  showmediuminfo            [disk|dvd|floppy] <uuid|filename>\n\n  createmedium              [disk|dvd|floppy] --filename <filename>\n                            [--size <megabytes>|--sizebyte <bytes>]\n                            [--diffparent <uuid>|<filename>]\n                            [--format VDI|VMDK|VHD] (default: VDI)]\n                            [--variant Standard,Fixed,Split2G,Stream,ESX,\n                                       Formatted]\n                            [[--property <name>=<value>] --property <name>=<value]...\n\n  modifymedium              [disk|dvd|floppy] <uuid|filename>\n                            [--type normal|writethrough|immutable|shareable|\n                                    readonly|multiattach]\n                            [--autoreset on|off]\n                            [--property <name=[value]>]\n                            [--compact]\n                            [--resize <megabytes>|--resizebyte <bytes>]\n                            [--move <path>]\n                            [--setlocation <path>]\n                            [--description <description string>]\n  clonemedium               [disk|dvd|floppy] <uuid|inputfile> <uuid|outputfile>\n                            [--format VDI|VMDK|VHD|RAW|<other>]\n                            [--variant Standard,Fixed,Split2G,Stream,ESX]\n                            [--existing]\n\n  mediumproperty            [disk|dvd|floppy] set <uuid|filename>\n                            <property> <value>\n\n                            [disk|dvd|floppy] get <uuid|filename>\n                            <property>\n\n                            [disk|dvd|floppy] delete <uuid|filename>\n                            <property>\n\n  encryptmedium             <uuid|filename>\n                            [--newpassword <file>|-]\n                            [--oldpassword <file>|-]\n                            [--cipher <cipher identifier>]\n                            [--newpasswordid <password identifier>]\n\n  checkmediumpwd            <uuid|filename>\n                            <pwd file>|-\n\n  convertfromraw            <filename> <outputfile>\n                            [--format VDI|VMDK|VHD]\n                            [--variant Standard,Fixed,Split2G,Stream,ESX]\n                            [--uuid <uuid>]\n  convertfromraw            stdin <outputfile> <bytes>\n                            [--format VDI|VMDK|VHD]\n                            [--variant Standard,Fixed,Split2G,Stream,ESX]\n                            [--uuid <uuid>]\n\n  getextradata              global|<uuid|vmname>\n                            <key>|[enumerate]\n\n  setextradata              global|<uuid|vmname>\n                            <key>\n                            [<value>] (no value deletes key)\n\n  setproperty               machinefolder default|<folder> |\n                            hwvirtexclusive on|off |\n                            vrdeauthlibrary default|<library> |\n                            websrvauthlibrary default|null|<library> |\n                            vrdeextpack null|<library> |\n                            autostartdbpath null|<folder> |\n                            loghistorycount <value>\n                            defaultfrontend default|<name>\n                            logginglevel <log setting>\n                            proxymode system|noproxy|manual\n                            proxyurl <url>\n\n  usbfilter                 add <index,0-N>\n                            --target <uuid|vmname>|global\n                            --name <string>\n                            --action ignore|hold (global filters only)\n                            [--active yes|no] (yes)\n                            [--vendorid <XXXX>] (null)\n                            [--productid <XXXX>] (null)\n                            [--revision <IIFF>] (null)\n                            [--manufacturer <string>] (null)\n                            [--product <string>] (null)\n                            [--remote yes|no] (null, VM filters only)\n                            [--serialnumber <string>] (null)\n                            [--maskedinterfaces <XXXXXXXX>]\n\n  usbfilter                 modify <index,0-N>\n                            --target <uuid|vmname>|global\n                            [--name <string>]\n                            [--action ignore|hold] (global filters only)\n                            [--active yes|no]\n                            [--vendorid <XXXX>|\"\"]\n                            [--productid <XXXX>|\"\"]\n                            [--revision <IIFF>|\"\"]\n                            [--manufacturer <string>|\"\"]\n                            [--product <string>|\"\"]\n                            [--remote yes|no] (null, VM filters only)\n                            [--serialnumber <string>|\"\"]\n                            [--maskedinterfaces <XXXXXXXX>]\n\n  usbfilter                 remove <index,0-N>\n                            --target <uuid|vmname>|global\n\n  guestproperty             get <uuid|vmname>\n                            <property> [--verbose]\n\n  guestproperty             set <uuid|vmname>\n                            <property> [<value> [--flags <flags>]]\n\n  guestproperty             delete|unset <uuid|vmname>\n                            <property>\n\n  guestproperty             enumerate <uuid|vmname>\n                            [--patterns <patterns>]\n\n  guestproperty             wait <uuid|vmname> <patterns>\n                            [--timeout <msec>] [--fail-on-timeout]\n\n  guestcontrol              <uuid|vmname> [--verbose|-v] [--quiet|-q]\n                              [--username <name>] [--domain <domain>]\n                              [--passwordfile <file> | --password <password>]\n\n                              run [common-options]\n                              [--exe <path to executable>] [--timeout <msec>]\n                              [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]\n                              [--ignore-operhaned-processes] [--profile]\n                              [--no-wait-stdout|--wait-stdout]\n                              [--no-wait-stderr|--wait-stderr]\n                              [--dos2unix] [--unix2dos]\n                              -- <program/arg0> [argument1] ... [argumentN]]\n\n                              start [common-options]\n                              [--exe <path to executable>] [--timeout <msec>]\n                              [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]\n                              [--ignore-operhaned-processes] [--profile]\n                              -- <program/arg0> [argument1] ... [argumentN]]\n\n                              copyfrom [common-options]\n                              [--follow] [-R|--recursive]\n                              <guest-src0> [guest-src1 [...]] <host-dst>\n\n                              copyfrom [common-options]\n                              [--follow] [-R|--recursive]\n                              [--target-directory <host-dst-dir>]\n                              <guest-src0> [guest-src1 [...]]\n\n                              copyto [common-options]\n                              [--follow] [-R|--recursive]\n                              <host-src0> [host-src1 [...]] <guest-dst>\n\n                              copyto [common-options]\n                              [--follow] [-R|--recursive]\n                              [--target-directory <guest-dst>]\n                              <host-src0> [host-src1 [...]]\n\n                              mkdir|createdir[ectory] [common-options]\n                              [--parents] [--mode <mode>]\n                              <guest directory> [...]\n\n                              rmdir|removedir[ectory] [common-options]\n                              [-R|--recursive]\n                              <guest directory> [...]\n\n                              removefile|rm [common-options] [-f|--force]\n                              <guest file> [...]\n\n                              mv|move|ren[ame] [common-options]\n                              <source> [source1 [...]] <dest>\n\n                              mktemp|createtemp[orary] [common-options]\n                              [--secure] [--mode <mode>] [--tmpdir <directory>]\n                              <template>\n\n                              stat [common-options]\n                              <file> [...]\n\n  guestcontrol              <uuid|vmname> [--verbose|-v] [--quiet|-q]\n\n                              list <all|sessions|processes|files> [common-opts]\n\n                              closeprocess [common-options]\n                              <   --session-id <ID>\n                                | --session-name <name or pattern>\n                              <PID1> [PID1 [...]]\n\n                              closesession [common-options]\n                              <  --all | --session-id <ID>\n                                | --session-name <name or pattern> >\n\n                              updatega|updateguestadditions|updateadditions\n                              [--source <guest additions .ISO>]\n                              [--wait-start] [common-options]\n                              [-- [<argument1>] ... [<argumentN>]]\n\n                              watch [common-options]\n\n  metrics                   list [*|host|<vmname> [<metric_list>]]\n                                                 (comma-separated)\n\n  metrics                   setup\n                            [--period <seconds>] (default: 1)\n                            [--samples <count>] (default: 1)\n                            [--list]\n                            [*|host|<vmname> [<metric_list>]]\n\n  metrics                   query [*|host|<vmname> [<metric_list>]]\n\n  metrics                   enable\n                            [--list]\n                            [*|host|<vmname> [<metric_list>]]\n\n  metrics                   disable\n                            [--list]\n                            [*|host|<vmname> [<metric_list>]]\n\n  metrics                   collect\n                            [--period <seconds>] (default: 1)\n                            [--samples <count>] (default: 1)\n                            [--list]\n                            [--detach]\n                            [*|host|<vmname> [<metric_list>]]\n\n  natnetwork                add --netname <name>\n                            --network <network>\n                            [--enable|--disable]\n                            [--dhcp on|off]\n                            [--port-forward-4 <rule>]\n                            [--loopback-4 <rule>]\n                            [--ipv6 on|off]\n                            [--port-forward-6 <rule>]\n                            [--loopback-6 <rule>]\n\n  natnetwork                remove --netname <name>\n\n  natnetwork                modify --netname <name>\n                            [--network <network>]\n                            [--enable|--disable]\n                            [--dhcp on|off]\n                            [--port-forward-4 <rule>]\n                            [--loopback-4 <rule>]\n                            [--ipv6 on|off]\n                            [--port-forward-6 <rule>]\n                            [--loopback-6 <rule>]\n\n  natnetwork                start --netname <name>\n\n  natnetwork                stop --netname <name>\n\n  natnetwork                list [<pattern>]\n\n  hostonlyif                ipconfig <name>\n                            [--dhcp |\n                            --ip<ipv4> [--netmask<ipv4> (def: 255.255.255.0)] |\n                            --ipv6<ipv6> [--netmasklengthv6<length> (def: 64)]]\n                            create |\n                            remove <name>\n\n  usbdevsource              add <source name>\n                            --backend <backend>\n                            --address <address>\n  usbdevsource              remove <source name>\nVBoxManage snapshot  <uuid|vmname>VBoxManage snapshot  <uuid|vmname>  take  <snapshot-name> [--description=description] [--live] [--uniquename Number,Timestamp,Space,Force]VBoxManage snapshot  <uuid|vmname>  delete  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restore  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restorecurrent VBoxManage snapshot  <uuid|vmname>  edit  < snapshot-name  |   --current > [--description=description] [--name=new-name]VBoxManage snapshot  <uuid|vmname>  list  [[--details] |  [--machinereadable]]VBoxManage snapshot  <uuid|vmname>  showvminfo  <snapshot-name>\nVBoxManage clonevm  <vmname|uuid> [--basefolder=basefolder] [--groups=group,...] [ --mode=machine  |   --mode=machinechildren  |   --mode=all ] [--name=name] [--options=option,...] [--register] [--snapshot=snapshot-name] [--uuid=uuid]\nVBoxManage mediumio  < --disk=uuid|filename  |   --dvd=uuid|filename  |   --floppy=uuid|filename > [--password-file=-|filename]  formatfat  [--quick]VBoxManage mediumio  < --disk=uuid|filename  |   --dvd=uuid|filename  |   --floppy=uuid|filename > [--password-file=-|filename]  cat  [--hex] [--offset=byte-offset] [--size=bytes] [--output=-|filename]VBoxManage mediumio  < --disk=uuid|filename  |   --dvd=uuid|filename  |   --floppy=uuid|filename > [--password-file=-|filename]  stream  [--format=image-format] [--variant=image-variant] [--output=-|filename]\nVBoxManage sharedfolder add  < uuid  |   vmname > <--name=name> <--hostpath=hostpath> [--readonly] [--transient] [--automount] [--auto-mount-point=path]VBoxManage sharedfolder remove  < uuid  |   vmname > <--name=name> [--transient]\nVBoxManage dhcpserver add  < --network=netname  |   --interface=ifname > <--server-ip=address> <--netmask=mask> <--lower-ip=address> <--upper-ip=address> < --enable  |   --disable > [[--global] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--incl-mac=address...] [--excl-mac=address...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--incl-vendor=string...] [--excl-vendor=string...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--incl-user=string...] [--excl-user=string...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--vm=name|uuid> [--nic=1-N] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...] [<--mac-address=address> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...]VBoxManage dhcpserver modify  < --network=netname  |   --interface=ifname > [--server-ip=address] [--lower-ip=address] [--upper-ip=address] [--netmask=mask] [ --enable  |   --disable ] [[--global] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--del-mac=address...] [--incl-mac=address...] [--excl-mac=address...] [--del-mac-wild=pattern...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--del-vendor=string...] [--incl-vendor=string...] [--excl-vendor=string...] [--del-vendor-wild=pattern...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--del-user=string...] [--incl-user=string...] [--excl-user=string...] [--del-user-wild=pattern...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--zap-conditions] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--vm=name|uuid> [--nic=1-N] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...] [<--mac-address=address> [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...]VBoxManage dhcpserver remove  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver restart  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver findlease  < --network=netname  |   --interface=ifname > <--mac-address=mac>\nVBoxManage debugvm  <uuid|vmname>  dumpvmcore  [--filename=name]VBoxManage debugvm  <uuid|vmname>  info  <item> [args...]VBoxManage debugvm  <uuid|vmname>  injectnmi VBoxManage debugvm  <uuid|vmname>  log  [[--release] |  [--debug]] [group-settings...]VBoxManage debugvm  <uuid|vmname>  logdest  [[--release] |  [--debug]] [destinations...]VBoxManage debugvm  <uuid|vmname>  logflags  [[--release] |  [--debug]] [flags...]VBoxManage debugvm  <uuid|vmname>  osdetect VBoxManage debugvm  <uuid|vmname>  osinfo VBoxManage debugvm  <uuid|vmname>  osdmesg  [--lines=lines]VBoxManage debugvm  <uuid|vmname>  getregisters  [--cpu=id] [reg-set.reg-name...]VBoxManage debugvm  <uuid|vmname>  setregisters  [--cpu=id] [reg-set.reg-name=value...]VBoxManage debugvm  <uuid|vmname>  show  [[--human-readable] |  [--sh-export] |  [--sh-eval] |  [--cmd-set]] [settings-item...]VBoxManage debugvm  <uuid|vmname>  stack  [--cpu=id]VBoxManage debugvm  <uuid|vmname>  statistics  [--reset] [--descriptions] [--pattern=pattern]\nVBoxManage extpack install  [--replace] [--accept-license=sha256] <tarball>VBoxManage extpack uninstall  [--force] <name>VBoxManage extpack cleanup \nVBoxManage unattended detect  <--iso=install-iso> [--machine-readable]VBoxManage unattended install  <uuid|vmname> <--iso=install-iso> [--user=login] [--password=password] [--password-file=file] [--full-user-name=name] [--key=product-key] [--install-additions] [--no-install-additions] [--additions-iso=add-iso] [--install-txs] [--no-install-txs] [--validation-kit-iso=testing-iso] [--locale=ll_CC] [--country=CC] [--time-zone=tz] [--hostname=fqdn] [--package-selection-adjustment=keyword] [--dry-run] [--auxiliary-base-path=path] [--image-index=number] [--script-template=file] [--post-install-template=file] [--post-install-command=command] [--extra-install-kernel-parameters=params] [--language=lang] [--start-vm=session-type]\nVBoxManage cloud  <--provider=name> <--profile=name>  list   instances  [--state=string] [--compartment-id=string]VBoxManage cloud  <--provider=name> <--profile=name>  list   images  <--compartment-id=string> [--state=string]VBoxManage cloud  <--provider=name> <--profile=name>  instance   create  <--domain-name=name> <<--image-id=id> |  <--boot-volume-id=id>> <--display-name=name> <--shape=type> <--subnet=id> [--boot-disk-size=size in GB] [--publicip=true/false] [--privateip=IP address] [--public-ssh-key=key string...] [--launch-mode=NATIVE/EMULATED/PARAVIRTUALIZED]VBoxManage cloud  <--provider=name> <--profile=name>  instance   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   terminate  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   start  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   pause  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   create  <--display-name=name> [--bucket-name=name] [--object-name=name] [--instance-id=unique id]VBoxManage cloud  <--provider=name> <--profile=name>  image   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   delete  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   import  <--id=unique id> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  image   export  <--id=unique id> <--display-name=name> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  network setup  <--local-gateway-iso=path> [--gateway-os-name=string] [--gateway-os-version=string] [--gateway-shape=string] [--tunnel-network-name=string] [--tunnel-network-range=string] [--guest-additions-iso=path] [--proxy=string]VBoxManage cloud  <--provider=name> <--profile=name>  network create  <--name=string> <--network-id=string> [ --enable  |   --disable ]VBoxManage cloud network update  <--name=string> [--network-id=string] [ --enable  |   --disable ]VBoxManage cloud   network delete  <--name=string>VBoxManage cloud   network info  <--name=string>\nVBoxManage cloudprofile  <--provider=name> <--profile=name>  add  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  update  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  delete VBoxManage cloudprofile  <--provider=name> <--profile=name>  show \n\n      Each time VBoxManage is invoked, only one\n      command can be executed. However, a command might support several\n      subcommands which then can be invoked in one single call. The\n      following sections provide detailed reference information on the\n      different commands.\n    8.3. General Options\n-v|--version: Show the version of this tool\n          and exit.\n        \n--nologo: Suppress the output of the logo\n          information. This option is useful for scripts.\n        \n--settingspw: Specifiy a settings password.\n        \n--settingspwfile: Specify a file containing\n          the settings password.\n        \n      The settings password is used for certain settings which need to\n      be stored in encrypted form for security reasons. At the moment,\n      the only encrypted setting is the iSCSI initiator secret, see\n      Section 8.17, “VBoxManage storageattach”. As long as no\n      settings password is specified, this information is stored in\n      plain text. After using the\n      --settingspw|--settingspwfile option once, it\n      must be always used. Otherwise, the encrypted setting cannot be\n      unencrypted.\n    8.4. VBoxManage list\n      The list command gives relevant information\n      about your system and information about Oracle VM VirtualBox's current\n      settings.\n    \n      The following subcommands are available with VBoxManage\n      list:\n    \nvms: Lists all virtual machines currently\n          registered with Oracle VM VirtualBox. By default this displays a\n          compact list with each VM's name and UUID. If you also specify\n          --long or -l, this will be a\n          detailed list as with the showvminfo\n          command, see Section 8.5, “VBoxManage showvminfo”.\n        \nrunningvms: Lists all currently running\n          virtual machines by their unique identifiers (UUIDs) in the\n          same format as with vms.\n        \nostypes: Lists all guest operating systems\n          presently known to Oracle VM VirtualBox, along with the identifiers\n          used to refer to them with the modifyvm\n          command.\n        \nhostdvds, hostfloppies:\n          Lists the DVD, floppy, bridged networking, and host-only\n          networking interfaces on the host, along with the name used to\n          access them from within Oracle VM VirtualBox.\n        \nintnets: Displays information about the\n          internal networks.\n        \nbridgedifs, hostonlyifs,\n          natnets, dhcpservers:\n          Lists the bridged network interfaces, host-only network\n          interfaces, NAT network interfaces, and DHCP servers currently\n          available on the host. See\n          Chapter 6, Virtual Networking.\n        \nhostinfo: Displays information about the\n          host system, such as CPUs, memory size, and operating system\n          version.\n        \nhostcpuids: Lists the CPUID parameters for\n          the host CPUs. This can be used for a more fine grained\n          analyis of the host's virtualization capabilities.\n        \nhddbackends: Lists all known virtual disk\n          back-ends of Oracle VM VirtualBox. For each such format, such as\n          VDI, VMDK, or RAW, this subcommand lists the back-end's\n          capabilities and configuration.\n        \nhdds, dvds,\n          floppies: Shows information about virtual\n          disk images currently in use by Oracle VM VirtualBox, including all\n          their settings, the unique identifiers (UUIDs) associated with\n          them by Oracle VM VirtualBox and all files associated with them.\n          This is the command-line equivalent of the Virtual Media\n          Manager. See Section 5.3, “The Virtual Media Manager”.\n        \nusbhost: Shows information about USB\n          devices attached to the host, including information useful for\n          constructing USB filters and whether they are currently in use\n          by the host.\n        \nusbfilters: Lists all global USB filters\n          registered with Oracle VM VirtualBox and displays the filter\n          parameters. Global USB filters are for devices which are\n          accessible to all virtual machines.\n        \nsystemproperties: Displays some global\n          Oracle VM VirtualBox settings, such as minimum and maximum guest RAM\n          and virtual hard disk size, folder settings and the current\n          authentication library in use.\n        \nextpacks: Displays all Oracle VM VirtualBox\n          extension packs that are currently installed. See\n          Section 1.5, “Installing Oracle VM VirtualBox and Extension Packs” and\n          Section 8.41, “VBoxManage extpack”.\n        \ngroups: Displays details of the VM Groups.\n          See Section 1.9, “Using VM Groups”.\n        \nwebcams: Displays a list of webcams\n          attached to the running VM. The output format is a list of\n          absolute paths or aliases that were used for attaching the\n          webcams to the VM using the webcam attach command.\n        \nscreenshotformats: Displays a list of\n          available screenshot formats.\n        \ncloudproviders: Displays a list of cloud\n          providers that are supported by Oracle VM VirtualBox. Oracle Cloud Infrastructure is an\n          example of a cloud provider.\n        \ncloudprofiles: Displays a list of cloud\n          profiles that have been configured.\n        \n          Cloud profiles are used when exporting VMs to a cloud service.\n          See Section 1.14.5, “Exporting an Appliance to Oracle Cloud Infrastructure”.\n        8.5. VBoxManage showvminfo\n      The showvminfo command shows information about\n      a particular virtual machine. This is the same information as\n      VBoxManage list vms --long would show for all\n      virtual machines.\n    \n      You will see information as shown in the following example.\n    $ VBoxManage showvminfo \"Windows XP\"\nVirtualBox Command Line Management Interface Version version-number\n(C) 2005-2018 Oracle Corporation\nAll rights reserved.\n\nName:            Windows XP\nGuest OS:        Other/Unknown\nUUID:            1bf3464d-57c6-4d49-92a9-a5cc3816b7e7\nConfig file:     /home/username/.config/VirtualBox/Machines/Windows XP/Windows XP.xml\nMemory size:     512MB\nVRAM size:       12MB\nNumber of CPUs:  2\nBoot menu mode:  message and menu\nBoot Device (1): DVD\nBoot Device (2): HardDisk\nBoot Device (3): Not Assigned\nBoot Device (4): Not Assigned\nACPI:            on\nIOAPIC:          on\n...\n    \n      Use the --machinereadable option to produce the\n      same output, but in machine readable format with a property=value\n      string on each line. For example:\n    \n...\ngroups=\"/\"\nostype=\"Oracle (64-bit)\"\nUUID=\"457af700-bc0a-4258-aa3c-13b03da171f2\"\n...\n 8.6. VBoxManage registervm/unregistervm\n      The registervm command enables\n      you to import a virtual machine definition in an XML file into\n      Oracle VM VirtualBox. The machine must not conflict with one already\n      registered in Oracle VM VirtualBox and it may not have any hard or\n      removable disks attached. It is advisable to place the definition\n      file in the machines folder before registering it.\n    Note\n        When creating a new virtual machine with VBoxManage\n        createvm, as shown in\n        Section 8.7, “VBoxManage createvm”, you can directly specify\n        the --register option to avoid having to\n        register it separately.\n      \n      The unregistervm command unregisters a virtual\n      machine. If --delete is also specified, the\n      following files will also be deleted automatically:\n    \n          All hard disk image files, including differencing files, which\n          are used by the machine and not shared with other machines.\n        \n          Saved state files that the machine created. One if the machine\n          was in Saved state and one for each online snapshot.\n        \n          The machine XML file and its backups.\n        \n          The machine log files.\n        \n          The machine directory, if it is empty after having deleted all\n          of the above files.\n        8.7. VBoxManage createvm\n      The VBoxManage createvm command creates a new\n      XML virtual machine definition file.\n    \n      You must specify the name of the VM by using --name\n      name. This name is used by\n      default as the file name of the settings file that has the\n      .xml extension and the machine folder, which\n      is a subfolder of the\n      .config/VirtualBox/Machines folder. Note that\n      the machine folder path name varies based on the OS type and the\n      Oracle VM VirtualBox version.\n    \n      Ensure that the VM name conforms to the host OS's file name\n      requirements. If you later rename the VM, the file and folder\n      names will be updated to match the new name automatically.\n    \n      The --basefolder path\n      option specifies the machine folder path name. Note that the names\n      of the file and the folder do not change if you rename the VM.\n    \n      The --group group-ID,\n      ... option assigns the VM to the specified groups. Note\n      that group IDs always start with\n      / so that they can be nested. By\n      default, each VM is assigned membership to the\n      / group.\n    \n      The --ostype ostype\n      option specifies the guest OS to run in the VM. Run the\n      VBoxManage list ostypes command to see the\n      available OS types.\n    \n      The --uuid uuid option\n      specifies the universal unique identifier (UUID) of the VM. The\n      UUID must be unique within the namespace of the host or of its VM\n      group memberships. By default, the VBoxManage\n      command automatically generates the UUID.\n    \n      The --default option applies a\n      default hardware configuration for the specified guest OS. By\n      default, the VM is created with minimal hardware.\n    \n      The --register option registers the VM with your\n      Oracle VM VirtualBox installation. By default, the VBoxManage\n      createvm command creates only the XML configuration for\n      the VM but does not registered the VM. If you do not register the\n      VM at creation, you can run the VBoxManage\n      registervm command after you create the VM.\n    8.8. VBoxManage modifyvm\n      This command changes the properties of a registered virtual\n      machine which is not running. Most of the properties that this\n      command makes available correspond to the VM settings that\n      Oracle VM VirtualBox graphical user interface displays in each VM's\n      Settings dialog. These are\n      described in Chapter 3, Configuring Virtual Machines. However, some of\n      the more advanced settings are only available through the\n      VBoxManage interface.\n    \n      These commands require that the machine is powered off, neither\n      running nor in a Saved state. Some machine settings can also be\n      changed while a machine is running. Those settings will then have\n      a corresponding subcommand with the VBoxManage\n      controlvm subcommand. See\n      Section 8.13, “VBoxManage controlvm”.\n    8.8.1. General Settings\n        The following general settings are available through\n        VBoxManage modifyvm:\n      \n--name <name>:\n            Changes the VM's name and can be used to rename the internal\n            virtual machine files, as described in\n            Section 8.7, “VBoxManage createvm”.\n          \n--groups <group>,\n            ...: Changes the group membership of a VM.\n            Groups always start with a\n            / and can be nested. By\n            default VMs are in group /.\n          \n--description <desc>:\n            Changes the VM's description, which is a way to record\n            details about the VM in a way which is meaningful for the\n            user. The GUI interprets HTML formatting, the command line\n            allows arbitrary strings potentially containing multiple\n            lines.\n          \n--ostype <ostype>:\n            Specifies what guest operating system is supposed to run in\n            the VM. To learn about the various identifiers that can be\n            used here, use VBoxManage list ostypes.\n          \n--iconfile\n            <filename>: Specifies the absolute\n            path on the host file system for the Oracle VM VirtualBox icon to\n            be displayed in the VM.\n          \n--memory\n            <memorysize>: Sets the amount of RAM,\n            in MB, that the virtual machine should allocate for itself\n            from the host. See Section 1.7, “Creating Your First Virtual Machine”.\n          \n--pagefusion on|off:\n            Enables and disables the Page Fusion feature. Page Fusion is\n            disabled by default. The Page Fusion feature minimises\n            memory duplication between VMs with similar configurations\n            running on the same host. See\n            Section 4.10.2, “Page Fusion”.\n          \n--vram <vramsize>:\n            Sets the amount of RAM that the virtual graphics card should\n            have. See Section 3.6, “Display Settings”.\n          \n--acpi on|off and\n            --ioapic on|off: Determines\n            whether the VM has ACPI and I/O APIC support. See\n            Section 3.5.1, “Motherboard Tab”.\n          \n--pciattach <host PCI address [@ guest\n            PCI bus address]>: Attaches a specified\n            PCI network controller on the host to a specified PCI bus on\n            the guest.\n\n\n          \n--pcidetach <host PCI\n            address>: Detaches a specified PCI\n            network controller on the host from the attached PCI bus on\n            the guest.\n\n\n          \n--hardwareuuid\n            <uuid>: The UUID presented to the\n            guest through memory tables (DMI/SMBIOS), hardware, and\n            guest properties. By default this is the same as the VM\n            UUID. This setting is useful when cloning a VM. Teleporting\n            takes care of this automatically.\n          \n--cpus <cpucount>:\n            Sets the number of virtual CPUs for the virtual machine, see\n            Section 3.5.2, “Processor Tab”. If CPU hot-plugging\n            is enabled, this then sets the maximum\n            number of virtual CPUs that can be plugged into the virtual\n            machines.\n          \n--cpuhotplug on|off:\n            Enables CPU hot-plugging. When enabled, virtual CPUs can be\n            added to and removed from a virtual machine while it is\n            running. See Section 9.4, “CPU Hot-Plugging”.\n          \n--plugcpu|unplugcpu\n            <id>: If CPU hot-plugging is enabled,\n            this setting adds or removes a virtual CPU on the virtual\n            machine. <id>\n            specifies the index of the virtual CPU to be added or\n            removed and must be a number from 0 to the maximum number of\n            CPUs configured with the\n            --cpus option. CPU 0 can\n            never be removed.\n          \n--cpuexecutioncap\n            <1-100>: Controls how much CPU time a\n            virtual CPU can use. A value of 50 implies a single virtual\n            CPU can use up to 50% of a single host CPU.\n          \n--pae on|off: Enables and\n            disables PAE. See Section 3.5.2, “Processor Tab”.\n          \n--longmode on|off: Enables\n            and disables long mode. See\n            Section 3.5.2, “Processor Tab”.\n          \n--spec-ctrl on|off: Enables\n            and disables the exposure of speculation control interfaces\n            to the guest, provided they are available on the host.\n            Depending on the host CPU and workload, enabling speculation\n            control may significantly reduce performance.\n          \n--cpu-profile <host|intel\n            80[86|286|386]>: Enables specification\n            of a profile for guest CPU emulation. Specify either one\n            based on the host system CPU (host), or one from a number of\n            older Intel Micro-architectures: 8086, 80286, 80386.\n          \n--hpet on|off: Enables and\n            disables a High Precision Event Timer (HPET) which can\n            replace the legacy system timers. This is turned off by\n            default. Note that Windows supports a HPET only from Vista\n            onwards.\n          \n--hwvirtex on|off: Enables\n            and disables the use of hardware virtualization extensions,\n            such as Intel VT-x or AMD-V, in the processor of your host\n            system. See Section 10.3, “Hardware Virtualization”.\n          \n--triplefaultreset on|off:\n            Enables resetting of the guest instead of triggering a Guru\n            Meditation. Some guests raise a triple fault to reset the\n            CPU so sometimes this is desired behavior. Works only for\n            non-SMP guests.\n          \n--apic on|off: Enables and\n            disables I/O APIC. With I/O APIC, operating systems can use\n            more than 16 interrupt requests (IRQs) thus avoiding IRQ\n            sharing for improved reliability. This setting is enabled by\n            default. See Section 3.5.1, “Motherboard Tab”.\n          \n--x2apic on|off: Enables\n            and disables CPU x2APIC support. CPU x2APIC support helps\n            operating systems run more efficiently on high core count\n            configurations, and optimizes interrupt distribution in\n            virtualized environments. This setting is enabled by\n            default. Disable this setting when using host or guest\n            operating systems that are incompatible with x2APIC support.\n          \n--paravirtprovider\n            none|default|legacy|minimal|hyperv|kvm:\n            Specifies which paravirtualization interface to provide to\n            the guest operating system. Specifying\n            none explicitly turns off\n            exposing any paravirtualization interface. The option\n            default selects an\n            appropriate interface when starting the VM, depending on the\n            guest OS type. This is the default option chosen when\n            creating new VMs. The\n            legacy option is used for\n            VMs which were created with older Oracle VM VirtualBox versions\n            and will pick a paravirtualization interface when starting\n            the VM with Oracle VM VirtualBox 5.0 and newer. The\n            minimal provider is\n            mandatory for Mac OS X guests.\n            kvm and\n            hyperv are recommended for\n            Linux and Windows guests respectively. These options are\n            explained in Section 10.5, “Paravirtualization Providers”.\n          \n--paravirtdebug <keyword=value>\n            [,<keyword=value> ...]: Specifies\n            debugging options specific to the paravirtualization\n            provider configured for this VM. See the provider specific\n            options in Section 9.29, “Paravirtualized Debugging” for a list of\n            supported keyword-value pairs for each provider.\n          \n--nestedpaging on|off: If\n            hardware virtualization is enabled, this additional setting\n            enables or disables the use of the nested paging feature in\n            the processor of your host system. See\n            Section 10.3, “Hardware Virtualization” and\n            Section 13.4.1, “CVE-2018-3646”.\n          \n--largepages on|off: If\n            hardware virtualization and nested\n            paging are enabled, for Intel VT-x only, an additional\n            performance improvement of up to 5% can be obtained by\n            enabling this setting. This causes the hypervisor to use\n            large pages to reduce TLB use and overhead.\n          \n--vtxvpid on|off: If\n            hardware virtualization is enabled, for Intel VT-x only,\n            this additional setting enables or disables the use of the\n            tagged TLB (VPID) feature in the processor of your host\n            system. See Section 10.3, “Hardware Virtualization”.\n          \n--vtxux on|off: If hardware\n            virtualization is enabled, for Intel VT-x only, this setting\n            enables or disables the use of the unrestricted guest mode\n            feature for executing your guest.\n          \n--nested-hw-virt on|off: If\n            hardware virtualization is enabled, this setting enables or\n            disables passthrough of hardware virtualization features to\n            the guest. See Section 9.33, “Nested Virtualization”.\n          \n--accelerate3d on|off: If\n            the Guest Additions are installed, this setting enables or\n            disables hardware 3D acceleration. See\n            Section 4.5.1, “Hardware 3D Acceleration (OpenGL and Direct3D 8/9)”.\n          \n--accelerate2dvideo on|off:\n            If the Guest Additions are installed, this setting enables\n            or disables 2D video acceleration. See\n            Section 4.5.2, “Hardware 2D Video Acceleration for Windows Guests”.\n          \n--chipset piix3|ich9: By\n            default, Oracle VM VirtualBox emulates an Intel PIIX3 chipset.\n            Usually there is no reason to change the default setting\n            unless this is required to relax some of its constraints.\n            See Section 3.5.1, “Motherboard Tab”.\n          \n            You can influence the BIOS logo that is displayed when a\n            virtual machine starts up with a number of settings. By\n            default, an Oracle VM VirtualBox logo is displayed.\n          \n            With --bioslogofadein\n            on|off and\n            --bioslogofadeout on|off,\n            you can determine whether the logo should fade in and out,\n            respectively.\n          \n            With --bioslogodisplaytime\n            <msec> you can set how long the logo\n            should be visible, in milliseconds.\n          \n            With --bioslogoimagepath\n            <imagepath> you can replace the image\n            that is shown with your own logo. The image must be an\n            uncompressed 256 color BMP file without color space\n            information (Windows 3.0 format). The image must not be\n            bigger than 640 x 480.\n          \n--biosbootmenu\n            disabled|menuonly|messageandmenu: Specifies\n            whether the BIOS enables the user to select a temporary boot\n            device. The menuonly option\n            suppresses the message, but the user can still press F12 to\n            select a temporary boot device.\n          \n--biosapic\n            x2apic|apic|disabled: Specifies the\n            firmware APIC level to be used. Options are: x2apic, apic or\n            disabled (no apic or x2apic) respectively.\n          \n            Note that if x2apic is specified and x2APIC is unsupported\n            by the VCPU, biosapic downgrades to apic, if supported.\n            Otherwise biosapic downgrades to disabled. Similarly, if\n            apic is specified, and APIC is unsupported, a downgrade to\n            disabled results.\n          \n--biossystemtimeoffset\n            <ms>: Specifies a fixed time offset,\n            in milliseconds, of the guest relative to the host time. If\n            the offset is positive, the guest time runs ahead of the\n            host time.\n          \n--biospxedebug on|off:\n            Enables or disables additional debugging output when using\n            the Intel PXE boot ROM. The output is written to the release\n            log file. See Section 12.1.2, “Collecting Debugging Information”.\n          \n--system-uuid-le on|off:\n            Enables or disables representing the system UUID in little\n            endian form. The default value is on for\n            new VMs. For old VMs the setting is off\n            to keep the content of the DMI/SMBIOS table unchanged, which\n            can be important for Windows license activation.\n          \n--boot<1-4>\n            none|floppy|dvd|disk|net: Specifies the\n            boot order for the virtual machine. There are four\n            slots, which the VM will try to access\n            from 1 to 4, and for each of which you can set a device that\n            the VM should attempt to boot from.\n          \n--rtcuseutc on|off: Sets\n            the real-time clock (RTC) to operate in UTC time. See\n            Section 3.5.1, “Motherboard Tab”.\n          \n--graphicscontroller\n            none|vboxvga|vmsvga|vboxsvga: Specifies the\n            use of a graphics controller, with an option to choose a\n            specific type. See Section 3.6.1, “Screen Tab”.\n          \n--snapshotfolder\n            default|<path>: Specifies the folder\n            where snapshots are kept for a virtual machine.\n          \n--firmware\n            bios|efi|efi32|efi64: Specifies the\n            firmware to be used to boot the VM: Available options are:\n            BIOS, or one of the EFI options: efi, efi32, or efi64. Use\n            EFI options with care.\n          \n--guestmemoryballoon\n            <size> Sets the default size of the\n            guest memory balloon. This is the memory allocated by the\n            Oracle VM VirtualBox Guest Additions from the guest operating\n            system and returned to the hypervisor for reuse by other\n            virtual machines.\n            <size> must be\n            specified in megabytes. The default size is 0 megabytes. See\n            Section 4.10.1, “Memory Ballooning”.\n          \n--defaultfrontend\n            default|<name>: Specifies the default\n            frontend to be used when starting this VM. See\n            Section 8.12, “VBoxManage startvm”.\n          \n--vm-process-priority\n            default|flat|low|normal|high: Specifies the\n            priority scheme of the VM process to be used when starting\n            this VM and during VM execution. See\n            Section 8.12, “VBoxManage startvm”.\n          8.8.2. Networking Settings\n        The following networking settings are available through\n        VBoxManage modifyvm. With all these settings,\n        the decimal number directly following the option name, 1-N in\n        the list below, specifies the virtual network adapter whose\n        settings should be changed.\n      \n--nic<1-N>\n            none|null|nat|natnetwork|bridged|intnet|hostonly|generic:\n            Configures the type of networking for each of the VM's\n            virtual network cards. Options are: not present\n            (none), not connected to\n            the host (null), use\n            network address translation\n            (nat), use the new network\n            address translation engine\n            (natnetwork), bridged\n            networking (bridged), or\n            use internal networking\n            (intnet), host-only\n            networking (hostonly), or\n            access rarely used sub-modes\n            (generic). These options\n            correspond to the modes described in\n            Section 6.2, “Introduction to Networking Modes”.\n          \n--nictype<1-N>\n            Am79C970A|Am79C973|Am79C970|82540EM|82543GC|82545EM|virtio:\n            Enables you to specify the networking hardware that\n            Oracle VM VirtualBox presents to the guest for a specified VM\n            virtual network card. See Section 6.1, “Virtual Networking Hardware”.\n          \n--cableconnected<1-N>\n            on|off: Enables you to temporarily\n            disconnect a virtual network interface, as if a network\n            cable had been pulled from a real network card. This might\n            be useful, for example for resetting certain software\n            components in the VM.\n          \n            With the nictrace options,\n            you can optionally trace network traffic by dumping it to a\n            file, for debugging purposes.\n          \n            With --nictrace<1-N>\n            on|off, you can enable network tracing for\n            a particular virtual network card.\n          \n            If enabled, you must specify with\n            --nictracefile<1-N>\n            <filename> the absolute path of the\n            file the trace should be logged to.\n          \n--nicproperty<1-N>\n            <paramname>=\"paramvalue\": This\n            option, in combination with\n            nicgenericdrv enables you\n            to pass parameters to rarely-used network backends.\n          \n            These parameters are backend engine-specific, and are\n            different between UDP Tunnel and the VDE backend drivers.\n            For examples, see Section 6.8, “UDP Tunnel Networking”.\n          \n--nicspeed<1-N>\n            <kbps>: Only has an effect if generic\n            networking has been enabled for a particular virtual network\n            card. See the --nic option.\n            This mode enables access to rarely used networking\n            sub-modes, such as VDE network or UDP Tunnel. This option\n            specifies the throughput rate in KBps.\n          \n--nicbootprio<1-N>\n            <priority>: Specifies the order in\n            which NICs are tried for booting over the network, using\n            PXE. The priority is an integer in the 0 to 4 range.\n            Priority 1 is the highest, priority 4 is low. Priority 0,\n            which is the default unless otherwise specified, is the\n            lowest.\n          \n            Note that this option only has an effect when the Intel PXE\n            boot ROM is used.\n          \n--nicpromisc<1-N>\n            deny|allow-vms|allow-all: Enables you to\n            specify how promiscuous mode is handled for the specified VM\n            virtual network card. This setting is only relevant for\n            bridged networking. deny,\n            the default setting, hides any traffic not intended for the\n            VM. allow-vms hides all\n            host traffic from the VM, but allows the VM to see traffic\n            to and from other VMs.\n            allow-all removes this\n            restriction completely.\n          \n--nicbandwidthgroup<1-N>\n            none|<name>: Adds and removes an\n            assignment of a bandwidth group for the specified virtual\n            network interface. Specifying\n            none removes any current\n            bandwidth group assignment from the specified virtual\n            network interface. Specifying\n            <name> adds an\n            assignment of a bandwidth group to the specified virtual\n            network interface.\n          \n            See Section 6.10, “Limiting Bandwidth for Network Input/Output”.\n          \n--bridgeadapter<1-N>\n            none|<devicename>: Only has an effect\n            if bridged networking has been enabled for a virtual network\n            card. See the --nic option.\n            Use this option to specify which host interface the given\n            virtual network interface will use. See\n            Section 6.5, “Bridged Networking”.\n          \n--hostonlyadapter<1-N>\n            none|<devicename>: Only has an effect\n            if host-only networking has been enabled for a virtual\n            network card. See the --nic\n            option. Use this option to specify which host-only\n            networking interface the given virtual network interface\n            will use. See Section 6.7, “Host-Only Networking”.\n          \n--intnet<1-N>\n            network: Only has an effect if internal\n            networking has been enabled for a virtual network card. See\n            the --nic option. Use this\n            option to specify the name of the internal network. See\n            Section 6.6, “Internal Networking”.\n          \n--nat-network<1-N> <network\n            name>: If the networking type is set to\n            natnetwork, not\n            nat, then this setting\n            specifies the name of the NAT network this adapter is\n            connected to. Optional.\n          \n--nicgenericdrv<1-N> <backend\n            driver>: Only has an effect if generic\n            networking has been enabled for a virtual network card. See\n            the --nic option. This mode\n            enables you to access rarely used networking sub-modes, such\n            as VDE network or UDP Tunnel.\n          \n--macaddress<1-N>\n            auto|<mac>: With this option you can\n            set the MAC address of a particular network adapter on the\n            VM. Normally, each network adapter is assigned a random\n            address by Oracle VM VirtualBox at VM creation.\n          8.8.2.1. NAT Networking Settings\n          The following NAT networking settings are available through\n          VBoxManage modifyvm. With all these\n          settings, the decimal number directly following the option\n          name, 1-N in the list below, specifies the virtual network\n          adapter whose settings should be changed.\n        \n--natnet<1-N>\n              <network>|default: If the\n              networking type is set to\n              nat, not\n              natnetwork, then this\n              setting specifies the IP address range to be used for this\n              network. See Section 9.8, “Fine Tuning the Oracle VM VirtualBox NAT Engine”.\n            \n--natpf<1-N>\n              [<name>],tcp|udp,[<hostip>],<hostport>,[<guestip>],\n              <guestport>: Defines a NAT\n              port-forwarding rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.\n            \n--natpf<1-N> delete\n              <name>: Deletes a NAT\n              port-forwarding rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.\n            \n--nattftpprefix<1-N>\n              <prefix>: Defines a prefix for the\n              built-in TFTP server. For example, where the boot file is\n              located. See Section 6.3.2, “PXE Booting with NAT” and\n              Section 9.8.2, “Configuring the Boot Server (Next Server) of a NAT Network Interface”.\n            \n--nattftpfile<1-N>\n              <bootfile>: Defines the TFT boot\n              file. See Section 9.8.2, “Configuring the Boot Server (Next Server) of a NAT Network Interface”.\n            \n--nattftpserver<1-N>\n              <tftpserver>: Defines the TFTP\n              server address to boot from. See\n              Section 9.8.2, “Configuring the Boot Server (Next Server) of a NAT Network Interface”.\n            \n--nattbindip<1-N>\n              <ip;>: Oracle VM VirtualBox's NAT engine\n              normally routes TCP/IP packets through the default\n              interface assigned by the host's TCP/IP stack. Use this\n              setting to instruct the NAT engine to bind to a specified\n              IP address instead. See\n              Section 9.8.3, “Tuning TCP/IP Buffers for NAT”.\n            \n--natdnspassdomain<1-N>\n              on|off: Specifies whether the built-in\n              DHCP server passes the domain name for network name\n              resolution.\n            \n--natdnsproxy<1-N>\n              on|off: Makes the NAT engine proxy all\n              guest DNS requests to the host's DNS servers. See\n              Section 9.8.5, “Enabling DNS Proxy in NAT Mode”.\n            \n--natdnshostresolver<1-N>\n              on|off: Makes the NAT engine use the\n              host's resolver mechanisms to handle DNS requests. See\n              Section 9.8.5, “Enabling DNS Proxy in NAT Mode”.\n            \n--natsettings<1-N>\n              [<mtu>],[<socksnd>],[<sockrcv>],[<tcpsnd>],\n              [<tcprcv>]: Controls several NAT\n              settings. See Section 9.8.3, “Tuning TCP/IP Buffers for NAT”.\n            \n--nataliasmode<1-N>\n              default|[log],[proxyonly],[sameports]:\n              Defines behaviour of the NAT engine core: log - enables\n              logging, proxyonly - switches off aliasing mode and makes\n              NAT transparent, sameports - enforces the NAT engine to\n              send packets through the same port as they originated on,\n              default - disable all aliasing modes. See\n              Section 9.8.7, “Configuring Aliasing of the NAT Engine”.\n            8.8.3. Miscellaneous Settings\n        The following hardware settings, such as serial port, audio,\n        clipboard, drag and drop, monitor, and USB settings are\n        available through VBoxManage modifyvm:\n      \n--mouse\n            <ps2|usb|usbtablet|usbmultitouch>:\n            Specifies the mode of the mouse to be used in the VM.\n            Available options are: ps2, usb, usbtablet, usbmultitouch.\n          \n--keyboard <ps2|usb>:\n            Specifies the mode of the keyboard to be used in the VM.\n            Available options are: ps2, usb.\n          \n--uart<1-N> off|<I/O base>\n            <IRQ>: Configures virtual serial\n            ports for the VM. See Section 3.10, “Serial Ports”.\n          \n--uartmode<1-N>\n            <arg>: Controls how Oracle VM VirtualBox\n            connects a given virtual serial port, configured with the\n            --uartX setting, to the\n            host on which the virtual machine is running. As described\n            in Section 3.10, “Serial Ports”, for each such port, you\n            can specify <arg> as\n            one of the following options:\n          \ndisconnected: Even\n                though the serial port is shown to the guest, it has no\n                \"other end\". This is like a real COM port without a\n                cable.\n              \nserver\n                <pipename>: On a Windows host,\n                this tells Oracle VM VirtualBox to create a named pipe on the\n                host named\n                <pipename> and\n                connect the virtual serial device to it. Note that\n                Windows requires that the name of a named pipe begins\n                with \\\\.\\pipe\\.\n              \n                On a Linux host, instead of a named pipe, a local domain\n                socket is used.\n              \nclient\n                <pipename>: Operates as for\n                server, except that the\n                pipe, or local domain socket, is not created by\n                Oracle VM VirtualBox but is assumed to exist already.\n              \ntcpserver <port>:\n                Configures Oracle VM VirtualBox to create a TCP socket on the\n                host with TCP\n                <port> and\n                connect the virtual serial device to it. Note that\n                UNIX-like systems require ports over 1024 for normal\n                users.\n              \ntcpclient\n                <hostname:port>: Operates as for\n                tcpserver, except that\n                the TCP socket is not created by Oracle VM VirtualBox, but is\n                assumed to exist already.\n              \nfile <file>:\n                Redirects the serial port output to a raw file\n                <file> specified by its absolute path on the host\n                file system.\n              \n<devicename>: If,\n                instead of the above options, the device name of a\n                physical hardware serial port of the host is specified,\n                the virtual serial port is connected to that hardware\n                port. On a Windows host, the device name will be a COM\n                port such as COM1. On a\n                Linux host, the device name will be\n                /dev/ttyS0 or similar. This enables\n                you to wire up a real serial port to a virtual machine.\n              \nuarttype <1-N>\n            16450|16550A|16750: Configures the UART\n            type for a virtual serial port. The default UART type is\n            16550A.\n          \n--lptmode<1-N>\n            <Device>: Specifies the Device Name\n            of the parallel port that the Parallel Port feature will be\n            using. Use this before\n--lpt. This feature depends\n            on the host operating system. For Windows hosts, use a\n            device name such as lpt1. On Linux hosts, use a device name\n            such as /dev/lp0.\n          \n--lpt<1-N> <I/O base>\n            <IRQ>: Specifies the I/O address of\n            the parallel port and the IRQ number that the Parallel Port\n            feature will be using. Optional. Use this\n            after\n--lptmod. I/O base address\n            and IRQ are the values that guest sees. For example, the\n            values avalable under guest Device Manager.\n          \n--audio\n            none|null|dsound|oss|alsa|pulse|coreaudio:\n            Specifies whether the VM should have audio support, and if\n            so, which type. The list of supported audio types depends on\n            the host and can be determined with VBoxManage\n            modifyvm.\n          \n--audiocontroller\n            ac97|hda|sb16: Specifies the audio\n            controller to be used with the VM.\n          \n--audiocodec\n            stac9700|ad1980|stac9221|sb16: Specifies\n            the audio codec to be used with the VM.\n          \n--audioin on: Specifies\n            whether capturing audio from the host is enabled or\n            disabled.\n          \n--audioout on: Specifies\n            whether audio playback from the guest is enabled or\n            disabled.\n          \n--clipboard-mode\n            disabled|hosttoguest|guesttohost|bidirectional:\n            Configues how the guest or host operating system's clipboard\n            should be shared with the host or guest. See\n            Section 3.4, “General Settings”. This setting requires\n            that the Guest Additions be installed in the virtual\n            machine.\n          \n--clipboard-file-transfers\n            enabled|disabled: Specifies if clipboard\n            file transfers are allowed between host and guest OSes or\n            not.\n          \n--draganddrop\n            disabled|hosttoguest|guesttohost|bidirectional:\n            Specifies the drag and drop mode to use between the host and\n            the virtual machine. See Section 4.4, “Drag and Drop”.\n            This requires that the Guest Additions be installed in the\n            virtual machine.\n          \n--monitorcount\n            <count>: Enables multi-monitor\n            support. See Section 3.6, “Display Settings”.\n          \n--usb on|off: Enables and\n            disables the VM's virtual USB controller. See\n            Section 3.11.1, “USB Settings”.\n          \n--usbehci on|off: Enables\n            and disables the VM's virtual USB 2.0 controller. See\n            Section 3.11.1, “USB Settings”.\n          \n--usbxhci on|off: Enables\n            and disables the VM's virtual USB 3.0 controller. See\n            Section 3.11.1, “USB Settings”.\n          \n--usbrename <oldname>\n            <newname>: Enables renaming of the\n            VM's virtual USB controller from <oldname> to\n            <newname>.\n          8.8.4. Recording Settings\n        The VBoxManage modifyvm command enables you\n        to modify recording settings for video recording, audio\n        recording, or both.\n      \n        Use the following options to update the recording settings:\n      \n--recording on|off enables or disables the\n            recording of a VM session into a WebM/VP8 file. When this\n            option value is on,\n            recording begins when the VM session starts.\n          \n--recordingscreens\n            all|screen-ID\n            [screen-ID ...] enables\n            you to specify which VM screens to record. The recording for\n            each screen that you specify is saved to its own file.\n          \n--recordingfile\n            filename specifies the\n            file in which to save the recording.\n          \n--recordingmaxsize\n            MB specifies the maximum\n            size of the recorded video file in megabytes. The recording\n            stops when the file reaches the specified size. If this\n            value is zero, the recording continues until you stop the\n            recording.\n          \n--recordingmaxtime\n            seconds specifies the\n            maximum amount time to record in seconds. The recording\n            stops after the specified number of seconds elapses. If this\n            value is zero, the recording continues until you stop the\n            recording.\n          \n--recordingopts\n            keyword=value[,keyword=value\n            ...] specifies additional video-recording options\n            in a comma-separated keyword-value format. For example,\n            foo=bar,a=b.\n          \n            Only use this option only if you are an advanced user. For\n            information about keywords, see Oracle VM\n            VirtualBox Programming Guide and Reference.\n          \n--recordingvideofps\n            fps specifies the\n            maximum number of video frames per second (FPS) to record.\n            Frames that have a higher frequency are skipped. Increasing\n            this value reduces the number of skipped frames and\n            increases the file size.\n          \n--recordingvideorate\n            bit-rate specifies the\n            bit rate of the video in kilobits per second. Increasing\n            this value improves the appearance of the video at the cost\n            of an increased file size.\n          \n--recordingvideores\n            widthxheight\n            specifies the video resolution of the recorded video in\n            pixels.\n          8.8.5. Remote Machine Settings\n        The following settings that affect remote machine behavior are\n        available through VBoxManage modifyvm:\n      \n--vrde on|off: Enables and\n            disables the VirtualBox Remote Desktop Extension (VRDE)\n            server.\n          \n--vrdeproperty\n            \"TCP/Ports|Address=<value>\": Sets the\n            port numbers and IP address on the VM that the VRDE server\n            can bind to.\n          \n                For TCP/Ports, <value> should be a port or a range\n                of ports that the VRDE server can bind to.\n                default or\n                0 means port 3389, the\n                standard port for RDP. See the description for the\n                --vrdeport option in\n                Section 8.8.5, “Remote Machine Settings”.\n              \n                For TCP/Address, <value> should be the IP address\n                of the host network interface that the VRDE server will\n                bind to. If specified, the server will accept\n                connections only on the specified host network\n                interface. See the description for the\n                --vrdeaddress option in\n                Section 8.8.5, “Remote Machine Settings”.\n              \n--vrdeproperty\n            \"VideoChannel/Enabled|Quality|DownscaleProtection=<value>\":\n            Sets the VRDP video redirection properties.\n          \n                For VideoChannel/Enabled, <value> can be set to\n                \"1\", switching the VRDP video channel on. See\n                Section 7.1.9, “VRDP Video Redirection”.\n              \n                For VideoChannel/Quality, <value> should be set\n                between 10 and 100% inclusive, representing a JPEG\n                compression level on the VRDE server video channel.\n                Lower values mean lower quality but higher compression.\n                See Section 7.1.9, “VRDP Video Redirection”.\n              \n                For VideoChannel/DownscaleProtection, <value> can\n                be set to \"1\" to enable the videochannel downscale\n                protection feature. When enabled, if a video's size\n                equals the shadow buffer size, then it is regarded as a\n                full screen video, and is displayed. But if its size is\n                between fullscreen and the downscale threshold then it\n                is not displayed, as it could be an\n                application window, which would be unreadable when\n                downscaled. When the downscale protection feature is\n                disabled, an attempt is always made to display videos.\n              \n--vrdeproperty\n            \"Client/DisableDisplay|DisableInput|DisableAudio|DisableUSB=1\":\n            Disables one of the VRDE server features: Display, Input,\n            Audio or USB respectively. To reenable a feature, use\n            \"Client/DisableDisplay=\" for example. See\n            Section 7.1.10, “VRDP Customization”.\n          \n--vrdeproperty\n            \"Client/DisableClipboard|DisableUpstreamAudio=1\":\n            Disables one of the VRDE server features: Clipboard or\n            UpstreamAudio respectively. To reenable a feature, use\n            \"Client/DisableClipboard=\" for example. See\n            Section 7.1.10, “VRDP Customization”.\n          \n--vrdeproperty\n            \"Client/DisableRDPDR=1\": Disables the VRDE\n            server feature: RDP device redirection for smart cards. To\n            reenable this feature, use \"Client/DisableRDPR=\".\n          \n--vrdeproperty\n            \"H3DRedirect/Enabled=1\": Enables the VRDE\n            server feature: 3D redirection. To disable this feature, use\n            \"H3DRedirect/Enabled=\".\n          \n--vrdeproperty\n            \"Security/Method|ServerCertificate|ServerPrivateKey|CACertificate=<value>\":\n            Sets the desired security method and path of server\n            certificate, path of server private key, path of CA\n            certificate, that are used for a connection.\n          \n--vrdeproperty\n                \"Security/Method=<value>\" sets\n                the desired security method, which is used for a\n                connection. Valid values are:\n              \nNegotiate: Both\n                    Enhanced (TLS) and Standard RDP Security connections\n                    are allowed. The security method is negotiated with\n                    the client. This is the default setting.\n                  \nRDP: Only Standard\n                    RDP Security is accepted.\n                  \nTLS: Only Enhanced\n                    RDP Security is accepted. The client must support\n                    TLS.\n                  \n                See Section 7.1.6, “RDP Encryption”.\n              \n--vrdeproperty\n                \"Security/ServerCertificate=<value>\"\n                where <value> is the absolute path of the server\n                certificate. See Section 7.1.6, “RDP Encryption”.\n              \n--vrdeproperty\n                \"Security/ServerPrivateKey=<value>\"\n                where <value> is the absolute path of the server\n                private key. See Section 7.1.6, “RDP Encryption”.\n              \n--vrdeproperty\n                \"Security/CACertificate=<value>\"\n                where <value> is the absolute path of the CA self\n                signed certificate. See Section 7.1.6, “RDP Encryption”.\n              \n--vrdeproperty\n            \"Audio/RateCorrectionMode|LogPath=<value>\"\n            sets the audio connection mode, or path of the audio\n            logfile.\n          \n--vrdeproperty\n                \"Audio/RateCorrectionMode=<value>\"\n                where <value> is the desired rate correction mode.\n                Allowed values are:\n              \nVRDP_AUDIO_MODE_VOID:\n                    No mode specified, use to unset any Audio mode\n                    already set.\n                  \nVRDP_AUDIO_MODE_RC:\n                    Rate correction mode.\n                  \nVRDP_AUDIO_MODE_LPF:\n                    Low pass filter mode.\n                  \nVRDP_AUDIO_MODE_CS:\n                    Client sync mode to prevent underflow or overflow of\n                    the client queue.\n                  \n--vrdeproperty\n                \"Audio/LogPath=<value>\" where\n                <value> is the absolute path of the Audio log\n                file.\n              \n--vrdeextpack\n            default|<name>: Specifies the library\n            to use for accessing the VM remotely. The default is to use\n            the RDP code which is part of the Oracle VM VirtualBox Extension\n            Pack.\n          \n--vrdeport\n            default|<ports>: A port or a range of\n            ports the VRDE server can bind to.\n            default or\n            0 means port 3389, the\n            standard port for RDP. You can specify a comma-separated\n            list of ports or ranges of ports. Use a dash between two\n            port numbers to specify a range. The VRDE server will bind\n            to one of the available ports from the\n            specified list. Only one machine can use a given port at a\n            time. For example, the option  --vrdeport\n            5000,5010-5012 will tell the server to bind\n            to one of following ports: 5000, 5010, 5011, or 5012.\n          \n--vrdeaddress <IP\n            address>: The IP address of the host\n            network interface the VRDE server will bind to. If\n            specified, the server will accept connections only on the\n            specified host network interface.\n          \n            The setting can be used to specify whether the VRDP server\n            should accept either IPv4, IPv6, or both connections:\n          \n                Only IPv4: --vrdeaddress\n                \"0.0.0.0\"\n\n                Only IPv6: --vrdeaddress\n                \"::\"\n\n                Both IPv6 and IPv4: --vrdeaddress\n                \"\"\n\n                This is the default setting.\n              \n--vrdeauthtype\n            null|external|guest: Enables you to\n            indicate use of authorization, and specify how authorization\n            will be performed. See Section 7.1.5, “RDP Authentication”.\n          \n--vrdeauthlibrary\n            default|<name>: Specifies the library\n            used for RDP authentication. See\n            Section 7.1.5, “RDP Authentication”.\n          \n--vrdemulticon on|off:\n            Enables multiple connections to be made to the same VRDE\n            server, if the server supports this feature. See\n            Section 7.1.7, “Multiple Connections to the VRDP Server”.\n          \n--vrdereusecon on|off: This\n            specifies the VRDE server behavior when multiple connections\n            are disabled. When this option is enabled, the server will\n            allow a new client to connect and will drop the existing\n            connection. When this option is disabled, the default\n            setting, a new connection will not be accepted if there is\n            already a client connected to the server.\n          \n--vrdevideochannel on|off:\n            Enables video redirection, if it is supported by the VRDE\n            server. See Section 7.1.9, “VRDP Video Redirection”.\n          \n--vrdevideochannelquality\n            <percent>: Specifies the image\n            quality for video redirection. See\n            Section 7.1.9, “VRDP Video Redirection”.\n          8.8.6. Teleporting Settings\n        With the following commands for VBoxManage\n        modifyvm you can configure a machine to be a target\n        for teleporting. See Section 7.2, “Teleporting”.\n      \n--teleporter on|off:\n            Enables and disables the teleporter feature whereby when the\n            machine is started, it waits to receive a teleporting\n            request from the network instead of booting normally.\n            Teleporting requests are received on the port and address\n            specified using the following parameters.\n          \n--teleporterport\n            <port>,\n            --teleporteraddress\n            <address>: These settings must be\n            used with --teleporter.\n            They specify the port and address the virtual machine should\n            listen to in order to receive a teleporting request sent\n            from another virtual machine.\n            <port> can be any\n            free TCP/IP port number, such as 6000.\n            <address> can be any\n            IP address or hostname and specifies the TCP/IP socket to\n            bind to. The default is 0.0.0.0, which means any address.\n          \n--teleporterpassword\n            <password>: If this optional setting\n            is used, then the teleporting request will only succeed if\n            the source machine specifies the same password as the one\n            given with this command.\n          \n--teleporterpasswordfile\n            <password>: If this optional setting\n            is used, then the teleporting request will only succeed if\n            the source machine specifies the same password as the one\n            specified in the file give with this command. Use\n            stdin to read the password\n            from stdin.\n          \n--cpuid <leaf> <eax> <ebx>\n            <ecx> <edx>: Advanced users can\n            use this setting before a teleporting operation, to restrict\n            the virtual CPU capabilities that Oracle VM VirtualBox presents to\n            the guest operating system. This must be run on both the\n            source and the target machines involved in the teleporting\n            and will then modify what the guest sees when it executes\n            the CPUID machine\n            instruction. This might help with misbehaving applications\n            that wrongly assume that certain CPU capabilities are\n            present. The meaning of the parameters is hardware\n            dependent, refer to the AMD or Intel processor\n            documentation.\n          8.8.7. Debugging Settings\n        The following settings are only relevant for low-level VM\n        debugging. Regular users will never need these settings.\n      \n--tracing-enabled on|off:\n            Enables the tracebuffer. This consumes some memory for the\n            tracebuffer and adds extra overhead.\n          \n--tracing-config\n            <config-string>: Enables tracing\n            configuration. In particular, this defines which group of\n            tracepoints are enabled.\n          \n--tracing-allow-vm-access\n            on|off: Enables and disables VM access to\n            the tracebuffer. By default, this setting is disabled.\n          8.8.8. USB Card Reader Settings\n        The following setting defines access to a USB Card Reader by the\n        guest environment. USB card readers are typically used for\n        accessing data on memory cards such as CompactFlash (CF), Secure\n        Digital (SD), or MultiMediaCard (MMC).\n      \n--usbcardreader on|off:\n            Enables and disables the USB card reader interface.\n          8.8.9. Autostarting VMs During Host System Boot\n        These settings configure the VM autostart feature, which\n        automatically starts the VM at host system boot-up. Note that\n        there are prerequisites that need to be addressed before using\n        this feature. See Section 9.21, “Starting Virtual Machines During System Boot”.\n      \n--autostart-enabled on|off:\n            Enables and disables VM autostart at host system boot-up,\n            using the specified user name.\n          \n--autostart-delay\n            <seconds>: Specifies a delay, in\n            seconds, following host system boot-up, before the VM\n            autostarts.\n          8.9. VBoxManage movevm\n      This command moves a virtual machine to a new location on the\n      host.\n    \n      Associated files of the virtual machine, such as settings files\n      and disk image files, are moved to the new location. The\n      Oracle VM VirtualBox configuration is updated automatically.\n    \n      The movevm subcommand requires the name of the\n      virtual machine which should be moved.\n    \n      Also required is the type of move operation, specified by\n      --type basic. Other types of move\n      operation may be supported in future releases.\n    \n      The --folder setting configures\n      the new location on the host file system. Enter a relative\n      pathname or a full pathname.\n    8.10. VBoxManage import\n      This command imports one or more virtual machines into\n      Oracle VM VirtualBox. You can import from either of the following:\n    \n          A virtual appliance in OVF format.\n        \n          A cloud service, such as Oracle Cloud Infrastructure. Only a single cloud instance\n          can be imported.\n        \n      See Section 1.14, “Importing and Exporting Virtual Machines” for more details on importing VMs into\n      Oracle VM VirtualBox.\n    8.10.1. Import from OVF\n        The import subcommand takes at least the path\n        name of an OVF file as input and expects the disk images, if\n        needed, to be in the same directory as the OVF file. Many\n        additional command-line options are supported. These enable you\n        to control in detail what is being imported and to modify the\n        import parameters, depending on the content of the OVF file.\n      \n        It is therefore recommended to first run the\n        import subcommand with the\n        --dry-run or\n        -n option. This will then print\n        a description of the appliance's contents to the screen how it\n        would be imported into Oracle VM VirtualBox, together with the\n        optional command-line options to influence the import behavior.\n      \n        Use of the --options\n        keepallmacs|keepnatmacs|keepdisknames option\n        enables additional fine tuning of the import operation. The\n        first two options enable you to specify how the MAC addresses of\n        every virtual network card should be handled. They can either be\n        reinitialized, which is the default setting, left unchanged\n        (keepallmacs) or left unchanged\n        when the network type is NAT\n        (keepnatmacs). If you add\n        keepdisknames all new disk\n        images are assigned the same names as the originals, otherwise\n        they are renamed.\n      \n        As an example, the following is a screen output for a sample\n        appliance containing a Windows XP guest:\n      VBoxManage import WindowsXp.ovf --dry-run\n      Interpreting WindowsXp.ovf...\n      OK.\n      Virtual system 0:\n       0: Suggested OS type: \"WindowsXP\"\n          (change with \"--vsys 0 --ostype <type>\"; use \"list ostypes\" to list all)\n       1: Suggested VM name \"Windows XP Professional_1\"\n          (change with \"--vsys 0 --vmname <name>\")\n       2: Suggested VM group \"/\"\n          (change with \"--vsys 0 --group <group>\")\n       3: Suggested VM settings file name \"/home/klaus/VirtualBox VMs/dummy2 2/dummy2 2.vbox\"\n          (change with \"--vsys 0 --settingsfile <filename>\")\n       4: Suggested VM base folder \"/home/klaus/VirtualBox VMs\"\n          (change with \"--vsys 0 --basefolder <path>\")\n       5: End-user license agreement\n          (display with \"--vsys 0 --eula show\";\n          accept with \"--vsys 0 --eula accept\")\n       6: Number of CPUs: 1\n          (change with \"--vsys 0 --cpus <n>\")\n       7: Guest memory: 956 MB (change with \"--vsys 0 --memory <MB>\")\n       8: Sound card (appliance expects \"ensoniq1371\", can change on import)\n          (disable with \"--vsys 0 --unit 5 --ignore\")\n       9: USB controller\n          (disable with \"--vsys 0 --unit 6 --ignore\")\n      10: Network adapter: orig bridged, config 2, extra type=bridged\n      11: Floppy\n          (disable with \"--vsys 0 --unit 8 --ignore\")\n      12: SCSI controller, type BusLogic\n          (change with \"--vsys 0 --unit 9 --scsitype {BusLogic|LsiLogic}\";\n          disable with \"--vsys 0 --unit 9 --ignore\")\n      13: IDE controller, type PIIX4\n          (disable with \"--vsys 0 --unit 10 --ignore\")\n      14: Hard disk image: source image=WindowsXp.vmdk,\n            target path=/home/user/disks/WindowsXp.vmdk, controller=9;channel=0\n          (change controller with \"--vsys 0 --unit 11 --controller <id>\";\n          disable with \"--vsys 0 --unit 11 --ignore\")\n        The individual configuration items are numbered, and depending\n        on their type support different command-line options. The import\n        subcommand can be directed to ignore many such items with a\n        --vsys X --unit Y --ignore\n        option, where X is the number of the virtual system and Y the\n        item number, as printed on the screen. X is zero, unless there\n        are several virtual system descriptions in the appliance.\n      \n        In the above example, Item #1 specifies the name of the target\n        machine in Oracle VM VirtualBox. Items #12 and #13 specify hard disk\n        controllers, respectively. Item #14 describes a hard disk image.\n        In this case, the additional\n        --controller option indicates\n        which item the disk image should be connected to, with the\n        default coming from the OVF file.\n      \n        You can combine several items for the same virtual system using\n        the --vsys option. For example,\n        to import a machine as described in the OVF, but without the\n        sound card and without the USB controller, and with the disk\n        image connected to the IDE controller instead of the SCSI\n        controller, use the following command:\n      VBoxManage import WindowsXp.ovf\n  --vsys 0 --unit 8 --ignore --unit 9 --ignore --unit 14 --controller 138.10.2. Import from Oracle Cloud Infrastructure\n        As the result of this operation, a file with the suffix\n        .oci is downloaded to the local host. This\n        file is a TAR archive which contains a bootable instance image\n        in QCOW2 format and a JSON file with some metadata related to\n        the imported instance.\n      \n        The downloaded file is deleted after a successful import. If\n        import fails, the downloaded file may not be deleted and the\n        VBoxSVC log file may indicate the location where the file was\n        stored.\n      \n        During import the bootable image is extracted from the archive\n        and converted into VMDK format. The JSON file is also extracted\n        and stored in the VM machine folder.\n      \n        The command syntax for importing an Oracle Cloud Infrastructure instance begins with\n        VBoxManage import OCI:// --cloud.\n      \n        You can list the available Oracle Cloud Infrastructure VM instances and their IDs by\n        using the following command:\n      VBoxManage cloud --provider=OCI --profile=cloud-profile-name list instances\n        To import a VM from a cloud service such as Oracle Cloud Infrastructure, use the\n        --cloud option to specify the import from the\n        Cloud. Some of the following options are settings for the VM,\n        for others you must enter an Oracle Cloud Identifier (OCID) for\n        a resource. Use the Oracle Cloud Infrastructure Console to view\n        OCIDs.\n      \n        The following parameters can be specified:\n      \n--vmname: Specifies a new name for the\n            imported VM. This name is used as the VM name by\n            Oracle VM VirtualBox.\n          \n--cloudinstanceid: The ID of an existing\n            instance in the Cloud.\n          \n--cloudprofile: Specifies the cloud profile\n            that is used to connect to the cloud service provider. The\n            cloud profile contains your Oracle Cloud Infrastructure account details, such as\n            your user OCID and the fingerprint for your public key. To\n            use a cloud profile, you must have the required permissions\n            on Oracle Cloud Infrastructure.\n          \n--cloudbucket: Specifies the bucket name in\n            which to store the object created from an instance bootable\n            volume. In Oracle Cloud Infrastructure, a bucket is a logical container for\n            storing objects.\n          \n        The following import options have the same meaning as for OVF\n        import:\n      \n--ostype: An OS type supported by\n            Oracle VM VirtualBox. Use the VBoxManage list\n            ostypes command to see the whole list of supported\n            OSes. If the type was not set, the\n            Unknown type is used.\n          \n--basefolder: The folder where the new VM\n            is stored.\n          \n--description: A string describing the VM.\n          \n--memory: The amount of RAM memory assigned\n            for the VM, in MB. If this option is not set either the\n            default memory size for the OS type is used, or the value is\n            taken from the Oracle Cloud Infrastructure instance.\n          \n--cpus: the number of virtual CPUs assigned\n            for the VM. If this option is not set, either the default\n            virtual CPUs setting for the OS type is used, or the value\n            is taken from the Oracle Cloud Infrastructure instance.\n          \n        The import options --disk,\n        --controller, --scsitype,\n        --unit, --settingsfile are not\n        valid for cloud import.\n      \n        The following example shows a typical command line for importing\n        an instance from Oracle Cloud Infrastructure:\n      # VBoxManage import OCI:// --cloud --vmname import_from_oci --memory 4000\n  --cpus 3 --ostype FreeBSD_64 --cloudprofile \"standard user\"\n  --cloudinstanceid ocid1.instance.oc1.iad.abuwc... --cloudbucket myBucket8.11. VBoxManage export\n      This command exports one or more virtual machines from\n      Oracle VM VirtualBox. You can export to either of the following:\n    \n          A virtual appliance in OVF format, including copying their\n          virtual disk images to compressed VMDK.\n        \n          A cloud service, such as Oracle Cloud Infrastructure. A single VM can be exported in\n          VMDK format.\n        \n      See Section 1.14, “Importing and Exporting Virtual Machines” for more details on exporting VMs from\n      Oracle VM VirtualBox.\n    8.11.1. Export to OVF\n        List the machine, or the machines, that you would like to export\n        to the same OVF file and specify the target OVF file after an\n        additional --output or\n        -o option. Note that the\n        directory of the target OVF file will also receive the exported\n        disk images in the compressed VMDK format, regardless of the\n        original format, and should have enough disk space left for\n        them.\n      \n        Beside a simple export of a given virtual machine, you can\n        append several product information to the appliance file. Use\n        --product,\n        --producturl,\n        --vendor,\n        --vendorurl,\n        --version and\n        --description to specify this\n        additional information. For legal reasons you may add a license\n        text or the content of a license file by using the\n        --eula and\n        --eulafile option respectively.\n      \n        As with OVF import, you use the --vsys\n        X option to apply these options to the correct\n        virtual machine.\n      \n        For virtualization products which are not fully compatible with\n        the OVF standard 1.0 you can enable an OVF 0.9 legacy mode with\n        the --legacy09 option. Other\n        options are --ovf09,\n        --ovf10,\n        --ovf20.\n      \n        To specify options controlling the exact content of the\n        appliance file, you can use --options to\n        request the creation of a manifest file, which enables detection\n        of corrupted appliances on import, the additional export of DVD\n        images, and the exclusion of MAC addresses. You can specify a\n        list of options, such as --options\n        manifest,nomacs. For details, check the help output of\n        VBoxManage export.\n      8.11.2. Export to Oracle Cloud Infrastructure\n        By default, an exported disk image is converted into stream VMDK\n        format. This ensures compatibility with Oracle Cloud Infrastructure.\n      \n        List the machine that you want to export to Oracle Cloud Infrastructure and specify\n        the target cloud service provider by using the\n        --output or\n        -o option.\n      \n        To export a VM to a cloud service such as Oracle Cloud Infrastructure, use the\n        --cloud option to specify the VM to export.\n        This option works in the same way as the --vsys\n        option for OVF export.\n      \n        Some of the following options are settings for the VM instance.\n        As a result, you must enter an Oracle Cloud Identifier (OCID)\n        for a resource. Use the Oracle Cloud Infrastructure Console to view OCIDs.\n      \n--output/-o: Specifies the short name of\n            the cloud service provider to which you export. For Oracle Cloud Infrastructure,\n            enter OCI://.\n          \n--cloud\nnumber-of-virtual-system:\n            Specifies a number that identifies the VM that you are\n            exporting. Numbering starts at\n            0 for the first VM.\n          \n--vmname name:\n            Specifies the name of the exported VM. This name is used as\n            the VM instance name in Oracle Cloud Infrastructure.\n          \n--cloudprofile\ncloud-profile-name: Specifies the\n            cloud profile that is used to connect to the cloud service\n            provider. The cloud profile contains your Oracle Cloud Infrastructure account\n            details, such as your user OCID and the fingerprint for your\n            public key. See Section 1.14.5, “Exporting an Appliance to Oracle Cloud Infrastructure”.\n          \n            To use a cloud profile, you must have the required\n            permissions on Oracle Cloud Infrastructure.\n          \n--cloudshape\nshape: Specifies the shape used\n            for the VM instance. The shape defines the number of CPUs\n            and the amount of memory allocated to the VM instance. The\n            shape must be compatible with the exported image.\n          \n--clouddomain\ndomain: Specifies the\n            availability domain to use for the VM instance. Enter the\n            full name of the availability domain.\n          \n--clouddisksize\ndisk-size-in-GB: Specifies the\n            disk size used for the exported disk image in gigabytes. The\n            minimum value is 50 GB and the maximum value is 300 GB.\n          \n--cloudbucket\nbucket-name: Specifies the bucket\n            in which to store the uploaded files. In Oracle Cloud Infrastructure, a bucket is\n            a logical container for storing objects.\n          \n--cloudocivcn\nOCI-vcn-ID: Specifies the virtual\n            cloud network (VCN) to use for the VM instance. Enter the\n            OCID for the VCN.\n          \n--cloudocisubnet\nOCI-subnet-ID: Specifies the\n            subnet of the VCN to use for the VM instance. Enter the OCID\n            for the subnet.\n          \n--cloudkeepobject true | false: Specifies\n            whether to store the exported disk image in Oracle Object\n            Storage.\n          \n--cloudlaunchinstance true | false:\n            Specifies whether to start the VM instance after the export\n            to Oracle Cloud Infrastructure completes.\n          \n--cloudpublicip true | false: Specifies\n            whether to enable a public IP address for the VM instance.\n          \n        The following example shows a typical command line for exporting\n        a VM to Oracle Cloud Infrastructure.\n      # VBoxManage export myVM --output OCI:// --cloud 0 --vmname myVM_Cloud \\\n--cloudprofile \"standard user\" --cloudbucket myBucket \\\n--cloudshape VM.Standard2.1 --clouddomain US-ASHBURN-AD-1 --clouddisksize 50  \\\n--cloudocivcn ocid1.vcn.oc1.iad.aaaa... --cloudocisubnet ocid1.subnet.oc1.iad.aaaa... \\\n--cloudkeepobject true --cloudlaunchinstance true --cloudpublicip true8.12. VBoxManage startvm\n      This command starts a virtual machine that is currently in the\n      Powered Off or Saved states.\n    \n      The optional --type specifier\n      determines whether the machine will be started in a window or\n      whether the output should go through\n      VBoxHeadless, with VRDE enabled or not. See\n      Section 7.1.2, “VBoxHeadless, the Remote Desktop Server”. The list of types is subject to\n      change, and it is not guaranteed that all types are accepted by\n      any product variant.\n    \n      The global or per-VM default value for the VM frontend type will\n      be taken if the type is not explicitly specified. If none of these\n      are set, the GUI variant will be started.\n    \n      The following values are allowed:\n    \ngui\n\n            Starts a VM showing a GUI window. This is the default.\n          \nheadless\n\n            Starts a VM without a window for remote display only.\n          \nseparate\n\n            Starts a VM with a detachable UI. Technically, it is a\n            headless VM with user interface in a separate process. This\n            is an experimental feature as it lacks certain\n            functionality, such as 3D acceleration.\n          Note\n        If you experience problems with starting virtual machines with\n        particular frontends and there is no conclusive error\n        information, consider starting virtual machines directly by\n        running the respective front-end, as this can give additional\n        error information.\n      8.13. VBoxManage controlvm\n      The controlvm subcommand enables you to change\n      the state of a virtual machine that is currently running. The\n      following can be specified:\n    \nVBoxManage controlvm <vm> pause:\n          Temporarily puts a virtual machine on hold, without\n          permanently changing its state. The VM window is gray, to\n          indicate that the VM is currently paused. This is equivalent\n          to selecting the Pause item\n          in the Machine menu of the\n          GUI.\n        \n          Use VBoxManage controlvm <vm> resume:\n          Undoes a previous pause command. This is\n          equivalent to selecting the\n          Resume item in the\n          Machine menu of the GUI.\n        \nVBoxManage controlvm <vm> reset: Has\n          the same effect on a virtual machine as pressing the Reset\n          button on a real computer. A cold reboot of the virtual\n          machine is done, which immediately restarts and reboots the\n          guest operating system. The state of the VM is not saved\n          beforehand, and data may be lost. This is equivalent to\n          selecting the Reset item in\n          the Machine menu of the GUI.\n        \nVBoxManage controlvm <vm> poweroff:\n          Has the same effect on a virtual machine as pulling the power\n          cable on a real computer. The state of the VM is not saved\n          beforehand, and data may be lost. This is equivalent to\n          selecting the Close item in\n          the Machine menu of the GUI,\n          or clicking the VM window's close button, and then selecting\n          Power Off the Machine in the\n          displayed dialog.\n        \n          After this, the VM's state will be Powered Off. From that\n          state, it can be started again. See\n          Section 8.12, “VBoxManage startvm”.\n        \nVBoxManage controlvm <vm> savestate:\n          Saves the current state of the VM to disk and then stops the\n          VM. This is equivalent to selecting the\n          Close item in the\n          Machine menu of the GUI or\n          clicking the VM window's close button, and then selecting\n          Save the Machine State in the\n          displayed dialog.\n        \n          After this, the VM's state will be Saved. From this state, it\n          can be started again. See\n          Section 8.12, “VBoxManage startvm”.\n        \nVBoxManage controlvm <vm>\n          acpipowerbutton: Sends an ACPI shutdown signal to\n          the VM, as if the power button on a real computer had been\n          pressed. So long as the VM is running a fairly modern guest\n          operating system providing ACPI support, this should trigger a\n          proper shutdown mechanism from within the VM.\n        \nVBoxManage controlvm <vm> keyboardputscancode\n          <hex> [<hex>...]: Sends commands using\n          keycodes to the VM. Keycodes are documented in the public\n          domain. For example:\n          http://www.win.tue.nl/~aeb/linux/kbd/scancodes-1.html.\n        \nVBoxManage controlvm \"VM name\" teleport --hostname\n          <name> --port <port> [--passwordfile <file>\n          | --password <password>]: Makes the machine\n          the source of a teleporting operation and initiates a teleport\n          to the given target. See Section 7.2, “Teleporting”. If\n          the optional password is specified, it must match the password\n          that was given to the modifyvm command for\n          the target machine. See\n          Section 8.8.6, “Teleporting Settings”.\n        \n      The following extra options are available with\n      controlvm that do not directly affect the VM's\n      running state:\n    \nsetlinkstate<1-N>\n          on|off: Connects or disconnects virtual\n          network cables from their network interfaces.\n        \nnic<1-N>\n          null|nat|bridged|intnet|hostonly|generic|natnetwork[<devicename>]:\n          Specifies the type of networking that should be made available\n          on the specified VM virtual network card. They available types\n          are: not connected to the host\n          (null), use network address\n          translation (nat), bridged\n          networking (bridged),\n          communicate with other virtual machines using internal\n          networking (intnet),\n          host-only networking\n          (hostonly), natnetwork\n          networking (natnetwork), or\n          access to rarely used submodes\n          (generic). These options\n          correspond to the modes which are described in detail in\n          Section 6.2, “Introduction to Networking Modes”.\n        \n          With the nictrace options,\n          you can optionally trace network traffic by dumping it to a\n          file, for debugging purposes.\n        \nnictrace<1-N> on|off:\n          Enables network tracing for a particular virtual network card.\n        \n          Before enabling you should specify a file name to which the\n          trace should be logged. This can be done with the\n          nictracefile<1-N>\n          <filename> option to\n          VBoxManage controlvm at runtime or with the\n          <filename> option to\n          VBoxManage modifyvm otherwise.\n        \nnicpromisc<1-N>\n          deny|allow-vms|allow-all: Specifies how the\n          promiscious mode is handled for the specified VM virtual\n          network card. This setting is only relevant for bridged\n          networking. The default setting of\n          deny hides any traffic not\n          intended for this VM.\n          allow-vms hides all host\n          traffic from this VM but enables the VM to see traffic to and\n          from other VMs. allow-all\n          removes this restriction completely.\n        \nnicproperty<1-N>\n          <paramname>=\"paramvalue\": This option,\n          in combination with\n          nicgenericdrv enables you to\n          pass parameters to rarely-used network backends.\n        \n          Those parameters are backend engine-specific, and are\n          different between UDP Tunnel and the VDE backend drivers. See\n          Section 6.8, “UDP Tunnel Networking”.\n        \nnatpf<1-N>\n          [<name>],tcp|udp,[<hostip>],<hostport>,[<guestip>],\n          <guestport>: Specifies a NAT\n          port-forwarding rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.\n        \nnatpf<1-N> delete\n          <name>: Deletes a NAT port-forwarding\n          rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.\n        \n          The guestmemoryballoon<balloon size in\n          MB>: Changes the size of the guest memory\n          balloon. This is the memory allocated by the Oracle VM VirtualBox\n          Guest Additions from the guest operating system and returned\n          to the hypervisor for reuse by other virtual machines. This\n          must be specified in megabytes. See\n          Section 4.10.1, “Memory Ballooning”.\n        \nusbattach<uuid|address> [--capturefile\n          <filename>]\n\n          and usbdetach <uuid|address>\n          [--capturefile <filename>]: Makes host\n          USB devices visible or invisible to the virtual machine on the\n          fly, without the need for creating filters first. The USB\n          devices can be specified by UUID (unique identifier) or by\n          address on the host system. Use the\n          --capturefile option to\n          specify the absolute path of a file for writing activity\n          logging data.\n        \n          You can use VBoxManage list usbhost to\n          locate this information.\n        \naudioin on: Selects whether\n          capturing audio from the host is enabled or disabled.\n        \naudioout on: Selects whether\n          audio playback from the guest is enabled or disabled.\n        \nclipboard mode\n          disabled|hosttoguest|guesttohost|bidirectional:\n          Selects how the guest or host operating system's clipboard\n          should be shared with the host or guest. See\n          Section 3.4, “General Settings”. This requires that the\n          Guest Additions be installed in the virtual machine.\n        \nclipboard filetransfers\n          enabled|disabled: Specifies if clipboard file\n          transfers are allowed between host and guest OSes or not.\n        \ndraganddrop\n          disabled|hosttoguest|guesttohost|bidirectional:\n          Selects the current drag and drop mode being used between the\n          host and the virtual machine. See\n          Section 4.4, “Drag and Drop”. This requires that the Guest\n          Additions be installed in the virtual machine.\n        \nvrde on|off: Enables and\n          disables the VRDE server, if it is installed.\n        \nvrdeport\n          default|<ports>: Changes the port or a\n          range of ports that the VRDE server can bind to.\n          default or\n          0 means port 3389, the\n          standard port for RDP. See the description for the\n          --vrdeport option in\n          Section 8.8.5, “Remote Machine Settings”.\n        \nvrdeproperty\n          \"TCP/Ports|Address=<value>\": Sets the\n          port numbers and IP address on the VM to which the VRDE server\n          can bind.\n        \n              For TCP/Ports, <value> should be a port or a range\n              of ports to which the VRDE server can bind.\n              default or\n              0 means port 3389, the\n              standard port for RDP. See the description for the\n              --vrdeport option in\n              Section 8.8.5, “Remote Machine Settings”.\n            \n              For TCP/Address, <value>: The IP address of the host\n              network interface that the VRDE server will bind to. If\n              specified, the server will accept connections only on the\n              specified host network interface. See the description for\n              the --vrdeaddress option\n              in\n              Section 8.8.5, “Remote Machine Settings”.\n            \nvrdeproperty\n          \"VideoChannel/Enabled|Quality|DownscaleProtection=<value>\":\n          Sets the VRDP video redirection properties.\n        \n              For VideoChannel/Enabled, <value> can be set to \"1\"\n              switching the VRDP video channel on. See\n              Section 7.1.9, “VRDP Video Redirection”.\n            \n              For VideoChannel/Quality, <value> should be set\n              between 10 and 100% inclusive, representing a JPEG\n              compression level on the VRDE server video channel. Lower\n              values mean lower quality but higher compression. See\n              Section 7.1.9, “VRDP Video Redirection”.\n            \n              For VideoChannel/DownscaleProtection, <value> can be\n              set to \"1\" to enable the videochannel downscale protection\n              feature. When enabled, if a video's size equals the shadow\n              buffer size, then it is regarded as a full screen video,\n              and is displayed. If its size is between fullscreen and\n              the downscale threshold it is not displayed, as it could\n              be an application window, which would be unreadable when\n              downscaled. When the downscale protection feature is\n              disabled, an attempt is always made to display videos.\n            \nvrdeproperty\n          \"Client/DisableDisplay|DisableInput|DisableAudio|DisableUSB=1\":\n          Disables one of the VRDE server features: Display, Input,\n          Audio, or USB. To reenable a feature, use\n          \"Client/DisableDisplay=\" for example. See\n          Section 7.1.10, “VRDP Customization”.\n        \nvrdeproperty\n          \"Client/DisableClipboard|DisableUpstreamAudio=1\".\n          Disables one of the VRDE server features: Clipboard or\n          UpstreamAudio. To reenable a feature, use\n          \"Client/DisableClipboard=\" for example. See\n          Section 7.1.10, “VRDP Customization”.\n        \nvrdeproperty\n          \"Client/DisableRDPDR=1\": Disables the VRDE\n          server feature: RDP device redirection for smart cards. To\n          reenable this feature, use \"Client/DisableRDPR=\".\n        \nvrdeproperty\n          \"H3DRedirect/Enabled=1\": Enables the VRDE\n          server feature: 3D redirection. To disable this feature, use\n          \"H3DRedirect/Enabled=\".\n        \nvrdeproperty\n          \"Security/Method|ServerCertificate|ServerPrivateKey|CACertificate=<value>\":\n          Sets the desired security method, path of the server\n          certificate, path of the server private key, and path of CA\n          certificate, used for a connection.\n        \nvrdeproperty\n              \"Security/Method=<value>\": Sets the\n              desired security method, which is used for a connection.\n              Valid values are as follows:\n            \nNegotiate: Both\n                  Enhanced (TLS) and Standard RDP Security connections\n                  are allowed. The security method is negotiated with\n                  the client. This is the default setting.\n                \nRDP: Only Standard\n                  RDP Security is accepted.\n                \nTLS: Only Enhanced\n                  RDP Security is accepted. The client must support TLS.\n                \n              See Section 7.1.6, “RDP Encryption”.\n            \nvrdeproperty\n              \"Security/ServerCertificate=<value>\"\n              where <value> is the absolute path of the server\n              certificate. See Section 7.1.6, “RDP Encryption”.\n            \nvrdeproperty\n              \"Security/ServerPrivateKey=<value>\"\n              where <value> is the absolute path of the server\n              private key. See Section 7.1.6, “RDP Encryption”.\n            \nvrdeproperty\n              \"Security/CACertificate=<value>\"\n              where <value> is the absolute path of the CA self\n              signed certificate. See Section 7.1.6, “RDP Encryption”.\n            \nvrdeproperty\n          \"Audio/RateCorrectionMode|LogPath=<value>\":\n          Sets the audio connection mode, or path of the audio logfile.\n        \nvrdeproperty\n              \"Audio/RateCorrectionMode=<value>\"\n              where <value> is the desired rate correction mode,\n              allowed values are:\n            \nVRDP_AUDIO_MODE_VOID:\n                  No mode specified, use to unset any Audio mode already\n                  set.\n                \nVRDP_AUDIO_MODE_RC:\n                  Rate correction mode.\n                \nVRDP_AUDIO_MODE_LPF:\n                  Low pass filter mode.\n                \nVRDP_AUDIO_MODE_CS:\n                  Client sync mode to prevent underflow or overflow of\n                  the client queue.\n                \nvrdeproperty\n              \"Audio/LogPath=<value>\" where\n              <value> is the absolute path of the audio log file.\n            \nvrdevideochannelquality\n          <percent>: Sets the image quality for\n          video redirection. See Section 7.1.9, “VRDP Video Redirection”.\n        \nsetvideomodehint: Requests\n          that the guest system change to a particular video mode. This\n          requires that the Guest Additions be installed, and will not\n          work for all guest systems.\n        \nscreenshotpng: Takes a\n          screenshot of the guest display and saves it in PNG format.\n        \nrecording on|off enables or\n          disables the recording of a VM session into a WebM/VP8 file.\n          When this option value is on,\n          recording begins when the VM session starts.\n        \nrecordingscreens\n          all|screen-ID\n          [screen-ID ...]\n          enables you to specify which VM screens to record. The\n          recording for each screen that you specify is saved to its own\n          file. You cannot modify this setting while recording is\n          enabled.\n        \nrecordingfile\n          filename specifies\n          the file in which to save the recording. You cannot modify\n          this setting while recording is enabled.\n        \nrecordingvideores\n          widthxheight\n          specifies the resolution of the recorded video in pixels. You\n          cannot modify this setting while recording is enabled.\n        \nrecordingvideorate\n          bit-rate specifies\n          the bit rate of the video in kilobits per second. Increasing\n          this value improves the appearance of the video at the cost of\n          an increased file size. You cannot modify this setting while\n          recording is enabled.\n        \nrecordingvideofps\n          fps specifies the\n          maximum number of video frames per second (FPS) to record.\n          Frames that have a higher frequency are skipped. Increasing\n          this value reduces the number of skipped frames and increases\n          the file size. You cannot modify this setting while recording\n          is enabled.\n        \nrecordingmaxtime\n          seconds specifies\n          the maximum amount time to record in seconds. The recording\n          stops after the specified number of seconds elapses. If this\n          value is zero, the recording continues until you stop the\n          recording.\n        \nrecordingmaxsize\n          MB specifies the\n          maximum size of the recorded video file in megabytes. The\n          recording stops when the file reaches the specified size. If\n          this value is zero, the recording continues until you stop the\n          recording. You cannot modify this setting while recording is\n          enabled.\n        \nrecordingopts\n          keyword=value[,keyword=value\n          ...] specifies additional recording options\n          in a comma-separated keyword-value format. For example,\n          foo=bar,a=b. You cannot\n          modify this setting while recording is enabled.\n        \n          Only use this option only if you are an advanced user. For\n          information about keywords, see Oracle VM VirtualBox\n          Programming Guide and Reference.\n        \nsetcredentials: Used for\n          remote logins on Windows guests. See\n          Section 9.1, “Automated Guest Logins”.\n        \nteleport --host <name> --port\n          <port>: Configures a VM as a target for\n          teleporting. <name> specifies the virtual machine name.\n          <port> specifies the port on the virtual machine which\n          should listen for teleporting requests from other virtual\n          machines. It can be any free TCP/IP port number, such as 6000.\n          See Section 7.2, “Teleporting”.\n        \n--maxdowntime\n              <msec>: Specifies the maximum\n              downtime, in milliseconds, for the teleporting target VM.\n              Optional.\n            \n--password\n              <password>: The teleporting request\n              will only succeed if the source machine specifies the same\n              password as the one given with this command. Optional.\n            \n--passwordfile <password\n              file>: The teleporting request will\n              only succeed if the source machine specifies the same\n              password as the one specified in the password file with\n              the path specified with this command. Use\n              stdin to read the\n              password from stdin. Optional.\n            \nplugcpu|unplugcpu <id>:\n          If CPU hot-plugging is enabled, this setting adds and removes\n          a virtual CPU to the virtual machine.\n          <id> specifies the\n          index of the virtual CPU to be added or removed and must be a\n          number from 0 to the maximum number of CPUs configured. CPU 0\n          can never be removed.\n        \n          The cpuexecutioncap\n          <1-100>: Controls how much CPU time a\n          virtual CPU can use. A value of 50 implies a single virtual\n          CPU can use up to 50% of a single host CPU.\n        \nvm-process-priority\n          default|flat|low|normal|high: Changes the\n          priority scheme of the VM process. See\n          Section 8.12, “VBoxManage startvm”.\n        \nwebcam attach <path|alias>\n          [<keyword=value>[;<keyword=value>...]]:\n          Attaches a webcam to a running VM. Specify the absolute path\n          of the webcam on the host operating system, or use its alias,\n          obtained by using the command: VBoxManage list\n          webcams.\n        \n          Note that alias '.0' means the default video input device on\n          the host operating system, '.1', '.2', etc. mean first,\n          second, etc. video input device. The device order is\n          host-specific.\n        \n          The optional settings parameter is a\n          ; delimited list of\n          name-value pairs, enabling configuration of the emulated\n          webcam device.\n        \n          The following settings are supported:\n        \n          MaxFramerate: Specifies the highest rate in frames per second,\n          at which video frames are sent to the guest. Higher frame\n          rates increase CPU load, so this setting can be useful when\n          there is a need to reduce CPU load. The default setting is\n          no maximum limit, thus\n          enabling the guest to use all frame rates supported by the\n          host webcam.\n        \n          MaxPayloadTransferSize: Specifies the maximum number of bytes\n          the emulated webcam can send to the guest in one buffer. The\n          default setting is 3060 bytes, which is used by some webcams.\n          Higher values can slightly reduce CPU load, if the guest is\n          able to use larger buffers. Note that higher\n          MaxPayloadTransferSize values may be not supported by some\n          guest operating systems.\n        \nwebcam detach\n          <path|alias>: Detaches a webcam from a\n          running VM. Specify the absolute path of the webcam on the\n          host, or use its alias obtained from the webcam\n          list command.\n        \n          Please note the following points, relating to specific host\n          operating systems:\n        \n              Windows hosts: When the webcam device is detached from the\n              host, the emulated webcam device is automatically detached\n              from the guest.\n            \n              Mac OS X hosts: OS X version 10.7 or newer is required.\n            \n              When the webcam device is detached from the host, the\n              emulated webcam device remains attached to the guest and\n              must be manually detached using the VBoxManage\n              controlvm webcam detach command.\n            \n              Linux hosts: When the webcam is detached from the host,\n              the emulated webcam device is automatically detached from\n              the guest only if the webcam is streaming video. If the\n              emulated webcam is inactive, it should be manually\n              detached using the VBoxManage controlvm webcam\n              detach command.\n            \nwebcam list: Lists webcams\n          attached to the running VM. The output is a list of absolute\n          paths or aliases that were used for attaching the webcams to\n          the VM using the webcam attach command.\n        \naddencpassword <id> <password\n          file>|- [--removeonsuspend\n          <yes|no>]: Supplies an encrypted VM\n          specified by <id> with the encryption password to enable\n          a headless start. Either specify the absolute path of a\n          password file on the host file system: <password file>,\n          or use - to instruct\n          VBoxManage to prompt the user for the\n          encryption password.\n        \n--removeonsuspend\n          <yes|no>: Specifies whether to remove\n          the passsword or keep the password in VM memory when the VM is\n          suspended. If the VM has been suspended and the password has\n          been removed, the user needs to resupply the password before\n          the VM can be resumed. This feature is useful in cases where\n          the user does not want the password to be stored in VM memory,\n          and the VM is suspended by a host suspend event.\n        Note\n            On Oracle VM VirtualBox versions 5.0 and later, data stored on\n            hard disk images can be transparently encrypted for the\n            guest. Oracle VM VirtualBox uses the AES algorithm in XTS mode and\n            supports 128 or 256 bit data encryption keys (DEK). The DEK\n            is stored encrypted in the medium properties, and is\n            decrypted during VM startup by supplying the encryption\n            password.\n          \n          The VBoxManage encryptmedium command is\n          used to create a DEK encrypted medium. See\n          Section 9.28.2, “Encrypting Disk Images”. When starting an\n          encrypted VM from the Oracle VM VirtualBox GUI, the user will be\n          prompted for the encryption password.\n        \n          For a headless encrypted VM start, use the following command:\n        \n          VBoxManage startvm \"vmname\" --type headless\n        \n          Then supply the required encryption password as follows:\n        \n          VBoxManage \"vmname\" controlvm \"vmname\" addencpassword ...\n        \nremoveencpassword <id>:\n          Removes encryption password authorization for password\n          <id> for all encrypted media attached to the VM.\n        \nremoveallencpasswords:\n          Removes encryption password authorization for all passwords\n          for all encrypted media attached to the VM.\n        \nchangeuartmode <1-N>:\n          Changes the connection mode for a given virtual serial port.\n        8.14. VBoxManage discardstate\n      This command discards the saved state of a virtual machine which\n      is not currently running. This will cause the VM's operating\n      system to restart next time you start it. This is the equivalent\n      of pulling out the power cable on a physical machine, and should\n      be avoided if possible.\n    8.15. VBoxManage adoptstate\n      If you have a Saved state file (.sav) that is\n      separate from the VM configuration, you can use this command to\n      adopt the file. This will change the VM to\n      saved state and when you start it, Oracle VM VirtualBox will attempt to\n      restore it from the saved state file you indicated. This command\n      should only be used in special setups.\n    8.16. VBoxManage closemedium\n      This command removes a hard disk, DVD, or floppy image from a\n      Oracle VM VirtualBox media registry.\n    VBoxManage closemedium      [disk|dvd|floppy] <uuid|filename>\n                            [--delete]\n      Optionally, you can request that the image be deleted. You will\n      get appropriate diagnostics that the deletion failed, however the\n      image will become unregistered in any case.\n    8.17. VBoxManage storageattach\n      This command attaches, modifies, and removes a storage medium\n      connected to a storage controller that was previously added with\n      the storagectl command. The syntax is as\n      follows:\n    VBoxManage storageattach    <uuid|vmname>\n                            --storagectl <name>\n                            [--port <number>]\n                            [--device <number>]\n                            [--type dvddrive|hdd|fdd]\n                            [--medium none|emptydrive|additions|\n                                      <uuid>|<filename>|host:<drive>|iscsi]\n                            [--mtype normal|writethrough|immutable|shareable\n                                     readonly|multiattach]\n                            [--comment <text>]\n                            [--setuuid <uuid>]\n                            [--setparentuuid <uuid>]\n                            [--passthrough on|off]\n                            [--tempeject on|off]\n                            [--nonrotational on|off]\n                            [--discard on|off]\n                            [--hotpluggable on|off]\n                            [--bandwidthgroup name|none]\n                            [--forceunmount]\n                            [--server <name>|<ip>]\n                            [--target <target>]\n                            [--tport <port>]\n                            [--lun <lun>]\n                            [--encodedlun <lun>]\n                            [--username <username>]\n                            [--password <password>]\n                            [--passwordfile <file>]\n                            [--initiator <initiator>]\n                            [--intnet]\n      A number of parameters are commonly required. Some parameters are\n      required only for iSCSI targets.\n    \n      The common parameters are as follows:\n    \nuuid|vmname\n\n            The VM UUID or VM Name. Mandatory.\n          \n--storagectl\n\n            Name of the storage controller. Mandatory. The list of the\n            storage controllers currently attached to a VM can be\n            obtained with VBoxManage showvminfo. See\n            Section 8.5, “VBoxManage showvminfo”.\n          \n--port\n\n            The number of the storage controller's port which is to be\n            modified. Mandatory, unless the storage controller has only\n            a single port.\n          \n--device\n\n            The number of the port's device which is to be modified.\n            Mandatory, unless the storage controller has only a single\n            device per port.\n          \n--type\n\n            Define the type of the drive to which the medium is being\n            attached, detached, or modified. This argument can only be\n            omitted if the type of medium can be determined from either\n            the medium given with the\n            --medium argument or from a\n            previous medium attachment.\n          \n--medium\n\n            Specifies what is to be attached. The following values are\n            supported:\n          \nnone: Any existing\n                device should be removed from the given slot.\n              \nemptydrive: For a\n                virtual DVD or floppy drive only, this makes the device\n                slot behave like a removeable drive into which no media\n                has been inserted.\n              \nadditions: For a\n                virtual DVD drive only, this attaches the\n                VirtualBox Guest Additions image to\n                the given device slot.\n              \n                If a UUID is specified, it must be the UUID of a storage\n                medium that is already known to Oracle VM VirtualBox. For\n                example, because it has been attached to another virtual\n                machine. See Section 8.4, “VBoxManage list” for\n                details of how to list known media. This medium is then\n                attached to the given device slot.\n              \n                If a filename is specified, it must be the full path of\n                an existing disk image in ISO, RAW, VDI, VMDK, or other\n                format. The disk image is then attached to the given\n                device slot.\n              \nhost:<drive>: For\n                a virtual DVD or floppy drive only, this connects the\n                given device slot to the specified DVD or floppy drive\n                on the host computer.\n              \niscsi: For virtual hard\n                disks only, this is used for specifying an iSCSI target.\n                In this case, additional parameters must be given. These\n                are described below.\n              \n            Some of the above changes, in particular for removeable\n            media such as floppies and CDs/DVDs, can be effected while a\n            VM is running. Others, such as device changes or changes in\n            hard disk device slots, require the VM to be powered off.\n          \n--mtype\n\n            Defines how this medium behaves with respect to snapshots\n            and write operations. See Section 5.4, “Special Image Write Modes”.\n          \n--comment\n\n            An optional description that you want to have stored with\n            this medium. For example, for an iSCSI target, \"Big storage\n            server downstairs\". This is purely descriptive and not\n            needed for the medium to function correctly.\n          \n--setuuid, --setparentuuid\n\n            Modifies the UUID or parent UUID of a medium before\n            attaching it to a VM. This is an expert option.\n            Inappropriate use can make the medium unusable or lead to\n            broken VM configurations if any other VM is referring to the\n            same media already. The most frequently used variant is\n            --setuuid \"\", which assigns\n            a new random UUID to an image. This option is useful for\n            resolving duplicate UUID errors if you duplicated an image\n            using a file copy utility.\n          \n--passthrough\n\n            For a virtual DVD drive only, you can enable DVD writing\n            support. This feature is currently experimental, see\n            Section 5.9, “CD/DVD Support”.\n          \n--tempeject\n\n            For a virtual DVD drive only, you can configure the behavior\n            for guest-triggered medium eject. If this is set to on, the\n            eject has only a temporary effect. If the VM is powered off\n            and restarted the originally configured medium will be still\n            in the drive.\n          \n--nonrotational\n\n            Enables you to enable the non-rotational flag for virtual\n            hard disks. Some guests, such as Windows 7 or later, treat\n            such disks like SSDs and do not perform disk fragmentation\n            on such media.\n          \n--discard\n\n            Enables the auto-discard feature for a virtual hard disks.\n            This specifies that a VDI image will be shrunk in response\n            to the trim command from the guest OS. The following\n            requirements must be met:\n          \n                The disk format must be VDI.\n              \n                The size of the cleared area must be at least 1 MB.\n              \n                Oracle VM VirtualBox will only trim whole 1 MB blocks. The\n                VDIs themselves are organized into 1 MB blocks, so this\n                will only work if the space being trimmed is at least a\n                1 MB contiguous block at a 1 MB boundary. On Windows,\n                occasional defragmentation with defrag.exe\n                /D, or on Linux running btrfs\n                filesystem defrag as a background cron job may\n                be beneficial.\n              Note\n              The Guest OS must be configured to issue the\n              trim command, and typically this means\n              that the guest OS is made to see the disk as an SSD. Ext4\n              supports the -o discard mount flag. Mac OS X probably\n              requires additional settings. Windows should automatically\n              detect and support SSDs, at least in versions 7, 8, and\n              10. The Linux exFAT driver from Samsung supports the\n              trim command.\n            \n            It is unclear whether Microsoft's implementation of exFAT\n            supports this feature, even though that file system was\n            originally designed for flash.\n          \n            Alternatively, there are other methods to issue trim. For\n            example, the Linux fstrim command, part\n            of the util-linux package. Earlier solutions required a user\n            to zero out unused areas, using zerofree or similar, and to\n            compact the disk. This is only possible when the VM is\n            offline.\n          \n--bandwidthgroup\n\n            Sets the bandwidth group to use for the given device. See\n            Section 5.8, “Limiting Bandwidth for Disk Images”.\n          \n--forceunmount\n\n            For a virtual DVD or floppy drive only, this forcibly\n            unmounts the DVD/CD/Floppy or mounts a new DVD/CD/Floppy\n            even if the previous one is locked down by the guest for\n            reading. See Section 5.9, “CD/DVD Support”.\n          \n      When iscsi is used with the\n      --medium parameter for iSCSI\n      support, additional parameters must or can be used. See also\n      Section 5.10, “iSCSI Servers”.\n    \n--server\n\n            The host name or IP address of the iSCSI target. Required.\n          \n--target\n\n            Target name string. This is determined by the iSCSI target\n            and used to identify the storage resource. Required.\n          \n--tport\n\n            TCP/IP port number of the iSCSI service on the target.\n            Optional.\n          \n--lun\n\n            Logical Unit Number of the target resource. Optional. Often,\n            this value is zero.\n          \n--encodedlun\n\n            Hex-encoded Logical Unit Number of the target resource.\n            Optional. Often, this value is zero.\n          \n--username, --password,\n          --passwordfile\n\n            Username and password, called the initiator secret, for\n            target authentication, if required. Optional.\n          Note\n              Username and password are stored without encryption, in\n              clear text, in the XML machine configuration file if no\n              settings password is provided. When a settings password is\n              specified for the first time, the password is stored in\n              encrypted form. As an alternative to providing the\n              password on the command line, a reference to a file\n              containing the text can be provided using the\n              passwordfile option.\n            \n--initiator\n\n            iSCSI Initiator. Optional.\n          \n            Microsoft iSCSI Initiator is a system, such as a server that\n            attaches to an IP network and initiates requests and\n            receives responses from an iSCSI target. The SAN components\n            in Microsoft iSCSI Initiator are largely analogous to Fibre\n            Channel SAN components, and they include the following:\n          \n                To transport blocks of iSCSI commands over the IP\n                network, an iSCSI driver must be installed on the iSCSI\n                host. An iSCSI driver is included with Microsoft iSCSI\n                Initiator.\n              \n                A gigabit Ethernet adapter that transmits 1000 megabits\n                per second (Mbps) is recommended for the connection to\n                an iSCSI target. Like standard 10/100 adapters, most\n                gigabit adapters use a preexisting Category 5 or\n                Category 6E cable. Each port on the adapter is\n                identified by a unique IP address.\n              \n                An iSCSI target is any device that receives iSCSI\n                commands. The device can be an end node, such as a\n                storage device, or it can be an intermediate device,\n                such as a network bridge between IP and Fibre Channel\n                devices. Each port on the storage array controller or\n                network bridge is identified by one or more IP addresses\n              \n--intnet\n\n            If specified, connect to the iSCSI target using Internal\n            Networking. This needs further configuration, see\n            Section 9.7.3, “Access iSCSI Targets Using Internal Networking”.\n          8.18. VBoxManage storagectl\n      This command attaches, modifies, and removes a storage controller.\n      After this, virtual media can be attached to the controller with\n      the storageattach command.\n    \n      The syntax for this command is as follows:\n    VBoxManage storagectl       <uuid|vmname>\n                            --name <name>\n                            [--add ide|sata|scsi|floppy|sas|usb|pcie]\n                            [--controller LSILogic|LSILogicSAS|BusLogic|\n                                          IntelAhci|PIIX3|PIIX4|ICH6|I82078|\n                                          USB|NVMe|VirtIO]\n                            [--portcount <1-30>]\n                            [--hostiocache on|off]\n                            [--bootable on|off]\n                            [--rename <name>]\n                            [--remove]\n      The parameters are as follows:\n    \nuuid|vmname\n\n            The VM UUID or VM Name. Mandatory.\n          \n--name\n\n            Specifies the name of the storage controller. Mandatory.\n          \n--add\n\n            Specifies the type of the system bus to which the storage\n            controller must be connected.\n          \n--controller\n\n            Enables a choice of chipset type being emulated for the\n            given storage controller.\n          \n--portcount\n\n            This specifies the number of ports the storage controller\n            should support.\n          \n--hostiocache\n\n            Configures the use of the host I/O cache for all disk images\n            attached to this storage controller. See\n            Section 5.7, “Host Input/Output Caching”.\n          \n--bootable\n\n            Specifies whether this controller is bootable.\n          \n--rename\n\n            Specifies a new name for the storage controller.\n          \n--remove\n\n            Removes the storage controller from the VM configuration.\n          8.19. VBoxManage bandwidthctl\n      This command creates, deletes, modifies, and shows bandwidth\n      groups of the given virtual machine.\n    VBoxManage bandwidthctl    <uuid|vmname>\n                           add <name> --type disk|network --limit <MBps>[k|m|g|K|M|G] |\n                           set <name> --limit <MBps>[k|m|g|K|M|G] |\n                           remove <name> |\n                           list [--machinereadable]\n      The following subcommands are available:\n    \nadd: Creates a new bandwidth group of a\n          given type.\n        \nset: Modifies the limit for an existing\n          bandwidth group.\n        \nremove: Deletes a bandwidth group.\n        \nlist: Shows all bandwidth groups defined\n          for the given VM. Use the\n          --machinereadable option to\n          produce the same output, but in machine readable format. This\n          is of the form: name=\"value\" on a line by line basis.\n        \n      The parameters are as follows:\n    \nuuid|vmname\n\n            The VM UUID or VM Name. Mandatory.\n          \n--name\n\n            Name of the bandwidth group. Mandatory.\n          \n--type\n\n            Type of the bandwidth group. Mandatory. Two types are\n            supported: disk and\n            network. See\n            Section 5.8, “Limiting Bandwidth for Disk Images” or\n            Section 6.10, “Limiting Bandwidth for Network Input/Output” for the\n            description of a particular type.\n          \n--limit\n\n            Specifies the limit for the given bandwidth group. This can\n            be changed while the VM is running. The default unit is\n            megabytes per second. The unit can be changed by specifying\n            one of the following suffixes:\n            k for kilobits per second,\n            m for megabits per second,\n            g for gigabits per second,\n            K for kilobytes per second,\n            M for megabytes per second,\n            G for gigabytes per second.\n          Note\n        The network bandwidth limits apply only to the traffic being\n        sent by virtual machines. The traffic being received by VMs is\n        unlimited.\n      Note\n        To remove a bandwidth group it must not be referenced by any\n        disks or adapters in the running VM.\n      8.20. VBoxManage showmediuminfo\n      This command shows information about a medium, notably its size,\n      its size on disk, its type, and the virtual machines which use it.\n    Note\n        For compatibility with earlier versions of Oracle VM VirtualBox, the\n        showvdiinfo command is also supported and\n        mapped internally to the showmediuminfo\n        command.\n      VBoxManage showmediuminfo     [disk|dvd|floppy] <uuid|filename>\n      The medium must be specified either by its UUID, if the medium is\n      registered, or by its filename. Registered images can be listed\n      using VBoxManage list hdds, VBoxManage\n      list dvds, or VBoxManage list\n      floppies, as appropriate. See\n      Section 8.4, “VBoxManage list”.\n    8.21. VBoxManage createmedium\n      This command creates a new medium. The syntax is as follows:\n    VBoxManage createmedium     [disk|dvd|floppy]    --filename <filename>\n                            [--size <megabytes>|--sizebyte <bytes>]\n                            [--diffparent <uuid>|<filename>\n                            [--format VDI|VMDK|VHD] (default: VDI)\n                            [--variant Standard,Fixed,Split2G,Stream,ESX]\n      The parameters are as follows:\n    \n--filename <filename>\n\n            Specifies a file name <filename> as an absolute path\n            on the host file system. Mandatory.\n          \n--size <megabytes>\n\n            Specifies the image capacity, in 1 MB units. Optional.\n          \n--diffparent\n          <uuid>|<filename>\n\n            Specifies the differencing image parent, either as a UUID or\n            by the absolute pathname of the file on the host file\n            system. Useful for sharing a base box disk image among\n            several VMs.\n          \n--format VDI|VMDK|VHD\n\n            Specifies the file format for the output file. Available\n            options are VDI, VMDK, VHD. The default format is VDI.\n            Optional.\n          \n--variant\n\n            Specifies any required file format variants for the output\n            file. This is a comma-separated list of variant flags.\n            Options are Standard,Fixed,Split2G,Stream,ESX. Not all\n            combinations are supported, and specifying mutually\n            incompatible flags results in an error message. Optional.\n          Note\n        For compatibility with earlier versions of Oracle VM VirtualBox, the\n        createvdi and createhd\n        commands are also supported and mapped internally to the\n        createmedium command.\n      8.22. VBoxManage modifymedium\n      With the modifymedium command, you can change\n      the characteristics of a disk image after it has been created.\n    VBoxManage modifymedium  [disk|dvd|floppy]    <uuid|filename>\n                         [--type normal|writethrough|immutable|shareable|\n                                 readonly|multiattach]\n                         [--autoreset on|off]\n                         [--property <name=[value]>]\n                         [--compact]\n                         [--resize <megabytes>|--resizebyte <bytes>]\n                         [--move <path>]\n                         [--setlocation <path>]Note\n        For compatibility with earlier versions of Oracle VM VirtualBox, the\n        modifyvdi and modifyhd\n        commands are also supported and mapped internally to the\n        modifymedium command.\n      \n      The disk image to modify must be specified either by its UUID, if\n      the medium is registered, or by its filename. Registered images\n      can be listed using VBoxManage list hdds, see\n      Section 8.4, “VBoxManage list”. A filename must be specified\n      as a valid path, either as an absolute path or as a relative path\n      starting from the current directory.\n    \n      The following options are available:\n    \n          With the --type argument, you\n          can change the type of an existing image between the normal,\n          immutable, write-through and other modes. See\n          Section 5.4, “Special Image Write Modes”.\n        \n          For immutable hard disks only, the --autoreset\n          on|off option determines whether the disk is\n          automatically reset on every VM startup. See\n          Section 5.4, “Special Image Write Modes”. By default, autoreset is on.\n        \n          The --compact option can be\n          used to compact disk images. Compacting removes blocks that\n          only contains zeroes. Using this option will shrink a\n          dynamically allocated image. It will reduce the\n          physical size of the image without\n          affecting the logical size of the virtual disk. Compaction\n          works both for base images and for differencing images created\n          as part of a snapshot.\n        \n          For this operation to be effective, it is required that free\n          space in the guest system first be zeroed out using a suitable\n          software tool. For Windows guests, you can use the\n          sdelete tool provided by Microsoft. Run\n          sdelete -z in the guest to zero the free\n          disk space, before compressing the virtual disk image. For\n          Linux, use the zerofree utility which\n          supports ext2/ext3 filesystems. For Mac OS X guests, use the\n          diskutil secureErase freespace 0\n          / command from an elevated Terminal.\n        \n          Please note that compacting is currently only available for\n          VDI images. A similar effect can be achieved by zeroing out\n          free blocks and then cloning the disk to any other dynamically\n          allocated format. You can use this workaround until compacting\n          is also supported for disk formats other than VDI.\n        \n          The --resize x option, where\n          x is the desired new total space in megabytes enables you to\n          change the capacity of an existing image. This adjusts the\n          logical size of a virtual disk without\n          affecting the physical size much.\n        \n          This option currently works only for VDI and VHD formats, and\n          only for the dynamically allocated variants. It can only be\n          used to expand, but not shrink, the capacity. For example, if\n          you originally created a 10 GB disk which is now full, you can\n          use the --resize 15360\n          command to change the capacity to 15 GB (15,360 MB) without\n          having to create a new image and copy all data from within a\n          virtual machine. Note however that this only changes the drive\n          capacity. You will typically next need to use a partition\n          management tool inside the guest to adjust the main partition\n          to fill the drive.\n        \n          The --resizebyte x option\n          does almost the same thing, except that x is expressed in\n          bytes instead of megabytes.\n        \n          The --move <path>\n          option can be used to relocate a medium to a different\n          location <path> on the host file system. The path can be\n          either relative to the current directory or absolute.\n        \n          The --setlocation\n          <path> option can be used to set the\n          new location <path> of the medium on the host file\n          system if the medium has been moved for any reasons. The path\n          can be either relative to the current directory or absolute.\n        Note\n            The new location is used as is, without any sanity checks.\n            The user is responsible for setting the correct path.\n          8.23. VBoxManage clonemedium\n      This command duplicates a virtual disk, DVD, or floppy medium to a\n      new medium, usually an image file, with a new unique identifier\n      (UUID). The new image can be transferred to another host system or\n      reimported into Oracle VM VirtualBox using the Virtual Media Manager.\n      See Section 5.3, “The Virtual Media Manager” and Section 5.6, “Cloning Disk Images”.\n      The syntax is as follows:\n    VBoxManage clonemedium      [disk|dvd|floppy] <uuid|inputfile> <uuid|outputfile>\n\n                            [--format VDI|VMDK|VHD|RAW|<other>]\n                            [--variant Standard,Fixed,Split2G,Stream,ESX]\n                            [--existing]\n      The medium to clone as well as the target image must be described\n      either by its UUIDs, if the mediums are registered, or by its\n      filename. Registered images can be listed by VBoxManage\n      list hdds. See Section 8.4, “VBoxManage list”. A\n      filename must be specified as valid path, either as an absolute\n      path or as a relative path starting from the current directory.\n    \n      The following options are available:\n    \n--format\n\n            Set a file format for the output file different from the\n            file format of the input file.\n          \n--variant\n\n            Set a file format variant for the output file. This is a\n            comma-separated list of variant flags. Not all combinations\n            are supported, and specifying inconsistent flags will result\n            in an error message.\n          \n--existing\n\n            Perform the clone operation to an already existing\n            destination medium. Only the portion of the source medium\n            which fits into the destination medium is copied. This means\n            if the destination medium is smaller than the source only a\n            part of it is copied, and if the destination medium is\n            larger than the source the remaining part of the destination\n            medium is unchanged.\n          Note\n        For compatibility with earlier versions of Oracle VM VirtualBox, the\n        clonevdi and clonehd\n        commands are still supported and mapped internally to the\n        clonemedium command.\n      8.24. VBoxManage mediumproperty\n      This command sets, gets, or deletes a medium property. The syntax\n      is as follows:\n    VBoxManage mediumproperty [disk|dvd|floppy] set <uuid|filename>\n                                                <property> <value>\n          Use <disk|dvd|floppy>\n          to optionally specify the type of medium: disk (hard drive),\n          dvd, or floppy.\n        \n          Use <uuid|filename> to\n          supply either the UUID or absolute path of the medium or\n          image.\n        \n          Use <property> to\n          supply the name of the property.\n        \n          Use <value> to supply\n          the property value.\n        VBoxManage mediumproperty [disk|dvd|floppy] get <uuid|filename>\n                                                <property>\n          Use <disk|dvd|floppy>\n          to optionally specify the type of medium: disk (hard drive),\n          dvd, or floppy.\n        \n          Use <uuid|filename> to\n          supply either the UUID or absolute path of the medium or\n          image.\n        \n          Use <property> to\n          supply the name of the property.\n        VBoxManage mediumproperty [disk|dvd|floppy] delete <uuid|filename>\n                                                   <property>\n          Use <disk|dvd|floppy>\n          to optionally specify the type of medium: disk (hard drive),\n          dvd, or floppy.\n        \n          Use <uuid|filename> to\n          supply either the UUID or absolute path of the medium or\n          image.\n        \n          Use <property> to\n          supply the name of the property.\n        8.25. VBoxManage encryptmedium\n      This command is used to create a DEK encrypted medium or image.\n      See Section 9.28.2, “Encrypting Disk Images”.\n    \n      The syntax is as follows:\n    VBoxManage encryptmedium <uuid|filename>\n                         [--newpassword <file|->]\n                         [--oldpassword <file|->]\n                         [--cipher <cipher id>]\n                         [--newpasswordid <password id>]\n          Use <uuid|filename> to\n          supply the UUID or absolute path of the medium or image to be\n          encrypted.\n        \n          Use --newpassword\n          <file|-> to supply a new encryption\n          password. Either specify the absolute pathname of a password\n          file on the host operating system, or\n          - to prompt you for the\n          password on the command line. Always use the\n          --newpasswordid option with\n          this option.\n        \n          Use --oldpassword\n          <file|-> to supply any old encryption\n          password. Either specify the absolute pathname of a password\n          file on the host operating system, or\n          - to prompt you for the old\n          password on the command line.\n        \n          Use this option to gain access to an encrypted medium or image\n          to either change its password using\n          --newpassword or change its\n          encryption using --cipher.\n        \n          Use --cipher <cipher>\n          to specify the cipher to use for encryption. This can be\n          either AES-XTS128-PLAIN64 or\n          AES-XTS256-PLAIN64.\n        \n          Use this option to change any existing encryption on the\n          medium or image, or to set up new encryption on it for the\n          first time.\n        \n          Use --newpasswordid <password\n          id> to supply the new password identifier.\n          This can be chosen by the user, and is used for correct\n          identification when supplying multiple passwords during VM\n          startup.\n        \n          If the user uses the same password when encrypting multiple\n          images and also the same password identifier, the user needs\n          to supply the password only once during VM startup.\n        8.26. VBoxManage checkmediumpwd\n      This command is used to check the current encryption password on a\n      DEK encrypted medium or image. See\n      Section 9.28.2, “Encrypting Disk Images”.\n    \n      The syntax is as follows:\n    VBoxManage checkmediumpwd <uuid|filename>\n                                      <pwd file|->\n          Use <uuid|filename> to\n          supply the UUID or absolute path of the medium or image to be\n          checked.\n        \n          Use <pwd file|-> to\n          supply the password identifier to be checked. Either specify\n          the absolute pathname of a password file on the host operating\n          system, or - to prompt you\n          for the password on the command line.\n        8.27. VBoxManage convertfromraw\n      This command converts a raw disk image to an Oracle VM VirtualBox Disk\n      Image (VDI) file. The syntax is as follows:\n    VBoxManage convertfromraw   <filename> <outputfile>\n                            [--format VDI|VMDK|VHD]\n                            [--variant Standard,Fixed,Split2G,Stream,ESX]\n                            [--uuid <uuid>]\nVBoxManage convertfromraw   stdin <outputfile> <bytes>\n                            [--format VDI|VMDK|VHD]\n                            [--variant Standard,Fixed,Split2G,Stream,ESX]\n                            [--uuid <uuid>]\n      The parameters are as follows:\n    \n--bytes\n\n            The size of the image file, in bytes, provided through\n            stdin.\n          \n--format\n\n            Select the disk image format to create. The default format\n            is VDI. Other options are VMDK and VHD.\n          \n--variant\n\n            Choose a file format variant for the output file. This is a\n            comma-separated list of variant flags. Not all combinations\n            are supported, and specifying inconsistent flags will result\n            in an error message.\n          \n--uuid\n\n            Specify the UUID of the output file.\n          \n      The stdin form of the command forces\n      VBoxManage to read the content of the disk\n      image from standard input. This useful when using the command in a\n      pipe.\n    Note\n        For compatibility with earlier versions of Oracle VM VirtualBox, the\n        convertdd command is also supported and\n        mapped internally to the convertfromraw\n        command.\n      8.28. VBoxManage getextradata/setextradata\n      These commands enable you to attach and retrieve string data for a\n      virtual machine or for an Oracle VM VirtualBox configuration, by\n      specifying global instead of a\n      virtual machine name. You must specify a keyword as a text string\n      to associate the data with, which you can later use to retrieve\n      it. For example:\n    VBoxManage setextradata Fedora5 installdate 2006.01.01\nVBoxManage setextradata SUSE10 installdate 2006.02.02\n      This example would associate the string \"2006.01.01\" with the\n      keyword installdate for the virtual machine Fedora5, and\n      \"2006.02.02\" on the machine SUSE10. You could then retrieve the\n      information as follows:\n    VBoxManage getextradata Fedora5 installdate\n      This would return the following:\n    VirtualBox Command Line Management Interface Version version-number\n(C) 2005-2018 Oracle Corporation\nAll rights reserved.\n\nValue: 2006.01.01\n      You could retrieve the information for all keywords as follows:\n    VBoxManage getextradata Fedora5 enumerate\n      To remove a keyword, the setextradata command\n      must be run without specifying data, only the keyword. For\n      example:\n    VBoxManage setextradata Fedora5 installdate8.29. VBoxManage setproperty\n      This command is used to change global settings which affect the\n      entire Oracle VM VirtualBox installation. Some of these correspond to\n      the settings in the Global\n      Settings dialog in the graphical user interface. The\n      following properties are available:\n    \nmachinefolder\n\n            Specifies the default folder in which virtual machine\n            definitions are kept. See Section 10.1, “Where Oracle VM VirtualBox Stores its Files”.\n          \nhwvirtexclusive\n\n            Specifies whether Oracle VM VirtualBox will make exclusive use of\n            the hardware virtualization extensions (Intel VT-x or AMD-V)\n            of the host system's processor. See\n            Section 10.3, “Hardware Virtualization”. If you wish to share these\n            extensions with other hypervisors running at the same time,\n            you must disable this setting. Doing so has negative\n            performance implications.\n          \nvrdeauthlibrary\n\n            Specifies which library to use when external authentication\n            has been selected for a particular virtual machine. See\n            Section 7.1.5, “RDP Authentication”.\n          \nwebsrvauthlibrary\n\n            Specifies which library the web service uses to authenticate\n            users. For details about the Oracle VM VirtualBox web service, see\n            the Oracle VM VirtualBox SDK reference,\n            Chapter 11, Oracle VM VirtualBox Programming Interfaces.\n          \nvrdeextpack\n\n            Specifies which library implements the VirtualBox Remote\n            Desktop Extension.\n          \nloghistorycount\n\n            Selects how many rotated VM logs are retained.\n          \nautostartdbpath\n\n            Selects the path to the autostart database. See\n            Section 9.21, “Starting Virtual Machines During System Boot”.\n          \ndefaultfrontend\n\n            Selects the global default VM frontend setting. See\n            Section 8.12, “VBoxManage startvm”.\n          \nlogginglevel\n\n            Configures the VBoxSVC release logging details. See\n            http://www.virtualbox.org/wiki/VBoxLogging.\n          \nproxymode\n\n            Configures the mode for an HTTP proxy server.\n          \nproxyurl\n\n            Configures the URL for an HTTP proxy server. Used when a\n            manual proxy is configured using the\n            manual setting of the\n            proxymode property.\n          8.30. VBoxManage usbfilter add/modify/removeVBoxManage usbfilter        add <index,0-N>\n                          --target <uuid|vmname>global\n                          --name <string>\n                          --action ignore|hold (global filters only)\n                         [--active yes|no (yes)]\n                         [--vendorid <XXXX> (null)]\n                         [--productid <XXXX> (null)]\n                         [--revision <IIFF> (null)]\n                         [--manufacturer <string> (null)]\n                         [--product <string> (null)]\n                         [--remote yes|no (null, VM filters only)]\n                         [--serialnumber <string> (null)]\n                         [--maskedinterfaces <XXXXXXXX>]\n    VBoxManage usbfilter        modify <index,0-N>\n                          --target <uuid|vmname>global\n                         [--name <string>]\n                         [--action ignore|hold (global filters only)]\n                         [--active yes|no]\n                         [--vendorid <XXXX>]\n                         [--productid <XXXX>]\n                         [--revision <IIFF>]\n                         [--manufacturer <string>]\n                         [--product <string>]\n                         [--remote yes|no (null, VM filters only)]\n                         [--serialnumber <string>]\n                         [--maskedinterfaces <XXXXXXXX>]\n    VBoxManage usbfilter        remove <index,0-N>\n                          --target <uuid|vmname>global\n    \n      The usbfilter commands are used for working\n      with USB filters in virtual machines, or global filters which\n      affect the whole Oracle VM VirtualBox setup. Global filters are applied\n      before machine-specific filters, and may be used to prevent\n      devices from being captured by any virtual machine. Global filters\n      are always applied in a particular order, and only the first\n      filter which fits a device is applied. For example, if the first\n      global filter says to hold, or make available, a particular\n      Kingston memory stick device and the second filter says to ignore\n      all Kingston devices. That particular Kingston memory stick will\n      be available to any machine with the appropriate filter, but no\n      other Kingston device will.\n    \n      When creating a USB filter using usbfilter add,\n      you must supply three or four mandatory parameters. The index\n      specifies the position in the list at which the filter should be\n      placed. If there is already a filter at that position, then it and\n      the following ones will be shifted back one place. Otherwise, the\n      new filter will be added onto the end of the list. The\n      target parameter selects the\n      virtual machine that the filter should be attached to or use\n      global to apply it to all virtual\n      machines. name is a name for the\n      new filter. For global filters,\n      action says whether to allow VMs\n      access to devices that fit the filter description (hold) or not to\n      give them access (ignore). In addition, you should specify\n      parameters to filter by. You can find the parameters for devices\n      attached to your system using VBoxManage list\n      usbhost. Finally, you can specify whether the filter\n      should be active. For local filters, whether they are for local\n      devices, remote devices over an RDP connection, or either.\n    \n      When you modify a USB filter using usbfilter\n      modify, you must specify the filter by index and by\n      target, which is either a virtual machine or\n      global. See the output of\n      VBoxManage list usbfilters to find global\n      filter indexes and VBoxManage showvminfo to\n      find indexes for individual machines. The properties which can be\n      changed are the same as for usbfilter add. To\n      remove a filter, use usbfilter remove and\n      specify the index and the target.\n    \n      The following is a list of the additional usbfilter\n      add and usbfilter modify options,\n      with details of how to use them.\n    \n--action ignore|hold:\n          Specifies whether devices that fit the filter description are\n          allowed access by machines (hold), or have access denied\n          (ignore). Applies to global filters only.\n        \n--active yes|no: Specifies\n          whether the USB Filter is active or temporarily disabled. For\n          usbfilter create the default\n          is active.\n        \n--vendorid <XXXX>|\"\":\n          Specifies a vendor ID filter. The string representation for an\n          exact match has the form XXXX, where X is the hexadecimal\n          digit, including leading zeroes.\n        \n--productid <XXXX>|\"\":\n          Specifies a product ID filter. The string representation for\n          an exact match has the form XXXX, where X is the hexadecimal\n          digit, including leading zeroes.\n        \n--revision <IIFF>|\"\":\n          Specifies a revision ID filter. The string representation for\n          an exact match has the form IIFF, where I is the decimal digit\n          of the integer part of the revision, and F is the decimal\n          digit of its fractional part, including leading and trailing\n          zeros. Note that for interval filters, it is best to use the\n          hexadecimal form, because the revision is stored as a 16-bit\n          packed BCD value. Therefore, the expression int:0x0100-0x0199\n          will match any revision from 1.0 to 1.99 inclusive.\n        \n--manufacturer\n          <string>|\"\": Specifies a manufacturer\n          ID filter, as a string.\n        \n--product <string>|\"\":\n          Specifies a product ID filter, as a string.\n        \n--remote yes|no\"\": Specifies\n          a remote filter, indicating whether the device is physically\n          connected to a remote VRDE client or to a local host machine.\n          Applies to VM filters only.\n        \n--serialnumber\n          <string>|\"\": Specifies a serial number\n          filter, as a string.\n        \n--maskedinterfaces\n          <XXXXXXXX>: Specifies a masked\n          interface filter, for hiding one or more USB interfaces from\n          the guest. The value is a bit mask where the set bits\n          correspond to the USB interfaces that should be hidden, or\n          masked off. This feature only works on Linux hosts.\n        8.31. VBoxManage guestproperty\n      The guestproperty commands enable you to get or\n      set properties of a running virtual machine. See\n      Section 4.7, “Guest Properties”. Guest properties are\n      arbitrary keyword-value string pairs which can be written to and\n      read from by either the guest or the host, so they can be used as\n      a low-volume communication channel for strings, provided that a\n      guest is running and has the Guest Additions installed. In\n      addition, a number of values whose keywords begin with\n      /VirtualBox/are automatically set\n      and maintained by the Guest Additions.\n    \n      The following subcommands are available, where\n      <vm> can either be a VM\n      name or a VM UUID, as with the other VBoxManage\n      commands:\n    \nenumerate <vm> [--patterns\n          <pattern>]: Lists all the guest\n          properties that are available for the given VM, including the\n          value. This list will be very limited if the guest's service\n          process cannot be contacted, for example because the VM is not\n          running or the Guest Additions are not installed.\n        \n          If --patterns <pattern>\n          is specified, it acts as a filter to only list properties that\n          match the given pattern. The pattern can contain the following\n          wildcard characters:\n        \n* (asterisk): Represents\n              any number of characters. For example,\n              \"/VirtualBox*\" would\n              match all properties beginning with \"/VirtualBox\".\n            \n? (question mark):\n              Represents a single arbitrary character. For example,\n              \"fo?\" would match both\n              \"foo\" and \"for\".\n            \n| (pipe symbol): Can be\n              used to specify multiple alternative patterns. For\n              example, \"s*|t*\" would\n              match anything starting with either \"s\" or \"t\".\n            \nget <vm>\n          <property>: Retrieves the value of a\n          single property only. If the property cannot be found, for\n          example because the guest is not running, the following\n          message is shown:\n        No value set!\nset <vm> <property> [<value>\n          [--flags <flags>]]: Enables you to set\n          a guest property by specifying the keyword and value. If\n          <value> is omitted, the\n          property is deleted. With\n          --flags, you can specify\n          additional behavior. You can combine several flags by\n          separating them with commas.\n        \nTRANSIENT: The value will\n              not be stored with the VM data when the VM exits.\n            \nTRANSRESET: The value\n              will be deleted as soon as the VM restarts or exits.\n            \nRDONLYGUEST: The value\n              can only be changed by the host, but the guest can only\n              read it.\n            \nRDONLYHOST: The value can\n              only be changed by the guest, but the host can only read\n              it.\n            \nREADONLY: The value\n              cannot be changed at all.\n            \nwait <vm> <pattern> --timeout\n          <timeout>: Waits for a particular value\n          described by the pattern string to change or to be deleted or\n          created. The pattern rules are the same as for the\n          enumerate subcommand.\n        \ndelete <vm>\n          <property>: Deletes a guest property\n          which has been set previously.\n        8.32. VBoxManage guestcontrol\n      The guestcontrol commands enable control of the\n      guest from the host. See\n      Section 4.9, “Guest Control of Applications” for an introduction.\n    \n      The guestcontrol command has two sets of\n      subcommands. The first set requires guest credentials to be\n      specified, the second does not.\n    \n      The first set of subcommands is of the following form:\n    VBoxManage guestcontrol <uuid|vmname> <sub-command>\n            [--username <name> ]\n            [--passwordfile <file> | --password <password>]\n            [--domain <domain> ]\n            [-v|--verbose] [-q|quiet] ...\n    \n      The common options are as follows:\n    \n           [--username <name> ]\n           [--passwordfile <file> | --password <password>]\n           [--domain <domain> ]\n           [-v|--verbose] [-q|quiet]\n    \n      The common options for the first set of subcommands are explained\n      in the following list.\n    \n<uuid|vmname>\n\n            Specifies the VM UUID or VM name. Mandatory.\n          \n--username <name>\n\n            Specifies the user name on guest OS under which the process\n            should run. This user name must already exist on the guest\n            OS. If unspecified, the host user name is used. Optional\n          \n--passwordfile\n          <file>|--password\n\n            Specifies the absolute path on guest file system of password\n            file containing the password for the specified user account\n            or password for the specified user account. Optional. If\n            both are omitted, empty password is assumed.\n          \n--domain <domain>\n\n            User domain for Windows guests. Optional.\n          \n-v|--verbose\n\n            Makes the subcommand execution more verbose. Optional\n          \n-q|--quiet\n\n            Makes the subcommand execution quieter. Optional.\n          \n      The first set of subcommands are as follows:\n    \nrun: Executes a guest\n          program, forwarding stdout, stderr, and stdin to and from the\n          host until it completes.\n        VBoxManage guestcontrol <uuid|vmname> run [common-options]\n            --exe <path to executable> [--timeout <msec>]\n           [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]\n           [--ignore-operhaned-processes] [--profile]\n           [--no-wait-stdout|--wait-stdout]\n           [--no-wait-stderr|--wait-stderr]\n           [--dos2unix] [--unix2dos]\n            -- <program/arg0> [argument1] ... [argumentN]]\n          \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--exe <path to\n              executable>\n\n                Specifies the absolute path of the executable on the\n                guest OS file system. Mandatory. For example:\n                C:\\Windows\\System32\\calc.exe.\n              \n--timeout <msec>\n\n                Specifies the maximum time, in microseconds, that the\n                executable can run, during which\n                VBoxManage receives its output.\n                Optional. If unspecified, VBoxManage\n                waits indefinitely for the process to end, or an error\n                occurs.\n              \n-E|--putenv\n              <NAME>=<VALUE>\n\n                Sets, modifies, and unsets environment variables in the\n                environment in which the program will run. Optional.\n              \n                The guest process is created with the standard default\n                guest OS environment. Use this option to modify that\n                default environment. To set or modify a variable use:\n                <NAME>=<VALUE>.\n                To unset a variable use:\n                <NAME>=\n\n                Any spaces in names and values should be enclosed by\n                quotes.\n              \n                To set, modify, and unset multiple variables, use\n                multiple instances of the\n                --E|--putenv option.\n              \n--unquoted-args\n\n                Disables escaped double quoting, such as \\\"fred\\\", on\n                arguments passed to the executed program. Optional.\n              \n--ignore-operhaned-processes\n\n                Ignore orphaned processes. Not yet implemented.\n                Optional.\n              \n--profile\n\n                Use Profile. Not yet implemented. Optional.\n              \n--no-wait-stdout|--wait-stdout\n\n                Does not wait or waits until the guest process ends and\n                receives its exit code and reason/flags. In the case of\n                --wait-stdout,\n                VBoxManage receives its stdout while\n                the process runs. Optional.\n              \n--no-wait-stderr|--wait-stderr\n\n                Does not wait or waits until the guest process ends and\n                receives its exit code, error messages, and flags. In\n                the case of\n                --wait-stderr,\n                VBoxManage receives its stderr while\n                the process runs. Optional.\n              \n--dos2unix\n\n                Converts output from DOS/Windows guests to\n                UNIX/Linux-compatible line endings, CR + LF to LF. Not\n                yet implemented. Optional.\n              \n--unix2dos\n\n                Converts output from a UNIX/Linux guests to\n                DOS/Windows-compatible line endings, LF to CR + LF. Not\n                yet implemented. Optional.\n              \n[-- <program/arg0>\n              [<argument1>] ...\n              [<argumentN>]]\n\n                Specifies the program name, followed by one or more\n                arguments to pass to the program. Optional.\n              \n                Any spaces in arguments should be enclosed by quotes.\n              Note\n            On Windows there are certain limitations for graphical\n            applications. See Chapter 14, Known Limitations.\n          \n          Examples of using the guestcontrol run\n          command are as follows:\n        VBoxManage --nologo guestcontrol \"My VM\" run --exe \"/bin/ls\"\n          --username foo --passwordfile bar.txt --wait-exit --wait-stdout -- -l /usrVBoxManage --nologo guestcontrol \"My VM\" run --exe \"c:\\\\windows\\\\system32\\\\ipconfig.exe\"\n          --username foo --passwordfile bar.txt --wait-exit --wait-stdout\n          Note that the double backslashes in the second example are\n          only required on UNIX hosts.\n        Note\n            For certain commands a user name of an existing user account\n            on the guest must be specified. Anonymous executions are not\n            supported for security reasons. A user account password,\n            however, is optional and depends on the guest's OS security\n            policy or rules. If no password is specified for a given\n            user name, an empty password will be used. On certain OSes\n            like Windows the security policy may needs to be adjusted in\n            order to allow user accounts with an empty password set.\n            Also, global domain rules might apply and therefore cannot\n            be changed.\n          \n          Starting at Oracle VM VirtualBox 4.1.2 guest process execution by\n          default is limited to serve up to five guest processes at a\n          time. If a new guest process gets started which would exceed\n          this limit, the oldest not running guest process will be\n          discarded in order to be able to run that new process. Also,\n          retrieving output from this old guest process will not be\n          possible anymore then. If all five guest processes are still\n          active and running, starting a new guest process will result\n          in an appropriate error message.\n        \n          To raise or lower the guest process execution limit, either\n          use the guest property\n          /VirtualBox/GuestAdd/VBoxService/--control-procs-max-kept\n          or VBoxService command line by specifying\n          --control-procs-max-kept\n          needs to be modified. A restart of the guest OS is required\n          afterwards. To serve unlimited guest processes, a value of\n          0 needs to be set, but this\n          is not recommended.\n        \nstart: Executes a guest\n          program until it completes.\n        VBoxManage guestcontrol <uuid|vmname> start [common-options]\n           [--exe <path to executable>] [--timeout <msec>]\n           [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]\n           [--ignore-operhaned-processes] [--profile]\n            -- <program/arg0> [argument1] ... [argumentN]]\n          \n          Where the options are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--exe <path to\n              executable>\n\n                Specifies the absolute path of the executable on the\n                guest OS file system. Mandatory. For example:\n                C:\\Windows\\System32\\calc.exe\n\n--timeout <msec>\n\n                Specifies the maximum time, in microseconds, that the\n                executable can run. Optional. If unspecified,\n                VBoxManage waits indefinitely for the\n                process to end, or an error occurs.\n              \n-E|--putenv\n              <NAME>=<VALUE>\n\n                Sets, modifies, and unsets environment variables in the\n                environment in which the program will run. Optional.\n              \n                The guest process is created with the standard default\n                guest OS environment. Use this option to modify that\n                default environment. To set or modify a variable use:\n                <NAME>=<VALUE>.\n                To unset a variable use:\n                <NAME>=\n\n                Any spaces in names and values should be enclosed by\n                quotes.\n              \n                To set, modify, or unset multiple variables, use\n                multiple instances of the\n                --E|--putenv option.\n              \n--unquoted-args\n\n                Disables escaped double quoting, such as \\\"fred\\\", on\n                arguments passed to the executed program. Optional.\n              \n--ignore-operhaned-processes\n\n                Ignores orphaned processes. Not yet implemented.\n                Optional.\n              \n--profile\n\n                Use a profile. Not yet implemented. Optional.\n              \n[-- <program/arg0>\n              [<argument1>] ...\n              [<argumentN>]]\n\n                Specifies the program name, followed by one or more\n                arguments to pass to the program. Optional.\n              \n                Any spaces in arguments should be enclosed by quotes.\n              Note\n            On Windows there are certain limitations for graphical\n            applications. See Chapter 14, Known Limitations.\n          \n          Examples of using the guestcontrol start\n          command are as follows:\n        VBoxManage --nologo guestcontrol \"My VM\" start --exe \"/bin/ls\"\n          --username foo --passwordfile bar.txt --wait-exit --wait-stdout -- -l /usrVBoxManage --nologo guestcontrol \"My VM\" start --exe \"c:\\\\windows\\\\system32\\\\ipconfig.exe\"\n          --username foo --passwordfile bar.txt --wait-exit --wait-stdout\n          Note that the double backslashes in the second example are\n          only required on UNIX hosts.\n        Note\n            For certain commands a user name of an existing user account\n            on the guest must be specified. Anonymous executions are not\n            supported for security reasons. A user account password,\n            however, is optional and depends on the guest's OS security\n            policy or rules. If no password is specified for a given\n            user name, an empty password will be used. On certain OSes\n            like Windows the security policy may needs to be adjusted in\n            order to allow user accounts with an empty password set.\n            Also, global domain rules might apply and therefore cannot\n            be changed.\n          \n          Starting at Oracle VM VirtualBox 4.1.2 guest process execution by\n          default is limited to serve up to five guest processes at a\n          time. If a new guest process gets started which would exceed\n          this limit, the oldest not running guest process will be\n          discarded in order to be able to run that new process. Also,\n          retrieving output from this old guest process will not be\n          possible anymore then. If all five guest processes are still\n          active and running, starting a new guest process will result\n          in an appropriate error message.\n        \n          To raise or lower the guest process execution limit, either\n          use the guest property\n          /VirtualBox/GuestAdd/VBoxService/--control-procs-max-kept\n          or VBoxService command line by specifying\n          --control-procs-max-kept\n          needs to be modified. A restart of the guest OS is required\n          afterwards. To serve unlimited guest processes, a value of\n          0 needs to be set, but this\n          is not recommended.\n        \ncopyfrom: Copies files from\n          the guest to the host file system. Only available with Guest\n          Additions 4.0 or later installed.\n        VBoxManage guestcontrol <uuid|vmname> copyfrom [common-options]\n           [--follow] [--R|recursive]\n            --target-directory <host-dst-dir>\n            <guest-src0> [<guest-src1> [...]] \n          Where the parameters are as follows:\n        \n<uid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--follow\n\n                Enables symlink following on the guest file system.\n                Optional.\n              \n-R|--recursive\n\n                Enables recursive copying of files and directories from\n                the specified guest file system directory. Optional.\n              \n--target-directory\n              <host-dst-dir>\n\n                Specifies the absolute path of the host file system\n                destination directory. Mandatory. For example:\n                C:\\Temp.\n              \n<guest-src0> [<guest-src1>\n              [...]]\n\n                Specifies the absolute paths of guest file system files\n                to be copied. Mandatory. For example:\n                C:\\Windows\\System32\\calc.exe.\n                Wildcards can be used in the expressions. For example:\n                C:\\Windows\\System*\\*.dll.\n              \ncopyto: Copies files from the\n          host to the guest file system. Only available with Guest\n          Additions 4.0 or later installed.\n        VBoxManage guestcontrol <uuid|vmname> copyto [common-options]\n           [--follow] [--R|recursive]\n            --target-directory <guest-dst>\n            <host-src0> [<host-src1> [...]] \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--follow\n\n                Enables symlink following on the host file system.\n                Optional.\n              \n-R|--recursive\n\n                Enables recursive copying of files and directories from\n                the specified host file system directory. Optional.\n              \n--target-directory\n              <guest-dst>\n\n                Specifies the absolute path of the guest file system\n                destination directory. Mandatory. For example:\n                C:\\Temp.\n              \n<host-src0> [<host-src1>\n              [...]]\n\n                Specifies the absolute paths of host file system files\n                to be copied. Mandatory. For example:\n                C:\\Windows\\System32\\calc.exe.\n                Wildcards can be used in the expressions. For example:\n                C:\\Windows\\System*\\*.dll.\n              \nmd|mkdir|createdir|createdirectory:\n          Creates one or more directories on the guest file system. Only\n          available with Guest Additions 4.0 or later installed.\n        VBoxManage guestcontrol <uuid|vmname>  md|mkdir|createdir|createdirectory [common-options]\n            [--parents] [--mode <mode>]\n            <guest-dir0> [<guest-dir1> [...]] \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--parents\n\n                Creates any absent parent directories of the specified\n                directory. Optional.\n              \n                For example: If specified directory is\n                D:\\Foo\\Bar and\n                D:\\Foo is absent, it will be\n                created. In such a case, had the\n                --parents option not\n                been used, this command would have failed.\n              \n--mode <mode>\n\n                Specifies the permission mode on the specified\n                directories, and any parents, if the\n                --parents option is\n                used. Currently octal modes only, such as.\n                0755, are supported.\n              \n<guest-dir0> [<guest-dir1>\n              [...]]\n\n                Specifies a list of absolute paths of directories to be\n                created on guest file system. Mandatory. For example:\n                D:\\Foo\\Bar.\n              \n                All parent directories must already exist unless the\n                switch --parents is\n                used. For example, in the above example\n                D:\\Foo. The specified user must\n                have sufficient rights to create the specified\n                directories, and any parents that need to be created.\n              \nrmdir|removedir|removedirectory:\n          Deletes specified guest file system directories. Only\n          available with installed Guest Additions 4.3.2 and later.\n        VBoxManage guestcontrol <uuid|vmname> rmdir|removedir|removedirectory [common-options]\n           [--recursive|-R]\n            <guest-dir0> [<guest-dir1> [...]]\n          \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--recursive\n\n                Recursively removes directories and contents. Optional.\n              \n<guest-dir0> [<guest-dir1>\n              [...]]\n\n                Specifies a list of the absolute paths of directories to\n                be deleted on guest file system. Mandatory. Wildcards\n                are allowed. For example:\n                D:\\Foo\\*Bar. The specified user\n                must have sufficient rights to delete the specified\n                directories.\n              \nrm|removefile: Deletes\n          specified files on the guest file system. Only available with\n          installed Guest Additions 4.3.2 and later.\n        VBoxManage guestcontrol <uuid|vmname> rm|removefile [common-options]\n           [-f|--force]\n            <guest-file0> [<guest-file1> [...]] \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n-f|--force\n\n                Enforce operation and override any requests for\n                confirmations. Optional.\n              \n<guest-file0> [<guest-file1>\n              [...]]\n\n                Specifies a list of absolute paths of files to be\n                deleted on guest file system. Mandatory. Wildcards are\n                allowed. For example:\n                D:\\Foo\\Bar\\text*.txt. The specified\n                user should have sufficient rights to delete the\n                specified files.\n              \nmv|move|ren|rename: Renames\n          files and/or directories on the guest file system. Only\n          available with installed Guest Additions 4.3.2 and later.\n        VBoxManage guestcontrol <uuid|vmname> mv|move|ren|rename [common-options]\n           <guest-source0> [<guest-source1> [...]] <guest-dest>\n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n<guest-source0>\n              [<guest-source1> [...]]\n\n                Specifies absolute paths of files or a single directory\n                to be moved and renamed on guest file system. Mandatory.\n                Wildcards are allowed in file names. The specified user\n                should have sufficient rights to access the specified\n                files.\n              \n<dest>\n\n                Specifies the absolute path of the destination file or\n                directory to which the files are to be moved. Mandatory.\n                If only one file to be moved, <dest> can be file\n                or directory, else it must be a directory. The specified\n                user must have sufficient rights to access the\n                destination file or directory.\n              \nmktemp|createtemp|createtemporary:\n          Creates a temporary file or directory on the guest file\n          system, to assist subsequent copying of files from the host to\n          the guest file systems. By default, the file or directory is\n          created in the guest's platform specific temp directory. Not\n          currently supported. Only available with installed Guest\n          Additions 4.2 and later.\n        VBoxManage guestcontrol <uuid|vmname> mktemp|createtemp|createtemporary [common-options]\n           [--directory] [--secure] [--mode <mode>] [--tmpdir <directory>]\n            <template>\n            \n          The parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--directory\n\n                Creates a temporary directory instead of a file,\n                specified by the <template> parameter. Optional.\n              \n--secure\n\n                Enforces secure file and directory creation. Optional.\n                The permission mode is set to\n                0755. Operation fails\n                if it cannot be performed securely.\n              \n--mode <mode>\n\n                Specifies the permission mode of the specified\n                directory. Optional. Currently only octal modes, such as\n                0755, are supported.\n              \n--tmpdir\n              <directory>\n\n                Specifies the absolute path of the directory on the\n                guest file system where the file or directory specified\n                will be created. Optional. If unspecified, the\n                platform-specific temp directory is used.\n              \n<template>\n\n                Specifies a file name without a directory path,\n                containing at least one sequence of three consecutive X\n                characters, or ending in X. Mandatory.\n              \nstat: Displays file or file\n          system statuses on the guest.\n        VBoxManage guestcontrol <uuid|vmname> stat [common-options]\n           <file0> [<file1> [...]]\n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n<file0> [<file1>\n              [...]]\n\n                Specifies absolute paths of files or file systems on the\n                guest file system. Mandatory. For example:\n                /home/foo/a.out. The specified user\n                should have sufficient rights to access the specified\n                files or file systems.\n              \n      The second set of subcommands is of the form:\n    VBoxManage guestcontrol <uuid|vmname> <sub-command>\n           [-v|--verbose] [-q|quiet] ...\n    \n      The common options are as follows:\n    \n            [-v|--verbose] [-q|--quiet]\n    \n      Details of the common options for the second set of subcommands\n      are as follows:\n    \n-v|--verbose\n\n            Makes the subcommand execution more verbose. Optional.\n          \n-q|--quiet\n\n            Makes the subcommand execution quieter. Optional.\n          \n      The second set of subcommands are as follows:\n    \nlist: Lists guest control\n          configuration and status data. For example: open guest\n          sessions, guest processes, and files.\n        VBoxManage guestcontrol <uuid|vmname> list [common-opts]\n           <all|sessions|processes|files> \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \nall|sessions|processes|files\n\n                Indicates whether to list all available data or guest\n                sessions, processes or files. Mandatory.\n              \ncloseprocess: Terminates\n          guest processes specified by PIDs running in a guest session,\n          specified by the session ID or name.\n        VBoxManage guestcontrol <uuid|vmname> closeprocess [common-options]\n           --session-id <ID> | --session-name <name or pattern>\n           <PID0> [<PID1> [...]] \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--session-id <ID>\n\n                Specifies the guest session by its ID. Optional.\n              \n--session-name <name or\n              pattern>\n\n                Specifies the guest session by its name, or multiple\n                sessions using a pattern containing wildcards. Optional.\n              \n<PID0> [<PID1>\n              [...]]\n\n                Specifies a list of process identifiers (PIDs) of guest\n                processes to be terminated. Mandatory.\n              \nclosesession: Closes\n          specified guest sessions, specified either by session ID or\n          name.\n        VBoxManage guestcontrol <uuid|vmname> closesession [common-options]\n           --session-id <ID> | --session-name <name or pattern> | --all \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--session-id <ID>\n\n                Specifies the guest session to be closed by ID.\n                Optional.\n              \n--session-name <name or\n              pattern>\n\n                Specifies the guest session to be closed by name.\n                Optional. Multiple sessions can be specified by using a\n                pattern containing wildcards.\n              \n--all\n\n                Close all guest sessions. Optional.\n              \nupdatega|updateadditions|updateguestadditions:\n          Ugrades Guest Additions already installed on the guest. Only\n          available for already installed Guest Additions 4.0 and later.\n        VBoxManage guestcontrol <uuid|vmname> updatega|updateadditions|updateguestadditions\n           [common-options]\n           [--source <New .ISO path>]\n           [--wait-start]\n           [-- <argument0> [<argument1> [...]]]\n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              \n--source <New .ISO\n              path>\n            \n                Specifies the absolute path on the guest file system of\n                the .ISO file for the Guest Additions update. Mandatory.\n              \n--wait-start\n\n                Indicates that VBoxManage starts the\n                usual updating process on the guest and then waits until\n                the actual Guest Additions updating begins, at which\n                point VBoxManage self-terminates.\n                Optional.\n              \n                Default behavior is that VBoxManage\n                waits for completion of the Guest Additions update\n                before terminating. Use of this option is sometimes\n                necessary, as a running VBoxManage\n                can affect the interaction between the installer and the\n                guest OS.\n              \n[-- <argument0> [<argument1>\n              [...]]]\n\n                Specifies optional command line arguments to be supplied\n                to the Guest Additions updater. Useful for retrofitting\n                features which are not currently installed.\n              \n                Arguments containing spaces should be enclosed by\n                quotes.\n              \nwatch: Prints current guest\n          control activity.\n        VBoxManage guestcontrol <uuid|vmname> watch [common-options]\n          \n          Where the parameters are as follows:\n        \n<uuid|vmname>\n\n                Specifies the VM UUID or VM name. Mandatory.\n              8.33. VBoxManage metrics\n      This command supports monitoring the usage of system resources.\n      Resources are represented by various metrics associated with the\n      host system or a particular VM. For example, the host system has a\n      CPU/Load/User metric that shows\n      the percentage of time CPUs spend executing in user mode over a\n      specific sampling period.\n    \n      Metric data is collected and retained internally. It may be\n      retrieved at any time with the VBoxManage metrics\n      query subcommand. The data is available as long as the\n      background VBoxSVC process is\n      alive. That process terminates shortly after all VMs and frontends\n      have been closed.\n    \n      By default no metrics are collected at all. Metrics collection\n      does not start until VBoxManage metrics setup\n      is invoked with a proper sampling interval and the number of\n      metrics to be retained. The interval is measured in seconds. For\n      example, to enable collecting the host processor and memory usage\n      metrics every second and keeping the five most current samples,\n      the following command can be used:\n    VBoxManage metrics setup --period 1 --samples 5 host CPU/Load,RAM/Usage\n      Metric collection can only be enabled for started VMs. Collected\n      data and collection settings for a particular VM will disappear as\n      soon as it shuts down. Use the VBoxManage metrics\n      list subcommand to see which metrics are currently\n      available. You can also use the --list option\n      with any subcommand that modifies metric settings to find out\n      which metrics were affected.\n    \n      Note that the VBoxManage metrics setup\n      subcommand discards all samples that may have been previously\n      collected for the specified set of objects and metrics.\n    \n      To enable or disable metrics collection without discarding the\n      data, VBoxManage metrics enable and\n      VBoxManage metrics disable subcommands can be\n      used. Note that these subcommands expect metrics as parameters,\n      not submetrics such as CPU/Load\n      or RAM/Usage. In other words\n      enabling CPU/Load/User while\n      disabling CPU/Load/Kernel is not\n      supported.\n    \n      The host and VMs have different sets of associated metrics.\n      Available metrics can be listed with VBoxManage metrics\n      list subcommand.\n    \n      A complete metric name may include an aggregate function. The name\n      has the following form:\n      Category/Metric[/SubMetric][:aggregate].\n      For example, RAM/Usage/Free:min\n      stands for the minimum amount of available memory over all\n      retained data if applied to the host object.\n    \n      Subcommands may apply to all objects and metrics or can be limited\n      to one object and a list of metrics. If no objects or metrics are\n      given in the parameters, the subcommands will apply to all\n      available metrics of all objects. You may use an asterisk\n      \"*\" to explicitly specify that\n      the command should be applied to all objects or metrics. Use\n      host as the object name to limit\n      the scope of the command to host-related metrics. To limit the\n      scope to a subset of metrics, use a metric list with names\n      separated by commas.\n    \n      For example, to query metric data on the CPU time spent in user\n      and kernel modes by the virtual machine named\n      test, use the following command:\n    VBoxManage metrics query test CPU/Load/User,CPU/Load/Kernel\n      The following list summarizes the available subcommands:\n    \nlist\n\n            Shows the parameters of the currently existing metrics. Note\n            that VM-specific metrics are only available when a\n            particular VM is running.\n          \nsetup\n\n            Sets the interval between taking two samples of metric data\n            and the number of samples retained internally. The retained\n            data is available for displaying with the\n            query subcommand. The\n            --list option shows which\n            metrics have been modified as the result of the command\n            execution.\n          \nenable\n\n            Resumes data collection after it has been stopped with the\n            disable subcommand. Note that specifying\n            submetrics as parameters will not enable underlying metrics.\n            Use --list to find out if\n            the command worked as expected.\n          \ndisable\n\n            Suspends data collection without affecting collection\n            parameters or collected data. Note that specifying\n            submetrics as parameters will not disable underlying\n            metrics. Use --list to find\n            out if the command worked as expected.\n          \nquery\n\n            Retrieves and displays the currently retained metric data.\n          Note\n              The query subcommand does not remove or\n              flush retained data. If you query often enough you will\n              see how old samples are gradually being phased out by new\n              samples.\n            \ncollect\n\n            Sets the interval between taking two samples of metric data\n            and the number of samples retained internally. The collected\n            data is displayed periodically until Ctrl+C is pressed,\n            unless the --detach option\n            is specified. With the\n            --detach option, this\n            subcommand operates the same way as\n            setup does. The\n            --list option shows which\n            metrics match the specified filter.\n          8.34. VBoxManage natnetwork\n      NAT networks use the Network Address Translation (NAT) service,\n      which works in a similar way to a home router. It groups systems\n      using it into a network and prevents outside systems from directly\n      accessing those inside, while letting systems inside communicate\n      with each other and outside systems using TCP and UDP over IPv4\n      and IPv6.\n    \n      A NAT service is attached to an internal network. Virtual machines\n      to make use of one should be attached to it. The name of an\n      internal network is chosen when the NAT service is created, and\n      the internal network will be created if it does not already exist.\n      The following is an example command to create a NAT network:\n    VBoxManage natnetwork add --netname natnet1 --network \"192.168.15.0/24\" --enable\n      Here, natnet1 is the name of the\n      internal network to be used and\n      192.168.15.0/24 is the network\n      address and mask of the NAT service interface. By default, in this\n      static configuration the gateway will be assigned the address\n      192.168.15.1, the address after the interface address, though this\n      is subject to change.\n    \n      To add a DHCP server to the NAT network after creation, run the\n      following command:\n    VBoxManage natnetwork modify --netname natnet1 --dhcp on\n      The subcommands for VBoxManage natnetwork are\n      as follows:\n    VBoxManage natnetwork add --netname <name>\n                         [--network <network>]\n                         [--enable|--disable]\n                         [--dhcp on|off]\n                         [--port-forward-4 <rule>]\n                         [--loopback-4 <rule>]\n                         [--ipv6 on|off]\n                         [--port-forward-6 <rule>]\n                         [--loopback-6 <rule>]\n    \nVBoxManage natnetwork add: Creates a new\n      internal network interface, and adds a NAT network service. This\n      command is a prerequisite for enabling attachment of VMs to the\n      NAT network. Parameters are as follows:\n    \n--netname <name>\n\n            Where <name> is the name of the new internal network\n            interface on the host OS.\n          \n--network <network>\n\n            Where <network> specifies the static or DHCP network\n            address and mask of the NAT service interface. The default\n            is a static network address.\n          \n--enable|--disable\n\n            Enables and disables the NAT network service.\n          \n--dhcp on|off\n\n            Enables and disables a DHCP server specified by\n            --netname. Use of this\n            option also indicates that it is a DHCP server.\n          \n--port-forward-4 <rule>\n\n            Enables IPv4 port forwarding, with a rule specified by\n            <rule>.\n          \n--loopback-4 <rule>\n\n            Enables the IPv4 loopback interface, with a rule specified\n            by <rule>.\n          \n--ipv6 on|off\n\n            Enables and disables IPv6. The default setting is IPv4,\n            disabling IPv6 enables IPv4.\n          \n--port-forward-6 <rule>\n\n            Enables IPv6 port forwarding, with a rule specified by\n            <rule>.\n          \n--loopback-6 <rule>\n\n            Enables the IPv6 loopback interface, with a rule specified\n            by <rule>.\n          VBoxManage natnetwork remove --netname <name> \nVBoxManage natnetwork remove: Removes a NAT\n      network service. Parameters are as follows:\n    \n--netname <name>\n\n            Where <name> specifies an existing NAT network\n            service. Does not remove any DHCP server enabled on the\n            network.\n          VBoxManage natnetwork modify --netname <name>\n                            [--network <network>]\n                            [--enable|--disable]\n                            [--dhcp on|off]\n                            [--port-forward-4 <rule>]\n                            [--loopback-4 <rule>]\n                            [--ipv6 on|off]\n                            [--port-forward-6 <rule>]\n                            [--loopback-6 <rule>]\n    \nVBoxManage natnetwork modify: Modifies an\n      existing NAT network service. Parameters are as follows:\n    \n--netname <name>\n\n            Where <name> specifies an existing NAT network\n            service.\n          \n--network <network>\n\n            Where <network> specifies the new static or DHCP\n            network address and mask of the NAT service interface. The\n            default is a static network address.\n          \n--enable|--disable\n\n            Enables and disables the NAT network service.\n          \n--dhcp on|off\n\n            Enables and disables a DHCP server. If a DHCP server is not\n            present, using enable adds a new DHCP server.\n          \n--port-forward-4 <rule>\n\n            Enables IPv4 port forwarding, with a rule specified by\n            <rule>.\n          \n--loopback-4 <rule>\n\n            Enables the IPv4 loopback interface, with a rule specified\n            by <rule>.\n          \n--ipv6 on|off\n\n            Enables and disables IPv6. The default setting is IPv4,\n            disabling IPv6 enables IPv4.\n          \n--port-forward-6 <rule>\n\n            Enables IPv6 port forwarding, with a rule specified by\n            <rule>.\n          \n--loopback-6 <rule>\n\n            Enables IPv6 loopback interface, with a rule specified by\n            <rule>.\n          VBoxManage natnetwork start --netname <name>\n    \nVBoxManage natnetwork start: Starts the\n      specified NAT network service and any associated DHCP server.\n      Parameters are as follows:\n    \n--netname <name>\n\n            Where <name> specifies an existing NAT network\n            service.\n          VBoxManage natnetwork stop --netname <name>\n    \nVBoxManage natnetwork stop: Stops the specified\n      NAT network service and any DHCP server. Parameters are as\n      follows:\n    \n--netname <name>\n\n            Where <name> specifies an existing NAT network\n            service.\n          VBoxManage natnetwork list [<pattern>] \nVBoxManage natnetwork list: Lists all NAT\n      network services, with optional filtering. Parameters are as\n      follows:\n    \n[<pattern>]\n\n            Where <pattern> is an optional filtering pattern.\n          8.35. VBoxManage hostonlyif\n      The hostonlyif command enables you to change\n      the IP configuration of a host-only network interface. For a\n      description of host-only networking, see\n      Section 6.7, “Host-Only Networking”. Each host-only interface is\n      identified by a name and can either use the internal DHCP server\n      or a manual IP configuration, both IP4 and IP6.\n    \n      The following list summarizes the available subcommands:\n    \nipconfig \"<name>\"\n\n            Configures a host-only interface.\n          \ncreate\n\n            Creates a new vboxnet<N> interface on the host OS.\n            This command is essential before you can attach VMs to a\n            host-only network.\n          \nremove vboxnet<N>\n\n            Removes a vboxnet<N> interface from the host OS.\n          8.36. VBoxManage usbdevsource\n      The usbdevsource commands enable you to add and\n      remove USB devices globally.\n    \n      The following command adds a USB device.\n    VBoxManage usbdevsource add <source name>\n                            --backend <backend>\n                            --address <address>\n    \n      Where the command line options are as follows:\n    \n<source name>:\n          Specifies the ID of the source USB device to be added.\n          Mandatory.\n        \n--backend <backend>:\n          Specifies the USB proxy service backend to use. Mandatory.\n        \n --address <address>:\n          Specifies the backend specific address. Mandatory.\n        \n      The following command removes a USB device.\n    VBoxManage usbdevsource remove <source name>\n    \n      Where the command line options are as follows:\n    \n<source name>:\n          Specifies the ID of the source USB device to be removed.\n          Mandatory.\n        8.37. VBoxManage unattendedUnattended guest OS installation.SynopsisVBoxManage unattended detect  <--iso=install-iso> [--machine-readable]VBoxManage unattended install  <uuid|vmname> <--iso=install-iso> [--user=login] [--password=password] [--password-file=file] [--full-user-name=name] [--key=product-key] [--install-additions] [--no-install-additions] [--additions-iso=add-iso] [--install-txs] [--no-install-txs] [--validation-kit-iso=testing-iso] [--locale=ll_CC] [--country=CC] [--time-zone=tz] [--hostname=fqdn] [--package-selection-adjustment=keyword] [--dry-run] [--auxiliary-base-path=path] [--image-index=number] [--script-template=file] [--post-install-template=file] [--post-install-command=command] [--extra-install-kernel-parameters=params] [--language=lang] [--start-vm=session-type]Descriptionunattended detectVBoxManage unattended detect  <--iso=install-iso> [--machine-readable]\n        Detects the guest operating system (OS) on the specified installation ISO\n        and displays the result.  This can be used as input when creating a VM for\n        the ISO to be installed in.\n      \n--iso=install-iso\nThe installation ISO to run the detection on.\n--machine-readable\nProduce output that is simpler to parse from a script.unattended installVBoxManage unattended install  <uuid|vmname> <--iso=install-iso> [--user=login] [--password=password] [--password-file=file] [--full-user-name=name] [--key=product-key] [--install-additions] [--no-install-additions] [--additions-iso=add-iso] [--install-txs] [--no-install-txs] [--validation-kit-iso=testing-iso] [--locale=ll_CC] [--country=CC] [--time-zone=tz] [--hostname=fqdn] [--package-selection-adjustment=keyword] [--dry-run] [--auxiliary-base-path=path] [--image-index=number] [--script-template=file] [--post-install-template=file] [--post-install-command=command] [--extra-install-kernel-parameters=params] [--language=lang] [--start-vm=session-type]\n        Reconfigures the specified VM for installation and optionally starts it up.\n      \nuuid|vmname\nEither the UUID or the name (case sensitive) of a VM.\n--iso=install-iso\nThe installation ISO to run the detection on.\n--user=login\nThe login name. (default: vboxuser)\n--password=password\nThe login password.  This is used for the user given by --user as well as the\n              root/administrator user.  (default: changeme)\n--password-file=file\nAlternative to --password for providing the password.  Special filename\n              stdin can be used to read the password from standard input.\n--full-user-name=name\nThe full user name.  (default: --user)\n--key=product-key\nThe guest OS product key.  Not all guest OSes requires this.--install-additions, --no-install-additionsWhether to install the VirtualBox guest additions.  (default: --no-install-addations)\n--additions-iso=add-iso\nPath to the VirtualBox guest additions ISO.  (default: installed/downloaded GAs)--install-txs, --no-install-txsWhether to install the test execution service (TXS) from the VirtualBox ValidationKit.\n              This is useful when preparing VMs for testing or similar.  (default: --no-install-txs)\n--validation-kit-iso=testing-iso\nPath to the VirtualBox ValidationKit ISO.  This is required if --install-txs\n              is specified. \n--locale=ll_CC\nThe base locale specification for the guest, like en_US, de_CH, or nn_NO.  (default: host or en_US)\n--country=CC\nThe two letter country code if it differs from the specified by --location.\n--time-zone=tz\nThe time zone to set up the guest OS with. (default: host time zone or UTC)\n--hostname=fqdn\nThe fully qualified domain name of the guest machine.\n              (default: vmname.myguest.virtualbox.org)\n--package-selection-adjustment=keyword\nAdjustments to the guest OS packages/components selection.  This can be specfied more than once.  Currently\n              the only recognized keyword is minimal which triggers a minimal installation for\n              some of the guest OSes.\n--dry-run\nDo not create any files or make any changes to the VM configuration.\n--start-vm=session-type\nStart the VM using the front end given by session-type. This is the same as\n              the --type option for the startvm command, but we have add\n              none for indicating that the VM should not be started.\n              (default: none)Advanced options:\n--auxiliary-base-path=path\nThe path prefix to the media related files generated for the installation.\n              (default: vm-config-dir/Unattended-vm-uuid-)\n--image-index=number\nWindows installation image index. (default: 1)\n--script-template=file\nThe unattended installation script template.  (default: IMachine::OSTypeId dependent)\n--post-install-template=file\nThe post installation script template.  (default: IMachine::OSTypeId dependent)\n--post-install-command=command\nA single command to run after the installation is completed.  The exact format and exactly\n              when this is run is guest OS installer dependent.\n--extra-install-kernel-parameters=params\n\n              List of extra linux kernel parameters to use during the installation. (default: IMachine::OSTypeId dependent)\n            \n--language=lang\n\n              Specifies the UI language for a Windows installation.  The lang is\n              generally on the form {ll}-{CC}.  See detectedOSLanguages results from VBoxManage unattended detect.\n              (default: detectedOSLanguages[0])8.38. VBoxManage snapshotManage Oracle VM VirtualBox virtual machine snapshots.SynopsisVBoxManage snapshot  <uuid|vmname>VBoxManage snapshot  <uuid|vmname>  take  <snapshot-name> [--description=description] [--live] [--uniquename Number,Timestamp,Space,Force]VBoxManage snapshot  <uuid|vmname>  delete  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restore  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restorecurrent VBoxManage snapshot  <uuid|vmname>  edit  < snapshot-name  |   --current > [--description=description] [--name=new-name]VBoxManage snapshot  <uuid|vmname>  list  [[--details] |  [--machinereadable]]VBoxManage snapshot  <uuid|vmname>  showvminfo  <snapshot-name>Description\n      The VBoxManage snapshot command manages\n      snapshots.\n    \n      Oracle VM VirtualBox uses the snapshot to capture the state of a virtual\n      machine (VM). You can later use the snapshot to revert to the\n      state described by the snapshot.\n    \n      A snapshot is a complete copy of a VM's settings. If you take the\n      snapshot while the VM is running, the snapshot also includes the\n      VM's state file.\n    \n      After you take a snapshot, Oracle VM VirtualBox creates a\n      differencing hard disk for each normal hard\n      disk that is associated with the host machine. When you restore a\n      snapshot, Oracle VM VirtualBox uses these differencing files to quickly\n      reset the contents of the VM's virtual hard disks.\n    \n      For each VBoxManage snapshot command, you must\n      specify the name or the universal unique identifier (UUID) of the\n      VM for which you want to take a snapshot.\n    General Command Operand\nuuid|vmname\n\n              Specifies the UUID or name of the VM.\n            Take a Snapshot of a Virtual MachineVBoxManage snapshot  <uuid|vmname>  take  <snapshot-name> [--description=description] [--live] [--uniquename Number,Timestamp,Space,Force]\n        The VBoxManage snapshot take command takes a\n        snapshot of the current state of the VM. You must supply a name\n        for the snapshot and can optionally supply a description. The\n        new snapshot is inserted into the snapshots tree as a child of\n        the current snapshot and then becomes the new current snapshot.\n      \n--description=description\n\n              Specifies a description of the snapshot.\n            \n--live\n\n              Specifies that the VM is not stopped while you create the\n              snapshot. This operation is know as live snapshotting.\n            \n--uniquename Number,Timestamp,Space,Force\n\n              TBD.\n            \nsnapshot-name\n\n              Specifies the name of the snapshot to create.\n            Delete a SnapshotVBoxManage snapshot  <uuid|vmname>  delete  <snapshot-name>\n        The VBoxManage snapshot delete command\n        removes the specified snapshot.\n      \n        The delete operation may take some time to finish. This is\n        because the differencing images that are associated with the\n        snapshot may need to be merged with their child differencing\n        images.\n      \nsnapshot-name\n\n              Specifies the UUID or name of the snapshot.\n            Restore a SnapshotVBoxManage snapshot  <uuid|vmname>  restore  <snapshot-name>\n        The VBoxManage snapshot restore command\n        restores the specified snapshot. This operation resets the VM's\n        settings and current state to that of the snapshot. The state of\n        the VM on which you restore a snapshot is lost. When restored,\n        the specified snapshot becomes the new current snapshot and\n        subsequent snapshots are children of that snapshot.\n      \nsnapshot-name\n\n              Specifies the UUID or name of the snapshot.\n            Restore the Current SnapshotVBoxManage snapshot  <uuid|vmname>  restorecurrent \n        The VBoxManage snapshot restorecurrent\n        command restores the current snapshot. The current snapshot is\n        the one from which the current state is derived. This command is\n        equivalent to using the VBoxManage snapshot\n        restore command and specifying the name or UUID of the\n        current snapshot.\n      Change the Name or Description of an Existing SnapshotVBoxManage snapshot  <uuid|vmname>  edit  < snapshot-name  |   --current > [--description=description] [--name=new-name]\n        The VBoxManage snapshot edit command enables\n        you to change the name or the description of a specified\n        snapshot.\n      \nsnapshot-name\n\n              Specifies the UUID or name of the snapshot to edit.\n            \n              This option is mutually exclusive with the\n              --current option.\n            \n--current\n\n              Specifies that you update the current version of the\n              snapshot.\n            \n              This option is mutually exclusive with a specific snapshot\n              name or its UUID.\n            \n--description=description\n\n              Specifies a new description for the snapshot.\n            \n--name=new-name\n\n              Specifies a new name for the snapshot.\n            List the SnapshotsVBoxManage snapshot  <uuid|vmname>  list  [[--details] |  [--machinereadable]]\n        The VBoxManage snapshot list command lists\n        all the snapshots for a VM.\n      \n--details\n\n              Specifies that the output shows detailed information about\n              the snapshot.\n            \n              This option is mutually exclusive with the\n              --machinereadable option.\n            \n--machinereadable\n\n              Specifies that the output is shown in a machine-readable\n              format.\n            \n              This option is mutually exclusive with the\n              --details option.\n            Show Information About a Snapshot's SettingsVBoxManage snapshot  <uuid|vmname>  showvminfo  <snapshot-name>\n        The VBoxManage snapshot showvminfo command\n        enables you to view the VM settings that are part of an existing\n        snapshot.\n      \nsnapshot-name\n\n              Specifies the UUID or name of the snapshot.\n            Examples\n      The following command creates a snapshot of the\n      ol7u4 VM. The snapshot is called\n      ol7u4-snap-001. The command uses\n      the --description option to provide a description\n      of the snapshot contents.\n    \n$ VBoxManage snapshot ol7u4 take ol7u4-snap-001 \\\n--description=\"Oracle Linux 7.4\"\n\n      The following command lists the snapshots for the\n      ol7u4 VM.\n    \n$ VBoxManage snapshot ol7u4 list\n\n      The following command changes the description for the\n      ol7u4-snap-001 snapshot of the\n      ol7u4 VM.\n    \n$ VBoxManage snapshot ol7u4 edit ol7u4-snap-001 \\\n--description=\"Oracle Linux 7.4 with UEK4 kernel\"\n\n      The following command shows VM settings for the\n      ol7u1-snap-001 snapshot of the\n      ol7u4 VM.\n    \n$ VBoxManage snapshot ol7u4 showvminfo ol7u4-snap-001\nName:            ol7u4\nGroups:          /\nGuest OS:        Oracle (64-bit)\nUUID:            43349d78-2ab3-4cb8-978f-0e755cd98090\nConfig file:     C:\\Users\\user1\\VirtualBox VMs\\ol7u4\\ol7u4.vbox\n...\nSnapshots:\n\n   Name: ol7u4-snap-001 (UUID: 1cffc37d-5c37-4b86-b9c5-a0f157a55f43)\n   Description: Oracle Linux 7.4 with UEK4 kernel\n8.39. VBoxManage clonevmCreate a clone of an existing Oracle VM VirtualBox virtual machine.SynopsisVBoxManage clonevm  <vmname|uuid> [--basefolder=basefolder] [--groups=group,...] [ --mode=machine  |   --mode=machinechildren  |   --mode=all ] [--name=name] [--options=option,...] [--register] [--snapshot=snapshot-name] [--uuid=uuid]Description\n      The VBoxManage clonevm command creates a clone\n      of an existing virtual machine (VM). The clone can be a full copy\n      of the VM or a linked copy of a VM.\n    \n      You must specify the name or the universal unique identifier\n      (UUID) of the VM you want to clone.\n    Command Operand and Options\n      The following list describes the operand and the options that you\n      can use with the VBoxManage clonevm command:\n    \nvmname|uuid\n\n            Specifies the name or UUID of the VM to clone.\n          \n--basefolder=basefolder\n\n            Specifies the name of the folder in which to save the\n            configuration for the new VM.\n          \n--groups=group,...\n\n            Assigns the clone to the specified group or groups. If you\n            specify more than one group, separate each group name with a\n            comma.\n          \n            Note that each group is identified by a group ID that starts\n            with a slash character (/)\n            so that groups can be nested. By default, a clone is always\n            assigned membership to the\n            / group.\n          \n--mode=machine|machineandchildren|all\n\n            Specifies which of the following cloning modes to use:\n          machine mode clones the\n                current state of the existing VM without any snapshots.\n                This is the default mode.\n              machineandchildren mode\n                clones the snapshot specified by by the\n                --snapshot option and all child\n                snapshots.\n              all mode clones all\n                snapshots and the current state of the existing VM.\n              \n--name=name\n\n            Specifies a new name for the new VM. The default value is\n            original-name\n            Clone where\n            original-name is the original\n            name of the VM.\n          \n--options=option,...\n\n            Specifies how to create the new clone.The --options argument can be used multiple\n            times to enable multiple options, or the options can be given as a\n            comma separated list.  The options are case insensitive.The following options (case-insensitive) are recognized:\nLink\n\n                  Creates a linked clone from a snapshot only.\n                \nKeepAllMACs\n\n                  Specifies that the new clone reuses the MAC addresses\n                  of each virtual network card from the existing VM.\n                \n                  If you do not specify this option or the\n                  --options=keepnatmacs option, the\n                  default behavior is to reinitialize the MAC addresses\n                  of each virtual network card.\n                \nKeepNATMACs\n\n                  Specifies that the new clone reuses the MAC addresses\n                  of each virtual network card from the existing VM when\n                  the network type is NAT.\n                \n                  If you do not specify this option or the\n                  KeepAllMACs option, the\n                  default behavior is to reinitialize the MAC addresses\n                  of each virtual network card.\n                \nKeepDiskNames\n\n                  Specifies that the new clone reuses the disk image\n                  names from the existing VM. By default, disk images\n                  are renamed.\n                \nKeepHwUUIDs\n\n                  Specifies that the new clone reuses the hardware IDs\n                  from the existing VM. By default, new UUIDs are used.\n                \n--register\n\n            Automatically registers the new clone in this Oracle VM VirtualBox\n            installation. You can manually register the new VM later by\n            using the VBoxManage registervm command.\n            See Section 8.6, “VBoxManage registervm/unregistervm”.\n          \n--snapshot=snapshot-name\n\n            Specifies the snapshot on which to base the new VM. By\n            default, the clone is created from the current state of the\n            specified VM.\n          \n--uuid=uuid\n\n            Specifies the UUID for the new VM. Ensure that this ID is\n            unique for the Oracle VM VirtualBox instance if you decide to\n            register this new VM. By default, Oracle VM VirtualBox provides a\n            new UUID.\n          Examples\n      The following command creates and registers an exact clone of the\n      ol7 VM. The clone is called\n      ol7-dev-001.\n    \n      The new clone includes all of the source VM's snapshots. The new\n      VM also reuses all network interface MAC addresses, disk names,\n      and UUIDs from the source VM.\n    \n$ VBoxManage clonevm ol7 --name=\"ol7-dev-001\" --register --mode=all \\\n    --options=keepallmacs --options=keepdisknames --options=keephwuuids\n\n      The following command creates and registers a clone of the\n      Snapshot 1 snapshot of the\n      ol7 VM. The clone is called\n      ol7-dev-002.\n    \n$ VBoxManage clonevm ol7 --name=\"ol7-dev-002\" --register --snapshot=\"Snapshot 1\"\nSee Also\nSection 8.6, “VBoxManage registervm/unregistervm”\n8.40. VBoxManage sharedfolderAdd and remove shared folders.SynopsisVBoxManage sharedfolder add  < uuid  |   vmname > <--name=name> <--hostpath=hostpath> [--readonly] [--transient] [--automount] [--auto-mount-point=path]VBoxManage sharedfolder remove  < uuid  |   vmname > <--name=name> [--transient]Description\n      Shared folders enable you to share data between the host system\n      and guests. To use shared folders, you must first install the\n      Oracle VM VirtualBox Guest Additions software on the guest OS.\n    \n      The shared folder is associated with a share name and the full\n      path name of the folder or directory on the host system. The share\n      name is a unique name within the namespace of the host OS.\n    Add a Shared FolderVBoxManage sharedfolder add  < uuid  |   vmname > <--name=name> <--hostpath=hostpath> [--readonly] [--transient] [--automount] [--auto-mount-point=path]\n        The VBoxManage sharedfolder add command\n        creates a shared folder. The folder you specify is on the host\n        computer. When configured, the contents of the folder on the\n        host system can be shared with the guest OS.\n      uuid|vmname\n              Specifies the name or UUID of the guest VM that shares a\n              folder with the host system.\n            --name=name\n              Specifies the name of the share, which is a unique name\n              within the namespace of the host OS.\n            --hostpath=hostpath\n              Specifies the absolute path of the folder or directory on\n              the host OS to share with the guest OS.\n            --readonly\n              Specifies that the share has only read-only access to\n              files at the host path.\n            \n              By default, shared folders have read-write access to the\n              files at the host path. However on Linux distributions,\n              shared folders are mounted with 770 file permissions with\n              the root user and the\n              vboxsf group. By using this option, the\n              file permissions become 700.\n            --transient\n              Specifies that the share is transient, which means that it\n              can be added and removed at runtime and does not persist\n              after the VM stops.\n            --automount\n              Specifies that the share is automatically mounted.\n            --auto-mount-point=path\n               Specifies the mount point of the share.  This guest OS specific.\n             \n               For Windows and OS/2 guest this must be an unused drive letter.\n               If left blank (or if the drive letter is already in use), the\n               last unused drive letter is used instead (i.e. searching from\n               Z: thru A:).\n             \n               For Linux, Solaris and other unix guest, it must be an absolute\n               path like /mnt/mysharedfolder.  If left\n               empty the default location is\n               /media/sf_sharename.\n             Remove a Shared FolderVBoxManage sharedfolder remove  < uuid  |   vmname > <--name=name> [--transient]\n        The VBoxManage sharedfolder remove command\n        removes a shared folder.\n      uuid|vmname\n              Specifies the name or UUID of the guest VM that shares a\n              folder with the host system.\n            --name=name\n              Specifies the name of the share to remove.\n            --transient\n              Specifies that the share is transient, which means that it\n              can be added and removed at runtime and does not persist\n              after the VM stops.\n            Examples\n      The following command creates a shared folder called\n      o7share for the ol7 VM.\n      The share is mounted automatically when the VM is started.\n    $ VBoxManage sharedfolder add ol7 --name ol7share --hostpath \"/home/user/ol7share\" --automount\n      The following command removes the shared folder called\n      o7share for the ol7 VM.\n    $ VBoxManage sharedfolder remove ol7 --name ol7share8.41. VBoxManage extpackExtension package management.SynopsisVBoxManage extpack install  [--replace] [--accept-license=sha256] <tarball>VBoxManage extpack uninstall  [--force] <name>VBoxManage extpack cleanup Descriptionextpack installVBoxManage extpack install  [--replace] [--accept-license=sha256] <tarball>\n        Installs a new extension pack on the system.  This command will fail if an older\n        version of the same extension pack is already installed.  The\n        --replace option can be used to uninstall any\n        old package before the new one is installed.\n      \n--replace\nUninstall existing extension pack version.\n--accept-license=sha256\nAccept the license text with the given SHA-256 hash value.VBoxManage will display the SHA-256 value when performing a manual\n            installation.  The hash can of course be calculated by looking inside\n            the extension pack and using sha256sum or similar on the license file.\ntarball\nThe file containing the extension pack to be installed.extpack uninstallVBoxManage extpack uninstall  [--force] <name>\n        Uninstalls an extension pack from the system.  The subcommand will also succeed\n        in the case where the specified extension pack is not present on the system.\n        You can use VBoxManage list extpacks to show\n        the names of the extension packs which are currently installed.\n      \n--force\nOverrides most refusals to uninstall an extension pack\nname\nThe name of the extension pack to be uninstalled.extpack cleanupVBoxManage extpack cleanup \n        Used to remove temporary files and directories that may have been left behind\n        if a previous install or uninstall command failed.\n      Examples\n          How to list extension packs:\n$ VBoxManage list extpacks\nExtension Packs: 1\nPack no. 0:   Oracle VM VirtualBox Extension Pack\nVersion:      4.1.12\nRevision:     77218\nEdition:\nDescription:  USB 2.0 Host Controller, VirtualBox RDP, PXE ROM with E1000 support.\nVRDE Module:  VBoxVRDP\nUsable:       true\nWhy unusable:How to remove an extension pack:\n$ VBoxManage extpack uninstall \"Oracle VM VirtualBox Extension Pack\"\n0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%\nSuccessfully uninstalled \"Oracle VM VirtualBox Extension Pack\".8.42. VBoxManage dhcpserverDHCP server management.SynopsisVBoxManage dhcpserver add  < --network=netname  |   --interface=ifname > <--server-ip=address> <--netmask=mask> <--lower-ip=address> <--upper-ip=address> < --enable  |   --disable > [[--global] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--incl-mac=address...] [--excl-mac=address...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--incl-vendor=string...] [--excl-vendor=string...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--incl-user=string...] [--excl-user=string...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--vm=name|uuid> [--nic=1-N] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...] [<--mac-address=address> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...]VBoxManage dhcpserver modify  < --network=netname  |   --interface=ifname > [--server-ip=address] [--lower-ip=address] [--upper-ip=address] [--netmask=mask] [ --enable  |   --disable ] [[--global] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--del-mac=address...] [--incl-mac=address...] [--excl-mac=address...] [--del-mac-wild=pattern...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--del-vendor=string...] [--incl-vendor=string...] [--excl-vendor=string...] [--del-vendor-wild=pattern...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--del-user=string...] [--incl-user=string...] [--excl-user=string...] [--del-user-wild=pattern...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--zap-conditions] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--vm=name|uuid> [--nic=1-N] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...] [<--mac-address=address> [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...]VBoxManage dhcpserver remove  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver restart  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver findlease  < --network=netname  |   --interface=ifname > <--mac-address=mac>Description\n      The dhcpserver commands enable you to control the DHCP\n       server that is built into VirtualBox.  You may find this useful when\n       using internal or host-only networking.  Theoretically, you can also\n       enable it for a bridged network, but that may cause conflicts with other\n       DHCP servers in your physical network.\n    Common optionsThe subcommands of dhcpserver all operate on an\n        internal network that can be identified via its name or in the host-only\n        case via the host-only interface name:--network=netnameThe internal network name.  This is the same as you\n            would use as value to the VBoxManage modifyvm --intnet\n            option when configuring a VM for internal networking.  Or you see as\n            VBoxNetworkName in the output from\n            VBoxManage list intnets,\n            VBoxManage list natnets, or\n            VBoxManage list hostonlyifs.\n          --interface=ifnameThe host only interface name.  This would be same value\n            as you would use for the VBoxManage modifyvm --hostonlyadapter\n            option when configuring a VM to use a host-only network.  The value\n            can also be found in the Name row in VBoxManage list hostonlyifs.\n          dhcpserver addVBoxManage dhcpserver add  < --network=netname  |   --interface=ifname > <--server-ip=address> <--netmask=mask> <--lower-ip=address> <--upper-ip=address> < --enable  |   --disable > [[--global] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--incl-mac=address...] [--excl-mac=address...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--incl-vendor=string...] [--excl-vendor=string...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--incl-user=string...] [--excl-user=string...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--vm=name|uuid> [--nic=1-N] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...] [<--mac-address=address> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...]\n        Adds a new DHCP server to a network or host-only interface.\n      \n        Options configuring the DHCP server core:\n      \n--server-ip=address\nThe IP address the DHCP server should use.--lower-ip=address, --upper-ip=addressThe IP address range for the DHCP server to manage.  This\n            should not include the address of the DHCP server itself, but it must be\n            in the same network as it.  The boundraries are inclusive, so both the\n            lower and upper addresses will be handed out to clients.\n--netmask=mask\nThe network mask.  Typically 255.255.255.0.--enable, --disableWhether to enable the DHCP server or disable it.  If not specified,\n            the server will be created in disabled state and no IP addresses handed out.\n        Options selecting the scope:\n      \n--global\nSet the configuration scope to global.  Any subsequent\n            --set-opt options will be apply to all the DHCP clients.\n--vm=vmname|uuid\nSet the configuration scope to the first NIC of the specified VM.  Any\n            subsequent --set-opt options will apply just to that interface,\n            nothing else.\n--nic=1-N\nSet the configuration scope to a NIC other than first of\n            the VM specified the in --vm.\n          \n--mac-address=address\nSet the configuration scope to the specified MAC address.\n--group=name\nSet the configuration scope to the specified group.\n        Options configuring the currently selected scope:\n      \n--set-opt=dhcp-opt-no value\nAdds the specified DHCP option number (0-255) and value.  The\n            value format is option specific (typically human readable) and will be\n            validated by the API and the DHCP server.\n          \n--set-opt-hex=dhcp-opt-no hexstring\nAdds the specified DHCP option number (0-255) and value.  The option value\n            is specified as a raw series of hex bytes, optionally separated by colons.  No validation\n            is performed on these by the API or the DHCP server, they will be pass as specified to the\n            client.\n          \n--force-opt=dhcp-opt-no\nForces the specified DHCP option number (0-255) onto to be\n            sent to the client whether it requested it or not (provided the option is\n            configured with a value at some level).\n          \n--suppress-opt=dhcp-opt-no\nPrevents the specified DHCP option number (0-255) from being\n            sent to the client when present in this or a high configuration scope.\n          \n--min-lease-time=seconds\nSets the minimum lease time for the current scope in seconds.\n            Zero means taking the value from a higher option level or use default.\n          \n--default-lease-time=seconds\nSets the default lease time for the current scope in seconds.\n            Zero means taking the value from a higher option level or use default.\n          \n--max-lease-time=seconds\nSets the maximum lease time for the current scope in seconds.\n            Zero means taking the value from a higher option level or use default.\n          \n--fixed-address=address\nFixed address assignment for a --vm or\n            --mac-address configuration scope.  Any empty\n            address turns it back to dynamic address assignment.\n          \n        Options configuring group membership conditions (excludes overrides includes):\n      \n--incl-mac=address\nInclude the specific MAC address in the group.\n--excl-mac=address\nExclude the specific MAC address from the group.\n--incl-mac-wild=pattern\nInclude the specific MAC address pattern in the group.\n--excl-mac-wild=pattern\nExclude the specific MAC address pattern from the group.\n--incl-vendor=string\nInclude the specific vendor class ID  in the group.\n--excl-vendor=string\nExclude the specific vendor class ID from the group.\n--incl-vendor-wild=pattern\nInclude the specific vendor class ID pattern in the group.\n--excl-vendor-wild=pattern\nExclude the specific vendor class ID pattern from the group.\n--incl-user=string\nInclude the specific user class ID  in the group.\n--excl-user=string\nExclude the specific user class ID from the group.\n--incl-user-wild=pattern\nInclude the specific user class ID pattern in the group.\n--excl-user-wild=pattern\nExclude the specific user class ID pattern from the group.dhcpserver modifyVBoxManage dhcpserver modify  < --network=netname  |   --interface=ifname > [--server-ip=address] [--lower-ip=address] [--upper-ip=address] [--netmask=mask] [ --enable  |   --disable ] [[--global] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--del-mac=address...] [--incl-mac=address...] [--excl-mac=address...] [--del-mac-wild=pattern...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--del-vendor=string...] [--incl-vendor=string...] [--excl-vendor=string...] [--del-vendor-wild=pattern...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--del-user=string...] [--incl-user=string...] [--excl-user=string...] [--del-user-wild=pattern...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--zap-conditions] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--vm=name|uuid> [--nic=1-N] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...] [<--mac-address=address> [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...]\n        This modifies an existing DHCP server configuration.  It takes the same\n        options as the add command with the addition of the following\n        on scope configuration:\n      \n--del-opt=dhcp-opt-no\nCounterpart to --set-opt that will cause the specified\n            DHCP option number (0-255) to be deleted from the server settings.  Like with\n            --set-opt the scope of the deletion is governed by the\n            --global, --vm, --mac-address\n            and --group options.\n          \n--unforce-opt=dhcp-opt-no\nRemoves the specified DHCP option number (0-255) from the forced\n            option list (i.e. the reverse of --force-opt).  Like with\n            --set-opt the scope of the deletion is governed by the\n            --global, --vm, --mac-address\n            and --group options.\n          \n--unsuppress-opt=dhcp-opt-no\nRemoves the specified DHCP option number (0-255) from the supressed\n            option list (i.e. the reverse of --suppress-opt). Like with\n            --set-opt the scope of the deletion is governed by the\n            --global, --vm, --mac-address\n            and --group options.\n          \n--remove-config\nRemoves the configuration currently being scoped.  The\n          --global scope is not removable.  The configuration scope will\n           change to --global after this option.\n          \n        And the addition of these group membership condition options:\n      \n--del-mac=address\nDelete the specific MAC address from the group conditions.\n--del-mac-wild=pattern\nDelete the specific MAC address pattern from the group conditions.\n--del-vendor=string\nDelete the specific vendor class ID from the group conditions.\n--del-vendor-wild=pattern\nDelete the specific vendor class ID pattern from the group conditions.\n--del-user=string\nDelete the specific user class ID pattern from the group conditions.\n--del-user-wild=pattern\nDelete the specific user class ID pattern from the group conditions.\n--zap-conditions\nDeletes all the group conditions.dhcpserver removeVBoxManage dhcpserver remove  < --network=netname  |   --interface=ifname >\n        Removes the specified DHCP server.\n      dhcpserver restartVBoxManage dhcpserver restart  < --network=netname  |   --interface=ifname >\n        Restarts the specified DHCP server.  The DHCP server must be running.\n      dhcpserver findleaseVBoxManage dhcpserver findlease  < --network=netname  |   --interface=ifname > <--mac-address=mac>\n        Performs a lease database lookup.  This is mainly for getting the IP\n        address of a running VM.\n      \n--mac-address=mac\nThe MAC address to lookup in the lease database.Common DHCP Options:1 - SubnetMaskIPv4 netmask. Set to the value of the --netmask option by default.2 - TimeOffsetUTC offset in seconds (32-bit decimal value).3 - RoutersSpace separated list of IPv4 router addresses.4 - TimeServersSpace separated list of IPv4 time server (RFC 868) addresses.5 - NameServersSpace separated list of IPv4 name server (IEN 116) addresses.6 - DomainNameServersSpace separated list of IPv4 DNS addresses.7 - LogServersSpace separated list of IPv4 log server addresses.8 - CookieServersSpace separated list of IPv4 cookie server (RFC 865) addresses.9 - LPRServersSpace separated list of IPv4 line printer server (RFC 1179) addresses.10 - ImpressServersSpace separated list of IPv4 imagen impress server addresses.11 - ResourseLocationServersSpace separated list of IPv4 resource location (RFC 887) addresses.12 - HostNameThe client name. See RFC 1035 for character limits. 13 - BootFileSizeNumber of 512 byte blocks making up the boot file (16-bit decimal value).14 - MeritDumpFileClient core file.15 - DomainNameDomain name for the client.16 - SwapServerIPv4 address of the swap server that the client should use.17 - RootPathThe path to the root disk the client should use.18 - ExtensionPathPath to a file containing additional DHCP options (RFC2123).19 - IPForwardingWhether IP forwarding should be enabled by the client (boolean).20 - OptNonLocalSourceRoutingWhether non-local datagrams should be forwarded by the client (boolean)21 - PolicyFilterList of IPv4 addresses and masks paris controlling non-local source routing.22 - MaxDgramReassemblySizeThe maximum datagram size the client should reassemble (16-bit decimal value).23 - DefaultIPTTLThe default time-to-leave on outgoing (IP) datagrams (8-bit decimal value).24 - PathMTUAgingTimeoutRFC1191 path MTU discovery timeout value in seconds (32-bit decimal value).25 - PathMTUPlateauTableRFC1191 path MTU discovery size table, sorted in ascending order (list of 16-bit decimal values).26 - InterfaceMTUThe MTU size for the interface (16-bit decimal value).27 - AllSubnetsAreLocalIndicates whether the MTU size is the same for all subnets (boolean).28 - BroadcastAddressBroadcast address (RFC1122) for the client to use (IPv4 address).29 - PerformMaskDiscoveryWhether to perform subnet mask discovery via ICMP (boolean).30 - MaskSupplierWhether to respond to subnet mask requests via ICMP (boolean).31 - PerformRouterDiscoveryWhether to perform router discovery (RFC1256) (boolean).32 - RouterSolicitationAddressWhere to send router solicitation requests (RFC1256) (IPv4 address).33 - StaticRouteList of network and router address pairs addresses.34 - TrailerEncapsulationWhether to negotiate the use of trailers for ARP (RTF893) (boolean).35 - ARPCacheTimeoutThe timeout in seconds for ARP cache entries (32-bit decimal value).36 - EthernetEncapsulationWhether to use IEEE 802.3 (RTF1042) rather than of v2 (RFC894) ethernet encapsulation (boolean).37 - TCPDefaultTTLDefault time-to-live for TCP sends (non-zero 8-bit decimal value).38 - TCPKeepaliveIntervalThe interface in seconds between TCP keepalive messages (32-bit decimal value).39 - TCPKeepaliveGarbageWhether to include a byte of garbage in TCP keepalive messages for backward compatibility (boolean).40 - NISDomainThe NIS (Sun Network Information Services) domain name (string).41 - NISServersSpace separated list of IPv4 NIS server addresses.42 - NTPServersSpace separated list of IPv4 NTP (RFC1035) server addresses.43 - VendorSpecificInfoVendor specific information. Only accessible using --set-opt-hex.44 - NetBIOSNameServersSpace separated list of IPv4 NetBIOS name server (NBNS) addresses (RFC1001,RFC1002).45 - NetBIOSDatagramServersSpace separated list of IPv4 NetBIOS datagram distribution server (NBDD) addresses (RFC1001,RFC1002).46 - NetBIOSNodeTypeNetBIOS node type (RFC1001,RFC1002): 1=B-node, 2=P-node, 4=M-node, and 8=H-node (8-bit decimal value).47 - NetBIOSScopeNetBIOS scope (RFC1001,RFC1002). Only accessible using --set-opt-hex.48 - XWindowsFontServersSpace separated list of IPv4 X windows font server addresses.49 - XWindowsDisplayManagerSpace separated list of IPv4 X windows display manager addresses.62 - NetWareIPDomainNameNetware IP domain name (RFC2242) (string).63 - NetWareIPInformationNetware IP information (RFC2242). Only accessible using --set-opt-hex.64 - NISPlusDomainThe NIS+ domain name (string).65 - NISPlusServersSpace separated list of IPv4 NIS+ server addresses.66 - TFTPServerNameTFTP server name (string).67 - BootfileNameBootfile name (string).68 - MobileIPHomeAgentsSpace separated list of IPv4 mobile IP agent addresses.69 - SMTPServersSpace separated list of IPv4 simple mail transport protocol (SMPT) server addresses.70 - POP3ServersSpace separated list of IPv4 post office protocol 3 (POP3) server addresses.71 - NNTPServersSpace separated list of IPv4 network news transport protocol (NTTP) server addresses.72 - WWWServersSpace separated list of default IPv4 world wide web (WWW) server addresses.73 - FingerServersSpace separated list of default IPv4 finger server addresses.74 - IRCServersSpace separated list of default IPv4 internet relay chat (IRC) server  addresses.75 - StreetTalkServersSpace separated list of IPv4 StreetTalk server addresses.76 - STDAServersSpace separated list of IPv4 StreetTalk directory assistance (STDA) server addresses.78 - SLPDirectoryAgentAddresses of one or more service location protocol (SLP) directory agent, and an indicator of whether their use is mandatory. Only accessible using --set-opt-hex.79 - SLPServiceScopeList of service scopes for the service location protocol (SLP) and whether using the list is mandator. Only accessible using --set-opt-hex.119 - DomainSearchDomain search list, see RFC3397 and section 4.1.4 in RFC1035 for encoding.  Only accessible using --set-opt-hex.8.43. VBoxManage debugvmIntrospection and guest debugging.SynopsisVBoxManage debugvm  <uuid|vmname>  dumpvmcore  [--filename=name]VBoxManage debugvm  <uuid|vmname>  info  <item> [args...]VBoxManage debugvm  <uuid|vmname>  injectnmi VBoxManage debugvm  <uuid|vmname>  log  [[--release] |  [--debug]] [group-settings...]VBoxManage debugvm  <uuid|vmname>  logdest  [[--release] |  [--debug]] [destinations...]VBoxManage debugvm  <uuid|vmname>  logflags  [[--release] |  [--debug]] [flags...]VBoxManage debugvm  <uuid|vmname>  osdetect VBoxManage debugvm  <uuid|vmname>  osinfo VBoxManage debugvm  <uuid|vmname>  osdmesg  [--lines=lines]VBoxManage debugvm  <uuid|vmname>  getregisters  [--cpu=id] [reg-set.reg-name...]VBoxManage debugvm  <uuid|vmname>  setregisters  [--cpu=id] [reg-set.reg-name=value...]VBoxManage debugvm  <uuid|vmname>  show  [[--human-readable] |  [--sh-export] |  [--sh-eval] |  [--cmd-set]] [settings-item...]VBoxManage debugvm  <uuid|vmname>  stack  [--cpu=id]VBoxManage debugvm  <uuid|vmname>  statistics  [--reset] [--descriptions] [--pattern=pattern]DescriptionThe \"debugvm\" commands are for experts who want to tinker with the\n      exact details of virtual machine execution.  Like the VM debugger\n      described in Section 12.1.4, “The Built-In VM Debugger”, these commands are only useful if you are\n      very familiar with the details of the PC architecture and how to debug\n      software.Common optionsThe subcommands of debugvm all operate on a running virtual\n      machine:\nuuid|vmname\nEither the UUID or the name (case sensitive) of a VM.debugvm dumpvmcoreVBoxManage debugvm  <uuid|vmname>  dumpvmcore  [--filename=name]\n        Creates a system dump file of the specified VM.  This file will have\n        the standard ELF core format (with custom sections); see\n        Section 12.1.5, “VM Core Format”.\n      \n        This corresponds to the writecore command in the debugger.\n      \n--filename=filename\nThe name of the output file.debugvm infoVBoxManage debugvm  <uuid|vmname>  info  <item> [args...]\n        Displays info items relating to the VMM, device emulations and\n        associated drivers.\n      \n        This corresponds to the info command in the debugger.\n      \ninfo\nName of the info item to display.  The special name\n            help will list all the available info items and\n            hints about optional arguments.\nargs\nOptional argument string for the info item handler.  Most info items\n            does not take any extra arguments.  Arguments not recognized are generally\n            ignored.debugvm injectnmiVBoxManage debugvm  <uuid|vmname>  injectnmi \n        Causes a non-maskable interrupt (NMI) to be injected into the guest. This\n        might be useful for certain debugging scenarios. What happens exactly is\n        dependent on the guest operating system, but an NMI can crash the whole\n        guest operating system. Do not use unless you know what you're doing.\n      debugvm logVBoxManage debugvm  <uuid|vmname>  log  [[--release] |  [--debug]] [group-settings...]\n        Changes the group settings for either debug (--debug)\n        or release (--release) logger of the VM process.\n      \n        The group-settings are typically strings on the form\n        em.e.f.l, hm=~0\n        and -em.f.  Basic wildcards are supported for\n        group matching.  The all group is an alias for\n        all the groups.\n      \n        Please do keep in mind that the group settings are applied as modifications\n        to the current ones.\n      \n        This corresponds to the log command in the debugger.\n      debugvm logdestVBoxManage debugvm  <uuid|vmname>  logdest  [[--release] |  [--debug]] [destinations...]\n        Changes the destination settings for either debug (--debug)\n        or release (--release) logger of the VM process.  For details\n        on the destination format, the best source is src/VBox/Runtime/common/log/log.cpp.\n      \n        The destinations is one or more mnemonics, optionally\n        prefixed by \"no\" to disable them.  Some of them take values after a \":\" or \"=\"\n        separator.  Multiple mnemonics can be separated by space or given as separate\n        arguments on the command line.\n      \n        List of available destination:\n      \nfile[=file], nofile\nSpecifies a log file.  It no filname is given, one will be\n              generated based on the current UTC time and VM process name and placed in\n              the current directory of the VM process.  Note that this will currently not\n              have any effect if the log file has already been opened.\n          \ndir=directory, nodir\nSpecifies the output directory for log files.  Note that this\n              will currently not  have any effect if the log file has already been opened.\n          \nhistory=count, nohistory\nA non-zero value enables log historization, with the value\n            specifying how many old log files to keep.\n          \nhistsize=bytes\nThe max size of a log file before it is historized.  Default is infinite.\nhisttime=seconds\nThe max age (in seconds) of a log file before it is historized.  Default is infinite.\nringbuffer, noringbuffer\nOnly log to the log buffer until an explicit flush (e.g. via an assertion)\n              occurs.  This is fast and saves diskspace.\nstdout, nostdout\nWrite the log content to standard output.\nstdout, nostdout\nWrite the log content to standard error.\ndebugger, nodebugger\nWrite the log content to the debugger, if supported by the host OS.\ncom, nocom\nWrites logging to the COM port. This is only applicable for raw-mode and ring-0 logging.\nuser, nouser\nCustom destination which has no meaning to VM processes..\n        This corresponds to the logdest command in the debugger.\n      debugvm logflagsVBoxManage debugvm  <uuid|vmname>  logflags  [[--release] |  [--debug]] [flags...]\n        Changes the flags on either debug (--debug) or release\n        (--release) logger of the VM process.  Please note that the\n        modifications are applied onto the existing changes, they are not replacing them.\n      \n        The flags are a list of flag mnemonics, optionally\n        prefixed by a \"no\", \"!\", \"~\" or \"-\" to negate their meaning.  The \"+\" prefix\n        can be used to undo previous negation or use as a separator, though better use\n        whitespace or separate arguments for that.\n      \n        List of log flag mnemonics, with their counter form where applicable\n        (asterisk indicates defaults):\n      \nenabled*, disabled\nEnables or disables logging.\nbuffered, unbuffered*\nEnabling buffering of log output before it hits the destinations.\nwritethrough(/writethru)\nWhether to open the destination file with writethru buffering settings or not.\nflush\nEnables flushing of the output file (to disk) after each log statement.\nlockcnts\nPrefix each log line with lock counts for the current thread.\ncpuid\nPrefix each log line with the ID of the current CPU.\npid\nPrefix each log line with the current process ID.\nflagno\nPrefix each log line with the numberic flags corresponding to the log statement.\nflag\nPrefix each log line with the flag mnemonics corresponding to the log statement.\ngroupno\nPrefix each log line with the log group number for the log statement producing it.\ngroup\nPrefix each log line with the log group name for the log statement producing it.\ntid\nPrefix each log line with the current thread identifier.\nthread\nPrefix each log line with the current thread name.\ntime\nPrefix each log line with the current UTC wall time.\ntimeprog\nPrefix each log line with the current monotonic time since the start of the program.\nmsprog\nPrefix each log line with the current monotonic timestamp value in milliseconds since the start of the program.\nts\nPrefix each log line with the current monotonic timestamp value in nanoseconds.\ntsc\nPrefix each log line with the current CPU timestamp counter (TSC) value.\nrel, abs*\nSelects the whether ts and\n              tsc prefixes should be displayed as relative to the\n              previous log line or as absolute time.\nhex*, dec\nSelects the whether the ts and\n              tsc prefixes should be formatted as hexadecimal\n              or decimal.\ncustom\nCustom log prefix, has by default no meaning for VM processes.\nusecrlf, uself*\nOutput with DOS style (CRLF) or just UNIX style (LF) line endings.\noverwrite*, append\nOverwrite the destination file or append to it.\n        This corresponds to the logflags command in the debugger.\n      debugvm osdetectVBoxManage debugvm  <uuid|vmname>  osdetect \n        Make the VMM's debugger facility (re)-detect the guest operating system (OS).\n        This will first load all debugger plug-ins.\n      \n        This corresponds to the detect command in the debugger.\n      debugvm osinfoVBoxManage debugvm  <uuid|vmname>  osinfo \n        Displays information about the guest operating system (OS) previously\n        detected by the VMM's debugger facility.\n      debugvm osdmesgVBoxManage debugvm  <uuid|vmname>  osdmesg  [--lines=lines]\n        Displays the guest OS kernel log, if detected and supported.\n      \n--lines=lines\nNumber of lines of the log to display, counting from\n          the end. The default is infinite.debugvm getregistersVBoxManage debugvm  <uuid|vmname>  getregisters  [--cpu=id] [reg-set.reg-name...]\n        Retrieves register values for guest CPUs and emulated devices.\n      \nreg-set.reg-name\nOne of more registers, each having one of the following forms:register-set.register-name.sub-fieldregister-set.register-namecpu-register-name.sub-fieldcpu-register-nameallThe all form will cause all registers\n              to be shown (no sub-fields).  The registers names are case-insensitive.\n            \n--cpu=id\nSelects the CPU register set when specifying just a\n            CPU register (3rd and 4th form).  The default is 0.debugvm setregistersVBoxManage debugvm  <uuid|vmname>  setregisters  [--cpu=id] [reg-set.reg-name=value...]\n        Changes register values for guest CPUs and emulated devices.\n      \nreg-set.reg-name=value\nOne of more register assignment, each having one of the following forms:register-set.register-name.sub-field=valueregister-set.register-name=valuecpu-register-name.sub-field=valuecpu-register-name=valueThe value format should be in the same style as what\n              getregisters displays, with the exception that\n              both octal and decimal can be used instead of hexadecimal.\n--cpu=id\nSelects the CPU register set when specifying just a\n            CPU register (3rd and 4th form).  The default is 0.debugvm showVBoxManage debugvm  <uuid|vmname>  show  [[--human-readable] |  [--sh-export] |  [--sh-eval] |  [--cmd-set]] [settings-item...]\n        Shows logging settings for the VM.\n      \n--human-readable\nSelects human readable output.\n--sh-export\nSelects output format as bourne shell style export commands.\n--sh-eval\nSelects output format as bourne shell style eval command input.\n--cmd-set\nSelects output format as DOS style SET commands.\nsettings-item\nWhat to display. One or more of the following:logdbg-settings - debug log settings.logrel-settings - release log settings.log-settings - alias for both debug and release log settings.debugvm stackVBoxManage debugvm  <uuid|vmname>  stack  [--cpu=id]\n        Unwinds the guest CPU stacks to the best of our ability.  It is\n        recommended to first run the osdetect command, as this\n        gives both symbols and perhaps unwind information.\n      \n--cpu=id\nSelects a single guest CPU to display the stack for.  The default is all CPUs.debugvm statisticsVBoxManage debugvm  <uuid|vmname>  statistics  [--reset] [--descriptions] [--pattern=pattern]\n        Displays or resets VMM statistics.\n      \n        Retrieves register values for guest CPUs and emulated devices.\n      \n--pattern=pattern\nDOS/NT-style wildcards patterns for selecting statistics.  Multiple\n            patterns can be specified by using the '|' (pipe) character as separator.\n--reset\nSelect reset instead of display mode.8.44. VBoxManage cloudprofileManage the cloud profiles.SynopsisVBoxManage cloudprofile  <--provider=name> <--profile=name>  add  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  update  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  delete VBoxManage cloudprofile  <--provider=name> <--profile=name>  show DescriptionCommon optionsThe subcommands of cloudprofile implement the standard CRUD operations for a cloud profile.\n        The next common options must be placed between the \"cloud\" and  the following sub-commands:--provider=nameShort cloud provider name.--profile=nameCloud profile name. cloudprofile addVBoxManage cloudprofile  <--provider=name> <--profile=name>  add  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]\n        Add new cloud profile for a specified cloud provider.\n      \n--clouduser\nThe name which fully identifies the user in the specified cloud provider.\n--fingerprint\nFingerprint for the key pair being used.\n--keyfile\nFull path and filename of the private key. \n--passphrase\nPassphrase used for the key, if it is encrypted.\n--tenancy\nID of your tenancy. \n--compartment\nID of your compartment.\n--region\nRegion name. Region is where you plan to deploy an application.cloudprofile showVBoxManage cloudprofile  <--provider=name> <--profile=name>  show \n        Display information about a cloud profile for a specified cloud provider.\n      cloudprofile updateVBoxManage cloudprofile  <--provider=name> <--profile=name>  update  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]\n        Modify a cloud profile for the specified cloud provider.\n      \n--clouduser\nThe name which fully identifies the user in the specified cloud provider.\n--fingerprint\nFingerprint for the key pair being used.\n--keyfile\nFull path and filename of the private key. \n--passphrase\nPassphrase used for the key, if it is encrypted.\n--tenancy\nID of your tenancy. \n--compartment\nID of your compartment.\n--region\nRegion name. Region is where you plan to deploy an application.cloudprofile deleteVBoxManage cloudprofile  <--provider=name> <--profile=name>  delete \n        Delete a cloud profile for a specified cloud provider.\n      8.45. VBoxManage cloudManage the cloud entities.SynopsisVBoxManage cloud  <--provider=name> <--profile=name>  list   instances  [--state=string] [--compartment-id=string]VBoxManage cloud  <--provider=name> <--profile=name>  list   images  <--compartment-id=string> [--state=string]VBoxManage cloud  <--provider=name> <--profile=name>  instance   create  <--domain-name=name> <<--image-id=id> |  <--boot-volume-id=id>> <--display-name=name> <--shape=type> <--subnet=id> [--boot-disk-size=size in GB] [--publicip=true/false] [--privateip=IP address] [--public-ssh-key=key string...] [--launch-mode=NATIVE/EMULATED/PARAVIRTUALIZED]VBoxManage cloud  <--provider=name> <--profile=name>  instance   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   terminate  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   start  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   pause  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   create  <--display-name=name> [--bucket-name=name] [--object-name=name] [--instance-id=unique id]VBoxManage cloud  <--provider=name> <--profile=name>  image   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   delete  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   import  <--id=unique id> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  image   export  <--id=unique id> <--display-name=name> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  network setup  <--local-gateway-iso=path> [--gateway-os-name=string] [--gateway-os-version=string] [--gateway-shape=string] [--tunnel-network-name=string] [--tunnel-network-range=string] [--guest-additions-iso=path] [--proxy=string]VBoxManage cloud  <--provider=name> <--profile=name>  network create  <--name=string> <--network-id=string> [ --enable  |   --disable ]VBoxManage cloud network update  <--name=string> [--network-id=string] [ --enable  |   --disable ]VBoxManage cloud   network delete  <--name=string>VBoxManage cloud   network info  <--name=string>DescriptionCommon optionsThe word \"cloud\" is an umbrella for all commands related to the interconnection with the Cloud.\n        The next common options must be placed between the \"cloud\" and  the following sub-commands:--provider=nameShort cloud provider name.--profile=nameCloud profile name. cloud list instancesVBoxManage cloud  <--provider=name> <--profile=name>  list   instances  [--state=string] [--compartment-id=string]\n        Displays the list of the instances for a specified compartment.\n      --state\"running/paused/terminated\"The state of cloud instance. The possible states are \"running/paused/terminated\" at moment.\n            If the state isn't provided the list of instances with all possible states is returned.\n            \n--compartment-id\nA compartment is the logical container used to organize and isolate cloud resources.\n            The different cloud providers can have the different names for this entity.\n            cloud list imagesVBoxManage cloud  <--provider=name> <--profile=name>  list   images  <--compartment-id=string> [--state=string]\n        Displays the list of the images for a specified compartment.\n      --state\"available/disabled/deleted\"The state of cloud image. The possible states are \"available/disabled/deleted\" at moment.\n            If the state isn't provided the list of images with all possible states is returned.\n            \n--compartment-id\nA compartment is the logical container used to organize and isolate cloud resources.\n              The different cloud providers can have the different names for this entity.\n              cloud instance createVBoxManage cloud  <--provider=name> <--profile=name>  instance   create  <--domain-name=name> <<--image-id=id> |  <--boot-volume-id=id>> <--display-name=name> <--shape=type> <--subnet=id> [--boot-disk-size=size in GB] [--publicip=true/false] [--privateip=IP address] [--public-ssh-key=key string...] [--launch-mode=NATIVE/EMULATED/PARAVIRTUALIZED]\n        Creates new instance in the Cloud.\n        There are two standard ways to create an instance in the Cloud:\n         1. Create an instance from an existing custom image.\n         2. Create an instance from an existing bootable volume. This bootable volume shouldn't  be attached to any instance.\n        For the 1st approach next parameters are required: image-id and  boot-disk-size.\n        For the 2nd approach next parameters are required: boot-volume-id;\n        The rest parameters are common for both cases:\n         display-name, launch-mode, subnet-id, publicIP, privateIP, shape, domain.\n      \n--domain-name\nCloud domain where new instance is created.\n--image-id\nUnique identifier which fully identifies a custom image in the Cloud.\n--boot-volume-id\nUnique identifier which fully identifies a boot volume in the Cloud.\n--display-name\nName for new instance in the Cloud.\n--shape\n The shape of instance, defines the number of CPUs and RAM memory.\n--subnet\n Unique identifier which fully identifies an existing subnet in the Cloud which will be used by the instance.\n--boot-disk-size\n The size of bootable image in GB. Default is 50GB.\n--publicip\nWhether the instance will have a public IP or not.\n--privateip\nPrivate IP address for the created instance.\n--public-ssh-key\nPublic SSH key used to connect to the instance via SSH.\n                This parameter may be repeated if you plan to use more than one key as:\n                \"--public-ssh-key=firstSSHKey --public-ssh-key=secondSSHKey\".\n              \n--launch-mode\nThe most known values here may be EMULATED, NATIVE, PARAVIRTUALIZED. cloud instance info\n        Display information about a cloud instance with a specified id.\n      \n--id\nUnique identifier which fully identify the instance in the Cloud.cloud instance termination\n        Delete a cloud instance with a specified id.\n      \n--id\nUnique identifier which fully identify the instance in the Cloud.cloud instance start\n        Start a cloud instance with a specified id.\n      \n--id\nUnique identifier which fully identify the instance in the Cloud.cloud instance pause\n        Pause a cloud instance with a specified id.\n      \n--id\nUnique identifier which fully identify the instance in the Cloud.cloud image createVBoxManage cloud  <--provider=name> <--profile=name>  image   create  <--display-name=name> [--bucket-name=name] [--object-name=name] [--instance-id=unique id]\n        Creates new image in the Cloud.\n        There are two standard ways to create an image in the Cloud:\n        1. Create an image from an object in the Cloud Storage;\n        2. Create an image from an existing cloud instance.\n        For the 1st approach next parameters are required:\n        bucket-name - cloud bucket name where an object is located;\n        object-name - name of object in the bucket;\n        display-name - name for new image in the Cloud.\n        For the 2d approach next parameters are required:\n        instance-id - Id of instance in the Cloud;\n        display-name - name for new image in the Cloud.\n      \n--display-name\nName for new image in the Cloud.\n--bucket-name\nCloud bucket name where an object is located.\n--object-name\nName of object in the bucket.\n--instance-id\nUnique identifier which fully identifies the instance in the Cloud.cloud image infoVBoxManage cloud  <--provider=name> <--profile=name>  image   info  <--id=unique id>\n        Display information about a cloud image with a specified id.\n      \n--id\nUnique identifier which fully identifies the image in the Cloud.cloud image deleteVBoxManage cloud  <--provider=name> <--profile=name>  image   delete  <--id=unique id>\n        Delete an image with a specified id from the Cloud.\n      \n--id\nUnique identifier which fully identifies the image in the Cloud.cloud image importVBoxManage cloud  <--provider=name> <--profile=name>  image   import  <--id=unique id> [--bucket-name=name] [--object-name=name]\n        Import an image with a specified id from the Cloud to a local host.\n        The result is an object in the local \"temp\" folder on the local host.\n        Possible approach may have two general steps:\n        1. Create an object from an image in the Cloud Storage;\n        2. Download the object to the local host.\n        So the next parameters may be required:\n        bucket-name - cloud bucket name where the object will be created;\n        object-name - name of object in the bucket. if parameter \"object-name\" is absent a displayed image name is used.\n        If the first step isn't needed only the parameter \"id\" is required.\n      \n--id\nUnique identifier which fully identifies the image in the Cloud.\n--bucket-name\nCloud bucket name where an object will be created.\n--object-name\n\n                Name of created object in the bucket. The downloaded object will have this name.\n              cloud image exportVBoxManage cloud  <--provider=name> <--profile=name>  image   export  <--id=unique id> <--display-name=name> [--bucket-name=name] [--object-name=name]\n        Export an existing VBox image with a specified uuid from a local host to the Cloud.\n        The result is new image in the Cloud.\n        Possible approach may have two general steps:\n        1. Upload VBox image to the Cloud Storage;\n        2. Create an image from the uploaded object.\n        So the next parameters may be required:\n        bucket-name -cloud bucket name where the object will be uploaded;\n        object-name - name of object in the bucket. If parameter \"object-name\" is absent the image id is used;\n        display-name - name for new image in the Cloud.\n        If the first step isn't needed the parameters \"id\" and \"display-name\" are required only.\n      \n--id\nUnique identifier of the image in the VirtualBox.\n--display-name\nName for new image in the Cloud.\n--bucket-name\nCloud bucket name where the image (object) will be uploaded.\n--object-name\nName of object in the bucket.cloud network setupVBoxManage cloud  <--provider=name> <--profile=name>  network setup  <--local-gateway-iso=path> [--gateway-os-name=string] [--gateway-os-version=string] [--gateway-shape=string] [--tunnel-network-name=string] [--tunnel-network-range=string] [--guest-additions-iso=path] [--proxy=string]\n        Set up a cloud network environment for the specified cloud profile.\n      \n--local-gateway-iso\nThe local path to an installation media for a local gateway.\n--gateway-os-name\nThe name of OS to use for a cloud gateway.\n--gateway-os-version\nThe version of OS to use for a cloud gateway.\n--gateway-shape\nThe instance shape to use for a cloud gateway. \n--tunnel-network-name\nThe name of VCN/subnet to use for tunneling.\n--tunnel-network-range\nThe IP address range to use for tunneling. \n--guest-additions-iso\nThe local path to an installation media for VirtualBox guest additions.\n--proxy\nThe proxy URL to be used in local gateway installation.cloud network createVBoxManage cloud  <--provider=name> <--profile=name>  network create  <--name=string> <--network-id=string> [ --enable  |   --disable ]\n        Create a new cloud network descriptor associated with an existing cloud subnet.\n      \n--name\nThe name to assign to the cloud network descriptor.\n--network-id\nThe unique identifier of an existing subnet in the cloud.--enable, --disableWhether to enable the network descriptor or disable it.  If not specified,\n            the network will be enabled.cloud network updateVBoxManage cloud network update  <--name=string> [--network-id=string] [ --enable  |   --disable ]\n        Modify an existing cloud network descriptor.\n      \n--name\nThe name of an existing cloud network descriptor.\n--network-id\nThe unique identifier of an existing subnet in the cloud.--enable, --disableWhether to enable the network descriptor or disable it.cloud network deleteVBoxManage cloud   network delete  <--name=string>\n        Delete an existing cloud network descriptor.\n      \n--name\nThe name of an existing cloud network descriptor.cloud network infoVBoxManage cloud   network info  <--name=string>\n        Display information about a cloud network descriptor.\n      \n--name\nThe name of an existing cloud network descriptor.8.46. vboximg-mountFUSE mount a virtual disk image for Mac OS and Linux hosts.Synopsisvboximg-mount  < -?  |   -h  |   --help >vboximg-mount  <--image=image-UUID> [--guest-filesystem] [-o=FUSE-option[,FUSE-option]] [--root] [--rw] <mountpoint>vboximg-mount  <--list> [--image=image-UUID] [--guest-filesystem] [--verbose] [--vm=vm-UUID] [--wide]Description\n      The vboximg-mount command enables you to make\n      Oracle VM VirtualBox disk images available to a Mac OS or Linux host\n      operating system (OS) for privileged or non-priviliged access. You\n      can mount any version of the disk from its available history of\n      snapshots. Use this command to mount, view, and optionally modify\n      the contents of an Oracle VM VirtualBox virtual disk image, and you can\n      also use this command to view information about registered virtual\n      machines (VMs).\n    \n      This command uses the Filesystem in Userspace (FUSE) technology to\n      provide raw access to an Oracle VM VirtualBox virtual disk image.\n    \n      When you use the --image option to specify a base\n      image identifier, only the base image is mounted. Any related\n      snapshots are disregarded. Alternatively, if you use the\n      --image option to specify a snapshot, the state\n      of the FUSE-mounted virtual disk is synthesized from the implied\n      chain of snapshots, including the base image.\n    \n      The vboximg-mount command includes experimental\n      read-only access to file systems inside a VM disk image. This\n      feature enables you to extract some files from the VM disk image\n      without starting the VM and without requiring third-party file\n      system drivers on the host system. Oracle VM VirtualBox supports the\n      FAT, NTFS, ext2, ext3,\n      and ext4 file systems.\n    \n      The virtual disk is exposed as a device node within a FUSE-based\n      file system that overlays the specified mount point.\n    \n      The FUSE file system includes a directory that contains a number\n      of files. The file system can also contain a directory that\n      includes a symbolic link that has the same base name (see the\n      basename(1) man page) as the virtual disk base\n      image and points to the location of the virtual disk base image.\n      The directory can be of the following types:\n    vhdd provides access to the raw disk\n          image data as a flat image\n        volID provides\n          access to an individual volume on the specified disk image\n        fsID provides\n          access to a supported file system without requiring a host\n          file system driver\n        General Command Optionsvboximg-mount  < -?  |   -h  |   --help >\n        Use the following options to obtain information about the\n        vboximg-mount command and its options.\n      --help, --h, or--?\n              Shows usage information.\n            Mounting an Oracle VM VirtualBox Disk Imagevboximg-mount  <--image=image-UUID> [--guest-filesystem] [-o=FUSE-option[,FUSE-option]] [--root] [--rw] <mountpoint>\n        Use the vboximg-mount command to mount an\n        Oracle VM VirtualBox virtual disk image on a Mac OS or Linux host\n        system. When mounted, you can view the contents of the disk\n        image or modify the contents of the disk image.\n      \n        You can use the vboximg-mount command to\n        restrict FUSE-based access to a subsection of the virtual disk.\n      \n--image=disk-image\n\n              Specifies the Universally Unique Identifier (UUID), name,\n              or path of the Oracle VM VirtualBox disk image.\n            \n              The short form of the --image option is\n              -i.\n            \n--guest-filesystem\n\n              Enables experimental read-only support for guest file\n              systems. When you specify this option, all known file\n              systems are made available to access.\n            \n              The short form of the --guest-filesystem\n              option is -g.\n            \n-o=FUSE-option[,FUSE-option...]\n\n              Specifies FUSE mount options.\n            \n              The vboximg-mount command enables you\n              to use the FUSE mount options that are described in the\n              mount.fuse(8) man page.\n            \n--root\n\n              Overrides the security measure that restricts file access\n              to the file system owner by also granting file access to\n              the root user.\n            \n              Same as the -o allow_root option. See the\n              -o option description.\n            \n              This option is incompatible with the -o\n              allow_other option.\n            \n--rw\n\n              Mounts the specified image as read-write, which is\n              required if you want to modify its contents. By default,\n              images are mounted as read-only.\n            \nmount-point\n\n              Specifies the path name of a directory on which to mount\n              the Oracle VM VirtualBox disk image.\n            Viewing Oracle VM VirtualBox Disk Image Informationvboximg-mount  <--list> [--image=image-UUID] [--guest-filesystem] [--verbose] [--vm=vm-UUID] [--wide]\n        Use the vboximg-mount command to view\n        information about registered VMs or an Oracle VM VirtualBox virtual\n        disk image.\n      \n--image=disk-image\n\n              Specifies the UUID, name, or path of the Oracle VM VirtualBox\n              disk image.\n            \n              The short form of the --image option is\n              -i.\n            \n--guest-filesystem\n\n              Enables experimental read-only support for guest file\n              systems. When you specify this option, all known file\n              systems are made available to access.\n            \n              The short form of the --guest-filesystem\n              option is -g.\n            \n--list\n\n              Shows information about the disks that are associated with\n              the registered VMs. If you specify a disk image, this\n              option shows information about the partitions of the\n              specified image.\n            \n              When you specify the --verbose option,\n              the output includes detailed information about the VMs and\n              media, including snapshot images and file paths.\n            \n              The short form of the --list option is\n              -l.\n            \n--verbose\n\n              Shows or logs detailed information.\n            \n              The short form of the --verbose option is\n              -v.\n            \n--vm=vm-UUID\n\n              Outputs information about the VM that is associated with\n              the specified UUID.\n            \n--wide\n\n              Outputs information in a wide format. This output includes\n              the lock state information of running VMs. For VMs that\n              are not running, the state is created.\n            \n              The wide output uses a tree-like structure in the VM\n              column to show the relationship between a VM base image\n              and its snapshots.\n            Examples\n      The following example shows how to mount a virtual disk image on\n      the host operating system (OS).\n    $ mkdir fuse_mount_point\n$ vboximg-mount --image=b490e578-08be-4f7d-98e9-4c0ef0952377 fuse_mount_point\n$ ls fuse_mount_point\nubu.vdi[32256:2053029880]   vhdd\n$ sudo mount fuse_mount_point/vhdd /mnt\n      The mkdir command creates a mount point called\n      fuse_mount_point on the host OS. The\n      vboximg-mount command is then used to mount the\n      specified disk image on the fuse_mount_point\n      mount point. The mount includes all snapshots for the disk image.\n    \n      The ls command shows the contents of\n      fuse_mount_point. The\n      mount command is then used to mount the\n      FUSE-mounted device node, vhdd, on the\n      /mnt mount point. The vhdd\n      device node represents the virtual disk image.\n    \n      The following example shows how to make the known file systems of\n      the b490e578-08be-4f7d-98e9-4c0ef0952377 disk\n      image accessible when the image is mounted on the\n      fuse_mount_point mount point:\n    $ vboximg-mount --image=b490e578-08be-4f7d-98e9-4c0ef0952377 \\\n--guest-filesystem fuse_mount_point\n\n      The following command outputs detailed information about all\n      registered VMs and their snapshots:\n    $ vboximg-mount --list --verbose\n      The following command shows an excerpt of the list output in wide\n      format.\n    $ vboximg-mount --list --wide\n\nVM  Image                 Size Type State   UUID (hierarchy)\n------------------------------------------  ------------------------------------\nProxy                                       0833f5bc-6304-42e1-b799-cdc81c576c60\n |\n +- Proxy.vdi             4.8G VDI  rlock   d5f84afb-0794-4952-ab71-6bbcbee07737\n |  +- <snapshot>        12.3G VDI  rlock     dffc67aa-3023-477f-8033-b27e3daf4f54\n |  +- <snapshot>         8.8G VDI  rlock       3b2755bd-5f2a-4171-98fe-647d510b6274\n |  +- <snapshot>        14.6G VDI  rlock         e2ccdb5f-49e8-4123-8623-c61f363cc5cf\n |  +- <snapshot>         7.4G VDI  wlock           3c1e6794-9091-4be3-9e80-11aba40c2649\n\n------------------------------------------  ------------------------------------\nOracle Linux 7                              5365ab5f-470d-44c0-9863-dad532ee5905\n |\n +- Oracle Linux 7.vdi     7.0G VDI created 96d2e92e-0d4e-46ab-a0f1-008fdbf997e7\n | +- <snapshot>          15.9G VDI created   f9cc866a-9166-42e9-a503-bbfe9b7312e8\n |\n +- kernel.vdi            11.1G VDI created 79a370bd-0c4f-480a-30bb-10cdea68423f\n\n      The output shows that the Proxy VM is running the fourth snapshot\n      of the Proxy.vdi virtual disk image. The\n      running state is indicated by the wlock value\n      in the State column.\n    \n      The Oracle Linux 7 VM is not running. It has two images:\n      Oracle Linux 7.vdi and\n      kernel.vdi. The Oracle Linux\n      7.vdi image has a snapshot.\n    \n      The following command shows information about the VM with the\n      specified UUID:\n    \n$ vboximg-mount --list --vm=b1d5563b-2a5b-4013-89f1-26c81d6bbfa0\n-----------------------------------------------------------------\nVM:   ubu\nUUID: b1d5563b-2a5b-4013-89f1-26c81d6bbfa0\n\n  Image:   ubu.vdi\n  UUID:    b490e578-08be-4f7d-98e9-4c0ef0952377\n\n       Snapshot: 35afe1e0-0a51-44f3-a228-caf172f3306f\n       Size:     12.1G\n\n       Snapshot: 874279c1-4425-4282-ada8-a9c07c00bbf9\n       Size:     13.6G\n\n  Image:   kernel.vdi\n  UUID:    79a370bd-6eb7-4dbf-8bc6-d29118f127e0",
   "man_entry": "",
   "tldr_summary": "# VBoxManage\n\n> Command-line interface to VirtualBox.\n> Includes all the functionality of the GUI and more.\n> More information: <https://www.virtualbox.org/manual/ch08.html#vboxmanage-intro>.\n\n- List all VirtualBox virtual machines:\n\n`VBoxManage list vms`\n\n- Show information about a particular virtual machine:\n\n`VBoxManage showvminfo {{name|uuid}}`\n\n- Start a virtual machine:\n\n`VBoxManage startvm {{name|uuid}}`\n\n- Start a virtual machine in headless mode:\n\n`VBoxManage startvm {{name|uuid}} -type headless`\n\n- Shutdown the virtual machine and save its current state:\n\n`VBoxManage controlvm {{name|uuid}} savestate`\n\n- Shutdown down the virtual machine without saving its state:\n\n`VBoxManage controlvm {{name|uuid}} poweroff`\n\n- Update VBox extension packs:\n\n`VBoxManage extpack install --replace {{VboxExtensionPackFileName}}`\n"
 },
 {
   "command": "wine",
   "doc_url": "https://wiki.winehq.org/",
   "doc_text": "\n\n\nWineHQ Wiki\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n☰\n\nWineHQ\nWiki\nAppDB\nBugzilla\nForums\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nMain page\nDiscussion\nView source\nHistory \n\n\n\n\nMain Page\n\nFrom WineHQ Wiki\n\nJump to: navigation, search\n\nTranslations of this page:  Français  Deutsch  한국어 (Translators, please see Discussion page.)\n\nWine\nWine enables Linux, Mac, FreeBSD, and Solaris users to run Windows applications without a copy of Microsoft Windows. Wine is free software under constant development. Other platforms may benefit as well.\n\nMost popular links\nFrequently Asked Questions: If you're having a general problem with Wine, please read the FAQ!\nWine documentation: If the FAQ didn't help, try reading the manual! 😃\nThe Wine Application Database: For help with a particular app, look up its entry in the AppDB.\nWine Users support forum: For asking questions that you can't find an answer to in the above.\nKnown Issues: Check here before you report a bug.\nwinetricks: A useful tool for using common workarounds to current deficiencies in Wine.\nmacOS: Running Wine on macOS.\nAbout the Wine project\nA brief overview of Wine Features and goals.\nSome short articles about the Importance Of Wine.\nAn overview of Wine Project Organization.\nWho's Who in the Wine project, Acknowledgements for major contributors, and a list of all registered wiki homepages.\nThe history of the Wine project and recent News.\nInformation about Wine's Licensing.\nContribute\nUser support: Help users by answering questions on the User's Forum or IRC.\nDevelopers: If you want to help with Wine or build it from source.\nAppDB Maintainers: If you are (or want to become) an AppDB Maintainer.\nDebuggers can help by testing Wine and narrowing down problems, or help triage bugs reported by other users.\nWriters can contribute by documenting the program, maintaining the wiki, and translating various parts of the project.\nDesigners can, among other tasks, draw icons for programs, or improve the style and function of the website.\nWine Development Fund: Please consider making a donation to support the Wine project.\nWeb Content Tasks contains things you can do by merely editing this wiki.\nPublic Relations: ways to help spread the word about Wine.\nCategory:ToDo: A list of all ToDo items in the Wiki.\nOther useful links\nList of all pages in this wiki (useful for wiki editors).\nA List of Commands for all the little tools that come with Wine.\nThird Party Applications and \"unofficial\" tools that might come in handy.\nUseful Registry Keys and various settings for configuring Wine.\nInstructions for Regression Testing.\nApplications which officially test against Wine as a platform.\nMore information\nThe Wine project Source Code can be downloaded or browsed online.\nYou can browse archived discussions or subscribe to the Wine mailing lists.\nInformation on development progress and the status of Wine.\nAssorted files such as site icons and images, and database dumps of Bugzilla, AppDB, and the wiki can be downloaded from WineHQ's download server.\nView WineHQ site statistics and rough estimates of Wine's Usage Statistics.\n\n\n\n\nRetrieved from \"https://wiki.winehq.org/index.php?title=Main_Page&oldid=3166\"\n \n\n\n\n\n\n\nNavigation\n\n\nMain page\nRecent changes\nRandom page\nHelp about MediaWiki\n\n\n\n\nTools\n\n\nWhat links here\nRelated changes\nSpecial pages\nPrintable version\nPermanent link\nPage information\n\n\n\n\nPersonal Menu\n\n\nCreate accountLog in \n\n\n\n\n\n\n\n\n This page was last edited on 15 January 2019, at 10:46.\nPrivacy policy\nAbout WineHQ Wiki\nDisclaimers\n\n\n\n\n                Hosted By\n                    \n\n",
   "man_entry": "",
   "tldr_summary": "# wine\n\n> Run Windows programs on Unix.\n> More information: <https://wiki.winehq.org/>.\n\n- Run ipconfig.exe program:\n\n`wine {{ipconfig}} {{/all}}`\n\n- Run cmd.exe in background:\n\n`wine start {{cmd}}`\n\n- Run Windows-like Package Manager:\n\n`wine uninstaller`\n\n- Install MSI packages:\n\n`wine msiexec /i {{package}}`\n"
 },
 {
   "command": "fatlabel",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# fatlabel\n\n> Sets or gets the label of a FAT32 partition.\n\n- Get the label of a FAT32 partition:\n\n`fatlabel {{/dev/sda1}}`\n\n- Set the label of a FAT32 partition:\n\n`fatlabel {{/dev/sdc3}} \"{{new_label}}\"`\n"
 },
 {
   "command": "line",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# line\n\n> Read a single line of input.\n\n- Read input:\n\n`line`\n"
 },
 {
   "command": "daemonize",
   "doc_url": "http://software.clapper.org/daemonize/",
   "doc_text": "\n\n\ndaemonize — A tool to run a command as a daemon\n\n\n\n\n\n\n\n\ndaemonize — A tool to run a command as a daemon\n\n\n\nHome\nCode\nOther Software\n\n\n\n\n\n\nTable of Contents\n\n\nIntroduction\ndaemonize runs a command as a Unix daemon. As defined in W. Richard\nStevens’ 1990 book, UNIX Network Programming (Addison-Wesley, 1990),\na daemon is “a process that executes ‘in the background’ (i.e., without an\nassociated terminal or login shell) either waiting for some event to occur,\nor waiting to perform some specified task on a periodic basis.” Upon\nstartup, a typical daemon program will:\n\nClose all open file descriptors (especially standard input, standard\noutput and standard error)\nChange its working directory to the root filesystem, to ensure that it\ndoesn’t tie up another filesystem and prevent it from being unmounted\nReset its umask value\nRun in the background (i.e., fork)\nDisassociate from its process group (usually a shell), to insulate itself\nfrom signals (such as HUP) sent to the process group\nIgnore all terminal I/O signals\nDisassociate from the control terminal (and take steps not to reacquire one)\nHandle any SIGCLD signals\n\nMost programs that are designed to be run as daemons do that work for\nthemselves. However, you’ll occasionally run across one that does not. When\nyou must run a daemon program that does not properly make itself into a\ntrue Unix daemon, you can use daemonize to force it to run as a true\ndaemon.\nSee the man page for full details.\nNotes\n\n\nIf the host operating system provides the daemon(3) library routine,\ndaemonize will use it. Otherwise, daemonize uses its own version of\ndaemon(3). This choice is made at compile time. (BSD 4.4-derived\noperating systems tend to provide their own daemon(3) routine.)\n\n\nFreeBSD 5.0 introduced a daemon(1) command that is similar to, but\nless functional, than daemonize.\n\n\nGetting daemonize\ndaemonize is written in C. Given the number of Unix-like operating\nsystems, and the number of releases of each, it is impractical for me to\nprovide binaries of daemonize for every combination of Unix-like\noperating system and operating system release.\nIf you’re on a Mac, you can use homebrew\nto instsall daemonize, like so:\n$ brew install daemonize\n\nIf you’re on any other Unix-like operating system, you must build\ndaemonize from source code, as described below.\nThere are two ways to get the source code:\nDownload a release zip\nYou can download a release zip file, containing the source, from the\nreleases page. Just unzip the file to unpack the source\ndirectory.\nClone the Git repository\nYou can also simply clone the git repository, using one of the following\ncommands.\n$ git clone git://github.com/bmc/daemonize.git\n$ git clone http://github.com/bmc/daemonize.git\n\nInstallation\nOnce you’ve unpacked the source, change your working directory to the\ndaemonize directory. From there, building and installing the code is\nfairly typical:\n$ sh configure\n$ make\n$ sudo make install\n\nFor a detailed report of the available configure options:\n$ sh configure --help\n\nNotes\nI have personally compiled and tested daemonize on the following platforms:\n\nFreeBSD 4.x, 8.0-RELEASE, 8.1-RELEASE and 8.2-RELEASE\nRed Hat Enterprise Linux 4 / CentOS 4\nSolaris (SunOS 5.8, 5.10)\nFedora Core 5\nUbuntu 8 through 15\nMac OS X 10.4 (Tiger) and 10.6 through 10.11.\n\nThe accompanying “configure” script was generated with GNU autoconf\nversion 2.69. It should work, as is, for most Unix systems.\nChange Log\nSee the daemonize Change Log for a description of the changes in\neach version.\nAuthor\nBrian Clapper, bmc@clapper.org\nWeb Page\n\nHome Page\nGitHub repo\n\nLicense\nWith the exception of the install-sh script and the getopt.c source,\nthis software is released under BSD license. See the license for details.\nCopyright\nWith the exception of the “install-sh” script and the “getopt.c” source,\nthis software is copyright 2003-2015, Brian M. Clapper\nPatches\nI gladly accept patches from their original authors. Feel free to email\npatches to me or to fork the GitHub repository and send me a\npull request. Along with any patch you send:\n\nPlease state that the patch is your original work.\nPlease indicate that you license the work to the daemonize\nproject under a BSD License.\n\n\n\n\n",
   "man_entry": "",
   "tldr_summary": "# daemonize\n\n> Run a command (that does not daemonize itself) as a Unix daemon.\n> More information: <http://software.clapper.org/daemonize/>.\n\n- Run a command as a daemon:\n\n`daemonize {{command}} {{command_arguments}}`\n\n- Write the pid to the specified file:\n\n`daemonize -p {{path/to/pidfile}} {{command}} {{command_arguments}}`\n\n- Use a lock file to ensure that only one instance runs at a time:\n\n`daemonize -l {{path/to/lockfile}} {{command}} {{command_arguments}}`\n\n- Use the specified user account:\n\n`sudo daemonize -u {{user}} {{command}} {{command_arguments}}`\n"
 },
 {
   "command": "modprobe",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# modprobe\n\n> Add or remove modules from the Linux kernel.\n\n- Pretend to load a module into the kernel, but don't actually do it:\n\n`sudo modprobe --dry-run {{module_name}}`\n\n- Load a module into the kernel:\n\n`sudo modprobe {{module_name}}`\n\n- Remove a module from the kernel:\n\n`sudo modprobe --remove {{module_name}}`\n\n- Remove a module and those that depend on it from the kernel:\n\n`sudo modprobe --remove-dependencies {{module_name}}`\n\n- Show a kernel module's dependencies:\n\n`sudo modprobe --show-depends {{module_name}}`\n"
 },
 {
   "command": "mkisofs",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# mkisofs\n\n> Create ISO files from directories.\n> Also aliased as `genisoimage`.\n\n- Create an ISO from a directory:\n\n`mkisofs -o {{filename.iso}} {{path/to/source_directory}}`\n\n- Set the disc label when creating an ISO:\n\n`mkisofs -o {{filename.iso}} -V {{\"label_name\"}} {{path/to/source_directory}}`\n"
 },
 {
   "command": "fcrackzip",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# fcrackzip\n\n> ZIP archive password cracking utility.\n\n- Brute-force a password with a length of 4 to 8 characters, and contains only alphanumeric characters (order matters):\n\n`fcrackzip --brute-force --length 4-8 --charset aA1 {{archive}}`\n\n- Brute-force a password in verbose mode with a length of 3 characters that only contains lowercase characters, `$` and `%`:\n\n`fcrackzip -v --brute-force --length 3 --charset a:$% {{archive}}`\n\n- Brute-force a password that contains only lowercase and special characters:\n\n`fcrackzip --brute-force --length 4 --charset a! {{archive}}`\n\n- Brute-force a password containing only digits, starting from the password `12345`:\n\n`fcrackzip --brute-force --length 5 --charset 1 --init-password 12345 {{archive}}`\n\n- Crack a password using a wordlist:\n\n`fcrackzip --use-unzip --dictionary --init-password {{wordlist}} {{archive}}`\n\n- Benchmark cracking performance:\n\n`fcrackzip --benchmark`\n"
 },
 {
   "command": "gpasswd",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# gpasswd\n\n> Administer \"/etc/group\" and \"/etc/gshadow\".\n\n- Define group administrators:\n\n`sudo gpasswd -A {{user1,user2}} {{group}}`\n\n- Set the list of group members:\n\n`sudo gpasswd -M {{user1,user2}} {{group}}`\n\n- Create a password for the named group:\n\n`gpasswd {{group}}`\n\n- Add a user to the named group:\n\n`gpasswd -a {{user}} {{group}}`\n\n- Remove a user from the named group:\n\n`gpasswd -d {{user}} {{group}}`\n"
 },
 {
   "command": "slapt-get",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# slapt-get\n\n> An apt like system for Slackware package management.\n> Package sources need to be configured in the slapt-getrc file.\n\n- Update the list of available packages and versions:\n\n`slapt-get --update`\n\n- Install a package, or update it to the latest available version:\n\n`slapt-get --install {{package_name}}`\n\n- Remove a package:\n\n`slapt-get --remove {{package_name}}`\n\n- Upgrade all installed packages to their latest available versions:\n\n`slapt-get --upgrade {{package_name}}`\n\n- Locate packages of interest by the package name, disk set, or version:\n\n`slapt-get --search {{package_name}}`\n\n- Show information about a package:\n\n`slapt-get --show {{package_name}}`\n"
 },
 {
   "command": "quotacheck",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "\nQUOTACHECK(8)\t\t  BSD System Manager's Manual\t\t QUOTACHECK(8)\n\nNAME\n     quotacheck -- filesystem quota consistency checker\n\nSYNOPSIS\n     quotacheck [-g] [-u] [-v] filesystem ...\n     quotacheck [-g] [-u] [-v] -a\n\nDESCRIPTION\n     Quotacheck examines each filesystem, builds a table of current disk\n     usage, and compares this table against that recorded in the disk quota\n     file for the filesystem.  If any inconsistencies are detected, both the\n     quota file and the current system copy of the incorrect quotas are\n     updated (the latter only occurs if an active filesystem is checked).  By\n     default both user and group quotas are checked.\n\n     Available options:\n\n     -a      If the -a flag is supplied in place of any filesystem names,\n\t     quotacheck will check all the read-write filesystems with an\n\t     existing mount option file at its root.  The mount option file\n\t     specifies the types of quotas that are to be checked.\n\n     -g      Only group quotas are checked. The mount option file,\n\t     .quota.ops.group, must exist at the root of the filesystem.\n\n     -u      Only user quotas are checked.  The mount option file,\n\t     .quota.ops.user, must exist at the root of the filesystem.\n\n     -v      quotacheck reports discrepancies between the calculated and\n\t     recorded disk quotas.\n\n     Specifying both -g and -u is equivalent to the default.  Parallel passes\n     are run on the filesystems required, in an identical fashion to fsck(8).\n\n     Normally quotacheck operates silently.\n\n     Quotacheck expects each filesystem being checked to have quota data files\n     named .quota.user and/or .quota.group located at the filesystem root.  If\n     a binary data file is not present, quotacheck will create it.  The\n     default filename and root location cannot be overridden.\n\n     Quotacheck is normally run at fsck time.\n\n     Quotacheck accesses the raw device in calculating the actual disk usage\n     for each user.  Thus, the filesystems checked should be quiescent while\n     quotacheck is running.\n\nFILES\n     Each of the following quota files is located at the root of the mounted\n     filesystem.  The mount option files are empty files whose existence indi-\n     cates that quotas are to be enabled for that filesystem. The binary data\n     files will be created by quotacheck, if they don't already exist.\n\n     .quota.user       data file containing user quotas\n     .quota.group      data file containing group quotas\n     .quota.ops.user   mount option file used to enable user quotas\n     .quota.ops.group  mount option file used to enable group quotas\n\nSEE ALSO\n     quota(1), quotactl(2), edquota(8), fsck(8), quotaon(8), repquota(8)\n\nHISTORY\n     The quotacheck command appeared in 4.2BSD.\n\n4.2 Berkeley Distribution      October 17, 2002      4.2 Berkeley Distribution\n",
   "tldr_summary": "# quotacheck\n\n> Scan a filesystem for disk usage; create, check and repair quota files.\n> It is best to run quota check with quotas turned off to prevent damage or loss to quota files.\n\n- Check quotas on all mounted non-NFS filesystems:\n\n`sudo quotacheck --all`\n\n- Force check even if quotas are enabled (this can cause damage or loss to quota files):\n\n`sudo quotacheck --force {{mountpoint}}`\n\n- Check quotas on a given filesystem in debug mode:\n\n`sudo quotacheck --debug {{mountpoint}}`\n\n- Check quotas on a given filesystem, displaying the progress:\n\n`sudo quotacheck --verbose {{mountpoint}}`\n\n- Check user quotas:\n\n`sudo quotacheck --user {{user}} {{mountpoint}}`\n\n- Check group quotas:\n\n`sudo quotacheck --group {{group}} {{mountpoint}}`\n"
 },
 {
   "command": "datamash",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# datamash\n\n> Tool to perform basic numeric, textual and statistical operations on input textual data files.\n\n- Get max, min, mean and median of a single column of numbers:\n\n`seq 3 | datamash max 1 min 1 mean 1 median 1`\n\n- Get the mean of a single column of float numbers (floats must use \",\" and not \".\"):\n\n`echo -e '1.0\\n2.5\\n3.1\\n4.3\\n5.6\\n5.7' | tr '.' ',' | datamash mean 1`\n\n- Get the mean of a single column of numbers with a given decimal precision:\n\n`echo -e '1\\n2\\n3\\n4\\n5\\n5' | datamash -R {{number_of_decimals_wanted}} mean 1`\n\n- Get the mean of a single column of numbers ignoring \"Na\" and \"NaN\" (literal) strings:\n\n`echo -e '1\\n2\\nNa\\n3\\nNaN' | datamash --narm mean 1`\n"
 },
 {
   "command": "bmon",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# bmon\n\n> Monitor bandwidth and capture network related statistics.\n\n- Display the list of all the interfaces:\n\n`bmon -a`\n\n- Display data transfer rates in bits per second:\n\n`bmon -b`\n\n- Set policy to define which network interface(s) is/are displayed:\n\n`bmon -p {{interface_1,interface_2,interface_3}}`\n\n- Set interval (in seconds) in which rate per counter is calculated:\n\n`bmon -R {{2.0}}`\n"
 },
 {
   "command": "eix",
   "doc_url": "",
   "doc_text": "",
   "man_entry": "",
   "tldr_summary": "# eix\n\n> Utilities for searching local Gentoo packages.\n> Update local package cache using `eix-update`.\n\n- Search for a package:\n\n`eix {{package_name}}`\n\n- Search for installed packages:\n\n`eix --installed {{package_name}}`\n\n- Seach in package descriptions:\n\n`eix --description \"{{description}}\"`\n\n- Seach by package license:\n\n`eix --license {{license}}`\n\n- Exclude results from search:\n\n`eix --not --license {{license}}`\n"
 }
]